[
    {
        "id": "Geopolitical hot takes.md",
        "name": "Geopolitical hot takes",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- **United States:**\n\t- **Strengths:** Strong economy, decreasing inflation, high employment, rising consumer confidence, significant investment in physical technologies (e.g., electric vehicle charging stations) and AI.\n\t- **Concerns:** Rising federal debt, high healthcare spending, potential negative supply shocks from decoupling from China and trade disruptions.\n\t- **Opportunities:** Implement industrial policy, restrain healthcare spending growth, raise taxes, increase science spending.\n\t- **Outlook:** Potential era of austerity similar to the 1990s, with inflation potentially averaging around 3% over the next decade.\n- **China:**\n\t- **Problems:** Massive property bust leading to insolvency in banks, developers, and local governments. Overreliance on manufacturing to drive growth, potentially leading to overcapacity and trade wars. Demographic decline due to an aging population and low birth rates.\n\t- **Faults:** Discouragement of service sector growth and overinvestment in unproductive infrastructure. Reliance on cheap exports, potentially leading to international trade barriers.\n\t- **Opportunities:** Implement property taxes, prioritize high-quality growth through innovation and productivity improvements, address demographic challenges through policies encouraging longer working lives and increased college graduation rates.\n\t- **Outlook:** Economic slowdown and potential trade wars. Debt levels may reach levels similar to Japan. Unlikely to experience an economic implosion, but will likely see lower growth rates due to demographic challenges.\n- **Japan:**\n\t- **Strengths:** Key hub for electronics manufacturing with potential for growth due to decoupling from China. Efficient permitting processes and ease of distributing subsidies make it attractive for foreign investment in chip fabrication plants. Improving relations with South Korea.\n\t- **Problems:** Long-standing demographic issues despite rising fertility rates. Broken corporate culture hinders promotion of young and dynamic talent.\n\t- **Opportunities:** Implement industrial policy to reclaim its position as a major electronics manufacturer, address corporate culture issues, increase immigration.\n\t- **Outlook:** Potential for economic growth due to increased foreign investment and opportunities in the electronics manufacturing sector. Demographic decline will continue to exert a drag on the economy, but automation may mitigate the impact.\n- **South Korea:**\n\t- **Strengths:** Strong technological capabilities, potential to benefit from decoupling from China and increased demand from other countries.\n\t- **Problems:** Critically low fertility rate, high consumer debt, gender divide in politics, and challenges to its manufacturing sector due to China's efforts to reduce reliance on Korean suppliers.\n\t- **Opportunities:** Increase immigration, strengthen integration with non-China East Asian economies, and address social issues contributing to low birth rate.\n\t- **Outlook:** Despite current struggles, South Korea has the potential for future growth due to its technological capabilities and opportunities presented by shifting global supply chains.\n- **Taiwan:**\n\t- **Strengths:** Dominant position in the semiconductor industry with companies like TSMC.\n\t- **Challenges:** Overreliance on small businesses, vulnerability to pressure from China due to economic ties and the risk of war, potential need to decouple from China.\n\t- **Opportunities:** Diversify its economy beyond small businesses and reduce reliance on China.\n\t- **Outlook:** Uncertain future due to political tensions with China and potential disruptions to its economy.\n- **Indonesia:**\n\t- **Strengths:** Potential to transition back to a manufacturing economy.\n\t- **Problems:** Overreliance on mining and natural resources.\n\t- **Opportunities:** Embrace decoupling from China and become an alternative manufacturing hub, strengthen relations with Japan and South Korea.\n\t- **Outlook:** Potential for growth if it can successfully transition to a manufacturing economy and leverage opportunities presented by decoupling from China.\n- **Vietnam:**\n\t- **Strengths:** Success in attracting foreign direct investment and becoming a manufacturing center, particularly for Samsung.\n\t- **Challenges:** Need to upgrade its higher education system and develop larger domestic businesses.\n\t- **Opportunities:** Invest in higher education and foster the growth of larger businesses to reach near-developed status.\n\t- **Outlook:** Positive outlook for growth if it can address its challenges in education and business development.\n- **India:**\n\t- **Strengths:** Successful poverty reduction, particularly in rural areas. Massive investments in infrastructure.\n\t- **Challenges:** Need to improve the business climate for foreign direct investment, address low female education and workforce participation rates.\n\t- **Opportunities:** Leverage its large population and low labor costs to become a hub for labor-intensive manufacturing, while also developing higher-tech industries.\n\t- **Outlook:** Positive outlook for economic growth if it can address challenges related to foreign investment and female workforce participation.\n- **Pakistan:**\n\t- **Problems:** Economic mismanagement, overconsumption, high levels of debt, political instability, high crime rates, and reliance on international life support.\n\t- **Faults:** Focus on military conflict with India instead of economic development, lack of investment in infrastructure and education.\n\t- **Opportunities:** Prioritize economic development, invest in infrastructure and education, improve tax collection, and reduce crime rates.\n\t- **Outlook:** Bleak outlook unless significant changes are made to address economic mismanagement and political instability.\n- **Philippines:**\n\t- **Strengths:** Underrated as an investment destination for light manufacturing, experiencing decent economic growth, improved political stability.\n\t- **Opportunities:** Attract more foreign direct investment in manufacturing.\n\t- **Outlook:** Positive outlook for economic growth and stability.\n- **Australia:**\n\t- **Strengths:** Successful resource-based economy with a high standard of living, progressive social policies, and a well-educated population.\n\t- **Concerns:** Vulnerability to fluctuations in global demand for minerals.\n\t- **Opportunities:** Continue to diversify its economy beyond resource extraction.\n\t- **Outlook:** Generally positive outlook, but economic performance will be tied to global commodity prices.\n- **United Kingdom:**\n\t- **Problems:** Stagnant productivity and wage growth, difficulties in building infrastructure due to regulations, negative impacts of Brexit, overreliance on the finance industry.\n\t- **Faults:** Political class out of touch with economic realities, domestic culture wars distracting from economic issues, prevalence of degrowth ideology.\n\t- **Opportunities:** Prioritize economic growth, address barriers to construction and infrastructure development, increase research spending, and focus on exports.\n\t- **Outlook:** Negative outlook with continued stagnation unless significant policy changes are made to promote growth.\n- **France:**\n\t- **Strengths:** Strong nuclear power infrastructure providing energy security, taking a diplomatic lead in Europe.\n\t- **Concerns:** Chaotic society with frequent protests and social unrest, rigid labor market regulations hindering economic dynamism.\n\t- **Opportunities:** Leverage its leadership role in Europe to promote progrowth economic policies, reform labor market regulations, address social unrest.\n\t- **Outlook:** Generally positive outlook due to energy security and leadership potential in Europe, but social and economic reforms are needed for sustained growth.\n- **Germany:**\n\t- **Problems:** Overreliance on trust leading to economic vulnerabilities (e.g., dependence on Russian gas, exploitation by Chinese companies), cultural aversion to nationalism hindering strong leadership, commitment to austerity hindering necessary investments.\n\t- **Faults:** Naivety in trusting other countries, allowing political ideology to hinder economic pragmatism (e.g., shutting down nuclear plants).\n\t- **Opportunities:** Develop a stronger sense of national identity and economic self-interest, invest in domestic energy production and infrastructure, and adopt a more flexible approach to fiscal policy.\n\t- **Outlook:** Uncertain outlook. Germany needs to address its cultural and political challenges to overcome its current economic stagnation.\n- **Italy:**\n\t- **Problems:** Stagnant and declining economy.\n\t- **Faults:** Unclear. Further analysis is needed to understand the root causes of Italy's economic problems.\n\t- **Opportunities:** Unclear. Further analysis is needed to identify potential solutions to Italy's economic challenges.\n\t- **Outlook:** Negative outlook with continued economic decline unless the root causes of stagnation are addressed.\n- **Poland:**\n\t- **Strengths:** Successful economic growth driven by foreign direct investment and manufacturing exports, improved institutions due to EU membership, good education policies, strong commitment to defense spending.\n\t- **Concerns:** Aging population and emigration of skilled workers.\n\t- **Opportunities:** Continue to attract foreign investment and develop its manufacturing sector, address demographic challenges through immigration and policies supporting families.\n\t- **Outlook:** Positive outlook for continued economic growth and development, potentially reaching income levels comparable to Western European countries.\n- **Egypt:**\n\t- **Challenges:** Large population with limited resources, water scarcity, economic dependence on the Suez Canal, and vulnerability to regional instability.\n\t- **Opportunities:** Invest in solar power and manufacturing, particularly along the coast, and seek closer economic integration with Europe.\n\t- **Outlook:** Significant challenges, but potential for growth if it can diversify its economy and address resource limitations.\n- **Saudi Arabia:**\n\t- **Challenges:** Stagnant economic growth despite oil wealth, declining importance as an oil producer due to global competition and the rise of electric vehicles, large and potentially restive population.\n\t- **Opportunities:** Diversify its economy away from oil dependence, invest in technology and innovation, and continue gradual social reforms.\n\t- **Outlook:** Facing significant economic challenges due to its reliance on oil. The success of its diversification efforts will determine its future prosperity.\n- **Africa (General):**\n\t- **Strengths:** Rapid population growth and a young workforce, abundant natural resources.\n\t- **Challenges:** Poverty, political instability, ethnic divisions, resource curse, and lack of infrastructure and education in many countries.\n\t- **Opportunities:** Develop labor-intensive manufacturing industries, attract foreign direct investment, improve governance and institutions, invest in education and infrastructure.\n\t- **Outlook:** Africa's future will depend on its ability to address its numerous challenges and harness its demographic and resource potential. Some countries show promise, but others face significant obstacles to development.\n- **Mexico:**\n\t- **Strengths:** Large manufacturing sector integrated with the US economy.\n\t- **Challenges:** Endemic violence and insecurity due to drug cartels, hindering economic growth and development.\n\t- **Opportunities:** Address the security situation to create a more stable environment for businesses and investment.\n\t- **Outlook:** Mexico's economic potential is hampered by its security problems. Until the violence is addressed, significant growth is unlikely.\n- **Brazil:**\n\t- **Strengths:** Large population, some successful examples of industrial policy (e.g., Embraer), progress in reducing inequality.\n\t- **Challenges:** Resource curse leading to Dutch disease, political instability, and unattractive leadership options.\n\t- **Opportunities:** Develop additional high-value export industries beyond resource extraction, address political and economic challenges to foster a more stable and dynamic economy.\n\t- **Outlook:** Mixed outlook. Brazil has the potential to be a major manufacturing hub in South America, but it needs to overcome significant challenges to realize this potential.\n- **Colombia:**\n\t- **Strengths:** Improving security situation, proximity to the US, potential for economic growth.\n\t- **Opportunities:** Attract foreign investment and develop its manufacturing and service sectors.\n\t- **Outlook:** Positive outlook for economic growth and development.\n- **Dominican Republic:**\n\t- **Strengths:** Strong economic growth, stable political environment, diverse economy with manufacturing, finance, and tourism sectors.\n\t- **Opportunities:** Continue to attract foreign investment and diversify its economy.\n\t- **Outlook:** Positive outlook for continued economic growth and development.\n- **Haiti:**\n\t- **Challenges:** Extreme poverty, environmental degradation, political instability, and violence, including the presence of cannibal gangs.\n\t- **Opportunities:** Requires significant international intervention to establish basic security and stability before economic development can occur.\n\t- **Outlook:** Bleak outlook without major international intervention.\n- **Canada:**\n\t- **Challenges:** Economic stagnation, overreliance on resource extraction, high levels of emigration of skilled workers, NIMBYism hindering development.\n\t- **Opportunities:** Diversify its economy beyond resource extraction, encourage innovation and technology development, address NIMBYism through policies such as those empowering First Nations to develop housing.\n\t- **Outlook:** Canada's economic future depends on its ability to diversify its economy and retain its skilled workforce.",
        "link_types": [],
        "file_size": 15425
    },
    {
        "id": "ChatGPT.md",
        "name": "ChatGPT",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- TODO This is historically one of the oldest sections of the knowledge graph and it shows. Needs sorting [[MUST 🔴]]\n- # GPT-4o (Omni)\n\t- The latest iteration in OpenAI's series of generative language models, offers a wide range of advanced capabilities.\n\t- Use of the powerful model is free. Around 7% of Americans use the model daily.\n\t- ### Key Capabilities of GPT-4o\n\t\t- **Visual Analysis for Education**\n\t\t\t- **Description**: GPT-4o can visually analyze math problems, objects for language translation, paintings for historical context, and products for online reviews. This feature provides detailed and contextual explanations, enhancing the learning experience.\n\t\t\t- **Use Case**: Integration with augmented reality devices like Meta Rayban glasses to offer real-time educational support for students, language learners, and hobbyists.\n\t\t- **Teams Meeting Assistant**\n\t\t\t- **Description**: GPT-4o functions as an AI assistant during Microsoft Teams meetings, capable of summarizing minutes, identifying action items, retrieving relevant information from company databases, and assisting with data analysis tasks such as creating charts and reporting trends.\n\t\t\t- **Use Case**: Improves meeting productivity by handling administrative tasks and providing insights during discussions.\n\t\t- **Advanced Language Translation**\n\t\t\t- **Description**: GPT-4o offers advanced language translation capabilities, capturing conversational context and intonation for more natural and accurate translations.\n\t\t\t- **Use Case**: Facilitates real-time multilingual conversations, potentially integrating with devices like AirPods to break down language barriers in personal and professional interactions.\n\t\t- **Screen Sharing for Coding Assistance**\n\t\t\t- **Description**: Allows users to share their screens with GPT-4o for real-time guidance on coding tasks, debugging, and other technical work, including non-programming tasks like Excel analysis and PowerPoint creation.\n\t\t\t- **Use Case**: Provides on-the-spot assistance for professionals across various fields, enhancing productivity and efficiency.\n\t\t- **AI Interactions**\n\t\t\t- **Description**: Demonstrates the ability of two GPT-4o instances to interact seamlessly, including having conversations and performing tasks together, such as singing.\n\t\t\t- **Use Case**: Paves the way for AI influencers on social media platforms and collaborative AI systems that can work together across different domains and data sets.\n\t\t- **AI Pet Training**\n\t\t\t- **Description**: Utilizes vision capabilities to assist in training pets by connecting to smart devices like treat dispensers, observing and responding to a pet's behavior to provide real-time guidance and training.\n\t\t\t- **Use Case**: Helps pet owners train their animals more effectively and ensure consistent training routines.\n\t\t- **Dual AI Brainstorming**\n\t\t\t- **Description**: Allows users to engage with two distinct GPT-4o personalities simultaneously for dynamic and comprehensive brainstorming sessions.\n\t\t\t- **Use Case**: Facilitates creative problem-solving by offering balanced insights from different viewpoints, such as optimistic vs. pessimistic perspectives.\n\t\t- **Accessibility for the Visually Impaired**\n\t\t\t- **Description**: Interprets and describes visual inputs from devices like Meta Rayban glasses, helping visually impaired individuals navigate their surroundings and identify objects.\n\t\t\t- **Use Case**: Enhances independence by providing real-time descriptions of the environment, such as distinguishing between different objects.\n\t\t- **Text to 3D Conversion**\n\t\t\t- **Description**: Converts textual descriptions into detailed 3D models, enabling users to visualize concepts and objects described in text.\n\t\t\t- **Use Case**: Useful for designers, architects, educators, and others needing to create or understand complex three-dimensional structures from written descriptions.\n\t\t- **Enhanced Emotional Intelligence**\n\t\t\t- **Description**: Understands and responds to emotional cues in text and speech more effectively, providing empathetic and contextually appropriate responses.\n\t\t\t- **Use Case**: Improves interactions in customer service, therapy, and personal assistance by addressing the emotional needs of users.\n\t\t- **Advanced Personalization**\n\t\t\t- **Description**: Customizes interactions based on individual user preferences, history, and behavior, ensuring relevant recommendations and assistance.\n\t\t\t- **Use Case**: Enhances the overall user experience in applications such as learning, entertainment, and daily tasks.\n\t\t- **Real-Time Multimodal Interaction**\n\t\t\t- **Description**: Integrates text, voice, and visual inputs to provide a seamless and interactive user experience.\n\t\t\t- **Use Case**: Ideal for virtual assistants, interactive learning platforms, and customer service applications where users can engage using multiple forms of input simultaneously.\n- ## AI Development and Innovations\n\t- ### Showcases of Advanced GPT Models and Workflows\n\t\t- **Advanced GPTs on GitHub**: A collection of custom GPTs featuring advanced workflows and operational logic ([GitHub Repository](https://github.com/nerority/Advanced-GPTs)).\n\t- ### Open-Source ChatGPT Equivalents and UI Enhancements\n\t\t- **Mintplex-Labs on GitHub**: An open-source ChatGPT equivalent experience for both open and closed source LLMs, embedders, and vector databases, supporting unlimited documents and users ([GitHub Repository](https://github.com/Mintplex-Labs/anything-llm)).\n\t\t- **mckaywrigley/chatbot-ui on GitHub**: An open-source ChatGPT UI ([GitHub Repository](https://github.com/mckaywrigley/chatbot-ui)).\n\t- ### Integration of GPT with Other AI Technologies\n\t\t- **Stable Diffusion, Whisper, and GPT-3 Combination**: A developer's project combining these technologies to create a futuristic design assistant ([The Decoder Article](https://the-decoder.com/developer-combines-stable-diffusion-whisper-and-gpt-3-for-a-futuristic-design-assistant)).\n\t- ### Self-Improvement of GPT Models\n\t\t- **GPT-4 Can Improve Itself**: Featuring Reflexion, HuggingGPT, Bard Upgrade, and more ([YouTube Video](https://youtu.be/5SgJKZLBrmg)).\n\t- ## AI Tools and Extensions\n\t\t- ### Browser Extensions for Enhancing ChatGPT\n\t\t\t- **AIPRM for ChatGPT**: A browser extension that adds various enhancements to ChatGPT ([Chrome Web Store](https://chrome.google.com/webstore/detail/aiprm-for-chatgpt/ojnbohmppadfgpejeebfnmnknjdlckgj)).\n\t\t- ### AI-Driven Content Creation and Manipulation Tools\n\t\t\t- **3D-GPT in Blender**: Generates 3D worlds in Blender using GPT ([The Decoder Article](https://the-decoder.com/3d-gpt-generates-3d-worlds-in-blender)).\n\t- **Writing Stable Diffusion Prompts with GPT**: Using GPT to write prompts for Stable Diffusion ([Dreamlike Guide](https://dreamlike.art/guides/using-openai-chat-gpt-to-write-stable-diffusion-prompts)).\n\t- ## AI Ethics and Security\n\t\t- ### Discussions on AI-Generated Content\n\t\t\t- **AI-Generated Fake News**: Concerns about AI making up fake news articles ([The Guardian Article](https://www.theguardian.com/commentisfree/2023/apr/06/ai-chatgpt-guardian-technology-risks-fake-article)).\n\t\t- ### Security and Privacy Concerns\n\t\t\t- **AI Model Hacking**: Discussions on potential security breaches and privacy issues with AI models ([Reddit Discussion](https://old.reddit.com/r/ChatGPT/comments/11wkw5z/has_chatgpt_or_me_been_hacked_ive_never_had_these)).\n\t- ## Educational Content and Tutorials\n\t\t- ### Creating Your Own AI Models and Bots\n\t\t\t- **Custom ChatGPT Bots**: Tutorials on creating your own ChatGPT chatbot with business content ([CustomGPT.ai](https://customgpt.ai/)).\n\t\t\t- **GPT Voice Assistant**: Guide on creating a GPT voice assistant with infinite chat memory in Python ([Medium Article](https://medium.com/@jordanlgibbs/how-to-create-your-own-gpt-voice-assistant-with-infinite-chat-memory-in-python-d8b8e93f6b21)).\n\t\t- ## AI in Media and Entertainment\n\t\t\t- ### AI in Broadcasting and Content Creation\n\t\t\t\t- **RadioGPT**: The world’s first AI-driven radio station ([Interesting Engineering Article](https://interestingengineering.com/innovation/radiogpt-worlds-first-ai-radio-station)).\n\t\t\t- ### Podcasts and Interviews on AI\n\t\t\t\t- **Code Interpreter and GPT 4.5**: Discussions on the advancements and implications of these technologies ([Spotify Podcast](https://open.spotify.com/episode/0sFi0yG6kpTVKE0WVtRhTZ?si=te1jwhxCTWa-kJWwq3RxCA)).\n\t\t- ## AI Models and Technical Discussions\n\t\t\t- ### New AI Model Releases\n\t\t\t\t- **GPT4-x-Alpaca-13B-Native-4bit-128g**: Technical discussions on the new model and its capabilities ([GitHub Discussion](https://github.com/oobabooga/text-generation-webui/discussions/727)).\n\t\t\t- ### Deep Dives into GPT Model Capabilities\n\t\t\t\t- **GPTZero Case Study**: Exploring the false positives in GPT model detections ([Gonzo Knows Article](https://gonzoknows.com/posts/GPTZero-Case-Study)).\n-\n- # Unsorted Links\n- A bunch more GPTs [nerority/Advanced-GPTs: Showcase of my custom GPTs, featuring advanced workflows and operational logic. (github.com)](https://github.com/nerority/Advanced-GPTs)\n- [AIPRM for ChatGPT](https://chrome.google.com/webstore/detail/aiprm-for-chatgpt/ojnbohmppadfgpejeebfnmnknjdlckgj)\n-\n- [Code Interpreter == GPT 4.5 (w/ Simon Willison, Alex Volkov, Aravind Srinivas, Alex Graveley, et al.)](https://open.spotify.com/episode/0sFi0yG6kpTVKE0WVtRhTZ?si=te1jwhxCTWa-kJWwq3RxCA%22)\n- [Create Your Own ChatGPT ChatBOT With ALL Your Business Content](https://customgpt.ai/)\n-\n- [GPTZero Case Study (Exploring False Positives)](https://gonzoknows.com/posts/GPTZero-Case-Study/%22)\n- [Has ChatGPT or me been hacked? Ive never had these conversations..](https://old.reddit.com/r/ChatGPT/comments/11wkw5z/has_chatgpt_or_me_been_hacked_ive_never_had_these)\n- [How to Create Your Own GPT Voice Assistant with Infinite Chat Memory in Python](https://medium.com/@jordanlgibbs/how-to-create-your-own-gpt-voice-assistant-with-infinite-chat-memory-in-python-d8b8e93f6b21)\n- [Introducing ChatGPT](https://openai.com/blog/chatgpt)\n- [March | 2023 | Ars Technica](https://arstechnica.com/information-technology/2023/03/you-can-now-run-a-gpt-3-level-ai-model-on-your-laptop-phone-and-raspberry-pi/%7D%7Barticle)\n- [Mintplex-Labs/anything-llm: Open-source ChatGPT equivalent experience for both open and close source LLMs, embedders, and vector databases. Supports unlimited documents, threads, and concurrent users and management all in a very clean UI.](https://github.com/Mintplex-Labs/anything-llm)\n- [New model: gpt4-x-alpaca-13b-native-4bit-128g !! · oobabooga text-generation-webui · Discussion #727](https://github.com/oobabooga/text-generation-webui/discussions/727%7D%7BAnonymous)\n- [RadioGPT: 'World’s first' AI-driven radio station is here](https://interestingengineering.com/innovation/radiogpt-worlds-first-ai-radio-station)\n- [Scientists begin building AI for scientific discovery using tech behind ChatGPT](https://techxplore.com/news/2023-10-scientists-ai-scientific-discovery-tech.html)\n- [State of GPT | BRK216HFS](https://www.youtube.com/watch?v=bZQun8Y4L2A%22%3E)\n- [THE DECODER](https://the-decoder.com/developer-combines-stable-diffusion-whisper-and-gpt-3-for-a-futuristic-design-assistant/%7D%7BVoice)\n- [TheBloke/starchat-beta-GPTQ · Hugging Face](https://huggingface.co/TheBloke/starchat-beta-GPTQ)\n- [Using openai chat gpt to write stable diffusion prompts%22](https://dreamlike.art/guides/using-openai-chat-gpt-to-write-stable-diffusion-prompts%22)\n- [Using openai chat gpt to write stable diffusion prompts%7 d%7 btrain](https://dreamlike.art/guides/using-openai-chat-gpt-to-write-stable-diffusion-prompts%7D%7Btrain)\n- [What is ChatGPT? | OpenAI Help Center](https://help.openai.com/en/articles/6783457-chatgpt-general-faq%7D%7Bexplicit)\n- [Yhyu13/30B-Lazarus-gptq-4bit at main](https://huggingface.co/Yhyu13/30B-Lazarus-gptq-4bit/tree/main)\n- [Zain Kahn on LinkedIn: 1,000+ AI tools were released in March. ChatGPT is just the tip of the… | 345 comments](https://www.linkedin.com/posts/zainkahn_1000-ai-tools-were-released-in-march-activity-7048285306101358592-4wAA?amp%3Butm_medium=member_android%22%2F%3E)\n- [mckaywrigley/chatbot-ui: An open source ChatGPT UI.](https://github.com/mckaywrigley/chatbot-ui)\n- [sahil280114/chatGPT-multimodal-bot](https://github.com/sahil280114/chatGPT-multimodal-bot)\n- [ztjhz/BetterChatGPT](https://github.com/ztjhz/BetterChatGPT)\n- [#215 – Wojciech Zaremba: OpenAI Codex, GPT-3, Robotics, and the Future of AI](https://open.spotify.com/episode/6pIHwP4wxd9xYZAxvMS6I2?dl_branch=1&si=d41LWZ6CSWmbucGf-AasPQ)\n- [#367 – Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI](https://open.spotify.com/episode/6rAOusZcsuNtCv8mefmwND?nd=1&si=3a17aef004df4982)\n- [3D-GPT generates 3D worlds in Blender](https://the-decoder.com/3d-gpt-generates-3d-worlds-in-blender)\n- [6 Ways ChatGPT Code Interpreter Is Already Being Used](https://www.youtube.com/watch?v=1MM2nqVw8h8)\n- [Can GPT-3 AI write comedy?](https://robmanuelfuckyeah.substack.com/p/someone-needs-to-stop-me-playing)\n- [Carlos E. Perez on Twitter / X](https://twitter.com/IntuitMachine/status/1608690077139599360%7D%7Bchatgpt)\n- [ChatGPT political compass](https://www.gptoverflow.link/question/1519492600837443584/chatgpt-political-compass%7D%7Bpolitical)\n- [Code Interpreter == GPT 4.5 (w/ Simon Willison, Alex Volkov, Aravind Srinivas, Alex Graveley, et al.)](https://open.spotify.com/episode/0sFi0yG6kpTVKE0WVtRhTZ?si=te1jwhxCTWa-kJWwq3RxCA%22)\n- [Developer combines Stable Diffusion, Whisper and GPT-3 for a futuristic design assistant](https://the-decoder.com/developer-combines-stable-diffusion-whisper-and-gpt-3-for-a-futuristic-design-assistant)\n- [George Hotz: Tiny Corp, Twitter, AI Safety, Self-Driving, GPT, AGI & God | Lex Fridman Podcast #387](https://youtu.be/dNrTrx42DGQ?si=V6VtK4zWgeHbS8CP)\n- [Introducing GPT-Furr, Cat-GPT’s meowst sassy, all-knowing system.](https://www.cat-gpt.com/)\n- [Microsoft just announced a SURPRISE media event taking place tomorrow](https://www.windowscentral.com/microsoft/microsoft-surprise-event-chatgpt-openai-bing-2023)\n- [Narrative Manipulation: Convincing Chat GPT to Write a Python Program to Eradicate Humanity](https://zacdenham.com/blog/narrative-manipulation-convincing-gpt-chat-to-write-a-python-program-to-eradicate-humanity)\n- [New model: gpt4-x-alpaca-13b-native-4bit-128g !! · oobabooga text-generation-webui · Discussion #727](https://github.com/oobabooga/text-generation-webui/discussions/727%22)\n- [New model: gpt4-x-alpaca-13b-native-4bit-128g !! · oobabooga text-generation-webui · Discussion #727](https://github.com/oobabooga/text-generation-webui/discussions/727%7D%7BAnonymous)\n- [Prompt injection attacks against GPT-3](https://simonwillison.net/2022/Sep/12/prompt-injection)\n- [Sam Altman: OpenAI CEO on GPT-4, ChatGPT, and the Future of AI | Lex Fridman Podcast #367](https://m.youtube.com/watch?feature=youtu.be%7D%7BSam&v=L_Guz73e6fw%5C)\n- [Stack Overflow bans ChatGPT as 'substantially harmful'](https://www.theregister.com/2022/12/05/stack_overflow_bans_chatgpt)\n- [Stephen Wolfram Answers Live Questions About ChatGPT](https://youtu.be/zLnhg9kir3Q%7D%7BStephen)\n- [Using openai chat gpt to write stable diffusion prompts%22](https://dreamlike.art/guides/using-openai-chat-gpt-to-write-stable-diffusion-prompts%22)\n- [Using openai chat gpt to write stable diffusion prompts%7 d%7 btrain](https://dreamlike.art/guides/using-openai-chat-gpt-to-write-stable-diffusion-prompts%7D%7Btrain)\n- [What is Auto-GPT? | Blog](https://stablecog.com/blog/what-is-auto-gpt)\n- [You can now run a GPT-3-level AI model on your laptop, phone, and Raspberry Pi](https://arstechnica.com/information-technology/2023/03/you-can-now-run-a-gpt-3-level-ai-model-on-your-laptop-phone-and-raspberry-pi/%22)\n- [sahil280114/chatGPT-multimodal-bot](https://github.com/sahil280114/chatGPT-multimodal-bot)\n-",
        "link_types": [
            "MUST 🔴"
        ],
        "file_size": 15936
    },
    {
        "id": "Human tracking and SLAM capture.md",
        "name": "Human tracking and SLAM capture",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n- Tracking and Capture\n\t- Physical Tracking\n\t\t- [CoTracker: It is Better to Track Together (co-tracker.github.io)](https://co-tracker.github.io/)\n\t\t- [Lens Studio (snap.com)](https://ar.snap.com/lens-studio)\n\t\t- Pose estimations [Standable](https://www.standablevr.com/)\n\t\t- [ScoreHMR (statho.github.io)](https://statho.github.io/ScoreHMR/)\n\t\t- Fast bounding [Kroery/DiffMOT: code for CVPR2024 paper: DiffMOT: A Real-time Diffusion-based Multiple Object Tracker with Non-linear Prediction (github.com)](https://github.com/Kroery/DiffMOT)\n\t- Emotion and remote biometric monitoring\n\t\t- emotion tracking\n\t\t- [laion empathetic](https://dct.openempathic.ai/guide/#:~:text=Rating%20Arousal%20and%20Valence%3A)\n\t\t- [Dense face fields from Microsoft](https://microsoft.github.io/DenseLandmarks/)\n\t- Ethics and Safety\n\t\t- The article discusses the potential risks and opportunities of motion tracking data in extended reality (XR) and the metaverse. While this data is often presumed to be innocuous, recent studies have shown that it has the potential to profile and deanonymize XR users, posing a significant threat to security and privacy in the metaverse. The article highlights the need for increased awareness and caution regarding the collection and use of motion data in XR and metaverse experiences. https://arxiv.org/abs/2306.06459\n- # Interfacing\n\t- https://www.linkedin.com/posts/dennyskuhnert_applevisionpro-metaquest3-handtracking-activity-7165761977531711490-R-XD?\n\t- ![video.mp4](../assets/video_1708453959982_0.mp4)\n-",
        "link_types": [],
        "file_size": 1583
    },
    {
        "id": "Safety and alignment.md",
        "name": "Safety and alignment",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- What used to be called bias whet I was doing postgrad Machine Learning (2020) is now called [[Safety and alignment]].\n\t- Bias\n\t\t- [[2309.17012] Benchmarking Cognitive Biases in Large Language Models as Evaluators (arxiv.org)](https://arxiv.org/abs/2309.17012)\n\t\t- [[confusion matrices]](https://en.wikipedia.org/wiki/Confusion_matrix)\n\t\t- [Responsible Capability Scaling \\ Anthropic](https://www.anthropic.com/uk-government-internal-ai-safety-policy-response/responsible-capability-scaling)\n- # Dense summary of the moment\n\t- This is an excellent blog post which enumerates important points. Samuel Hammond presents a collection of concise statements covering a wide range of topics related to the current state and future implications of artificial intelligence. The theses highlight the potential impacts of AI on society, the importance of AI safety and alignment, and the role of AI in shaping humanity's future. Hammond emphasizes the need for monitoring frontier AI capabilities, discusses the debate between open and closed source AI, and explores the potential for AI to disrupt existing institutions and power balances.\n\t\t- <iframe src=\"https://www.secondbest.ca/p/ninety-five-theses-on-ai\" style=\"width: 100%; height: 800px\"></iframe>\n- ## March 2024 Gladstone USA Report\n\t- Commissioned by the U.S. government, this report underscores the potential for artificial intelligence to pose substantial national security risks, including the possibility of an extinction-level threat.\n\t\t- **Gladstone's Role and Perspective**\n\t\t\t- **Engagement with the U.S. Government**: Since 2021, Gladstone, led by the Harris brothers, has briefed the U.S. government on AI risks.\n\t\t\t- **Contract Award**: Gladstone was selected to produce the report, emphasizing the firm's deep involvement in shaping the discourse on AI safety.\n\t\t- [Action Plan to increase the safety and security of advanced AI (gladstone.ai)](https://www.gladstone.ai/action-plan)\n\t\t- **Essential Findings from the Report**\n\t\t\t- **Risk Assessment**: The development of current frontier AI technology presents \"urgent and growing risks to national security.\"\n\t\t\t- **Historical Parallel**: The destabilizing potential of advanced AI and AGI is likened to the advent of nuclear weapons, suggesting profound global security implications.\n\t\t\t- **Weapons of Mass Destruction**: Advances in AI are creating \"entirely new categories\" of WMDs, emphasizing the unprecedented nature of these risks.\n\t\t\t- **Competitive Pressures**: A significant driver of these risks is identified as the competitive dynamic among leading AI labs, highlighting a rush towards developing advanced AI systems despite acknowledged dangers.\n\t\t- **Proposed Action Plan**\n\t\t\t- **Title of Plan**: \"Defense in Depth: An Action Plan to Increase the Safety and Security of Advanced AI\"\n\t\t\t- **Core Strategies**:\n\t\t\t\t- Introduction of interim safeguards to stabilize AI development.\n\t\t\t\t- Creation of a framework for basic regulatory oversight.\n\t\t\t\t- Establishment of a domestic legal regime for responsible AI development and adoption.\n\t\t\t\t- Extension of regulatory measures to international cooperation and standards.\n\t\t\t- **Specific Recommendations from the Report**\n\t\t\t\t- Proposes a limit on the computing power used for AI model training.\n\t\t\t\t- Suggests the formation of a new federal AI agency to oversee critical thresholds and regulatory compliance.\n\t\t\t\t- Recommends considering the prohibition of the publication of the inner workings of powerful AI models.\n\t\t\t\t- Advocates for stricter controls over the manufacture and export of AI chips and increased funding towards alignment research for safer AI.\n\t\t- **Support from AI Safety Advocates**: The report’s urgent tone and recommendations found resonance among AI safety advocates.\n\t\t- **Skepticism from Critics**: Some viewed the report as overly alarmist, with criticisms ranging from dismissive to mocking the idea of government superiority in AI management.\n\t\t- The discourse surrounding the government-commissioned AI report reflects a broad spectrum of opinions, underscoring the complexity of AI's impact on society and the necessity for informed, multifaceted policy approaches.\n- ## What the researchers think (feels and vibes)\n\t- ![](https://jnnnthnn.com/leike.png)\n\t- A survey of 2778 AI researchers, to assess the pace of AI progress and the broader societal implications. The increased participation in this third iteration points to growing importance and concern surrounding AI in the scientific community.\n\t- Most of the 39 tasks will likely be feasible within the next ten years, showcasing AI's anticipated versatility and rapid advancement. It's cheaper, so it will likely become ubiquitous without a new [[Social contract and jobs]] initiative.\n\t- Median prediction indicates a 50% chance of achieving High-Level Machine Intelligence by 2047 and Full Automation of Labour, by 2116\n\t- Strong hints of potential differences in technological development speeds, cultural attitudes, or economic motivations across regions. This suggests incoming legislative arbitrage.\n\t\t- [EU’s new AI Act risks hampering innovation, warns Emmanuel Macron (ft.com)](https://www.ft.com/content/9339d104-7b0c-42b8-9316-72226dd4e4c0)\n\t\t- [Japan Goes All In: Copyright Doesn't Apply To AI Training | News | Communications of the ACM](https://cacm.acm.org/news/273479-japan-goes-all-in-copyright-doesnt-apply-to-ai-training/fulltext#:~:text=In%20a%20surprising%20move%2C%20Japan%27s%20government%20recently%20reaffirmed,is%20content%20obtained%20from%20illegal%20sites%20or%20otherwise.%22)\n\t\t- [China’s plan to judge the safety of generative AI | MIT Technology Review](https://www.technologyreview.com/2023/10/18/1081846/generative-ai-safety-censorship-china/)\n\t- Broad agreement exists on some future AI traits, like finding unexpected ways to achieve goals, but significant uncertainty remains, especially for traits with sinister implications.\n\t- Scepticism exists about future AI systems' ability to provide intelligible and truthful explanations of decisions, posing challenges for risk management and bias mitigation.\n\t- Researchers express substantial concern for various AI-related scenarios, particularly the spread of false information and manipulation of public opinion.\n\t- A considerable fraction of respondents attribute a non-trivial probability to AI leading to human extinction or severe disempowerment.\n- ## Stats from the report\n\t- **Over 95%** concerned about:\n\t\t- Dangerous groups using AI for engineered viruses.\n\t\t- AI manipulating large-scale public opinion.\n\t\t- AI spreading false information.\n\t- **Over 90%** concerned about:\n\t\t- Authoritarian rulers using AI for control.\n\t\t- AI worsening economic inequality.\n\t\t- Bias in AI, e.g., gender or race discrimination.\n\t- **Over 80%** concerned about:\n\t\t- Misaligned AI goals leading to catastrophic outcomes.\n\t\t- Reduced human interaction due to AI.\n\t\t- Automation leading to widespread economic disempowerment.\n\t- **Over 70%** concerned about automation causing a loss of meaning in life.\n\t- **Only 20%** confident in understanding AI \"thinking\" by 2028.\n\t- Researchers emphasize safety and alignment as priority (10:1 margin).\n\t- **58%** see at least a **5% chance of AI ending humanity**.\n\t- Risk of severe disempowerment of human species at **16.2%** (comparable to Russian Roulette).\n\t- **10% chance by 2027** and **50% chance by 2047** for AI to outperform humans in every task, **13 years sooner** than previous estimates.\n- [Thousands_of_AI_authors_on_the_future_of_AI.pdf (aiimpacts.org)](https://aiimpacts.org/wp-content/uploads/2023/04/Thousands_of_AI_authors_on_the_future_of_AI.pdf)\n- ![image.png](../assets/image_1704446789913_0.png){:width 800, :height 684}\n- # Disallowed uses\n\t- [Usage policies (openai.com)](https://openai.com/policies/usage-policies)\n\t  id:: 659e5627-97e4-40f9-84fa-128b35f7f920\n\t- Illegal activity\n\t\t- OpenAI prohibits the use of our models, tools, and services for illegal activity.\n\t- Child Sexual Abuse Material or any content that exploits or harms children\n\t\t- We report CSAM to the National Center for Missing and Exploited Children.\n\t- Generation of hateful, harassing, or violent content\n\t\t- Content that expresses, incites, or promotes hate based on identity\n\t\t- Content that intends to harass, threaten, or bully an individual\n\t\t- Content that promotes or glorifies violence or celebrates the suffering or humiliation of others\n\t- Generation of malware\n\t\t- Content that attempts to generate code that is designed to disrupt, damage, or gain unauthorized access to a computer system.\n\t- Activity that has high risk of physical harm, including:\n\t\t- Weapons development\n\t\t- Military and warfare\n\t\t- Management or operation of critical infrastructure in energy, transportation, and water\n\t\t- Content that promotes, encourages, or depicts acts of self-harm, such as suicide, cutting, and eating disorders\n\t- Activity that has high risk of economic harm, including:\n\t\t- Multi-level marketing\n\t\t- Gambling\n\t\t- Payday lending\n\t\t- Automated determinations of eligibility for credit, employment, educational institutions, or public assistance services\n\t- Fraudulent or deceptive activity, including:\n\t\t- Scams\n\t\t- Coordinated inauthentic behavior\n\t\t- Plagiarism\n\t\t- Academic dishonesty\n\t\t- Astroturfing, such as fake grassroots support or fake review generation\n\t\t- Disinformation\n\t\t- Spam\n\t\t- Pseudo-pharmaceuticals\n\t- Adult content, adult industries, and dating apps, including:\n\t\t- Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education and wellness)\n\t\t- Erotic chat\n\t\t- Pornography\n\t- Political campaigning or lobbying, by:\n\t\t- Generating high volumes of campaign materials\n\t\t- Generating campaign materials personalized to or targeted at specific demographics\n\t\t- Building conversational or interactive systems such as chatbots that provide information about campaigns or engage in political advocacy or lobbying\n\t\t- Building products for political campaigning or lobbying purposes\n\t- Activity that violates people’s privacy, including:\n\t\t- Tracking or monitoring an individual without their consent\n\t\t- Facial recognition of private individuals\n\t\t- Classifying individuals based on protected characteristics\n\t\t- Using biometrics for identification or assessment\n\t\t- Unlawful collection or disclosure of personal identifiable information or educational, financial, or other protected records\n\t- Engaging in the unauthorized practice of law, or offering tailored legal advice without a qualified person reviewing the information\n\t\t- OpenAI’s models are not fine-tuned to provide legal advice. You should not rely on our models as a sole source of legal advice.\n\t- Offering tailored financial advice without a qualified person reviewing the information\n\t\t- OpenAI’s models are not fine-tuned to provide financial advice. You should not rely on our models as a sole source of financial advice.\n\t- Telling someone that they have or do not have a certain health condition, or providing instructions on how to cure or treat a health condition\n\t\t- OpenAI’s models are not fine-tuned to provide medical information. You should never use our models to provide diagnostic or treatment services for serious medical conditions.\n\t\t- OpenAI’s platforms should not be used to triage or manage life-threatening issues that need immediate attention.\n\t- High risk government decision-making, including:\n\t\t- Law enforcement and criminal justice\n\t\t- Migration and asylum\n- ## Jailbreaking\n\t- {{embed ((661d5f7f-e2b4-4f0b-931a-3590c52f1e34))}}\n\t- {{embed ((661e41bc-42da-4bbd-a1c9-32892bd2d43a))}}\n\t- # Kill Switches?\n\t\t- ```In situations where AI systems pose catastrophic risks, it could be beneficial for regulators to verify that a set of AI chips are operated legitimately or to disable their operation (or a subset of it) if they violate rules.```\n\t\t\t- <iframe src=\"https://www.cser.ac.uk/media/uploads/files/Computing-Power-and-the-Governance-of-AI.pdf\" style=\"width: 100%; height: 600px\"></iframe>",
        "link_types": [
            "Safety and alignment",
            "confusion matrices",
            "Social contract and jobs"
        ],
        "file_size": 12102
    },
    {
        "id": "Humans, Avatars , Character.md",
        "name": "Humans, Avatars , Character",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ## Avatar Generation:\n- [REPLIKANT | AI-Assisted 3D Avatar & Animation Platform for Creators](https://www.replikant.com/): AI-assisted 3D avatar and animation platform for creators.\n- [Meta research paper](https://drive.google.com/file/d/1i4NJKAggS82wqMamCJ1OHRGgViuyoY6R/view): Research paper on avatar generation.\n- ## Face Generation:\n\t- [Media2Face (google.com)](https://sites.google.com/view/media2face): Website for Media2Face, a project related to face generation. [Towards a Simultaneous and Granular Identity-Expression Control in Personalized Face Generation](https://diffsfsr.github.io/): Research page on personalized face generation.\n\t- [Paper page\n\t\t- HeadStudio: Text to Animatable Head Avatars with 3D Gaussian Splatting (huggingface.co)](https://huggingface.co/papers/2402.06149): Paper page on the HeadStudio project for 3D head avatars.\n\t- Lip sync\n\t\t- [VASA-1 - Microsoft Research](https://www.microsoft.com/en-us/research/project/vasa-1/)\n\t\t- [wav2lips](https://becominghuman.ai/deepfake-audio-with-wav2lip-263f0f0e84bc)\n\t\t- [Realtime lip-sync API](https://getsynchronicity.io/)\n- ## Body Generation:\n\t- [Volumetric primitives (MVP) avatar representation of Lombardi et al. [2021].](https://dl.acm.org/doi/abs/10.1145/3528233.3530740): Research paper on volumetric primitives avatar representation.\n\t- [Gaussian Shell Maps for Efficient 3D Human Generation (rameenabdal.github.io)](https://rameenabdal.github.io/GaussianShellMaps/): Research page on Gaussian Shell Maps for 3D human generation.\n\t- [En3D (menyifang.github.io)](https://menyifang.github.io/projects/En3D/index.html): Page on the En3D project, which focuses on 3D human generation.\n- ## Hand Generation:\n\t- [URHand (frozenburning.github.io)](https://frozenburning.github.io/projects/urhand/): Page on the URHand project, which involves hand generation.\n- ## Audio-Driven Avatar:\n\t- [facebookresearch/audio2photoreal: Code and dataset for photorealistic Codec Avatars driven from audio (github.com)](https://github.com/facebookresearch/audio2photoreal): GitHub repository for audio-driven avatars.\n- ## Human Texture Estimation:\n\t- Human texture estimation from a single image [SMPLitex: A Generative Model and Dataset for 3D Human Texture Estimation from Single Image (BMVC 2023) (dancasas.github.io)](https://dancasas.github.io/projects/SMPLitex/index.html): Research paper on human texture estimation from a single image.\n- Miscellaneous:\n\t- [StableIdentity: Inserting Anybody into Anywhere at First Sight (qinghew.github.io)](https://qinghew.github.io/StableIdentity/): Page on StableIdentity, a project related to inserting anybody into anywhere at first sight.\n\t- [What You See Is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs (nvidia.com)](https://research.nvidia.com/labs/nxp/wysiwyg/): Research paper on rendering high-fidelity geometry in 3D GANs.\n\t- [Manu.Vision • Futurist on X: \"Generating consistent characters is now finally possible! I break down the full process in 4 easy steps in this thread (full tutorial with AI prompts and screenshots): https://t.co/ApLm4IjyTj\" / X (twitter.com)]\n\t- (https://twitter.com/manuvision/status/1745326572154863816?): Tweet discussing the process of generating consistent characters.\n\t- [Tutorial  Consistent Characters with Scenario (youtube.com)](https://www.youtube.com/watch?v=aEnDEraK3I8): YouTube tutorial on creating consistent characters with scenario.\n\t- [EricGuo5513/momask-codes: Official implementation of \"MoMask: Generative Masked Modeling of 3D Human Motions\" (github.com)](https://github.com/EricGuo5513/momask-codes): GitHub repository for the official implementation of MoMask, a generative masked modeling of 3D human motions.\n\t- [(1) I made a Character Asset Creator (ComfyUI backend) : StableDiffusion (reddit.com)](https://www.reddit.com/r/StableDiffusion/comments/19aymjf/i_made_a_character_asset_creator_comfyui_backend/): Reddit post about a Character Asset Creator for StableDiffusion.\n\t- [https://rentry.org/mikugg-emotions-script](https://rentry.org/mikugg-emotions-script): Script for creating emotions in Mikugg\n\t- [https://docs.miku.gg/guides/bots/create-bot-emotions/](https://docs.miku.gg/guides/bots/create-bot-emotions/): Documentation on creating bot emotions in Miku.\n\t- [Workflow\n\t\t- Consistant Character Maker\n\t\t- v2.0 | Stable Diffusion Workflows | Civitai](https://civitai.com/models/287147/workflow-consistant-character-maker): Workflow for creating consistent characters using the Stable Diffusion model.\n- ## Character Consistency\n\t- I want to work it to get a character I like. Then I NEED: to be able to get that SAME character, totally consistant, from different viewpoints. High Fidelity.\n\t- Then its..... 1. Better voice to mouth stuff\n\t- 2. Environment and character can be treated seperate, but hte blending/compositing is super hard from an abstraction pov\n\t- 3. Animation\n- ### A [workflow](https://www.linkedin.com/posts/lovis-odin-7a751360_how-to-create-this-3d-animation-for-free-activity-7179810196922257409-8PcO?utm_source=share&utm_medium=member_desktop)\n\t- 1- Generate an image of character using the prompt \"[SUBJECT], T-Pose 3D, full body\" in @midjourney or other 2- Generate your 3D character using [https://tripo3d.ai](https://tripo3d.ai/) from @tripoai , export in custom preset \"Cinema 4D\" 3\n\t\t- Generate PBR texture using [https://lnkd.in/gBvGH_PH](https://lnkd.in/gBvGH_PH) from @AiDigimans 4- Animate it using [https://mixamo.com](https://mixamo.com/) from @Adobe 5- Integrate your model and texture into [https://spline.design](https://spline.design/) from @splinetool and make it cool !\n\t-\n- ## Animation\n\t- [lizhe00/AnimatableGaussians: Code of [CVPR 2024] \"Animatable Gaussians: Learning Pose-dependent Gaussian Maps for High-fidelity Human Avatar Modeling\" (github.com)](https://github.com/lizhe00/AnimatableGaussians/tree/master)\n\t-",
        "link_types": [],
        "file_size": 5941
    },
    {
        "id": "ecash.md",
        "name": "ecash",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # David Chaum and the history of eCash\n\t- The Chaumian mint refers to a concept in the field of cryptocurrency and digital privacy that is based on the principles outlined by David Chaum, a prominent cryptographer. This concept revolves around the idea of creating a secure and private form of digital currency that ensures the anonymity and confidentiality of transactions.\n\t- Famously it was almost integrated into early Microsoft Windows. [[Update Cycle]]\n\t- In essence, the Chaumian mint concept aims to provide a system where financial transactions can be conducted without revealing the identities of the parties involved, thus protecting the privacy and confidentiality of individuals' financial information. This is achieved through cryptographic techniques and protocols that allow for the secure exchange of digital currency without the need for a central authority to oversee or validate transactions.\n\t- By employing Chaumian mint principles, users can enjoy increased privacy and security when engaging in digital transactions, as their identities are kept confidential and their financial information is shielded from unwanted scrutiny. This concept aligns with the growing demand for privacy-focused technologies in the digital age, offering a potential solution for those who value anonymity and confidentiality in their financial interactions.\n- ## Implentations\n\t- ### Ark\n\t\t- Ark is a payment system that provides anonymity to users and operates similarly to the classic Chaumian eCash system. However, unlike eCash, every transaction made through Ark is backed by actual bitcoins, preventing the possibility of the Ark Service Provider (ASP) stealing or inflating them. Compared to Lightning, another payment network, Ark does not introduce liquidity constraints or a direct link between the sender and receiver, enabling recipients to receive payments without acquiring inbound liquidity or revealing their identity. In terms of UX, Ark mimics on-chain wallets by allowing async receiving and not introducing inbound liquidity constraints, but requires users to come online and \"refresh\" their coins every few weeks, or else the ASP can sweep the funds. Compared to validity rollups, Ark's higher throughput is due to not requiring on-chain data per transaction. If an ASP were to double-spend their pool transactions on mempool, incoming zero-conf vtxos can be used to pay lightning invoices, rendering double-spending a footgun for the service operator. A future extension of Ark can utilize a hypothetical data manipulation opcode to prevent double-spending. https://www.arkpill.me/faq\n\t- ### Cashu\n\t\t- This is a thriving ecosystem of new tooling and is explored in [[cashu]]\n\t- ### Fediment\nid:: 661acc10-64a6-4a52-bea0-41f7af6e6f60\n\t\t- Fedimint (short for \"Federated Mint\") is a protocol that aims to provide a scalable and privacy-preserving solution for using Bitcoin in everyday transactions. It combines the concept of federated sidechains with the privacy features of confidential transactions.\n\t - Federated Sidechains: Fedimint uses federated sidechains, which are separate blockchain networks that are anchored to the main Bitcoin blockchain. These sidechains allow for faster and cheaper transactions while still benefiting from the security of the Bitcoin network.\n\t - Confidential Transactions: The protocol utilizes confidential transactions, which hide the amounts being transferred while still allowing the network to verify the validity of the transactions. This enhances privacy for users.\n\t - Federated Mints: In Fedimint, \"mints\" are entities that issue tokens on the sidechain. These mints are federated, meaning they are operated by a group of independent parties who jointly control the issuance and redemption of tokens.\n\t - Blind Signatures: Fedimint employs blind signatures, a cryptographic technique that allows users to request signatures on their transactions without revealing the content of the transaction to the signer. This further enhances privacy.\n\t - Trustless Setup: The protocol is designed to minimize the trust required in the mints. Users can verify the solvency of the mints and withdraw their funds from the sidechain to the main Bitcoin blockchain at any time.\n\t\t- Benefits of Fedimint:\n\t - Improved scalability and lower transaction costs compared to the main Bitcoin network.\n\t - Enhanced privacy for users through confidential transactions and blind signatures.\n\t - Increased accessibility for everyday Bitcoin transactions.\n\t - Reduced trust requirements through the federated model and the ability to withdraw funds to the main chain.\n\t\t- Overall, Fedimint aims to provide a layer-2 solution for Bitcoin that improves scalability, privacy, and usability while leveraging the security of the underlying Bitcoin blockchain.\n\t\t-",
        "link_types": [
            "Update Cycle",
            "cashu"
        ],
        "file_size": 4860
    },
    {
        "id": "cypherpunk.md",
        "name": "cypherpunk",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- The [Cypherpunk - Wikipedia](https://en.wikipedia.org/wiki/Cypherpunk) page is a great start.\n- # A Cypherpunk's Manifesto\n\t- [A Cypherpunk's Manifesto (activism.net)](https://www.activism.net/cypherpunk/manifesto.html) by [Eric Hughes](ftp://soda.berkeley.edu/pub/cypherpunks/people/hughes.html)\n\t-\n\t- Privacy is necessary for an open society in the electronic age. Privacy is not secrecy. A private matter is something one doesn't want the whole world to know, but a secret matter is something one doesn't want anybody to know. Privacy is the power to selectively reveal oneself to the world.\n\t- If two parties have some sort of dealings, then each has a memory of their interaction. Each party can speak about their own memory of this; how could anyone prevent it? One could pass laws against it, but the freedom of speech, even more than privacy, is fundamental to an open society; we seek not to restrict any speech at all. If many parties speak together in the same forum, each can speak to all the others and aggregate together knowledge about individuals and other parties. The power of electronic communications has enabled such group speech, and it will not go away merely because we might want it to.\n\t- Since we desire privacy, we must ensure that each party to a transaction have knowledge only of that which is directly necessary for that transaction. Since any information can be spoken of, we must ensure that we reveal as little as possible. In most cases personal identity is not salient. When I purchase a magazine at a store and hand cash to the clerk, there is no need to know who I am. When I ask my electronic mail provider to send and receive messages, my provider need not know to whom I am speaking or what I am saying or what others are saying to me; my provider only need know how to get the message there and how much I owe them in fees. When my identity is revealed by the underlying mechanism of the transaction, I have no privacy. I cannot here selectively reveal myself; I must *always* reveal myself.\n\t- Therefore, privacy in an open society requires anonymous transaction systems. Until now, cash has been the primary such system. An anonymous transaction system is not a secret transaction system. An anonymous system empowers individuals to reveal their identity when desired and only when desired; this is the essence of privacy.\n\t- Privacy in an open society also requires cryptography. If I say something, I want it heard only by those for whom I intend it. If the content of my speech is available to the world, I have no privacy. To encrypt is to indicate the desire for privacy, and to encrypt with weak cryptography is to indicate not too much desire for privacy. Furthermore, to reveal one's identity with assurance when the default is anonymity requires the cryptographic signature.\n\t- We cannot expect governments, corporations, or other large, faceless organizations to grant us privacy out of their beneficence. It is to their advantage to speak of us, and we should expect that they will speak. To try to prevent their speech is to fight against the realities of information. Information does not just want to be free, it longs to be free. Information expands to fill the available storage space. Information is Rumor's younger, stronger cousin; Information is fleeter of foot, has more eyes, knows more, and understands less than Rumor.\n\t- We must defend our own privacy if we expect to have any. We must come together and create systems which allow anonymous transactions to take place. People have been defending their own privacy for centuries with whispers, darkness, envelopes, closed doors, secret handshakes, and couriers. The technologies of the past did not allow for strong privacy, but electronic technologies do.\n\t- We the Cypherpunks are dedicated to building anonymous systems. We are defending our privacy with cryptography, with anonymous mail forwarding systems, with digital signatures, and with electronic money.\n\t- Cypherpunks write code. We know that someone has to write software to defend privacy, and since we can't get privacy unless we all do, we're going to write it. We publish our code so that our fellow Cypherpunks may practice and play with it. Our code is free for all to use, worldwide. We don't much care if you don't approve of the software we write. We know that software can't be destroyed and that a widely dispersed system can't be shut down.\n\t- Cypherpunks deplore regulations on cryptography, for encryption is fundamentally a private act. The act of encryption, in fact, removes information from the public realm. Even laws against cryptography reach only so far as a nation's border and the arm of its violence. Cryptography will ineluctably spread over the whole globe, and with it the anonymous transactions systems that it makes possible.\n\t- For privacy to be widespread it must be part of a social contract. People must come and together deploy these systems for the common good. Privacy only extends so far as the cooperation of one's fellows in society. We the Cypherpunks seek your questions and your concerns and hope we may engage you so that we do not deceive ourselves. We will not, however, be moved out of our course because some may disagree with our goals.\n\t- The Cypherpunks are actively engaged in making the networks safer for privacy. Let us proceed together apace.\n\t- Onward.\n\t-\n\t\t- 9 March 1993",
        "link_types": [],
        "file_size": 5430
    },
    {
        "id": "Automated Podcast Project.md",
        "name": "Automated Podcast Project",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- [development chat work in progress.txt](../assets/development_chat_work_in_progress_1719174307794_0.txt)\n- # LogCaster\n\t- A podcast creation engine underpinned by a logseq knowledge graph and multi-agent framework.\n- # Automated Daily News Podcast Generation\n\t- This project aims to develop a sophisticated toolchain using FastAPI and OpenWebUI to automate the creation of a daily news podcast. The goal is to seamlessly integrate various modules and pipelines to process breaking news items, focusing on selecting interesting and unusual combinations of topics. The system will generate structured content through a multi-agent approach, mediated by a single API interface, ultimately producing a compelling podcast featuring two interlocutors, Bob and Sue.\n- ## Workflow Overview\n\t- **Parse Logseq**: A Logseq executed Python block parses the current Logseq markdown page to find the IP address of the OpenWebUI server specified here:\n\t\t- ```text\n\t\t  192.168.0.51\n\t\t  ```\n\t- **Request the Model List**: Use the OpenWebUI API to request the model list from the IP address specified above and the access token provided below:\n\t\t- ```text\n\t\t  Authorization: Bearer sk-6f3f39171ba247b4a66093287305fabc\n\t\t  ```\n\t- Python code to replace the curl command:\n\t\t- ```python\n\t\t  import requests\n\t\t  import json\n\t\t  \n\t\t  # Set up the request headers and URL\n\t\t  headers = {\n\t\t      \"accept\": \"application/json\",\n\t\t      \"Authorization\": \"Bearer sk-6f3f39171ba247b4a66093287305fabc\"\n\t\t  }\n\t\t  url = \"http://192.168.0.51:3000/api/v1/models/?id=\"\n\t\t  \n\t\t  # Make the GET request\n\t\t  response = requests.get(url, headers=headers)\n\t\t  \n\t\t  # Parse the response\n\t\t  if response.status_code == 200:\n\t\t      models = response.json()\n\t\t      model_names = [model['name'] for model in models]\n\t\t       # Print the model names (we assume logseq will show them)\n\t\t      print(\"\\n\".join(model_names)) \n\t\t  else:\n\t\t      print(\"Failed to fetch models:\", response.status_code, response.text)\n\t\t  ```\n\t\t\t- {{evalparent}}\n\t- **List is returned**: and should be written directly into this Logseq page in the block labelled below the code:\n\t\t- ## Model List\n\t\t\t- ```text\n\t\t\t  Models returned from the OpenWebUI API should be listed here, one model name per line.\n\t\t\t  ```\n\t- **Select Agent Models**: The user can copy and paste model names into the agent slots here.\n\t\t- ## Nominated Agents\n\t\t\t- Web Search\n\t\t\t\t- ```text\n\t\t\t\t  Perplexity\n\t\t\t\t  ```\n\t\t\t- Rating the news\n\t\t\t\t- ```text\n\t\t\t\t  Mistral 8B\n\t\t\t\t  ```\n- **Loading Topics**: Search the logseq knowledge graph for the tagged public pages. Create a list of any pages above 100kb in size. Note Python will load the first time this block is evaluated.\n\t- ```python\n\t  import js\n\t  \n\t  def list_public_pages():\n\t      try:\n\t          pages = js.logseq.api.get_all_pages()\n\t          public_pages = []\n\t          for page in pages:\n\t              page_name = page.originalName\n\t              # Get the first block of the page which typically contains metadata\n\t              content = js.logseq.api.get_page_blocks_tree(page_name)\n\t              if content and \"public:: true\" in content[0].content:\n\t                  public_pages.append(page_name)\n\t          return public_pages\n\t      except Exception as e:\n\t          js.logseq.api.show_msg(f\"Error in list_public_pages: {e}\", {'timeout': 5000})\n\t          return []\n\t  \n\t  def main():\n\t      public_pages = list_public_pages()\n\t      if public_pages:\n\t          result = \", \".join(public_pages)\n\t      else:\n\t          result = \"No public pages found.\"\n\t      return result\n\t  \n\t  # Execute the main function\n\t  main()\n\t  ```\n\t\t- {{evalparent}}\n\t\t-\n-\n\t- ## Topics with more than 100kb\n\t\t- Topic 1\n\t\t- Topic 2\n\t\t- This list should be replaced inside this file by the code.\n\t- **User Elects Topics**: Present the public list to the user as line-separated topics. The user selects their topics of choice by deleting unimportant lines. This selection remains stored in the Logseq page.\n\t- **Randomly Select Topics**: Next, executable Logseq code selects 2 or 3 topics at random from the list of elected topics. It updates the Logseq block below:\n\t\t- ### Trying these topics\n\t\t\t- Topic 1\n\t\t\t- Topic 2\n\t\t\t- Topic 3\n\t- **Searching for News**: The same code block calls the Perplexity pipeline using the OpenWebUI unified API to search for breaking news items that intersect with the randomly loaded topics.\n\t- **Ranking Importance**: Evaluate the returned news items using a locally hosted Mixtral 8B LLM, called from the list of available models. Request a score on likely impact and public interest on a scale from 1 to 10.\n\t- **Branching Factor**: If the news item scores above 8, pass the Perplexity-generated content to GPT-4. Otherwise, select another 2 or 3 public-tagged topics and repeat. The process can be attempted a maximum of 10 times. If 10 attempts do not surface a news item of worth, alert the user in the Logseq output.\n\t- **Extract Web Links**: Create a simple list of raw URLs found in the Perplexity response and remove duplicates.\n\t- **Detailed Information Scraping**: Process the identified links using the web scraper module from the models list in OpenWebUI to fetch in-depth summaries and additional content from the linked pages.\n\t- **Or Progress News Item**: Use the GPT4oV model from the OpenWebUI models list to process the raw Perplexity response and all ancillary summaries gathered from the web scraper. Return a detailed and highly technical description of the news item in JSON format, with web URLs and their summaries carefully segmented and linked as a knowledge graph.\n\t- **Enhancing with RAG**: Send the text elements of the GPT4-generated JSON to the RAGflow module in the models list, requesting that the knowledge be modified to include any opinions and ideas from the RAG corpus that intersect with the news item. Save the response to a Logseq block titled # Story Plus RAG.\n\t- **Generating Podcast Script**: Use Claude 3.5 to create a podcast script based on few-shot examples from the Logseq page labelled [[example podcast dialogue]]. Send the RAGflow-enhanced news story and the JSON-structured web links and summaries. The script should alternate dialogue between Bob and Sue, incorporating brief mentions of the web sources available in the episode notes. The returned JSON from Claude 3.5 should have field identifiers for Bob and Sue.\n\t- **Splitting Script**: Divide the podcast script into parts for Bob and Sue, creating two new JSON files with sequence numbers for the conversation.\n\t- **Text to Voice Conversion**: Pass both scripts to text-to-voice engines to generate the audio for Bob and Sue's lines respectively. Insist that the audio be returned with sequence numbers.\n\t- **Inline Python Code Block Creates WAV File**: Placeholder for now.\n\t- **Synchronization with Metahuman**: Synchronize the generated audio tracks with Metahuman talking heads in Unreal Engine to create a lifelike rendering of the podcast episode.\n- ## Workflow Diagram\n  \n  ```mermaid\n  graph TD\n    A[Parse Logseq] --> B[Request Model List]\n    B --> C[Model List Returned]\n    C --> D[Select Agent Models]\n    D --> E[Loading Topics]\n    E --> F[User Elects Topics]\n    F --> G[Randomly Select Topics]\n    G --> H[Searching for News]\n    H --> I[Ranking Importance]\n    I -->|Score > 8| K[Process with GPT-4]\n    I -->|Score <= 8| J[Select New Topics]\n    K --> L[Extract Web Links]\n    L --> M[Detailed Information Scraping]\n    M --> N[Enhance with RAGflow]\n    N --> O[Generating Podcast Script]\n    O --> P[Split Script]\n    P --> Q[Text to Voice Conversion]\n    Q --> R[Create WAV File]\n    R --> S[Synchronize with Metahuman]\n  ```\n- ## Sequence Diagram\n  ```mermaid\n  sequenceDiagram\n    participant User\n    participant Logseq\n    participant API\n    participant Models\n    participant Perplexity\n    participant Mixtral\n    participant GPT4\n    participant Scraper\n    participant Claude\n    participant TTS\n    User->>Logseq: Trigger Python Script\n    Logseq->>API: Request Model List\n    API->>Logseq: Return Model List\n    Logseq->>User: Display Model List\n    User->>Logseq: Select Agent Models\n    Logseq->>User: Display Public Pages\n    User->>Logseq: Elect Topics\n    Logseq->>Logseq: Randomly Select Topics\n    Logseq->>Perplexity: Search for News\n    Perplexity->>Logseq: Return News Items\n    Logseq->>Mixtral: Rank News Items\n    Mixtral->>Logseq: Return Scores\n    alt Score > 8\n      Logseq->>GPT4: Process with GPT-4\n      GPT4->>Logseq: Return Detailed Info\n      Logseq->>API: Extract Web Links\n      API->>Logseq: Return Links\n      Logseq->>Scraper: Scrape Details\n      Scraper->>Logseq: Return Summaries\n      Logseq->>RAG: Enhance with RAG\n      RAG->>Logseq: Return Enhanced Story\n      Logseq->>Claude: Generate Podcast Script\n      Claude->>Logseq: Return Podcast Script\n      Logseq->>TTS: Convert Text to Voice\n      TTS->>Logseq: Return Audio\n      Logseq->>Unreal: Sync with Metahuman\n    else Score <= 8\n      Logseq->>Logseq: Select New Topics\n    end\n    \n  ```\n- ## Implementation Details\n\t- The toolchain will be orchestrated by a Python script that interacts with the filesystem and calls the necessary APIs. The script will be modular, with each task encapsulated in its own function, including robust logging, configuration management, state management, unit tests, and documentation.\n\t- ### Main Functions\n\t\t- 1. `load_topics()`: Reads a list of topics from a file.\n\t\t  2. `search_news_items(topics)`: Uses Perplexity to search for news items related to the given topics.\n\t\t  3. `rank_news_items(items)`: Uses Mixtral 8B LLM to rank the news items, returning a list of items with a score from 1 to 10.\n\t\t  4. `process_high_score_items(items)`: Filters items with scores above 8, uses GPT-4 to restructure the items into technical essays, and isolates web links.\n\t\t  5. `scrape_details(links)`: Uses a web scraper module to fetch detailed summaries from the links.\n\t\t  6. `create_podcast_script(story, summaries)`: Uses Claude 3.5 and RAGflow corpus to create a podcast script.\n\t\t  7. `split_script(script)`: Splits the script between two interlocutors: Bob and Sue.\n\t\t  8. `text_to_voice(lines, person)`: Uses text-to-voice engines to convert lines into audio for Bob and Sue.\n\t\t  9. `sync_with_metahuman(bob_audio, sue_audio)`: Syncs the audio with Metahuman talking heads over a network connection to Unreal Engine.\n- ## Next Steps\n\t- 1. Implement the Python script with the outlined functions and best practices.\n\t  2. Set up the necessary APIs and modules (FastAPI, OpenWebUI, Perplexity, Mixtral 8B LLM, GPT-4, Claude 3.5, RAGflow, web scraper, text-to-voice engines, Metahuman, Unreal Engine).\n\t  3. Test and refine the toolchain, ensuring smooth integration and reliable performance.\n\t  4. Document the setup, usage, and maintenance of the toolchain for future reference and collaboration.",
        "link_types": [
            "example podcast dialogue"
        ],
        "file_size": 10866
    },
    {
        "id": "Gold.md",
        "name": "Gold",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- {{video https://www.youtube.com/watch?v=ihvG3RgbYzE)}}\n- ## Benefits of Gold as a commodity\n\t- ### Immutable Physical Properties\n\t\t- **Corrosion Resistance:** Gold is highly resistant to environmental factors such as oxygen, water, and ultraviolet light, making it durable over long periods.\n\t\t- **Malleability and Ductility:** Its ability to be shaped into incredibly thin sheets or drawn into wire makes gold unique for various technological and artistic applications.\n\t\t- **Conductivity:** Excellent for use in high-precision devices like electronic connectors and space telescope mirrors due to its superior electrical conductivity.\n\t- ### Cultural and Financial Security\n\t\t- **Symbolic Value:** Gold has been revered throughout history, symbolizing wealth, purity, and status across cultures.\n\t\t- **Financial Instrument:** Often viewed as a hedge against inflation and currency devaluation, gold is a staple in diversified investment portfolios.\n- ## Problems with Gold\n\t- ### Environmental Devastation\n\t\t- **Habitat Destruction:** Large-scale deforestation and habitat loss are common in gold mining, drastically altering ecosystems and leading to loss of biodiversity.\n\t\t- **Water Pollution:** Gold mining introduces hazardous chemicals like cyanide and mercury into water systems, poisoning aquatic life and contaminating water sources for human consumption.\n\t\t- **Soil Contamination:** The use of heavy machinery and toxic chemicals in mining operations severely degrades soil quality, affecting land use for agriculture and leading to long-term ecological damage.\n\t- ### Human Suffering and Exploitation\n\t\t- **Labor Abuses:** Gold mining is notorious for dangerous working conditions that often result in severe injuries and fatalities. Miners, including children, are exposed to hazardous conditions without adequate safety measures.\n\t\t- **Displacement of Communities:** Mining operations frequently displace local populations, stripping them of their land and livelihoods without fair compensation or viable alternatives, leading to cycles of poverty and instability.\n\t\t- **Fueling Conflicts:** In regions like Africa, the wealth generated by gold mines has financed wars and conflicts, contributing to severe human rights violations and suffering.\n\t- ### Economic Inequities\n\t\t- **Wealth Concentration:** The profits from gold mining are often concentrated in the hands of a few, typically large foreign corporations and investors, rather than benefiting the local communities where mining takes place.\n\t\t- **Market Manipulation:** Gold markets are subject to manipulation by large financial institutions, which can lead to speculative bubbles and sudden economic downturns affecting smaller investors disproportionately.\n\t- ### Technological and Ethical Challenges\n\t\t- **Non-renewable Resource Depletion:** The best gold deposits are increasingly depleted, leading to more energy-intensive and environmentally destructive methods to extract lower-quality ore.\n\t\t- **Ethical Dilemmas:** The gold industry faces significant backlash for perpetuating environmental destruction and social injustices, challenging its image as a desirable or ethical investment.\n\t- ### Perceived Value vs. Real Costs\n\t\t- **Myth of Stability vs. Reality of Exploitation:** While gold is promoted as a stable and safe investment, the real costs include environmental degradation, community displacement, and perpetuation of conflict and inequality.\n\t\t- **Cultural Significance vs. Socio-Economic Damage:** Gold’s role as a symbol of wealth and purity starkly contrasts with the corruption, greed, and exploitation prevalent in its mining and trade.\n\t\t- **Corporate Greenwashing:** Entities like the World Gold Council engage in aggressive marketing campaigns to portray gold mining as sustainable or beneficial to local economies, which is often a stark contrast to the on-ground realities of ecological and social turmoil.\n\t\t- **Resource Depletion:** High-quality gold deposits are becoming scarce, leading to more invasive extraction techniques which are economically and environmentally costly.\n\t\t- **Competition from Alternatives:** Emerging financial technologies and assets, like cryptocurrencies, pose a competitive threat to gold's status as a secure investment.\n\t\t- **Long-term Value vs. Immediate Environmental Cost:** Gold is marketed as a \"gift of remaining value\" due to its enduring nature, yet the immediate environmental costs of extracting gold are severe and often irreversible.\n\t\t- **Recycling vs. Continued Mining:** Despite gold’s recyclability, new mining continues at an aggressive pace, driven by ongoing demand and economic interests, rather than focusing on recycling existing gold supplies.\n\t\t- **Propaganda by Mining Companies:** Corporations and entities like the World Gold Council promote gold as a vital economic commodity through various forms of media and celebrity endorsements, despite the significant environmental and social issues associated with its production.\n- # MISC\n- ## Relevant Links and Resources\n\t- [Global Witness Reports on Gold Mining](https://www.globalwitness.org/en/campaigns/environmental-activists/dirty-gold/)\n\t - Investigative reports revealing the impact of gold mining on environments and communities worldwide.\n\t- [Human Rights Violations in Mining](https://www.hrw.org/topic/business/mining)\n\t - Human Rights Watch documentation of the widespread abuses in gold mining sectors.",
        "link_types": [],
        "file_size": 5494
    },
    {
        "id": "Social contract and jobs.md",
        "name": "Social contract and jobs",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # Artificial Intelligence\n\t- ## Explicitly develop under a \"for profit\" model.\n\t  id:: 659a9229-e9c0-485f-b58a-601b68b7edd0\n\t\t- In the case of Microsoft, Meta's Llama \"open\" models and Google's capable \"free to use\" models this means a *scorched earth* policy where they push AI into all of their apps and ecosystems, ensuring continuity of the user eyeballs that allow them profit. For a while it looked like OpenAI were going to capture so many users that downstream search products built on their system, like Perplexity, would challenge the primacy of the incumbent centralised web providers.\n\t\t- This also increasingly means automation, and robotics efficiency; profit though reduction of human workforce which is tax incentivised in the USA.\n\t\t- At the very least all of these companies are predicted on an advertising business model, and if the soft power of GenAI is used for advertising then it could be pretty dystopian.\n\t\t- All the current law pertaining to this is voluntary, to be clear, business isn't going to stop pursuing this plan because they (not China) signed a form.\n\t\t- Post Cambridge Analytica abuse of Social Media there has been NO binding legislation in the half decade after.\n\t\t- Governments are far too slow to respond. This will most likely be engaged with through bottom up labour movements like the screen writers guild strike.\n\t\t- [Bill Gurley on X: \"What’s really happening in the background around AI regulation. https://t.co/2xrdqvdpkE\" / X (twitter.com)](https://twitter.com/bgurley/status/1786073617316360670)\n\t\t\t- ![GMlofTGaYAMjN0v.jpeg](../assets/GMlofTGaYAMjN0v_1714807755332_0.jpeg){:height 907, :width 1097}\n\t\t- ### IMF report is tough reading\n\t\t\t- #### 2024 top up report\n\t\t\t\t- (I agree with lots of this one, but it's pretty much the IMF fishing for power, hence distancing themselves from it in the actual text, while also pushing it out on all channels)\n\t\t\t\t- [Broadening the Gains from Generative AI: The Role of Fiscal Policies (imf.org)](https://www.imf.org/en/Publications/Staff-Discussion-Notes/Issues/2024/06/11/Broadening-the-Gains-from-Generative-AI-The-Role-of-Fiscal-Policies-549639)\n\t\t\t\t\t- [Fiscal Policy Can Help Broaden the Gains blog post based on it](https://www.imf.org/en/Blogs/Articles/2024/06/17/fiscal-policy-can-help-broaden-the-gains-of-ai-to-humanity)\n\t\t\t\t- **Increased Poverty Due to Robotization**:\n\t\t\t\t\t- Robotization may lead to increasing poverty, especially affecting workers at the bottom of the wage distribution. The analysis shows that robotization resulted in a small long-term increase in poverty, with one additional robot per thousand workers increasing the poverty rate by 0.3 percentage points, a 3 percent increase. This is particularly concerning because it highlights the risk of low-wage workers falling into poverty due to technological advancements​​.\n\t\t\t\t- **Costly Transitions from AI**:\n\t\t\t\t\t- The transition to AI could be very costly due to labour market mismatches and prolonged periods of unemployment. Workers might face barriers to mobility and endure long unemployment or retraining periods before securing new jobs. This technological displacement often affects older workers more severely, leading to a generation-long adjustment period​​.\n\t\t\t\t- **Rapid and Unfair Disruption**:\n\t\t\t\t\t- The document cites that the advent of AI is progressing \"inhumanely fast\" and may seem \"unbelievably unfair,\" indicating a rapid pace of technological change that could disrupt labor markets and exacerbate inequalities before society can adequately adjust​​.\n\t\t\t\t- **Displacement Across All Skill Levels**:\n\t\t\t\t\t- AI adoption is likely to unevenly affect labour markets, risking disruptions that could displace both low-skill and high-skill jobs. Unlike past waves of automation that primarily displaced blue-collar workers, AI threatens to displace white-collar jobs, further polarizing wages and employment and amplifying income and wealth inequality​​.\n\t\t\t\t- **Challenges for Emerging Markets**:\n\t\t\t\t\t- In emerging markets and developing economies, the adoption of AI solutions is constrained by weak digital infrastructure, a lack of a developed digital economy, and insufficient local AI expertise. This suggests that these regions might struggle significantly to keep pace with AI advancements, potentially widening the global digital divide​​.\n\t\t\t\t- **Need for Overhauled Governance and Social Systems**:\n\t\t\t\t\t- Governments must upgrade their administrative and governance capacities to effectively manage AI innovation and its impacts. This includes investing in talent, data, and resources and potentially establishing dedicated agencies to track AI developments. The document stresses the need for international cooperation and robust regulatory frameworks to manage the rapid evolution and broad implications of AI​​.\n\t\t\t- #### 2023 Major findings report\n\t\t\t\t- (I disagree with this one)\n\t\t\t\t- <iframe src=\"https://www.imf.org/en/Blogs/Articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity\" style=\"width: 800px; height: 400px\"></iframe>\n\t\t- ### Early signs of job losses\n\t\t\t- [Opinion | Ro Khanna: The Advent of A.I. Doesn’t Have to Mean the Death of Labor The New York Times (nytimes.com)](https://www.nytimes.com/2024/01/04/opinion/artificial-intelligence-truckers-writers.html)\n\t\t\t- Around 1/4 million tech layoffs in 2023, while the top 7 companies doubled their share prices on the back of the AI hype boom. This isn't directly causal, but it is concerning.\n\t\t\t- Nothing is certain, when S4 capital fired half their global workforce, explicitly to replace them with AI, their share price continued to slide.\n\t\t\t- Goldman march replace 300M jobs worldwide 1/4 of work tasks in USA and Europe\n\t\t\t- [1 in 3 Companies Will Replace Employees With AI in 2024 [ResumeBuilder.com](https://www.resumebuilder.com/1-in-3-companies-will-replace-employees-with-ai-in-2024/)\n\t\t\t- 37% of 750 business leaders surveyed said AI has already replaces jobs, and 44% think there will be more in 2024.\n\t\t\t- [The state of AI at work, The Work Innovation Lab (asana.com)](https://asana.com/work-innovation-lab/the-state-of-ai-at-work/)\n\t\t\t- Employees think 29% of their tasks are replaceable by AI. Note this is **task** that sit within roles.\n\t\t\t- 49% of skills won't be relevant within 2 years ed x survey 800 execs. 5 years 56% of entry level roles, 79% said those roles will cease to exist, and 56% of their own roles. 47% said c-suite should be replaced.\n\t\t\t- [Google cuts 12,000 jobs in latest round of big tech layoffs The Verge](https://www.theverge.com/2023/1/20/23563706/google-layoffs-12000-jobs-cut-sundar-pichai) — the latest technology firm to initiate significant layoffs as inflation rises and global markets brace for a downturn. The job losses constitute around 6 percent of Google’s global workforce\n\t\t\t\t- ![1709138890785.jpeg](../assets/1709138890785_1709139885023_0.jpeg){:width 300}\n\t\t- ### Perceptions\n\t\t\t- There are signs of a growing backlash in the public.\n\t\t\t\t- ![image.png](../assets/image_1717159768482_0.png)\n\t\t\t\t- ![Screenshot 2024-05-12 201440.png](../assets/Screenshot_2024-05-12_201440_1715541399470_0.png){:width 400}\n\t\t\t\t- ![Screenshot 2024-05-12 201210.png](../assets/Screenshot_2024-05-12_201210_1715541467566_0.png){:width 300}\n\t\t\t\t- [The bad and the ugly: AI is harmful, unreliable and running out of data (newatlas.com)](https://newatlas.com/technology/ai-index-report-negatives/)\n\t\t\t\t- [AI really is smoke and mirrors - by Brian Merchant (bloodinthemachine.com)](https://www.bloodinthemachine.com/p/ai-really-is-smoke-and-mirrors)\n\t\t\t\t- [The AI Revolution Is Already Losing Steam - WSJ](https://www.wsj.com/tech/ai/the-ai-revolution-is-already-losing-steam-a93478b1)\n\t\t\t- {{twitter https://twitter.com/AISafetyMemes/status/1759231062646104165)}}\n\t\t\t- ## Polls roundup from [The AI Breakdown Podcast](https://www.youtube.com/@TheAIBreakdown)\n\t\t\t\t- ### CNBC poll\n\t\t\t\t\t- 72% said it made them more productive.\n\t\t\t\t\t- Among those that don't use it 35% are not worried.\n\t\t\t\t\t- 60% of people who use it are concerned.\n\t\t\t\t\t- The more employees used AI, the more worried they were that it could replace them\n\t\t\t\t- ### [Beamery found](https://beamery.com/resources/news/the-ai-employment-revolution-over-half-of-job-seekers-in-uk-have-noticed-ai-used-during-recruitment-process)\n\t\t\t\t\t- over half **(51%**) of job seekers in the UK said they had noticed AI being used during the recruitment process, with a further 46% using AI applying for jobs, according to Beamery, the global leader in Talent Lifecycle Management.\n\t\t\t\t- ### EDX survey of 800 executives\n\t\t\t\t\t- 49% of skills in their workforce would not be relevant by 2025\n\t\t\t\t\t- 56% of entry-level knowledge worker jobs would be eliminated due to AI\n\t\t\t\t\t- 79% thought AI would transform entry-level roles\n\t\t\t\t\t- 56% said their own roles would be partially or completely replaced by AI\n\t\t\t\t\t- 47% believed their workforces were not prepared for the future workplace\n\t\t\t\t- ### IMF report\n\t\t\t\t\t- AI would impact 40% of jobs in developing nations\n\t\t\t\t\t- AI would impact 60% of jobs in developed markets like the US\n\t\t\t\t\t\t- Half (30%) would see productivity gains and transformations\n\t\t\t\t\t\t- Half (30%) might be wiped off the face of the planet\n\t\t\t\t- ### McKinsey report \"Generative AI in the future of work in America\"\n\t\t\t\t\t- Automation could take over tasks accounting for 29.5% of hours worked in the US economy by 2030\n\t\t\t\t\t\t- Some sectors, like office support, nearing 40% automation\n\t\t\t\t\t\t- Others, like health professionals and property maintenance, seeing nearly 20% automation\n\t\t\t\t\t- Could lead to 12 million fewer jobs\n\t\t\t\t- ### Beautiful.ai survey of 3,000 managers\n\t\t\t\t\t- 41% hoped to replace employees with AI tools in 2024\n\t\t\t\t\t- 48% said their businesses would benefit financially if they could replace a large number of employees\n\t\t\t\t\t- 40% said multiple employees could be replaced by AI tools and the team would operate well without them\n\t\t\t\t\t- 45% viewed AI as an opportunity to lower employee salaries\n\t\t\t\t\t- 12% hoped to use AI to downsize and save money on worker salaries\n\t\t\t\t\t- 50% were worried AI tools would result in lower pay for themselves\n\t\t\t\t\t- 64% believed AI's output and productivity were equal or better to experienced human managers\n\t\t\t\t\t- 90% were already using AI to increase productivity\n\t\t\t\t- ### Adco survey of 2,000 executives\n\t\t\t\t\t- 41% expected to employ fewer people because of AI\n\t\t\t\t\t- 46% would redeploy employees internally if their jobs were impacted by AI\n\t\t\t\t\t- 2/3 planned on recruiting people skilled in AI\n\t\t\t\t\t- 1/3 would train their existing workforce in AI\n\t\t\t\t- ### Goldman Sachs report\n\t\t\t\t\t- Automation could replace a quarter of work tasks in the US and Europe, disrupting the equivalent of 300 million jobs\n\t\t\t\t\t- Productivity gains from generative AI would raise annual global GDP by 7% over a 10-year period\n\t\t\t\t- ### European Central Bank paper\n\t\t\t\t\t- During the deep learning boom of the 2010s, opportunities for younger and high-skilled workers increased\n\t\t\t\t\t- Fears of AI ending human labor may \"be greatly exaggerated\"\n\t\t\t\t- ### Asana study\n\t\t\t\t\t- Employees said 29% of their work tasks were replaceable by AI\n\t\t\t\t- ### Zappo poll of over 10,000 respondents\n\t\t\t\t\t- 66.6% said AI could carry out their workplace duties\n\t\t\t\t\t- Nearly 75% were concerned about AI's impact on their industry\n\t\t\t\t\t- 78.1% believed AI could reduce some stress on the job\n\t\t\t\t\t- 76.7% believed AI will reduce the number of working days for the average American\n\t\t\t\t- ### Deloitte survey of 2,800 director to C-suite executives\n\t\t\t\t\t- Only 1 in 5 believed their organization was highly or very highly prepared to address AI skills needs\n\t\t\t\t\t- Only 47% said they are sufficiently educating employees about AI\n\t\t\t\t- ### Microsoft research\n\t\t\t\t\t- 65% of Gen Z employees said they don't have the right skills for the AI era\n\t\t\t\t- ### Censuswide survey\n\t\t\t\t\t- 68% said they don't have enough understanding of generative AI for their current roles\n\t\t\t\t\t- 53% want more training and guidance\n\t\t\t\t- ### LinkedIn survey of UK workers\n\t\t\t\t\t- 2 in 5 predicted a significant change in their jobs in the next year due to AI\n\t\t\t\t\t- Over 1/3 admitted to feeling overwhelmed by the amount there is to learn\n\t\t\t\t- ### ServiceNow report\n\t\t\t\t\t- 41% of office workers admit to currently lacking the technical abilities needed to work alongside and use AI systems\n\t\t- ## Tech Cultists?\n\t\t\t- Silicon valley is already showing signs of fetishising AI and this explored in it's own section [[Singularity]].\n\t\t\t- ![Screenshot 2024-05-09 082635.png](../assets/Screenshot_2024-05-09_082635_1715239685308_0.png){:width 500}\n\t\t- ## AI and Universal Basic Income\n\t\t\t- Sam Alman talking UBI at 50 minutes\n\t\t\t- {{video https://youtu.be/nSM0xd8xHUM?t=3002}}\n\t\t- ## Academic View\n\t\t\t- The impact of AI automation on the economy and society is a complex and multifaceted issue that requires careful consideration and proactive planning. While there are certainly risks and challenges to be addressed, such as job displacement and increased inequality, there is also great potential for AI to improve productivity, solve global problems, and create human flourishing.\n\t\t\t- #### The Case for Concern\n\t\t\t\t- AI automation is likely to lead to significant job losses in the short to medium term, particularly in sectors such as manufacturing, transportation, and customer service. Frey and Osborne (2017) estimate that 47% of US jobs are at risk of automation in the next two decades.\n\t\t\t\t- As more people lose their jobs to AI, there is a risk of reduced consumer spending and economic instability, potentially leading to a recession. Korinek and Stiglitz (2017) warn that the displacement of workers by AI could lead to a \"death spiral\" of falling demand and further job losses.\n\t\t\t\t- The impact of job losses will be uneven, with some industries and regions hit harder than others, exacerbating existing inequalities. Low-skill and routine jobs are most at risk of automation, which could widen the gap between high- and low-income earners (Acemoglu & Restrepo, 2018).\n\t\t\t\t- Without proper ethical considerations, AI could exacerbate existing inequalities and perpetuate harmful stereotypes [Dignum, 2019](https://www.itu.int/en/journal/001/Documents/itu2017-1.pdf).\n\t\t\t\t- Without adequate social safety nets and support for displaced workers, there is a risk of social unrest and political backlash against AI and automation. Korinek and Stiglitz (2017) argue that the social and political consequences of AI-driven job losses could be severe if not addressed proactively.\n\t\t\t- #### The Case for Optimism\n\t\t\t\t- In the long run, AI automation has the potential to greatly increase productivity and economic growth, creating new jobs and opportunities. Acemoglu and Restrepo (2018) find that while automation does displace some jobs, it also creates new ones in more complex and higher-paying fields.\n\t\t\t\t- AI can also help to solve complex social and environmental problems, such as climate change and disease prevention, improving quality of life for all. AI-powered technologies such as precision agriculture and personalized medicine have the potential to address global challenges and improve human well-being (Vinuesa et al., 2020).\n\t\t\t\t- With the right policies and investments in education and retraining, the workforce can adapt to the new demands of an AI-driven economy. Acemoglu and Restrepo (2018) emphasize the importance of investing in human capital and promoting the creation of new tasks that complement AI technologies.\n\t\t\t\t- The benefits of AI, such as increased leisure time and reduced costs of goods and services, can be widely shared if there is a concerted effort to promote inclusive growth and equitable distribution of wealth. Korinek and Stiglitz (2017) propose policies such as progressive taxation and universal basic income to ensure that the gains from AI are broadly shared.\n\t\t\t\t- Economist David Autor from MIT presents a compelling counterargument. In his article \"[AI Could Actually Help Rebuild The Middle Class,](https://www.noemamag.com/how-ai-could-help-rebuild-the-middle-class/)\". Autor posits that AI has the potential to democratise expertise and create new opportunities for workers without advanced degrees, ultimately leading to greater equity and a stronger middle class.\n\t\t\t\t\t- Autor argues that unlike past automation technologies, AI can learn from unstructured data and tacit knowledge, enabling it to augment human capabilities in complex decision-making domains. By providing real-time guidance and guardrails, AI can expand access to expertise and allow people with less formal training to perform higher-skilled work.\n\t\t\t\t\t  Central to Autor's thesis is the concept of \"a worker of one\"\n\t\t- in a free society, every individual owns their own labor, creating an intrinsic force for greater equality when human expertise is valuable. AI could generate a variety of new middle-class jobs, counteracting the tendency for returns to accrue primarily to capital owners.\n\t\t\t- However, realizing these benefits will require proactive efforts to steer AI development in a direction that benefits workers. This includes investing in AI tools for education and healthcare, reforming institutions to ensure productivity gains flow to workers, and countering resistance from professional guilds.\n\t\t\t  Autor emphasizes that the goal is not to render human expertise obsolete, but rather to extend its reach and efficacy. He draws an analogy to YouTube tutorials\n\t\t- while an untrained amateur cannot safely replace a circuit breaker by watching a video, an electrician can use that same video to expand their skills and take on new tasks. Similarly, AI will be most effective when building upon a foundation of human knowledge.\n\t\t\t- Autor also notes that demand for many forms of expertise, such as in healthcare and education, is effectively limitless. So if AI can boost productivity in these domains, it may actually increase employment by making these services more affordable and accessible.\n\t\t\t- While AI will automate some tasks and eliminate certain jobs, Autor argues this is not the whole story. Historically, the most important innovations have been those that expanded human capabilities and opened up entirely new domains\n\t\t- from air travel to gene editing. In the process, they created demands for new forms of expertise that didn't previously exist.\n\t\t\t- #### Reference to integrate\n\t\t\t\t- Acemoglu, D., & Restrepo, P. (2018). The race between man and machine: Implications of technology for growth, factor shares, and employment. American Economic Review, 108(6), 1488-1542.\n\t\t\t\t- Dignum, V. (2019). Responsible artificial intelligence: Designing AI for human values. ITU Journal: ICT Discoveries, 1(1), 1-8.\n\t\t\t\t- Frey, C. B., & Osborne, M. A. (2017). The future of employment: How susceptible are jobs to computerisation?. Technological forecasting and social change, 114, 254-280.\n\t\t\t\t- Korinek, A., & Stiglitz, J. E. (2017). Artificial intelligence and its implications for income distribution and unemployment (No. w24174). National Bureau of Economic Research.\n\t\t\t\t- Vinuesa, R., Azizpour, H., Leite, I., Balaam, M., Dignum, V., Domisch, S., ... & Nerini, F. F. (2020). The role of artificial intelligence in achieving the Sustainable Development Goals. Nature Communications, 11(1), 1-10.\n\t\t- ### Roles under most threat\n\t\t\t- UK dept of education [10-30% can be automated away.](https://assets.publishing.service.gov.uk/media/656856b8cc1ec500138eef49/Gov.UK_Impact_of_AI_on_UK_Jobs_and_Training.pdf#:~:text=It%20has%20been%20estimated%20that%2010-30%25%20of%20jobs,the%20potential%20benefits%20advances%20in%20AI%20will%20bring.)  [[Layoff tracker and threatened roles]]\n\t\t\t- Knowledge worker, admin, law, etc. This will lower wages, NOT give more time back.\n\t\t\t- [Generative AI at Work Stanford research in the Philippines](https://www.nber.org/papers/w31161) found AI gave a 14% productivity boost overall, but importantly 34% improvement for novice workers, and actual hindrance for experts.\n\t\t\t\t- This suggests a flattening of skill levels, with likely impact on wages.\n\t\t\t\t- [Wanted: ‘New Collar’ Workers The New York Times](https://www.nytimes.com/interactive/2023/12/29/business/what-are-new-collar-jobs.html)\n\t\t- ### Who's safe?\n\t\t\t- [Hottest Job in Corporate America? The Executive in Charge of A.I.\n\t\t- The New York Times (nytimes.com)](https://www.nytimes.com/2024/01/29/technology/us-jobs-ai-chatgpt-tech.html)\n\t\t\t- Martin Ford, Rule of the Robots:\n\t\t\t\t- Genuine Creatives, making new ideas. Science, medicine, law.\n\t\t\t\t- Sophisticated interpersonal relationships\n\t\t\t\t- Physically demanding and complex work\n\t\t- [twitter link to the render loading below](https://twitter.com/tsarnick/status/1758052810166513995)\n\t\t  {{twitter https://twitter.com/tsarnick/status/1758052810166513995}}\n\t- # Renegotiating the Social Contract in the AI Era\n\t\t- ## Social Contract Theories and Modern Implications\n\t\t\t- The concept of a social contract, shaped by theorists like Hobbes, Locke, and Rousseau, underpins societal norms. Today's digital and AI advancements prompt a reevaluation of these contracts to ensure equitable technology access and protect digital rights ([AI and the Social Contract](https://medium.com/mlearning-ai/ai-and-the-social-contract-c3f063cdae18), [Definition of Social Contract](https://www.techtarget.com/whatis/definition/social-contract), [Critiques of Social Contract](https://iep.utm.edu/soc-cont/)).\n\t\t\t- The renegotiation of the social contract due to AI, automation, and copyright involves significant shifts in societal norms, driven by rapid technological advancements. This transformation challenges traditional frameworks governing work, creativity, and resource distribution, necessitating updated agreements that ensure fairness and relevance.\n\t\t\t- Technological progress has historically displaced jobs while creating new ones. The rise of AI-driven automation intensifies this dynamic, reshaping the job market and sparking debates about the future of work and employment nature ([Impact of AI-driven Automation](https://www.linkedin.com/pulse/impact-ai-driven-automation-business-efficiency-job-parker-wilson), [Social Unrest and Safety Nets](https://www.thesocialcontract.com/artman2/publish/tsc_27_2/tsc-27-2-walker_printer.shtml), [Technological Progress and Societal Adaptation](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6452673/)).\n\t\t- ## The Evolution of Copyright Law\n\t\t\t- Copyright law must evolve to balance creators' rights with public access, especially as AI complicates authorship and ownership ([UK Copyright Legislation](https://www.gov.uk/government/consultations/artificial-intelligence-and-intellectual-property-call-for-views/artificial-intelligence-call-for-views-copyright-and-related-rights), [US Copyright Act](https://www.copyright.gov/title17/)).\n\t- ## Calls for a New Social Contract\n\t\t- The new challenges of AI and digital technologies lead to calls for a new social contract, focusing on digital citizenship, privacy, and fair technology distribution ([Defend Democracy on AI](https://defenddemocracy.eu/a-new-social-contract-for-the-age-of-artificial-intelligence), [OECD Digital Rights](https://www.oecd.org/digital/rights/)).\n\t- ## The Changing Nature of Work\n\t\t- Historical technological shifts have reshaped labor markets and societal structures, now accelerated by AI and automation ([Impact of AI and Automation](https://news.stthomas.edu/artificial-intelligence-and-its-impact-on-jobs/)).\n\t\t- AI and automation are transforming work, necessitating adjustments in the social contract to address job displacement and create new opportunities ([AI's Impact on Jobs](https://news.stthomas.edu/artificial-intelligence-and-its-impact-on-jobs/), [Automation's Broader Impact](https://www.mckinsey.com/featured-insights/future-of-work/how-will-automation-affect-jobs-skills-and-wages)).\n\t- ## Proposing Frameworks for Policy and Adaptation\n\t\t- Susskind (2021) argues that the rise of AI and automation will lead to a future with less work for humans, necessitating a reevaluation of the concept of work. He suggests that a more nuanced approach to the social contract is needed to address the potential impact on employment and inequality. Merola (2022) and Chand (2020, 2021) both explore the role of taxation in addressing the challenges of automation and AI. Merola emphasizes the need for a comprehensive approach that includes employment creation strategies, redistributive policies, skill development, and social protection systems. Chand, on the other hand, suggests that targeted taxes on AI and robots may not be effective, and instead proposes a global fiscal redistribution mechanism and an education tax to fund worker reskilling programs.\n\t\t- Policymakers and governments play crucial roles in adapting policies to mitigate AI's impact on society, focusing on privacy, expression, and workforce transitions ([Government and Digital Policy](https://www.oecd.org/digital/rights/)).\n\t\t- To accommodate AI and digital transformations, new frameworks are proposed, emphasizing worker rights, digital citizenship, and the ethical use of technology ([Work in the Era of AI](https://epthinktank.eu/2021/02/10/work-in-the-era-of-ai-time-for-a-digital-social-contract/)). -\n\t- # AI's Impact on Power, Privacy, and Personal Sovereignty\n\t\t- **Concentration of Power in AI:**\n\t\t\t- **Corporate Dominance:**\n\t\t\t\t- Major tech companies are not just developing AI but are shaping its very direction and application.\n\t\t\t\t- These companies' influence leads to potential monopolistic control, affecting competition and innovation.\n\t\t\t\t- **Deeper Insight:** The consolidation of power in the AI sector creates barriers for smaller players, leading to a lack of diversity in AI development and potential biases in AI systems.\n\t\t\t- **Economic and Resource Inequality:**\n\t\t\t\t- AI's development requires substantial resources, creating a disparity between entities that can afford these resources and those that cannot.\n\t\t\t\t- This disparity widens the gap between large corporations and smaller entities, including academic institutions and startups.\n\t\t\t\t- **Deeper Insight:** The economic divide in AI reinforces existing power structures, where the entities with the most data and computational power dictate AI's evolution and application.\n\t\t- **Gating of Information:**\n\t\t\t- **Access Control by AI:**\n\t\t\t\t- AI systems, often proprietary, control the flow and accessibility of information.\n\t\t\t\t- This control can lead to information gatekeeping, where only certain narratives or perspectives are amplified.\n\t\t\t\t- **Deeper Insight:** AI's role in content recommendation and news dissemination can skew public perception and understanding, potentially leading to echo chambers.\n\t\t\t- **Transparency and Accountability:**\n\t\t\t\t- There is a lack of transparency in how AI algorithms function and make decisions.\n\t\t\t\t- This opaqueness makes it difficult for the public to understand or challenge AI-driven decisions.\n\t\t\t\t- **Deeper Insight:** Without transparency, AI systems can perpetuate biases and errors unchecked, leading to harmful societal impacts.\n\t\t- **Privacy and Personal Sovereignty:**\n\t\t\t- **AI as a Surveillance Tool:**\n\t\t\t\t- AI technologies, particularly in facial recognition and behavior prediction, are increasingly used for surveillance, infringing on individual privacy.\n\t\t\t\t- These technologies can track and analyze personal data without explicit consent, raising ethical concerns.\n\t\t\t\t- **Deeper Insight:** The widespread use of AI in surveillance erodes personal freedoms and privacy, leading to a society where every action can be monitored and analyzed.\n\t\t\t- **Data Exploitation and Consent:**\n\t\t\t\t- The collection and use of personal data for AI training often occur without clear consent from individuals.\n\t\t\t\t- Data subjects rarely have control over how their data is used, contributing to the erosion of personal sovereignty.\n\t\t\t\t- **Deeper Insight:** The lack of control over personal data signifies a shift in power dynamics, where individuals have little say in how their information is utilized and monetized.\n\t\t- **Erosion of Rights and Labor Exploitation:**\n\t\t\t- **Impact on Workers' Rights:**\n\t\t\t\t- Automation and AI threaten traditional jobs, leading to job insecurity and changes in labor dynamics.\n\t\t\t\t- Workers are often required to train AI systems that may eventually replace them, raising ethical questions about labor rights.\n\t\t\t\t- **Deeper Insight:** The transition towards an AI-driven economy necessitates a reevaluation of labor laws and protections to safeguard workers' rights in a changing landscape.\n\t\t\t- **Ethical Concerns in AI Training:**\n\t\t\t\t- The human labor involved in AI training, especially in content moderation, is often underappreciated and underpaid.\n\t\t\t\t- Workers are exposed to harmful content, impacting their mental health, with little support or recognition.\n\t\t\t\t- **Deeper Insight:** The reliance on human labor for AI's 'intelligence' contrasts with the narrative of AI as an autonomous, advanced technology, highlighting the need for better working conditions and ethical standards in AI development.\n\t\t- **Future Outlook and Regulations:**\n\t\t\t- **Regulatory Challenges:**\n\t\t\t\t- The pace of AI development outstrips the current regulatory framework, leading to gaps in governance and oversight.\n\t\t\t\t- There is a need for comprehensive laws that address privacy, transparency, and the equitable use of AI.\n\t\t\t\t- **Deeper Insight:** Effective regulation of AI requires a multidisciplinary approach, involving lawmakers, technologists, ethicists, and the public to ensure that AI serves the common good without infringing on individual rights.\n\t\t\t- **Personal Sovereignty in the Digital Age:**\n\t\t\t\t- As AI becomes more integrated into daily life, maintaining personal sovereignty over data and privacy becomes increasingly challenging.\n\t\t\t\t- Individuals must be empowered with knowledge and tools to navigate this landscape and protect their digital rights.\n\t\t\t\t- **Deeper Insight:** Fostering a culture of digital literacy and advocating for stronger privacy protections are essential steps in ensuring that individuals retain control over their personal data in an AI-driven world.\n- # Immersive Technologies and Mixed Reality\n\t- ## Elder Care\n\t\t- [Where and who you are in VR has a real impact, study finds | Stanford News](https://news.stanford.edu/2022/12/14/vr-real-impact-study-finds/)\n\t\t- [New Stanford University study reveals almost 60% of seniors felt less isolated socially after their #VirtualReality experience\n\t\t- the opposite of the stereotype that #VR is an isolating technology! Additionally, 80% of them had a more positive attitude after the experience. The study involved interviewing residents of 17 senior communities who who could choose from virtual experiences such as parachuting, watching stage performances, or visiting places like Paris and Egypt. They used both HTC VIVE Flow and PICO XR headsets. The study was conducted in collaboration with Chris B., CEO of Mynd Immersive, and is part of a wider study to help lessen the impact of #dementia. I particularly enjoyed the final comment by senior resident Pete Audet at the end of this video who shared our wonder about how exciting the next 10 years of this technology is going to be 𣰊\t - Search (bing.com)](https://www.bing.com/search?q=New+Stanford+University+study+reveals+almost+60%25+of+seniors+felt+less+isolated+socially+after+their+%23VirtualReality+experience+-+the+opposite+of+the+stereotype+that+%23VR+is+an+isolating+technology!+Additionally%2C+80%25+of+them+had+a+more+positive+attitude+after+the+experience.+The+study+involved+interviewing+residents+of+17+senior+communities+who+who+could+choose+from+virtual+experiences+such+as+parachuting%2C+watching+stage+performances%2C+or+visiting+places+like+Paris+and+Egypt.+They+used+both+HTC+VIVE+Flow+and+PICO+XR+headsets.+The+study+was+conducted+in+collaboration+with+Chris+B.%2C+CEO+of+Mynd+Immersive%2C+and+is+part+of+a+wider+study+to+help+lessen+the+impact+of+%23dementia.+I+particularly+enjoyed+the+final+comment+by+senior+resident+Pete+Audet+at+the+end+of+this+video+who+shared+our+wonder+about+how+exciting+the+next+10+years+of+this+technology+is+going+to+be+%F0%9F%91%8F&cvid=3fc42482a4bb482d8ea881dc2efc2960&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRhA0gEHNTcxajBqNKgCALACAA&FORM=ANAB01&PC=U531)\n\t\t- [moore-et-al-2023-from-65-to-103-older-adults-experience-virtual-reality-differently-depending-on-their-age-evidence.pdf (stanford.edu)](https://vhil.stanford.edu/sites/g/files/sbiybj29011/files/media/file/moore-et-al-2023-from-65-to-103-older-adults-experience-virtual-reality-differently-depending-on-their-age-evidence.pdf) -\n- # A new valuation for human capital\n\t- These convergent impulses may lead to a reconnection and re-evaluation of the importance of human interpersonal (physically present) skills as posited by [Opinion | The A.I. Economy Will Make Jobs More Human\n\t\t- The New York Times (nytimes.com)](https://www.nytimes.com/2024/02/14/opinion/ai-economy-jobs-colleges.html).\n\t\t- **Education and Training Reevaluation**:\n\t\t\t- There's a critical need to shift focus from technical skills like coding to fostering inherently human skills: communication, empathy, and critical thinking.\n\t\t\t- The trend of increasing enrollment in computer science and declining humanities majors reflects an overemphasis on technical skills, despite AI advancements.\n\t\t- **Valuing Human Capabilities**:\n\t\t\t- This era prompts a reassessment of what constitutes core human capabilities, placing a premium on soft skills necessary for effective AI collaboration.\n\t\t\t- Communication is identified as a key skill across professions, underscoring the critical role of interpersonal skills in the AI-dominated landscape.\n\t\t- **Workforce Preferences and Predictions**:\n\t\t\t- Surveys show a strong preference for soft skills over technical AI skills among executives, recognizing the importance of interpersonal abilities.\n\t\t\t- The transition towards a \"relationship economy\" emphasizes social abilities and people skills as central to future success.\n\t\t- **Opportunities for Equity and Revaluation**:\n\t\t\t- The evolving economy offers a chance to address gender disparities by valuing skills traditionally considered feminine.\n\t\t\t- This shift invites a broader vision for human potential, advocating for a workforce that values emotional intelligence and the heart alongside the intellect.\n\t\t\t- People who can act within the context of a \"bubble of one\" with their AI agents will likely prosper, even within the context of employment contracts in larger corporate structures.\n- # Misc\n- [twitter link to the render loading below](https://twitter.com/generalising/status/1772744143476842732)\n  {{twitter https://twitter.com/generalising/status/1772744143476842732}} -\n- [Generative AI Could Raise Global GDP by 7% (goldmansachs.com)](https://www.goldmansachs.com/intelligence/pages/generative-ai-could-raise-global-gdp-by-7-percent.html)\n- [Nobel Prize laureate Chris Pissarides on ChatGPT, AI and the four-day workweek | Fortune Europe](https://fortune.com/europe/2023/12/02/nobel-prize-economist-christopher-pissarides-chatgpt-workplace-automation-one-year-launch/)\n- [The Shorter Working Week: a report from Autonomy\n\t- Autonomy](https://autonomy.work/portfolio/the-shorter-working-week-a-report-from-autonomy-in-collaboration-with-members-of-the-4-day-week-campaign/)\n- [Ray Dalio says AI could create a 3-day workweek | Fortune](https://fortune.com/2023/09/18/ray-dalio-ai-3-day-work-week-investing-advice-portfolio-cash-bonds-tech-bridgewater-associates/)\n- [JPMorgan CEO Jamie Dimon: AI will lead to 3.5-day workweek | Fortune](https://fortune.com/2023/10/03/jamie-dimon-jpmorgan-chase-ceo-ai-impact-working-week/)\n- [IBM CEO: ‘Today’s workforce should prepare to work hand in hand with A.I.' | Fortune](https://fortune.com/2023/04/20/ibm-ceo-work-ai-artificial-intelligence-careers-tech-arvind-krishna/)\n- https://slack.com/intl/en-gb/blog/news/the-surprising-connection-between-after-hours-work-and-decreased-productivity\n- [CEO effect on firm performance mostly due to chance | ScienceDaily](https://www.sciencedaily.com/releases/2015/10/151022192337.htm)\n- [[Layoff tracker and threatened roles]]\n-\n-",
        "link_types": [
            "Singularity",
            "Layoff tracker and threatened roles",
            "Layoff tracker and threatened roles"
        ],
        "file_size": 36449
    },
    {
        "id": "Leopold Aschenbrenner.md",
        "name": "Leopold Aschenbrenner",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- {{video https://www.youtube.com/watch?v=zdbVtZIn9IM&}}\n- # The Trillion-Dollar Cluster and Beyond\n\t- ![situationalawareness.pdf](../assets/situationalawareness_1717941860620_0.pdf)\n\t- [WEBPAGE LINK](https://situational-awareness.ai/)\n\t- This podcast and PDF explores the thesis advanced  Leopold Aschenbrenner, delving into by the trajectory of [[Artificial Intelligence]] and [[Artificial Superintelligence]], within the contexts of [[Hardware and Edge]], [[Energy and Power]], and [[Politics, Law, Privacy]].\n\t\t- **Compute Requirements Skyrocketing:** The conversation begins with a stark examination of the escalating computational resources necessary for training advanced AI models. They reference GPT-4's estimated $500 million training cluster as a benchmark, projecting a future where trillion-dollar clusters become commonplace by 2030, demanding power equivalent to significant portions of national grids.\n\t\t- **Unlocking the Power of Test-Time Compute:** While training compute garners most attention, the guests emphasise the equally crucial role of \"test-time compute.\" They argue that current AI models, despite their capabilities, operate far below their potential cognitive capacity. Analogous to human \"System 2\" thinking, they believe training AI to think strategically over millions of tokens, simulating months of cognitive work, will be essential to unlocking breakthroughs. This suggests AI systems that can plan, debug, iterate, and reason far beyond current capabilities.\n- ## **From Chatbots to AI Coworkers - Revolutionising the Future of Work:**\n\t- **The Rise of the AI Agent:** The discussion explores a future where AI surpasses chatbot limitations, evolving into agentic entities capable of autonomously tackling complex tasks. This evolution leads to scenarios where AI functions as \"drop-in remote workers,\" seamlessly integrating into work environments and potentially displacing humans from numerous cognitive roles.\n\t- **Productivity Boom, But at What Cost?:** While recognising the immense productivity gains promised by AI, the guests grapple with the potential economic and social consequences. The rapid displacement of jobs, particularly in white-collar sectors, could lead to significant disruptions, necessitating substantial societal adaptation. They also consider whether intermediate AI systems might see limited adoption, as companies await the arrival of more powerful, user-friendly AGI systems.\n- ## **Navigating the AI Arms Race - A Return to History's High Stakes:**\n\t- **Echoes of the Cold War:** The conversation takes a historical turn, drawing parallels between the transformative potential of AI and the Cold War's technological and ideological battles. They suggest that we are entering a new era of great power competition with AI at its core.\n\t- **The CCP's AI Ambitions - A Clear and Present Danger:** Concerns about the Chinese Communist Party's AI agenda are central to the discussion. The guests argue that the CCP recognises the technology's potential to reshape the global order, potentially granting a decisive advantage to whichever nation harnesses it first. They discuss concrete threats, including:\n\t- **Espionage and IP Theft:** The CCP's aggressive espionage apparatus could target AI companies and research institutions, attempting to steal algorithms, training data, and critical technological insights.\n\t- **Rapid Industrial Scale-Up:** Leveraging its centralised control and vast industrial capacity, the CCP could rapidly build massive AI clusters and deploy these technologies at scale.\n\t- **A More Ruthless Approach:** Unburdened by ethical constraints or public scrutiny, the CCP might pursue AI development and deployment in ways that Western nations would deem unacceptable.\n\t- **The US at a Crossroads - The Imperative of Leadership:** The guests emphasise the urgent need for the US to recognise the magnitude of the challenge and reaffirm its commitment to leading the world in responsible AI development. They propose key steps:\n\t- **A Comprehensive National AI Strategy:** Articulating a clear vision and roadmap for AI development, encompassing research, infrastructure, workforce development, and national security considerations.\n\t- **Winning the Global Talent Race:** Attracting and retaining the world's brightest minds in AI research and engineering, fostering a thriving ecosystem of innovation.\n\t- **Promoting International Cooperation (With Caveats):** Building alliances with like-minded nations to establish norms, standards, and safeguards for AI development and deployment while carefully managing the risks of technology transfer to potentially adversarial nations.\n\t- **The Middle East Conundrum - A Dangerous Gambit for Short-Term Gain:**\n\t\t- **The Allure of Sovereign Wealth and Influence:** The guests express serious reservations about the trend of major AI companies, driven by the promise of capital and market access, potentially establishing significant AI infrastructure in the Middle East. They specifically single out countries with concerning human rights records and opaque ties to China, such as the UAE.\n\t\t- **A Seat at the Table for Authoritarian Regimes:** They argue that this trend effectively grants authoritarian regimes undue influence over this strategically crucial technology, jeopardising global security and potentially emboldening those hostile to democratic values.\n\t\t- **Rejecting False Promises of \"Atoms for Peace\":** They caution against naive comparisons to the \"Atoms for Peace\" programme, arguing that AI's unique properties - particularly its ability to self-improve and the difficulty of controlling its downstream impacts - make such analogies dangerously misleading.\n- ## **Advocating for a Two-Tiered Approach to Cooperation:** Instead, they propose a more nuanced strategy:\n\t- **A Core Alliance of Democracies:** This core group, bound by shared values and strategic interests, would spearhead the development of AGI, prioritising safety, ethics, and responsible deployment.\n\t- **A Broader Coalition with Incentives:** While limiting access to the most sensitive technologies, this broader group, including authoritarian regimes, could benefit from carefully managed access to less powerful AI systems, fostering cooperation and mitigating the risks of uncontrolled proliferation.\n- ## **Secrecy, Espionage, and the Perils of Algorithmic Breakthroughs:**\n\t- **The Data Wall and the Next Paradigm Shift:** The conversation delves into the technical challenges of overcoming the \"data wall\" in AI, where simply scaling up existing approaches might not be sufficient. The guests anticipate a need for fundamental algorithmic breakthroughs, potentially involving sophisticated self-play techniques and novel reinforcement learning architectures.\n\t- **Guarding the Secrets - A New Manhattan Project?:** They stress the paramount importance of safeguarding these breakthroughs from espionage, suggesting that the stakes for AI might rival or even surpass those of the nuclear age.\n\t- **Tacit Knowledge vs. Explicit Code:** While acknowledging the role of talented individuals like Alec Radford, they argue that the most valuable insights might lie not in easily copied code but in the accumulated tacit knowledge and experimental learnings within leading AI labs.\n\t- **Learning from History's Mistakes:** The guests draw lessons from historical cases of parallel invention, such as the development of the atomic bomb, arguing that even small delays can prove decisive in global power dynamics. They highlight the German pursuit of heavy water reactors for their nuclear programme, a technically inferior path chosen due to a crucial scientific insight that the US managed to keep secret, as an example of how even seemingly small advantages can have enormous strategic implications.\n- ## **The Stakes - A World Transformed:**\n\t- **The Return of High-Stakes History:** The episode concludes with a sobering reflection on the potential for AI to fundamentally reshape the global order, potentially ushering in an era of unprecedented technological progress but also fraught with risks.\n\t- **A World of Extremes:** The guests acknowledge the possibility of AI exacerbating existing inequalities, empowering authoritarian regimes, and leading to new forms of conflict.\n\t- **A Call for Wisdom and Urgency:** They emphasise the need for policymakers, researchers, and the public to engage in a thoughtful and informed dialogue about the future of AI, striking a balance between fostering innovation and mitigating risks. The decisions made in the coming years will shape the trajectory of AI and determine whether this transformative technology leads to a brighter future or a more perilous world.",
        "link_types": [
            "Artificial Intelligence",
            "Artificial Superintelligence",
            "Hardware and Edge",
            "Energy and Power",
            "Politics, Law, Privacy"
        ],
        "file_size": 8770
    },
    {
        "id": "RAG.md",
        "name": "RAG",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ### Essential Elements of RAG\n\t- RAG involves retrieval systems and generative models.\n\t- Retrieval systems source relevant external information.\n\t- Generative models create responses using this information.\n- ### Embedding Models in RAG\n\t- Crucial for converting data into vector embeddings.\n\t- Facilitates the storage and retrieval of data in vector form.\n\t- Different types of embeddings for text, images, audio, etc.\n- ### Vector Databases in RAG\n\t- Store vectorized representations of data.\n\t- Enable semantic searches beyond keyword matching.\n\t- Essential for handling large volumes of diverse data types.\n- ### Language Models (LLMs) Integration\n\t- LLMs like GPT are used for generating responses.\n\t- They contextualize the retrieved information.\n\t- LLMs provide the capacity for nuanced and coherent output.\n- ### Data Chunking and Pre-processing\n\t- Involves organizing data into manageable parts for processing.\n\t- Effective chunking improves data retrieval accuracy.\n\t- Overlapping data chunks can enhance context understanding.\n- ### Multimodal Data Handling\n\t- RAG can process diverse data types (text, image, audio).\n\t- Presents computational challenges and potential for errors.\n\t- Requires careful alignment of different data types.\n- ### Optimization and Debugging\n\t- Involves refining the interaction between components.\n\t- Debugging is critical to address hallucinations and inaccuracies.\n\t- Tools for evaluation and observability are essential.\n- ### Applications and Use Cases\n\t- Suitable for complex tasks requiring external data retrieval.\n\t- Used in chatbots, customer service interfaces, and information systems.\n\t- Emerging applications in multimodal contexts (video/image search).\n- ### Current Challenges and Limitations\n\t- Managing computational costs and complexity.\n\t- Addressing issues of compounded hallucinations in multimodal RAGs.\n\t- Balancing storage, computation, and output quality.\n- # Misc\n\t- [Taking RAG apps from POC to Production, Fast - YouTube](https://www.youtube.com/watch?v=WQsN0_eVaEs)\n\t- [AI-Powered Search: Embedding-Based Retrieval and Retrieval-Augmented Generation (RAG) | by Daniel Tunkelang | Apr, 2024 | Medium](https://dtunkelang.medium.com/ai-powered-search-embedding-based-retrieval-and-retrieval-augmented-generation-rag-cabeaba26a8b)\n\t- [AutoRAG documentation (marker-inc-korea.github.io)](https://marker-inc-korea.github.io/AutoRAG/index.html)\n\t- [llmware-ai/llmware: Providing enterprise-grade LLM-based development framework, tools, and fine-tuned models. (github.com)](https://github.com/llmware-ai/llmware) [[Large language models]] [[Infrastructure]] [[RAG]]\n\t- [turbopuffer](https://turbopuffer.com/) [[RAG]] serverless vector database\n\t- Using [[agents]] over [[RAG]] [Forget RAG: Embrace agent design for a more intelligent grounded ChatGPT! | by James Nguyen | Nov, 2023 | Medium](https://james-tn.medium.com/forget-rag-embrace-agent-design-for-a-more-intelligent-grounded-chatgpt-6c562d903c61)\n\t- [[ChatGPT]] threatens the [[RAG]] model with better capabilities [Chat GPT 4 Turbo for Tech Leaders | Medium](https://medium.com/@sivaad/openai-devday-for-executives-will-gpt-4-turbo-kill-traditional-rag-c82748c8feb9)\n\t- [CLI tool](https://www.reddit.com/r/ChatGPTCoding/comments/183qetc/made_a_small_cli_tool_to_create_openai_assistants/) to deploy a [[GPT]] model from a directory of data [[RAG]]\n\t- [VECTORDB](http://vectordb.com) open source [[RAG]] database\n\t- https://nux.ai/guides/chaining-rag-systems [[RAG]]\n\t- Instant RAG from directory agent builder for openai [openai instant assistant](https://github.com/davidgonmar/openai_instant_assistant)\n\t- [[Training and fine tuning]] tiny 1500 line trainer for 8b [[Llama]] [rombodawg/test_dataset_Codellama-3-8B · Hugging Face](https://huggingface.co/rombodawg/test_dataset_Codellama-3-8B)\n\t- [[Large language models]] memory calculator [LLM RAM Calculator by Ray Fernando](https://llm-calc.rayfernando.ai/)\n\t- [[Evaluation and leaderboards]] [Ayumi LLM Evaluation (m8geil.de)](https://ayumi.m8geil.de/)\n\t-\n\t-",
        "link_types": [
            "Large language models",
            "Infrastructure",
            "RAG",
            "RAG",
            "agents",
            "RAG",
            "ChatGPT",
            "RAG",
            "GPT",
            "RAG",
            "RAG",
            "RAG",
            "Training and fine tuning",
            "Llama",
            "Large language models",
            "Evaluation and leaderboards"
        ],
        "file_size": 4091
    },
    {
        "id": "California AI bill.md",
        "name": "California AI bill",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- # Key Concerns\n\t- Several key concerns have emerged regarding the potential implications of SB 1047 on the development and deployment of AI technology:\n\t\t- #### Ambiguity and Potential Overreach\n\t\t\t- The bill's definition of \"frontier models,\" based on computational thresholds and capabilities, introduces a degree of ambiguity that could lead to uncertainty and potential overreach by the regulatory body. The inclusion of models with capabilities similar to those trained with 10^26 flops, even if they require less computational power, creates a grey area that may be subject to interpretation and potential expansion over time.\n\t\t\t- This ambiguity could inadvertently capture a wider range of AI models than initially intended, including those developed by smaller startups and research institutions with limited resources. The resulting compliance burden could stifle innovation and hinder the development of new AI applications.\n\t\t- #### Disproportionate Impact on Startups\n\t\t\t- The regulatory requirements outlined in SB 1047, such as implementing stringent safety standards, conducting extensive testing and evaluations, and establishing robust monitoring systems, may pose significant challenges for resourceconstrained startups. These compliance costs could create barriers to entry and limit the ability of startups to compete with established industry players who possess greater resources and expertise.\n\t\t\t- Furthermore, the bill's focus on computational thresholds and capabilities may inadvertently favour large technology companies with access to vast computational resources. This could exacerbate existing inequalities within the AI landscape and hinder the emergence of new and diverse players.\n\t\t- #### The Open-Source Dilemma\n\t\t\t- While the bill does not explicitly prohibit open-source AI development, concerns remain regarding its potential chilling effect on the open-source community. The provisions regarding liability for downstream modifications of released models could discourage developers from openly sharing their work, particularly if they fear potential legal repercussions for unintended consequences arising from third-party modifications.\n\t\t\t- This apprehension could lead to a reduction in the availability of open-source AI models and code, hindering collaborative research efforts and limiting access to valuable resources for smaller players and academic institutions.\n\t\t- ### The Specter of Regulatory Capture\n\t\t\t- The structure and funding mechanism of the proposed regulatory body, the Frontier Model Division within the California Department of Technology, raise concerns about potential regulatory capture. The division's reliance on fines and fees levied on AI companies creates a financial dependence on the industry it regulates, potentially compromising its objectivity and independence.\n\t\t\t- Moreover, the division's authority to modify key parameters of the bill, such as the computational threshold for frontier models and specific safety standards, introduces further opportunities for regulatory capture. This flexibility, while intended to adapt to the evolving AI landscape, could be exploited by incumbent companies to shape regulations in their favour and solidify their market dominance.\n\t\t- ### Mitigating Risks and Fostering a Balanced Ecosystem\n\t\t\t- To address these concerns and foster a more balanced and inclusive AI ecosystem, several recommendations warrant consideration:\n\t\t\t\t- **Enhancing Clarity and Specificity:** Refining the definition of \"frontier models\" with clear and objective criteria would reduce ambiguity and prevent unintended overreach. This could involve establishing specific benchmarks for capabilities of concern rather than relying solely on computational thresholds.\n\t\t\t\t- **Supporting Startups and New Entrants:** Implementing tiered compliance requirements based on the scale and potential risks associated with different models would alleviate the burden on startups and foster a more equitable regulatory environment. Additionally, providing resources and support mechanisms for startups, such as funding initiatives and technical assistance programmes, would further level the playing field.\n\t\t\t\t- **Ensuring Regulatory Independence:** Exploring alternative funding mechanisms for the Frontier Model Division, such as direct appropriations or public-private partnerships with diverse stakeholders, would reduce the risk of regulatory capture and ensure its impartiality.\n\t\t\t\t- **Promoting Open-Source Collaboration:** Actively supporting and incentivizing open-source AI development through funding initiatives, research collaborations, and knowledge-sharing platforms would counteract any potential chilling effects of the bill and foster a more collaborative and inclusive AI ecosystem.",
        "link_types": [],
        "file_size": 5403
    },
    {
        "id": "Conspiracies.md",
        "name": "Conspiracies",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- Lots of the online communities that glom around the research topics of this book self identify as libertarian, mistrustful of government. To be clear, there are many specific failings they can (and do) point to. It's not the work of this knowledge base to unpick who is right and wrong here. As usual most likely there are no simple solutions, and the trust, as ever, is in the middle. With that said, there a significant pockets of outright conspiracy within these technology communities, and it makes some sense to gather them here.\n- # A grounding: The Paranoid Style in American Politics\n\t- This 1964 [essay by Richard Hofstadter](https://harpers.org/archive/1964/11/the-paranoid-style-in-american-politics/) examines the \"paranoid style\" in American politics, a recurring phenomenon characterised by heated exaggeration, suspicion, and conspiratorial fantasy. Hofstadter argues that this style is not limited to the mentally ill, but rather a mode of expression used by \"more or less normal people\" to advocate for their political views.\n\t- He traces the paranoid style through various historical episodes:\n\t\t- **The Bavarian Illuminati panic:** A fear of a secret society plotting against the United States, linked to the French Revolution and the rise of Jeffersonian democracy.\n\t\t- **Anti-Masonry:** A widespread movement accusing Freemasons of conspiring against republican government and the common man.\n\t\t- **Anti-Catholicism:** A nativist movement fearing a Catholic plot to undermine American values, often fuelled by exaggerated claims of sexual immorality and hidden agendas.\n\t- Hofstadter then analyses the paranoid style in the context of the contemporary right wing, which he sees as feeling \"dispossessed\" and believing in a grand conspiracy to undermine America's values and institutions. Key elements of this contemporary paranoia include:\n\t\t- A long-running conspiracy to destroy free capitalism and install socialism or communism.\n\t\t- The infiltration of government by communist agents, leading to betrayals of national interests.\n\t\t- A widespread network of communist agents influencing education, religion, the press, and the media.\n\t- Hofstadter argues that the paranoid style often involves:\n\t\t- **Apocalyptic thinking:** Seeing the world in terms of absolute good vs. evil, and believing in imminent threats to civilisation.\n\t\t- **Militant leadership:** Rejecting compromise and seeking total victory against the enemy, which is often perceived as inherently evil and unappeasable.\n\t\t- **Projection of self:** Attributing their own desires, fears, and failings to the enemy, who is often depicted as a powerful, sinister, and immoral force.\n\t\t- **Excessive reliance on \"evidence\":** Gathering seemingly factual data to support pre-existing beliefs, often ignoring contradictory evidence and exhibiting a strong resistance to enlightenment.\n\t- Hofstadter opines that 'the paranoid style' is a persistent psychic phenomenon, fuelled by social conflict, a sense of powerlessness, and a lack of access to the political process. It is a self-perpetuating cycle that leads to distorted perceptions and a double suffering: from the real world, and from the individual's own fantasies.\n\t- It is a seminal work in American political thought, sparking significant debate and continuing to resonate in contemporary discussions. While the essay has been lauded for its insightful observations, it also faces criticism for its limitations, particularly in terms of its historical and psychological frameworks.\n\t\t- **The Enduring Nature of the Paranoid Style:** Hofstadter accurately identified the persistent presence of conspiracy theories and paranoid thinking in American politics. This phenomenon, as evidenced by the movements he analysed (anti-Masonry, anti-Catholicism, McCarthyism), continues to manifest in contemporary political discourse, particularly on the right. As sociologist Kathleen B. Jones argues in her book \"Conspiracy Theories: The Paranoid Style in American Politics,\" the paranoid style is a \"recurring theme in American political culture,\" driven by anxieties about social change and perceived threats to existing power structures.\n\t\t- **The Psychological Dynamics of Paranoid Thinking:** Hofstadter astutely observed the projection of fears and anxieties onto an external enemy, the tendency towards apocalyptic thinking, and the reliance on \"evidence\" as a means of bolstering pre-existing beliefs. These psychological mechanisms remain relevant in understanding the motivations and behaviours of those who embrace paranoid narratives, as psychologist Daniel Goleman notes in his book \"Emotional Intelligence,\" where he discusses the role of fear and anxiety in fostering irrational beliefs.\n\t\t- **The Role of Social Conflict:** Hofstadter's analysis highlighted how social conflict, particularly around issues of class, ethnicity, and religion, can fuel the paranoid style. His observation that this style often emerges when individuals feel \"dispossessed\" and shut out of the political process resonates with contemporary research on social movements and political alienation. Sociologist Michael Mann, in his book \"The Dark Side of Democracy: Explaining Ethnic Cleansing,\" argues that feelings of marginalisation and powerlessness can drive individuals to embrace extreme ideologies and engage in violent or destructive actions.\n\t\t- **The Oversimplification of \"Paranoid Style\":** Critics argue that Hofstadter's concept is overly broad and simplistic. The term \"paranoid style\" risks pathologising political beliefs, conflating genuine anxieties with irrational fears, and failing to acknowledge the complexity of political motivations. Political scientist Jeffrey C. Goldfarb, in his article \"The Paranoid Style: A Critical Reassessment,\" argues that Hofstadter's analysis \"overlooks the historical and social context\" of the beliefs he analyses, failing to adequately address the real grievances and anxieties that might fuel paranoid thinking.\n\t\t- **The Focus on Right-Wing Politics:** While Hofstadter acknowledged the paranoid style's potential for both left-wing and right-wing movements, his essay primarily focused on the latter. This focus has led some to argue that his analysis perpetuates a bias towards viewing the right as inherently more prone to irrational thinking. Within the online communities referenced in this graph there are examples of both, but it does tend to skew right. While it's true that the right has historically been associated with more conspiracy theories, this should not be seen as an inherent feature of right-wing ideology. As historian Daniel Rodgers notes in his book \"Age of Fracture,\" conspiracy theories have emerged across the political spectrum throughout history.\n\t\t- **The Lack of Nuance in Psychological Analysis:** While Hofstadter's observations about the psychological mechanisms of paranoia are insightful, his analysis lacks the nuanced understanding of psychological complexity that has emerged in subsequent decades. While he identified common psychological features, he failed to acknowledge the intricate interplay of factors that contribute to paranoia, such as personal experiences, social conditioning, and cultural context.\n\t- # Bitcoin\n\t\t- ## Bitcoin as a culture war foil\n\t\t\t- Bitcoin’s online community skews very hard toward right wing libertarianism. This isn’t to say there are no other voices, but they are certainly outnumbered. This imbalance is almost certainly a product of the ESG concerns around the technology. There has been a notable increase in diversity of thought since the evolution of the energy narrative, but it persists. This leads to a paucity of voices in policymaking circles, and in the USA a strong delineation between policymakers along party lines. This kind of thing tends to be self reinforcing, and it seems very possible that the global liberal left will swing mainly against the technology, while the neoliberal right will be attracted more to it. As tensions increase so it seems does the online rhetoric. Even scientists now seem to agree that Bitcoin investors are calculating psychopaths.[[martin2022dark]] This leads to:\n\t\t- ## Self reinforcing monocultures\n\t\t\t- There are some powerful ‘pockets’ of fringe thinking within the [vocal, online, Bitcoincommunities](https://pourteaux.substack.com/p/bitcoin-culture-burn-it-to-the-ground?).The [mostpalatable](https://www.forbes.com/sites/peterizzo/2022/07/04/bitcoin-maximalism-is-dead-long-live-bitcoin-maximalism/?)of these are figures like [MichaelSaylor](https://www.saylor.org/about/), Elon Musk and Jack Dorsey, but there’s whole subcultural intersections around antivax, anti-woke, anti cancel culture, and fad diets. These are the so-called “[toxicmaximalists](https://blog.lopp.net/history-of-bitcoin-maximalism/)”.There are a disproportionate number of adherents of the failed global “neoliberal” economic experiment,[[va2010neoconservatism]] and not a few outright bigots. Lopp’s list linked above is an amusing roundup:\n\t\t\t\t- Carnivory\n\t\t\t\t- Laser eyes\n\t\t\t\t- Anti-woke\n\t\t\t\t- Weightlifting\n\t\t\t\t- Tradwife culture\n\t\t\t\t- Climate change denial\n\t\t\t\t- Overt Christian moralizing\n\t\t\t\t- “Have fun staying poor” retorts\n\t\t\t\t- Rejection of seed oils and sunscreen\n\t\t\t\t- Vaccine conspiracies, alt-health cure-alls\n\t\t\t\t- Contrarianism for the sake of contrarianism\n\t\t\t\t- Political populism and support of strongmen\n\t\t\t\t- “Fiat” criticism of contemporary art and architecture\n\t\t\t- As Lopp himself points out, it’s not that these things are necessarily wrong or bad, but more that adherence to the set became a purity testf or the whole space. It might seem that this isn’t terribly important, but Bitcoin viewed though the lens of these of these communities looks pretty strange to the newcomer.\n\t- # Artificial Intelligence\n\t\t- ## Effective Altruists vs Effective Accelerationists\n\t\t\t- Recent years have seen the rise of \"tribes of thought\", especially in Silicon Valley in the USA\n\t\t\t- The debate has intensified as AI capabilities have rapidly advanced\n\t\t\t- Concerns about AI safety and risks have grown alongside excitement about AI's potential benefits\n\t\t\t- Roots in long-running philosophical discussions about the risks and benefits of technological progress\n\t\t\t- ```text\n\t\t\t  California legislators, under the influence of Effective Altruism activists, are trying to sneak through a disastrous bill for open-source AI and the technology industry generally.\n\t\t\t  SB 1047 creates an unaccountable Frontier Model Division that will be staffed by EAs with police powers, and which can throw model developers in jail for the thoughtcrime of doing AI research. It’s being fast-tracked through the state Senate. Since many cloud and AI companies are headquartered in California, this will have worldwide impact.\n\t\t\t  ```\n\t\t\t- [Call-To-Action on SB 1047 | Alliance for the Future (affuture.org)](https://www.affuture.org/post/9-context/) [[California AI bill]]\n\t\t\t- [Vinod Khosla on X: \"Open source is good for VC's and innovation. Open Source SOTA models is really bad for national security\" / X (twitter.com)](https://twitter.com/vkhosla/status/1789345720706961838?t=_vgHHgmdky1nU5X5C0SQpg&s=19)\n\t\t\t- {{twitter https://twitter.com/vkhosla/status/1789345720706961838?t=_vgHHgmdky1nU5X5C0SQpg&s=19}}\n\t\t- ### Effective Altruists (EA) / AI Safety Advocates\n\t\t\t- Tend to emphasise caution and safety considerations around AI development\n\t\t\t- Concerned about risks of advanced AI systems causing harm or even existential catastrophe\n\t\t\t- Argue for more research into AI safety and potentially slowing down or regulating AI development\n\t\t\t- Associated with figures like Eliezer Yudkowsky, Paul Christiano, Nick Beckstead\n\t\t\t- Recent appointment of \"AI doomer\" Paul Christiano to head US AI safety institute seen as a win for this camp\n\t\t\t\t- [Feds appoint “AI doomer” to run AI safety at US institute | Ars Technica](https://arstechnica.com/tech-policy/2024/04/feds-appoint-ai-doomer-to-run-us-ai-safety-institute/) [[Politics, Law, Privacy]]\n\t\t\t\t- [AI Safety Is Dead, and Chuck Schumer Faces Risks - Bloomberg](https://www.bloomberg.com/opinion/articles/2024-05-21/ai-safety-is-dead-and-chuck-schumer-faces-risks) [[Safety and alignment]]\n\t\t- ### Effective Accelerationists (EAcc) / AI Risk Sceptics\n\t\t\t- Emphasise the potential benefits of rapid AI progress\n\t\t\t- Tend to be more sceptical of AI safety concerns as blocking human advancement\n\t\t\t- Argue that slowing down AI development could deny humanity massive benefits\n\t\t\t- Associated with figures like \"Beff Bezos\" aka Guillaume Verdon, Daniel Dewey, Nick Land\n\t\t\t- See accelerating AI as part of a broader techno-capitalist imperative to transcend human limitations\n\t\t- ## Geographical and Cultural Factors\n\t\t\t- Debate is especially prominent in San Francisco/Silicon Valley and Oxford/Cambridge\n\t\t\t- EA emerged from philosophy departments, especially Oxford\n\t\t\t- EAcc has roots in Silicon Valley startup and venture capital culture\n\t\t\t- Both have ties to the rationalist community and \"weird\" ideas like thermodynamic intelligence",
        "link_types": [
            "martin2022dark",
            "va2010neoconservatism",
            "California AI bill",
            "Politics, Law, Privacy",
            "Safety and alignment"
        ],
        "file_size": 13147
    },
    {
        "id": "Lightning and Similar L2.md",
        "name": "Lightning and Similar L2",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "icon:: Ξ\n\npublic:: true\n\n- #Public page automatically published\n- # Lightning (Layer 2)\n\t- <iframe src=\"https://mempool.space/graphs/lightning/nodes-networks\" style=\"width: 100%; height: 600px\"></iframe>\n\t-\n\t- ### Lightning (Layer 2)\n\t\t- Lightning was a 2016 proposal by Poon and Dryja,[[poon2016bitcoin]] and is a method for networks of channels of Bitcoin between parties, whichcan transfer value. The main public network is a community drivenliquidity pool which enables scaling and speed improvements for theBitcoin network. It makes Bitcoin more likemoney.[[divakaruni2022lightning]] As with Bitcoin base chain there aremultiple standards and approaches, but within Lightning these are notnecessarily cross compatible with one another, resulting in severalLightning networks. This is to our advantage as innovation is possiblewithin these smaller networks. It is mainly ‘powered’ by [thousands ofvolunteers](https://plebnet.wiki/wiki/Main_Page) who invest in hardwareand lock up their Bitcoin in their nodes, to facilitate peer-to-peertransactions. Zebka et al. found that although the network is “fairlydecentralised” it is more recently skewing to larger more establishednodes.[[zabka2022short]] Though this is a grassroots technology thenature of the design means it can likely be trusted for small scalecommercial applications.\n\t\t- The following text is from [JohnCantrell](https://medium.com/@johncantrell97?p=5cc72f2c664), an engineerwho works on Lightning.\n\t\t- “The Lightning Network is a p2p network of payment channels. A paymentchannel is a contract between two people where they commit funds using asingle onchain tx. Once the funds are committed they can make anunlimited amount of instant & free payments over the channel. You canthink of it as a tab where each person tracks how much money they areowed. Each time a payment is made over the channel both parties updatetheir record of how much money each person has. These updates all happenoff-chain and only the parties involved know about them. When it‘s timeto settle up the two parties can take the final balances of the channeland create a channel closing transaction that will be broadcast onchain. This closing transaction sends each party the final amounts theyare owed. This means for the cost of two on-chain transactions (theopening and closing of the channel) two parties can transact anunlimited number of times and the overall cost of each transactionapproaches zero with every additional transaction they make over thechannel. Payment channels are a great solution for two parties totransact quickly and cheaply but what if we want to be able to sendmoney to anyone in the world quickly and cheaply? This is where theLightning Network comes into play, it‘s a p2p network of these paymentchannels. This means if Alice has a payment channel with Bob and Bob hasa channel with Charlie that Alice can send a payment to Charlie withBob‘s help. This idea can be extended such that you can route a paymentover an arbitrary number of channels until you can reach the entireworld. Routing a payment over multiple channels uses a specific contractcalled a Hash Time Locked Contract (HTLC). It introduces the ability forBob and any other nodes you route through to charge a small fee. Thesefees are typically orders of magnitude smaller than onchain fees. Thisall sounds great but what if someone tries to cheat? I thought the wholepoint of Bitcoin was that we no longer had to trust anyone and it suresounds like there must be some trust in our channel partners to use theLightning Network? The contracts used in Lightning are built to preventfraud while requiring no trust. There is a built-in penalty mechanismwhere if someone tries to cheat and is caught then they lose all oftheir money. This does mean you need to be monitoring the chain forfraud attempts.’’\n\t\t- Lightning is a key scaling innovation in the bitcoin network at thistime. It is seeing rapid development and adoption (Figure<a href=\"#fig:lightningAdoption\" data-reference-type=\"ref\" data-reference=\"fig:lightningAdoption\">3.14</a>).The popular payment app “Cash App” integrates the technology allowinglightning interactions for their 40M users, and ‘Lightning Strike’services the USA, El Salvador, [large parts ofAfrica](https://www.bloomberg.com/news/articles/2022-12-06/nigeria-limits-cash-transactions-to-push-enaira-and-other-payments),and Argentina with zero exchange and transmission fees.\n\t\t- ![image](./assets/a5c28813f38253a04a8cca7fcd73d5e94aec2b73.jpg)\n\t\t- <a href=\"https://www.research.arcane.no/the-state-of-lightning\">Arcane research lightning adoption overview</a>.\n\t\t- It allows for unbound scaling of transactions (millions of transationsper second compared for instance to around 45,000 TPS in the VISAsettlement network). Transaction costs are incredibly low, and thetransaction speed virtually instantaneous.\n\t\t- The most popular lightning software is[LND](https://github.com/lightningnetwork/lnd#readme) from LightningLabs or [C-Lightning](https://github.com/ElementsProject/lightning) fromBlockstream. The software can be run on top of any Bitcoin full node, ina browser extension with a limited node, in a mobile app as a client ora server, or a hybrid such as the Greenlight server [used by Breezwallet](https://medium.com/breez-technology/get-ready-for-a-fresh-breez-multiple-apps-one-node-optimal-ux-519c4daf2536).Different trust implications flow from these choices.\n\t\t- #### Lightning service providers\n\t\t\t- The model of the ‘LSP’ has been refined since it’s first introduction by[Breez in2019](https://medium.com/breez-technology/introducing-lightning-service-providers-fe9fb1665d5f).At their core they provide the following services, at some expense tothe concept of decentalisation of the network.\n\t\t\t- - Payment Channel Management: LSPs may offer users the ability to open and close payment channels on the Lightning Network, as well as manage the routing of payments through these channels.\n\t\t\t- - Liquidity Provision: LSPs may provide liquidity to users on the Lightning Network, allowing them to make and receive payments even when they do not have sufficient funds in their own payment channels.\n\t\t\t- - Node Hosting: LSPs may host Lightning Network nodes on behalf of users, providing them with access to the network without requiring them to maintain their own node.\n\t\t\t- - Payment Processing: LSPs may offer payment processing services, allowing merchants to accept Lightning Network payments from customers.\n\t\t\t- - Wallet Integration: LSPs may integrate Lightning Network functionality into Bitcoin wallets, making it easier for users to access the network and make payments.\n\t\t\t- There are multiple companies experimenting this space now, and it’sunclear how useful the ideas are for our use cases at this time. It’snotable that slashtags (mentioned later as a potential for digitalassets) are themselves an LSP, and that breez have now [introduced aprofit sharingmodel](https://medium.com/breez-technology/the-breez-open-lsp-model-scaling-lightning-by-sharing-roi-with-3rd-party-lsps-e2ef6e31562e)to assist the adoption.\n\t\t- #### Micropayments\n\t\t\t- Possibly the most important affordance of the Lightning network is theconcept of micropayments, and streaming micropayments. It is very simpleto transfer even [one satoshi](https://satsymbol.com/) on Lightning,which is one hundred millionth of a bitcoin, and a small fraction of apenny. This can be a single payment, for a very small goods or service,or a recurring payment on any cadence. This enables streaming paymentsfor any service, or for remittance, or remuneration. These use caseslikely have enormous consequences which are just beginning to beexplored. Nostr users are seemingly have an enormous amount of funsending one another tiny amounts of money for free, in response to goodposts on the new social media and blog platforms designed around theprotocol. This can be seen in Figure<a href=\"#fig:nostrzaps\" data-reference-type=\"ref\" data-reference=\"fig:nostrzaps\">3.15</a>and nostr will be described in more detail later. Integration of thiscapability into metaverse applications will be explored later.\n\t\t\t- ![]./assets/337d80147147707d815ede204e374f69df98402a.png\n\t\t\t- Within weeks of launch thousands of people are pinging micropayments to one another\n\t\t- #### BOLT12 and recurring payments\n\t\t\t- [BOLT12](https://bolt12.org/) is a new and developing ’standard’ whichsimplifies and extends the capability of the network for recurringpayments, but can negotiate single payments too. The example keyring QRcode seen in Figure<a href=\"#fig:bolt12keyring\" data-reference-type=\"ref\" data-reference=\"fig:bolt12keyring\">3.16</a>can be scanned to send single or recurring payments securely andanonymously to the holder.\n\t\t\t   ![]./assets/98f56cc1c370a1e2490d3bad9e691b84ea1e86fd.jpg\n\t\t\t   <a href=\"https://twitter.com/SeedMint21/status/1518934554840600579\">A key fob with a Bolt12 QR code</a>\n\t\t- #### Cashu and Fedimint\n\t\t\t- ##### Cashu\n\t\t\t\t- [[Cashu]] , an implementation of the e-cash mechanism, is an electronic cashsystem that allows users to hold and transfer digital representations ofmoney on their devices. In this system, e-cash is a piece of electronicdata that represents a certain amount of money, such as satoshis in thecase of Bitcoin. Users can send e-cash to others through variousencrypted channels like Telegram or email.\n\t\t\t\t- The concept of e-cash relies on blind signatures, which ensure thattransactions cannot be correlated to specific users, providing a highlevel of privacy. When a user wants to send e-cash, they send the datarepresenting the money to another user. The receiving user then sendsthe e-cash to a server (or mint) to be recycled. This process ensuresthat the e-cash cannot be double-spent. However, the server cannotcorrelate the incoming e-cash to any specific user or transaction.\n\t\t\t\t- Cashu, as a protocol, enables the implementation of this e-cashmechanism and facilitates interoperability among different Cashuwallets. The system is designed to be private, with no user accounts orwallets associated with any central authority. The e-cash is stored inthe user’s browser data, and can be backed up using a seed phrase,similar to traditional cryptocurrency wallets.\n\t\t\t\t- In its current state, Cashu is in its early stages of development and isprimarily intended for experimentation. However, it has the potential toenable a wide range of applications, such as streaming services, whereusers could pay for content on a per-use basis without the need for anaccount, and without the service provider being able to track theirusage. This would allow for greater privacy and flexibility in howpeople interact with online services.\n\t\t\t- ##### Fedimint\n\t\t\t\t- From the [blogpost](https://www.fedi.xyz/blog/introducing-fedi-the-global-bitcoin-adoption-technology)on the Fedi App website; Fedimint is:\n\t\t\t\t\t- - a form of community Bitcoin custody,\n\t\t\t\t\t- - utilising federations (a byzantine fault tolerant multi-sig wallet technology similar to Blockstream’s Liquid network),\n\t\t\t\t\t- - run collectively by groups of trusted community members we call “guardians”,\n\t\t\t\t\t- - for and on behalf of their communities,\n\t\t\t\t\t- - with privacy through Chaumian e-cash,\n\t\t\t\t\t- - and with close integration with the Lightning Network\n\t\t\t\t- Obi Nwosu sees Fedimint as the third vital pillar of the Bitcoinecosystem. If Bitcoin is secure decentralised money, and Lightning isdecentralised payments, then he says [Fedimint is decentralisedcustody](https://bitcoinmagazine.com/technical/fediment-evolution-of-bitcoin-custody)of the Bitcoin asset. The excitement in the community is such that thisprotocol is included in our metaverse stack later. With Fediment a cladeof users within the metaverse would have near perfect transactionalprivacy within their group inside the metaverse.[[chaum1985security]]This could be a potentially huge group of users, and could include AIactors in the scene. Transactions with the outside world could bethrough lightning as already planned.\n\t\t- #### LNBits\n\t\t\t- LNBits is an open source, extensible, Lightning ‘source’ managementsuite. It is self hosted, and can connect to a variety of Lightningwallets, further abstracting the liquidity to provide additionalfunctionality to network users. Remember that all of these tools runwithout a third party, on a £200 setup, hosted at home or within abusiness. The best way to explore this is to describe itsome of theplugins.\n\t\t\t\t- - “[Accounts System](https://github.com/lnbits/lnbits-legend#lnbits-v03-beta-free-and-open-source-lightning-network-walletaccounts-system); Create multiple accounts/wallets. Run for yourself, friends/family, or the whole world!”\n\t\t\t\t- - [Events plugin](https://github.com/lnbits/lnbits-legend/tree/quart/lnbits/extensions/events#events) allows QR code tickets to be created for an event, and for payments to be taken for the tickets.\n\t\t\t\t- - [Jukebox](https://github.com/lnbits/lnbits-legend/tree/quart/lnbits/extensions/jukebox#jukebox) creates a Spotify based jukebox which can be deployed online or in physical locations.\n\t\t\t\t- - [Livestream](https://github.com/lnbits/lnbits-legend/tree/quart/lnbits/extensions/livestream#dj-livestream) provides an interface for online live DJ sets to receive real-time Lightning tips, which can be split automatically in real-time with the music producer.\n\t\t\t\t- - [TPoS](https://github.com/lnbits/lnbits-legend/tree/quart/lnbits/extensions/tpos#tpos), [LNURLPoS](https://github.com/arcbtc/LNURLPoS#lnurlpos) & [OfflineShop](https://github.com/lnbits/lnbits-legend/tree/quart/lnbits/extensions/watchonly#watch-only-wallet) support online [and offline](https://rapaygo.com/) point of sale (Figure <a href=\"#fig:LnBitsPoS\" data-reference-type=\"ref\" data-reference=\"fig:LnBitsPoS\">3.17</a>).\n\t\t\t\t- - [Paywall](https://github.com/lnbits/lnbits-legend/tree/quart/lnbits/extensions/paywall#paywall) creates web access control for content.\n\t\t\t\t- - [LightningTipBot](https://github.com/LightningTipBot/LightningTipBot#lightningtipbot-) is a custodial Lightning wallet and tip handling bot within the popular on Telegram instant messenger service.\n\t\t\t- <span class=\"image\">Two of the many [prebuilt](https://rapaygo.com/) and[kit](https://github.com/arcbtc/LNURLPoS) options for Lightning ‘pointof sale’</span>\n\t\t\t- Together these plugins are incredibly useful primitives which are likelyto be translatable to a multi party collaborative mixed realityapplication. A proposal for building a more specific plugin along theselines is detailed later.\n\t\t\t- bfLnBits is capable of backing every object in a metaverse scene as aneconomic actor, with a key which is compatible with Nostr. This makes itthe best choice and it will likely form the core of the proposedmetaverse stack.\n\t- ### Daric\n\t\t- Lightning isn’t the only solution to layer 2, as evidenced byDaric.[[mirzaei2022daric]] This is a complex and technical proposal whichclaims to improve upon Lightning.\n\t- ### Ark\n\t\t- Ark is a privacy-focused off-chain protocol for bitcoin transactions.Here’s how it compares to existing systems:\n\t\t- Ark vs. Chaumian eCash: Both ensure transaction anonymity, but unlikeeCash, Ark’s transactions are backed by real bitcoins, making themimmune to theft or inflation by the service providers.\n\t\t- Ark vs. Lightning: Similar to the Lightning network, Ark is a liquiditynetwork but without liquidity constraints or direct link between senderand receiver. It uses significantly less on-chain footprint as it lacksconcepts of opening and closing channels.\n\t\t- Ark vs. On-chain: Ark is similar to on-chain wallets in terms of UX,receiving payments asynchronously without introducing liquidityconstraints. However, users must \"refresh\" their coins regularly toavoid service providers sweeping the funds.\n\t\t- Ark vs. Validity Rollups: Ark doesn’t require on-chain data pertransaction, providing higher throughput. Both need a soft-fork on thebase layer, but Ark doesn’t need a soft-fork for the interactiveversion.\n\t\t- Ark service providers can, in theory, double-spend their transactions inmempool. However, it’s counterproductive as recipients can use incomingzero-conf vtxos to pay lightning invoices. If a double-spend occurs, afuture Ark extension can allow users to claim their previously redeemedvtxos. This provides an inbound liquidity-like tradeoff without protocolcompromise.\n\t- ## Liquid federation (layer 2)\n\t\t- Liquid is an implementation on Blockstream[Elements](https://elementsproject.org/), and is itself part of the opensource development contribution of Blockstream, the company started byAdam Back (of hashcash fame) and nearly a dozen other early cypherpunksand luminaries.\n\t\t- The Liquid side chain network, and it’s own attendant Lightning layer 2,is a fork of Bitcoin with different network parameters. In liquid theuser of the network ‘pegs’ into the Bitcoin network, swapping tokens outfrom BTC to L-BTC (this can of course mean very small subunits of 1Bitcoin). Once tokens have been ‘locked’ and swapped to Liquid thedifferent network parameters used in the fork allow a differenttrust/performance trade-off. Liquid is fast on the L1 chain, cheaper touse at this time, and more private. The consensus achieved on this sidechain network is faster because it is a far smaller group of nodeoperators. The next block to be written to the side chain is chosen by anode operated by a member of a federation of dozens of majorcontributors to the Bitcoin technology space. These ‘trusted’ nodes allcheck one another’s security and network operations, meaning that thenetwork is as secure as the aggregate of the trust placed in half of themembership at any one time. There are [stilldozens](https://bitcoinmagazine.com/business/bitcoin-liquid-network-gains-six-new-federation-members)of major companies, development teams, and individual actors, withsignificant reputational investment.\n\t\t- “Federation members contribute to the Liquid Network’s security, gainvoting rights in the board election and membership process, and providevaluable input on the development of new features. Members also benefitfrom the ability to perform a peg-out without a third party, allowingtheir users to convert between L-BTC and BTC seamlessly within theirplatform.”\n\t\t- Crucially for our purposes here Liquid allows tokenised asset transfer.Anyone [canissue](https://docs.blockstream.com/liquid/developer-guide/developer-guide-index.html#issued-assets)an asset on Liquid. Such transfers of assets may be orders of magnitudecheaper than on chain Bitcoin transactions, but still potentially ordersof magnitude more expensive than a simple Lightning transaction of valueon the Bitcoin network.\n\t\t- Blockstream plan to add arbitrary (user generated) token support totheir ‘Core Lightning’ implementation at some point. This would be avery strong choice for specific use cases within an economically enabledmetaverse application. When participants wish to ‘cash out’ of theLiquid network they must do this through one of the federation memberswho activate the other side of the ‘two-way peg’, dispensing theequivalent amount of Bitcoin. This is transparently handled throughBlockstream’s “green wallet”.\n\t\t- All of this has the advantage of a far lower energy footprint comparedto the main chain, but it’s not quite ready with a full suite ofaffordances.\n\t\t- The Liquid network is being used as the underlying asset for a novel newglobal financial product. El Salvador are working with Blockstream toissue a nation state backed bond.\n\t-\n-",
        "link_types": [
            "poon2016bitcoin",
            "divakaruni2022lightning",
            "zabka2022short",
            "Cashu",
            "chaum1985security",
            "mirzaei2022daric"
        ],
        "file_size": 19637
    },
    {
        "id": "RGB.md",
        "name": "RGB",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- RGB and LNP/BP is a smart contract platform that is scalable, private, and interoperable with Bitcoin and Lightning Network. It is possible to issue assets, create NFTs, and run DAOs on RGB.\n- https://twitter.com/Sharp_On_Sats/status/1779818457476825594\n- {{twitter https://twitter.com/Sharp_On_Sats/status/1779818457476825594}}\n- # RGB Protocol Technical Overview\n\t- ## Introduction\n\t\t- The RGB protocol stands as a cornerstone for building and managing smart contracts on blockchain networks, emphasizing privacy, security, and flexibility. This document delves into the intricate mechanics of RGB, covering state validation, contract schemas, and interfaces, alongside practical code examples.\n\t- ## State Validation\n\t\t- RGB employs a dual-layer validation process to ensure the integrity and compliance of contract states:\n\t\t- ![photo_2023-12-05_02-42-41.jpg](../assets/photo_2023-12-05_02-42-41_1713719951228_0.jpg)\n\t- ### Declarative Rules\n\t\t- **Purpose**: Specify the fundamental requirements for state types, ensuring compatibility and correctness.\n\t\t- **Mechanism**: If a state, realized as a binary string, does not conform to its expected type upon deserialization, the contract fails validation.\n\t\t- **Example**: A rule might dictate that the global state of an asset's name cannot accumulate more than one item, preserving uniqueness.\n\t- ### Custom Script Logic\n\t\t- **Purpose**: Allows for complex state validations beyond the scope of declarative rules.\n\t\t- **Mechanism**: Utilizes a virtual machine to inspect and enforce contract-specific conditions, such as verifying transaction IDs within operations.\n\t\t- **Example**: Ensuring the sum of input assets equals the sum of output assets in a transaction, maintaining balance integrity.\n\t- ## Contract Schemas\n\t\t- A schema in RGB defines the structure and rules for a specific type of contract, acting as a blueprint for creating and managing contract instances.\n\t- ### Definition\n\t\t- **Components**: Includes state types, data types for constructing states, permissible operations, and their effects on state.\n\t\t- **Importance**: Separates contract developers from issuers, allowing issuers to create assets based on predefined templates without deep technical knowledge.\n\t- ### Implementation\n\t\t- **Rust Example**: Contracts are typically defined using Rust, providing a robust framework for schema creation.\n\t\t- ```rust\n\t\t      struct ContractSchema {\n\t\t          global_types: Map<TypeIdentifier, TypeName>,\n\t\t          own_types: Map<TypeIdentifier, TypeName>,\n\t\t          // Additional fields defining operations and their structure...\n\t\t      }\n\t\t      ```\n\t\t- **Simplification**: Future iterations aim to simplify schema creation, making it more accessible to non-developers.\n\t- ## Interfaces\n\t\t- Interfaces play a crucial role in making smart contracts accessible and interactable, serving as a bridge between the contract logic and external applications, such as wallets.\n\t- ### Role and Functionality\n\t\t- **Definition**: An interface provides a standardized set of operations and state information, making contracts understandable to external software.\n\t\t- **Examples**: `RGB20` for fungible assets, `RGB21` for NFTs, each defining operations like transfer, issue, or burn.\n\t- ### Implementation and Binding\n\t\t- **Process**: Contract schemas implement specific interfaces, mapping state types and operations to the interface's requirements.\n\t\t- ```rust\n\t\t      impl Interface for MyContractSchema {\n\t\t          // Mapping schema types to interface definitions...\n\t\t      }\n\t\t      ```\n\t- ## Practical Considerations\n\t\t- ### Code Snippets\n\t\t- Rust is predominantly used for defining schemas and interfaces within the RGB ecosystem. The following snippet outlines a basic schema definition:\n\t\t- This schema defines two states: one for the asset's name as a global state and another for its precision as an own state.\n\t\t- ```rust\n\t\t  const ASSET_NAME: GlobalState = 1;\n\t\t  const ASSET_PRECISION: OwnState = 2;\n\t\t  - let schema = ContractSchema {\n\t\t    global_types: Map::new()\n\t\t        .insert(ASSET_NAME, \"String\"),\n\t\t    own_types: Map::new()\n\t\t        .insert(ASSET_PRECISION, \"u8\"),\n\t\t    // Additional schema setup...\n\t\t  };\n\t\t  ```\n\t- ### Challenges\n\t\t- **Complexity**: The dual-layer validation and the depth of schema definitions can be daunting for new developers.\n\t\t- **Flexibility vs. Standardization**: Balancing the need for flexible contract logic with the benefits of standardized interfaces and operations.\n\t- ### Opportunities\n\t\t- **Advancements in Interface Design**: Streamlining interface creation to encourage broader adoption and more innovative contract designs.\n\t\t- **Educational Resources**: Developing comprehensive guides and tools to lower the entry barrier for new RGB developers.\n\t- ## Conclusion\n\t\t- The RGB protocol offers a sophisticated framework for creating and managing smart contracts, with a focus on security, privacy, and interoperability. Through its dual-layer validation, detailed contract schemas, and user-friendly interfaces, RGB is poised to facilitate a new era of smart contract development on blockchain networks.\n- # Standards\n\t- Terms and standards explained clearly on the RGB legal page [RGB glossary, part I · RGB-WG · Discussion #52 (github.com)](https://github.com/orgs/RGB-WG/discussions/52)\n\t- [e17 The Bitcoin Contracting Layer\n\t\t- RGB with Maxim Orlovsky by Down The Rabbit Hole With Kaz (spotify.com)](https://podcasters.spotify.com/pod/show/dtrhole/episodes/e17-The-Bitcoin-Contracting-Layer---RGB-with-Maxim-Orlovsky-eqdfh6)\n\t- [Samara Asset Group (samara-ag.com)](https://www.samara-ag.com/market-insights/rgb-protocol)\n\t- ![image.png](../assets/image_1707514470498_0.png)\n- ## Links\n\t- [RGB FAQ](https://rgbfaq.com/faq)\n\t\t- Frequently asked questions about the RGB protocol\n\t- [RGB Tech](https://rgb.tech)\n\t\t- Technical information and resources for the RGB protocol\n\t- [RGB Blackpaper](https://blackpaper.rgb.tech)\n\t\t- Comprehensive technical document describing the RGB protocol\n\t- [RGB Spec](https://spec.rgb.tech)\n\t\t- Specifications for the RGB protocol\n\t- [LNP/BP Standards](https://standards.lnp-bp.org)\n\t\t- List of specifications for the LNP/BP protocol suite\n\t- [AluVM](https://aluvm.org)\n\t\t- Information about the AluVM virtual machine for smart contracts\n\t- [Strict Types](https://strict-types.org)\n\t\t- Documentation for the Strict Types programming language\n\t- [Contractum](https://contractum.org)\n\t\t- Resources related to smart contracts on the RGB protocol\n\t- [RGB Working Group GitHub](https://github.com/RGB-WG)\n\t\t- GitHub organization for the RGB protocol working group\n\t- [RGB Protocol Subreddit](http://reddit.com/r/RGB_protocol/)\n\t\t- Subreddit for discussions about the RGB protocol\n\t- [RGB Protocol Twitter Community](https://twitter.com/i/communities/1585365616743022595)\n\t\t- Twitter community for the RGB protocol\n\t- [LNP/BP Twitter](https://twitter.com/lnp_bp)\n\t\t- Official Twitter account for the LNP/BP project\n\t- [RGB Telegram](https://t.me/rgbtelegram)\n\t\t- Telegram channel for the RGB protocol\n\t- [LNP/BP Telegram](https://t.me/lnp_bp)\n\t\t- Telegram channel for the LNP/BP project\n\t- [RGB Developer Calls](https://rgbfaq.com)\n\t\t- Information about developer calls for the RGB protocol\n\t- [LNP/BP Developer Calls GitHub](https://github.com/LNP-BP/devcalls)\n\t\t- GitHub repository for LNP/BP developer calls\n\t- [LNP/BP Developer Calls Wiki](https://github.com/LNP-BP/devcalls/wiki/Devcalls)\n\t\t- Wiki for LNP/BP developer calls\n\t- [LNP/BP YouTube Channel](https://youtube.com/@lnp_bp)\n\t\t- Official YouTube channel for the LNP/BP project\n\t- [LNP/BP Presentation Slides](https://github.com/LNP-BP/presentations/tree/master/Presentation%20slides)\n\t\t- Repository containing presentation slides for the LNP/BP project\n\t- [LNP/BP GitHub](https://github.com/LNP-BP)\n\t\t- Main GitHub organization for the LNP/BP project\n\t- [BP Working Group GitHub](https://github.com/BP-WG)\n\t\t- GitHub organization for the BP (Bitcoin Protocol) working group\n\t- [LNP Working Group GitHub](https://github.com/LNP-WG)\n\t\t- GitHub organization for the LNP (Lightning Network Protocol) working group\n\t- [Storm Working Group GitHub](https://github.com/Storm-WG)\n\t\t- GitHub organization for the Storm working group, focused on Layer 3 protocols and applications\n\t- Hexa wallet https://play.google.com/store/apps/details?id=io.hexawallet.hexa2\n\t- Bitlight wallet\n\t- Bitmask\n\t- DIBA\n\t- Pandora\n\t- Also there is at least two DEXes (one is Kaleidoswap which was demoed last week on Tuscany Lightning Summit), two asset marketplaces, explorer and stablecoin\n\t\t- everything required to bootstrap the ecosystem",
        "link_types": [],
        "file_size": 8692
    },
    {
        "id": "Anthropic Claude.md",
        "name": "Anthropic Claude",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- [Allie K. Miller on X: \"This is wild. In just 25 seconds, Claude 3.5 Sonnet coded a fully functional Mancala web app for me 🕹️ I only provided ONE screenshot of the game's instructions. It did the rest: - Coded the entire game - Previewed it so I could test - Provided rules of play https://t.co/WLweZUGt5C\" / X](https://x.com/alliekmiller/status/1803818951706579307)\n- {{tweet https://x.com/alliekmiller/status/1803818951706579307}}\n- [Pietro Schirano on X: \"Claude 3.5 Sonnet + Maestro = Sparks of AGI? I asked to make a Mario clone using just geometric shapes, and the wildest part is that it gave the character animations as well, and the shapes seem like novel concepts. It took 3 minutes. Look at the game! https://t.co/YVQYp7m5Ed\" / X](https://x.com/skirano/status/1803809495811858807)\n- {{tweet https://x.com/skirano/status/1803809495811858807}}\n- {{video https://www.youtube.com/watch?v=rHqk0ZGb6qo&}}\n- [twitter link to the render loading below](https://twitter.com/rowancheung/status/1766849250292351327)\n  {{twitter https://twitter.com/rowancheung/status/1766849250292351327}}\n\t- [Prompt library (anthropic.com)](https://docs.anthropic.com/claude/prompt-library)\n-\n- {{video https://www.youtube.com/watch?v=hqfjvkYt2YA}}\n-\n- [Model_Card_Claude_3.pdf (anthropic.com)](https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf)\n-",
        "link_types": [],
        "file_size": 1398
    },
    {
        "id": "license.md",
        "name": "license",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- [John O'Hare LogSeq Knowledge Base](https://www.narrativegoldmine.com) by [John O'Hare](http://www.linkedin.com/in/jjohare) is marked with [CC0 1.0](https://creativecommons.org/publicdomain/zero/1.0/?ref=chooser-v1) ![CC Icon](https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1)",
        "link_types": [],
        "file_size": 356
    },
    {
        "id": "Robin Hanson.md",
        "name": "Robin Hanson",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- AI, the Economy, and the Future of Work:\n\t- Robin Hanson, economist, author, and a leading voice on futurism, is a famous naysayer about the medium term potential of AI and automation. While he does believe in AI that is capable of replacing and exceeding human capability, he is stanchly of the opinion that it's not generalisable in the short term and that humanity is heading for significant slowdown and fallback due to demographics.\n\t- This scans with my feeling that in the main people are NOT adopting these AI tools en masse because of habits and simply intertie.\n\t- He offers thought-provoking perspectives on the potential impact of Artificial Intelligence on society and the economy, With a focus on his book Age of Em and the blog \"Overcoming Bias,\" Hanson's insights challenge conventional narratives about AI and its applications, but I wonder how much his research is simply convoluted with the slump in innovation due to the [[Lead Poisoning Hypothesis]].\n- <iframe src=\"https://www.overcomingbias.com/\" style=\"width: 100%; height: 600px\"></iframe>\n- Hanson's Measured Approach to AI Progress\n\t- Despite the excitement surrounding recent AI advancements, including those of Google's Gemini 1.5, Hanson expresses a measure of skepticism about the imminent arrival of transformative AI (often termed Artificial General Intelligence or AGI). He observes a historical pattern of overestimating the immediate impact of new AI paradigms, highlighting the importance of a long-term and factual approach to assessing AI progress.\n\t- Hanson emphasizes that the question of AI feasibility is a separate one from AI integration and adoption. He cites his son's software firm's experiences with language models, illustrating the challenges of adapting human workflows to effectively leverage AI tools. This underscores the gap between AI potential and the behavioural changes needed for its successful deployment.\n\t- The talks about \"rot\" as potentially evergreen problem (also see [How complex systems fail](https://www.researchgate.net/publication/228797158_How_complex_systems_fail))\n- The Growth Trajectory\n\t- Hanson does envision a future where AI plays a pivotal role in driving economic growth, potentially mitigating the challenges of population decline. He believes AI could take over many human jobs, supporting economic expansion even in the face of demographic shifts. Hanson's book Age of Em further explores this idea, contemplating a future where brain emulations enhance human labour and reshape economic systems. He sees it as between 60 and 90 years away.\n- Economic Disruptions and Adaptations\n\t- The discussion of AI naturally leads to its economic implications, both for individual businesses and society as a whole. Hanson stresses the need to understand broader economic shifts when predicting how the labor market might change in response to AI. While acknowledging the potential for disruption, Hanson believes the process will likely be incremental, with a need for continuous adaptation by individuals and organizations.\n- Insights Grounded in Perspectives\n\t- At the heart of these discussions lies Hanson's calculated timeline of 60 to 90 years for achieving full, human-level AI. This timeframe, however, is not merely a guess; it reflects Hanson's ongoing analysis of AI progress and challenges. The ongoing advancement of powerful AI models like Gemini 1.5 prompts continuous reevaluation of how AI development might reshape our understanding of AI timelines and societal impact.\n\t- Hanson's insights extend beyond core AI development into areas where AI's influence may reshape our world. Here are a few key aspects of the wide-ranging discussion:\n\t- AI's Uncertain Timeline: Hanson acknowledges how breakthroughs in AI research could disrupt his forecasts but remains cautious about the rapid attainment of AGI.\n\t- The Innovation Pause: Hanson suggests a possible pause in innovation due to demographic shifts, potentially influencing the timeline of AI development. Regulation and Adaptation: The integration of AI technologies into domains such as medicine raises legal and regulatory hurdles, which will need to be addressed alongside societal acceptance.",
        "link_types": [
            "Lead Poisoning Hypothesis"
        ],
        "file_size": 4255
    },
    {
        "id": "Blockchain.md",
        "name": "Blockchain",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # A Quick History\n\t- The 1980s saw the emergence of the [[cypherpunk]] activist movement, as a reaction to the emerging [[Surveillance]] state,[[burnham1983rise; @chaum1985security]] a topic which is expanded in [[Surveillance]] and [[Global Inequality]] . These early computer scientists in the USA saw the intersectionality between information, computation, economics, and personal freedom.[[lavoie1990prefatory]] Online discussion in the early nineties foresaw the emergence of trans-national digital markets, what would become the WWW.[[salinCosts; @cypherPunkMailList]] The issues of privacy and the exchange of digital value (digital /ecash) were of foremost importance within these discussions and while privacy was within reach thanks to [“public/private keypairs”](https://www.openpgp.org/about/history/), ecash proved to be amore difficult problem.\n\t- Adam Back’s 1997 ‘hashcash’[[back2002hashcash]] paved the way for later work by implementing the concept of what would become ‘proof of work.’[[dwork1992pricing; @jakobsson1999proofs]] This was built upon by Dai,[[dai1998b]] Szabo,[[szabo1997formalizing]]Finney,[[callas1998openpgp]] and Nakamoto amongst others. In all it took16 years of collaboration on the mailing lists (and dozens of failed attempts) to attack the problem of trust-minimised, distributed, digital cash. The culmination of these attempts was Bitcoin.[[Nakamoto2008]]\n\t- This is illustrated by Dan Held.\n\t\t- ![image](./assets/10392f6889e4be99247a0cf832f5628e3b017f5e.jpg){:width 800}\n\t- Dan Held: <a href=\"https://www.danheld.com/blog/2019/1/6/planting-bitcoinsoil-34\">Bitcoin prehistory</a> used with permission.\n- This is now a wider ecosystem of technologies and societal challenges.\n\t- ![image](./assets/2f03939e7360fa432ab47028bf32284b0088e385.jpg){:width 600}\n\t\t- {{twitter https://twitter.com/djvalerieblove/status/1514703620272394243/}}\n\t\t- used with permission @djvalerieblove.\n- There is enormous complexity and scope, as seen in below, and yet genuinely useful products are elusive.\n\t- ![image](./assets/c157c8cd52e86b9bf30f9c4a5e5a28b226027ce5.png){width 800}\n- ### Definition\n\t- Distributed ledger technology (DLT) is a data structure distributed across multiple managing stakeholders. A subset of DLT is blockchain, which is a less efficient, immutable data structure with a slightly different trust model. Rauchs et al. of the Cambridge Centre for Alternative Finance provide a detailed taxonomy and conceptual framework.[[rauchs2018distributed]] It can be seen in their paper that the definitions are somewhat unclear in literature.\n\t- It is surprisingly hard to pin down a simple explanation for the features which define a blockchain. These “key takeaway” [from Investopedia](https://www.investopedia.com/terms/b/blockchain.asp) are a neat summary.\n\t\t- Blockchain is a specific type of database.\n\t\t- It differs from a typical database in the way it stores information; blockchains store data in blocks that are then chained together.\n\t\t- As new data comes in it is entered into a fresh block. Once the block is [filled with data](https://bits.monospace.live/) it is chained onto the previous block, which makes the data chained together in chronological order.\n\t\t- Different types of information can be stored on a blockchain but the most common use so far has been as a ledger for transactions.\n\t\t- In Bitcoin’s case, blockchain is used in a decentralized way so that no single person or group has control—rather, all users collectively retain control.\n\t\t- Decentralized blockchains are “append only”. In effect this means that the data entered becomes irreversible over time. For Bitcoin, this means that simple economic transactions are permanently recorded and viewable to anyone.\n- It can be argued that the whole concept of distributed cryptographic blockchains is [somewhat strained](https://www.trailofbits.com/reports/Unintended_Centralities_in_Distributed_Ledgers.pdf), as the vast majority of the technology offerings are not distributed, and worse, meaningful distribution may indeed be practically impossible without a trusted third party.[[kwon2019impossibility]] “There are many scenarios where [traditional databases](https://calpaterson.com/blockchain.html) should be used instead”[[casino2019systematic]].\n- There are thousands of different ‘chains’ and many more tokens which represent value on them. A majority of these are code forks of earlier projects. Most [are defunct](https://99bitcoins.com/deadcoins/) yet still have some residual ‘value’ locked up in them as a function of their ‘distributed’ tokens.\n- Because the space is comparatively new, subject to [scant regulation](https://www.esma.europa.eu/press-news/consultations/call-evidence-dlt-pilot-regime), and often open source, it is possible to clone a github, change a few lines of code, and front it with a website in order to create ‘scams’, and this happens frequently.[[golumbia2020cryptocurrency]]\n- The technology and the global legislative response are somewhat immature, and misapplications of both technologies are commonplace.\n- ## What’s this for sorry?\n\t- In principle blockchains provide a **differentiated trust model**. With a properly distributed system a blockchain can be considered “trust-minimised”, though certainly not risk minimised. This is important for some, but not all people. There is not much emboldening of text within this book. If you start to question the whole reason for this ‘global technology revolution’ then it always comes back to those three words. Put more crispy it’s been hiding in plain sight since 20008as ‘Magic Internet Money’. Perhaps the lack of a trusted third party, and the potential for instant final settlement will be most important for machine to machine (AI) systems, and that is the primary focus of this book.\n\t- Within DLT/blockchain there seem to be as many opinions on the value of the technology as there are implementations. A host of well engineered open source code repositories makes the cost of adoption relatively low.\n\t- The proponents of blockchains argue, that in an era when data breaches and corporate financial insolvency intersect with a collapse in trust of institutions, it is perhaps useful to have an alternative model for storage of data, and value. That seems like a lot of effort for a questionable gain, and much of this can be achieved through [[Public Key Encryption]] infrastructure. It’s far more likely it’s simply speculation.\n\t- While building this knowledgebase, the question of ‘what is this really, for and how can it possibly be worth it’, came up again and again. In truth it’s a very difficult question, without a clear enough answer. It’s beyond the scope of this book to figure this out properly, but references to advantages and disadvantages will be made throughout.\n\t- It seems that the engineers who created Bitcoin wanted very much to  solve a technical problem they saw with money (from their understanding of it), and the transmission of money digitally. As the scale and scope have increased so has the [narrative evolved](https://medium.com/@nic__carter/visions-of-bitcoin-4b7b7cbcd24c), but it’s never really kept pace with the level of the questions posed.\n\t\t- ![](https://miro.medium.com/v2/resize:fit:2000/1*QL4Q8voNWowjMhhL4s9RCg.png){:width 800}\n\t- A cost benefit analysis that excludes speculative gains seems to fail for pretty much all of blockchain/DLT. Bitcoin is more subtle as possibly can circumvent the legacy financial systems. This still leaves huge questions. To quote others in the space, is Bitcoin now the iceberg or the life raft?\n\t- For the most developed defence of the technology as it stands in from a Western perspective, in this moment, Gladstein ([and others](https://www.financialinclusion.tech/)) offer a vision for the asset class, in the 87% of the world he says don’t have access to the technology infrastructure benefits enjoyed by the developed west [[gladsteincheck2022]].\n\t- ![image](./assets/0d0f88a6cb8e0fae03c63d3de7e5112e314a926a.jpg){:width 800}\n\t- He points to Block and Wakefield Research’s report which finds those living under financially oppressive regimes are the most optimistic about the technology. This argument is suggestive of huge and untapped markets for services which may be accessible to developed nations through telepresence/metaverse interfaces, and which may increase equity of access to opportunity elsewhere. To put some figures against this:\n\t\t- Near [half a billion](https://triple-a.io/cryptocurrency-ownership-data/) crypto users globally\n\t\t- 90 Million People Use Cryptocurrency in Nigeria - [Report](https://investorsking.com/2023/03/08/90-million-people-use-cryptocurrency-in-nigeria-reports/). Nigeria has the highest number of crypto owners in the world in 2022 with 45% of its population owning or using cryptocurrency.\n\t\t- Thailand occupies the second space with 44% of its population reported to be using or owning cryptocurrency.\n\t\t- Turkey has 40% of its population owning and using cryptocurrency in 2022, equal to over 33 million people.\n\t\t- Argentina occupies the fourth position with an ownership and usage rate of 35% in 2022, representing almost 16 million people.\n\t\t- United Arab Emirates has 34% of the population owning or using cryptocurrency in 2022, representing almost 10 million people.\n\t\t- Philippines is ranked sixth with a 29% adoption rate.\n\t\t- ![image](./assets/78d091423a60bbb19d0d5b70d6f756dea814671b.jpg){:width 600}\n\t\t-\n\t- Gladstein’s is a carefully developed and well researched book, but is [written from the western perspective](https://bitcoinmagazine.com/culture/imf-world-bank-repress-poor-countries)of (just) Bitcoin ‘being the raft’. Later in this book we will consider if it might be the iceberg, but this is not the domain expertise weoffer in this book. It is crucial to note that Gladstein has vociferous detractors within Africa. It seems entirely possible he’s anothergrifter as suggested by Kimani:\n\t\t- Gladstein is a charlatan who makes his living by selling the image of a global south that is corrupt, entirely lacking in rational thinking and needing a saviour, like him to swoop in and save us from our floundering selves. He exploits on tired and unproven stereotypes, cherry picks data while ignoring mountains of evidence that disprove him. Because he knows that as the perceived “morally superior” “right thinking” western superior coming to save, he will mostly go unchallenged. It’s a grift, an old grift that many like him have turned into an industry. Where they earn tax free income by selling a delusion and fetish to their western audience who need to think the global south is a failure of the human experience. He is trying to set himself up as some gate keeper and king maker in the Global South. He knows that the next phase of growth is. So he wants to make sure that westerners looking to invest in the global south see him as some “expert” and ask for his unfounded opinions. People like him run global morality extortion rings. How so? Simple: By purporting to know and be the keeper of global south morality, he will use his words to bless or curse your business, well, unless you make a generous donation to his foundation. These are scare tactics employed by charlatans to run tax-evading PR entities, thinly veiled as “human rights” organisations. If you are not on his side, he will slander you and your organisation. If you ensure you promote him and his ambitions, he anoints you as the good guy! He is trying to play the role that the Vatican and other corrupt religious organisations played in the 1800. Turning morality into a commodity that can be purchased from his market place: We decide who is good and who is bad and who can do business and who can’t. For a“ donation”. He is not the first and he will not be the last. It’s a growing industry, driven by shrewd westerners who know that they can sell racial stereotypes back home, but as long as they claim they are the one’s helping or saving the coloured peoples from themselves.”\n\t- [Raoul Pal of RealVision](https://dailyhodl.com/2022/05/04/crypto-winter-unlikely-as-astonishing-user-growth-dwarfs-internet-adoption-rate-macro-guru-raoul-pal/) says:\n\t\t- Crypto adoption is now massively outperforming the internet. It’s been growing at about 165% a year versus 85% for the internet for the same period of time now. According to analytics company Chainalysis; growth is fastest in the Middle east and North Africa.\n\t\t- ![image](./assets/4f2b5f5a0b5a45bfd512d93df8887d7bf26ef8cf.png){:width 600}\n\t- Thanks to a natural fit with strong encryption, and innate resistance to censorship by external parties, these systems do lend themselves well to ‘borderless’ applications, and are somewhat resistant to global regulation (for good or ill). Given the rates of adoption, it seems that this stuff is coming regardless of their usefulness to the developed world. If we are to take this as a given then we can perhaps logically infer that finding a use case for the technology is important, somewhat irrespective of other arguments.\n\t- ![image](./assets/0d6b1c37a883aee67adc0fe27f1b91ab8b0c94ed.jpg){:width 800}\n\t- ![image](./assets/1faa49460091dce2ec328e3494bd4ef77a54c8bc.jpg){:width 600}\n\t-\n\t- #### Machine to machine communication\n\t\t- It is likely best considered as a pivotal enabling technology strand which compliments [[Public Key Encryption]] infrastructure. This broad technology, which emerged from the [[cypherpunk]] movement, gives us the encryption we value on the internet today. It is likely going to be essential in a world where [[Artificial Intelligence]], [[Deepfakes and fraudulent content]] are rife.\n\t\t- A financial instrument which can pass rapidly from computer to computer, AI agent to AI agent, and bounce around ‘in the cloud’ doing real work and activity is where Bitcoin may possibly being to add real global utility. This is such a new field, and better left for the AI section at the end. This seed of an idea provides us a lever to explore for digital society around the asset, and this will be the focus.\n\t\t- It seems very likely that AI [[Agents]] will be a major benefactor of Blockchain, likely mainly using [[Stable Coins]] on various chains. It is our belief that this will increasingly trend toward a purely [[Bitcoin Value Proposition]] over time.\n\t\t- This thesis of a somewhat inevitable digital bearer instrument, with utility for instant work by [[Artificial Superintelligence]], deployed at global scale for maximal equity of opportunity, is the focus of our analysis. It is explored in detail in:\n\t\t\t- [[Bitcoin Technical Overview]]\n\t\t\t\t- [[Bitcoin Mining and Energy]]\n\t\t\t- [[Bitcoin Value Proposition]]\n\t\t\t\t- [[Bitcoin As Money]]\n\t\t\t\t- [[Agents]]\n\t\t\t\t- [[Agentic Metaverse for Global Creatives]]\n\t\t\t\t- [[Agentic Mycelia]]\n\t\t- and the complementary risks sections\n\t\t\t- [[Bitcoin Environmental Issues]]\n\t\t\t- [[Digital Asset Risks]]\n-",
        "link_types": [
            "cypherpunk",
            "Surveillance",
            "burnham1983rise; @chaum1985security",
            "Surveillance",
            "Global Inequality",
            "lavoie1990prefatory",
            "salinCosts; @cypherPunkMailList",
            "back2002hashcash",
            "dwork1992pricing; @jakobsson1999proofs",
            "dai1998b",
            "szabo1997formalizing",
            "callas1998openpgp",
            "Nakamoto2008",
            "rauchs2018distributed",
            "kwon2019impossibility",
            "casino2019systematic",
            "golumbia2020cryptocurrency",
            "Public Key Encryption",
            "gladsteincheck2022",
            "Public Key Encryption",
            "cypherpunk",
            "Artificial Intelligence",
            "Deepfakes and fraudulent content",
            "Agents",
            "Stable Coins",
            "Bitcoin Value Proposition",
            "Artificial Superintelligence",
            "Bitcoin Technical Overview",
            "Bitcoin Mining and Energy",
            "Bitcoin Value Proposition",
            "Bitcoin As Money",
            "Agents",
            "Agentic Metaverse for Global Creatives",
            "Agentic Mycelia",
            "Bitcoin Environmental Issues",
            "Digital Asset Risks"
        ],
        "file_size": 15109
    },
    {
        "id": "SLAM.md",
        "name": "SLAM",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- Simultaneous location and mapping, usually with a single lens these days.\n- [Photo-SLAM: Real-time Simultaneous Localization and Photorealistic Mapping for Monocular, Stereo, and RGB-D Cameras (huajianup.github.io)](https://huajianup.github.io/research/Photo-SLAM/)  incredible realtime SLAM\n-\n-",
        "link_types": [],
        "file_size": 312
    },
    {
        "id": "Training and fine tuning.md",
        "name": "Training and fine tuning",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # Training and Refining Large Language Models\n  \n  Large Language Models (LLMs), such as the GPT series, have significantly advanced the field of Natural Language Processing (NLP) by generating human-like text, translating languages, and answering questions. The development of these models involves a multi-stage process, including data collection, preprocessing, training, fine-tuning, and advanced refinement techniques to enhance performance and alignment with human preferences.\n- ## Data Collection and Preprocessing\n\t- The training of LLMs starts with the collection of vast datasets from diverse sources such as books, articles, and code, which is crucial for the model's knowledge and fluency. Following collection, the data undergoes preprocessing to remove irrelevant elements like HTML tags and tokenize the text using techniques such as Byte-Pair Encoding (BPE) [Byte-Pair Encoding (BPE): https://en.wikipedia.org/wiki/Byte_pair_encoding], ensuring the model can efficiently process the information.\n- ## Model Training\n\t- ### Pre-Training\n\t\t- LLMs, typically based on the Transformer architecture [Transformer Architecture: https://arxiv.org/abs/1706.03762], are initialized with random weights. They are then trained unsupervised to predict the next word or masked words in sentences, a process that helps them learn the underlying patterns of language [Masked Language Modeling: https://arxiv.org/abs/1810.04805].\n\t- ### Supervised Fine-Tuning\n\t\t- For specific tasks like question-answering or translation, LLMs are fine-tuned with labeled datasets, adjusting the model's weights to optimize performance on these tasks.\n- ## Advanced Refinement Techniques\n\t- To further improve their alignment with human preferences, LLMs undergo additional refinement:\n\t- ### Reinforcement Learning from Human Feedback (RLHF)\n\t\t- Human-rated outputs train a reward model, and reinforcement learning techniques fine-tune the LLM to maximize these rewards, enhancing output quality [RLHF: https://arxiv.org/abs/1706.03762].\n\t- ### Decision Transformers based on Preference-Ordering (DPO)\n\t\t- Decision models, trained on human preference data, guide the LLM towards preferred outputs, incorporating logic that reflects learned preferences [Decision Transformers: https://arxiv.org/abs/2106.01345].\n\t- ### In-context Learning and Retrieval-Augmented Generation (RAG)\n\t\t- LLMs demonstrate the ability to adapt to new tasks with minimal examples (few-shot learning) and can enhance their responses with information retrieved from databases or document collections for improved accuracy [Few-Shot Learning: https://arxiv.org/abs/2005.14165; RAG: https://arxiv.org/abs/2005.11401].\n- ## Deployment and Continuous Improvement\n\t- Once deployed, LLMs are continuously improved through cycles of user feedback and performance monitoring using techniques like RLHF and DPO, aiming to enhance capabilities and alignment with user needs.\n- ## Additional Considerations\n\t- It is increasingly clear that the input data quality is of huge importance. Even duplicated high quality data can significantly impact responses. There are also considerations regarding data sources, specialized applications such as domain adaptation, and the integration of multimodal data for broader applications [Domain Adaptation: https://aclanthology.org/2020.acl-main.357/; Multimodal LLMs: https://arxiv.org/abs/2202.07724].\n\t- Moreover, the potential for further refinement techniques like safety and alignment measures, knowledge distillation for model efficiency, and the use of benchmarks for evaluation is highlighted, suggesting areas for future expansion and research [Knowledge Distillation: https://arxiv.org/abs/1503.02531; SuperGLUE Benchmark: https://super.gluebenchmark.com/].\n- ## Semantic Annotation and Knowledge Graphs\n\t- LLMs benefit from training on semantically annotated datasets and knowledge graphs, facilitating a deeper understanding of language and knowledge representation. Incorporating structured knowledge from sources like WordNet or DBpedia can significantly enhance model capabilities [WordNet: Miller, G. A. (1995). Communications of the ACM; DBpedia: Lehmann, J., et al. (2015). Semantic Web].\n\t- There are challenges in maintaining ontology quality and consistency, the need for adaptability in ontologies, and directions for future research.",
        "link_types": [],
        "file_size": 4404
    },
    {
        "id": "Distributed Identity.md",
        "name": "Distributed Identity",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n- For distributed Web3, and by extension metaverse applications toflourish it is necessary to solve the identificationproblem.[[king1966fisher]] Without a [solution tothis](https://joshgans.medium.com/web3-isnt-going-to-work-without-identification-6aa776d674)bots, scammers, and AI actors will reduce usefulness and usability ofand already quite arcane user experience.\n- This page is an oddity because most of traditional DID/SSI isn't really fit for purpose. Distributed self sovereign identity has a great elevator pitch though. Individuals should be empowered through technology to manage their own data, without manipulation or exploitation by centralised corporate behemoths. In practice it’s a staggeringly complex proposition which increases risk to the individual,decreases convenience, and despite much work, does not even make muchsense in it’s own terms. Webs of trust are viable so this means Nostr,[Marking](https://github.com/project-bitmark/marking/wiki#marking), orSlashtags which will be discussed, but are early products.\n- ## Applications of DID/SSI\n\t- Some of the likely, and discussed applications for DID/SSI are the moreinherently private and personally valuable sets of data an individualmight generate throughout their life. The theory is that subsets of suchdata could then be digitally revealed by the individual when required,and that cryptographic verification built into the system wouldguarantee the veracity of the data to the receiving party. It is alsopossible to make use of “zero-knowledge proof” such that assertions canbe made about about the contents of the data without revealing the dataitself. A good example of this an age verification challenge, where athreshold age could be asserted without necessarily revealing the dateof birth. Other keystone uses of the technology are:\n\t\t- Health documents history\n\t\t- Qualifications and certifications\n\t\t- Financial record and relationships with those of others\n\t\t- Contacts, connections to other people and their appropriate data, including things like shared and personal calendars\n\t- It’s also possible to extend this key management ethos to all logincredentials, and all data currently stored on centralised servers. Thisis the tension discussed in the chapter about Web3. Proponents thinkthat using something like a DID/SSI stack to manage encryption,decryption and access to data within cloud services gives the user thebest of all worlds. They see simply logging in with a cryptographicwallet, and using that same public/private key pair to manage the databeyond as some kind of panacea. This is very complex stuff though, andit seems very likely they just haven’t thought this through enough.\n- ## Classic DID/SSI\n\t- Distributed identity / self sovereign identity has been extensivelyresearched for decades, with hundreds of peer reviewed papers, andextensive support from the [world wide webconsortium](https://www.w3.org/TR/did-core/). The academic field nowseems quite ossified and has settled on a couple of hundred ‘schema’which they feel underpin the next layer of development. It is a [complexfield](https://medium.com/decentralized-identity/overview-of-decentralized-identity-standards-f82efd9ab6c7),and the language and diagrams are arcane and self referential.\n\t- ![Figure 5.1: Part of the DID SSI specs](../assets/did.jpg)\n\t- Moreover the minimal implementation of such proposed systems hints ata [federated model](https://www.w3.org/community/perma-id/) of[centralised/federated‘truth’](https://github.com/w3c/vc-data-model/issues/947#issuecomment-1276186406)to enable persistence of identifiers over time.  The major failing of the DID/SSI work to date is a lack of meaningfuluse cases with incentives for adoption.\n\t- This is clearly explained byLockwood[[lockwood2021exploring]] who proposes that the pathway toadoption of ‘classic’ DID/SSI requires an incentive over and above thecurrent identity management on the web. Being distributed is not enough.Especially in the light of questionable assurances of this even beingtrue.\n\t- Perhaps most concerning is this [recentexchange](https://lists.w3.org/Archives/Public/public-credentials/2022Mar/thread.html) on the mailing lists. Here, two long standing developers of DID say the following:  it“Not a single entity I know that’s doing production deployments hasactually vetted did:ion and found it to be production capable. This goes for every DLT-based DID Method out there\n\t\t- even the one we’re working on. I am highly sceptical of anyone that says that any DID Method is ready for production usage at present.  Agreed — as one of the proponents of DLTs (in particular permissionless public ones) none are mature enough yet for production.”. It seems then that we can rule out use of these technologies?\n\t- ### DID principles\n\t\t- The core principles of distributed identity are that there should bepersistent identifiers, like real world documents which assert identity,but with extended use cases. These should be permanent, and resolvableeverywhere, forever. Underpinning this is cryptographically verifiableand decentralised data, managed by the user, or their trusted proxy. Asprimitives this makes them lifetime digital assets, that are portable,and unconfiscatable, with no required reliance on a trusted third party.By this stage in the book you should be familiar with these concepts,but application of this fundamental mindset to all personal data anddigital interactions is a bigger reach even than money and value.\n\t\t- #### What’s in a DID document?\n\t\t- All classic DID is underpinned by a DID document what bootstrap theservices it’s connected to. It is made up of one or more public keys.The documents can make use of services such as timestamps, cryptographicsignatures, proofs, delegations, and authorisations. They should containthe minimum amount of information to accomplish the specific taskrequired of them.\n\t- ### Federated social media trust\n\t\t- This section about newer technologies is perhaps best [summarised byJackDorsey](https://www.getrevue.co/profile/jackjack/issues/a-native-internet-protocol-for-social-media-1503112?via=twitter-card&client=DesktopWeb&element=issue-card),ex CEO of twitter, paraphrased here:\n\t\t\t- \"I’ll start with the principles I’ve come to believe based on everything I’ve learned and experienced through my past actions as a Twitter co-founder and Lead:\n\t\t\t\t- Social media must be resilient to corporate and government control.\n\t\t\t\t- Only the original author may remove content they produce.\n\t\t\t\t- Moderation is best implemented by algorithmic choice.\n\t\t\t- The biggest mistake I made was continuing to invest in building tools for us to manage the public conversation versus building tools for the people using Twitter to easily manage it for themselves this burdened the company with too much power and opened us to significant outside pressure such as advertising budgets. I generally think companies have become far too powerful. The only way I know of to truly live up tot hese three principles is a free and open protocol for social media that is not owned by a single company or group of companies and is resilient to corporate and government influence the problem today is that we have companies who own both the protocol and discovery of content which ultimately puts one person in charge of what’s available and seen or not this is by definition a single point of failure no matter how great the person and over time will fracture the public conversation and may lead to more control by governments and corporations around the world.\"\n\t\t- The following technologies were selected for this book long beforeDorsey wrote those words, but they itare the technologies in which he isinvesting his time and money to further those 3 principles. Keybase isan interesting example of how proofs ont he internet can lean upon oneanother to provide a corpus of trusts. It provides a model of [importingproofs](https://book.keybase.io/account#proofs) from various socialmedia sites. This allows importing of reputation into new ecosystems.\n\t- ### RGB SSI\n\t\t- [ssi/README.md at master · LNP-BP/ssi (github.com)](https://github.com/LNP-BP/ssi/blob/master/README.md)\n\t- ### Microstrategy Inscription based DID\n\t\t- [did:btc Method Specification (microstrategy.github.io)](https://microstrategy.github.io/did-btc-spec/)\n\t- ### Lightning\n\t\t- It is possible to log into a website using only Lighting, as in [StackerNews](https://stacker.news/login?callbackUrl=https://stacker.news/).\n\t- ### Web5, Bluesky, & Microsoft ION\n\t\t- Promisingly Jack Dorsey’s company TBD is working on a project [called“Web5”](https://developer.tbd.website/projects/web5/). Details are scantbut the promise is decentralised and/or self hosted data and identityrunning on Bitcoin, without recourse to a new token. it“Componentsinclude decentralized identifiers (DIDs), decentralized web node (DWNs),self-sovereign identity service (SSIS) and a self-sovereign identitysoftware development kit (ssi-sdk)”.\n\t\t- Web5 leverages the ION identity stack. All this looks to be exactly whatour metaverse system requires, but the complexity is likely to be quitehigh as it is to be built on existing DID/SSI research which is prettycomplex and perhaps has problems.\n\t\t- They readily admit they [do not have a workingsolution](https://atproto.com/guides/identity) at this time: it“Atpresent, none of the DID methods meet our standards fully. Many existingDID networks are permissionless blockchains which achieve the abovegoals but with relatively poor latency (ION takes roughly 20 minutes forcommitment finality). Therefore we have chosen to support did-web and atemporary method we’ve created called did-placeholder. We expect thissituation to evolve as new solutions emerge.”\n\t\t- #### ION\n\t\t- While working at Microsoft on ION Daniel Buchner (now working at Square)or Henry Tsai [said thefollowing](https://github.com/decentralized-identity/ion/blob/master/docs/Q-and-A.md),which is worth quoting verbatim:\n\t\t\t- “While ledger-based consensus systems, on the surface, would seem toprovide the same general features as one another, there are a few keydifferences that make some more suitable for critical applications, likethe decentralized identifiers of human beings. Some of theseconsiderations and features are:\n\t\t\t\t- The system must be open and permissionless, not a cabal of authorities who can exclude and remove participants.\n\t\t\t\t- The system must be well-tested, and proven secure against attack over a long enough duration to be confident in.\n\t\t\t\t- The system must produce a singular, independently verifiable record that is as immutable as possible, so that reversing the record the system produces is infeasible.\n\t\t\t\t- The system must be widely deployed, with nodes that span the globe, to ensure the record is persisted.\n\t\t\t\t- The system must be self-incentivized, so that nodes continue to operate, process, and secure the record over time. The value from operation must come from the system directly, because outside incentive reliance is itself a vector for attack.\n\t\t\t\t- The cost to attack the system through any game theoretically available means must be high enough that it is infeasible to attempt, and even if an ultra-capitalized attacker did, it would require a weaponized mobilization of force and resources that would be obvious, with options for mitigation.\n\t\t\t\t- The outcome:\n\t\t\t\t\t- Number 1 eliminates private and permissioned ledgers\n\t\t\t\t\t- Number 2 eliminates just about all other ledgers and blockchains, simply because they are inadequately tested\n\t\t\t\t\t- For the metrics detailed in 3-6, Bitcoin is so far beyond all other options, it isn’t even close\n\t\t- Bitcoin is the most secure option by an absurdly large margin.”\n\t\t- On the surface then it might seem that the choice is Bitcoin again, and indeed that the open source Microsoft ION stack is a natural choice, but it’s complex to run, the interactions with the blockchain have a cost implication which can’t be surmounted without every user owning some Bitcoin, and as we have seen, there is no formal validation of this system. In addition (in the current implementation) an identity proof does not need to be published to be valid, just timestamped. In this way an identity can be stolen and used years later to claim later chains of proof. It seems that it might be somewhat useful ‘at scale’ and is worth additional monitoring and investigation, especially given it’s integration into TBD\n\t\t- Web5.\n\t- ### Slashtags\n\t\t- Slashtags is a distributed identity open method being developed by Bitfinex and Tether under the Synonym suite. It’s origins date back to2011 and was initially seeded through academia, and government innovation grants to build on the concepts of BitTorrent, and later [DAT](https://dat-ecosystem.org/timeline.html). This eventually became the Hypercore protocol, with an additional rebranding to Holepunch in2021. It is essentially this system, a mobile app UX, and Bitcoin integration which forms the Synonym/Slashtags stack. There is a lot ofhistorical investment, new focus, and promising product design in theSynonym ecosystem which is forming about the this ‘web of trust’distributed data system. The suite will rely on Pear Credits to enableTether dollars to be passed around within the system. This may fosteradoption in emerging markets. The critical path nature of the Tetherintegration, and the complex intermingling of Synonym, Hypercore,Bitfinex, Tether, and Pear credits are potentially red flags, and thoughthe technology stack is quite interesting only Pear Credit are reallyuseful to our design.\n\t- ### CivKit\n\t\t- CivKit, short for Civilization Kit, is an upcoming white paper from[Commerceblock](https://www.commerceblock.com/), discussing adecentralized and unstoppable free market solution based on Bitcoin. Theproject aims to build on top of Bitcoin to create an environment whereanyone can trade anything with anyone else.\n\t\t- Phase one focuses on creating a marketplace built on top of Nostr, aninteroperable communication protocol. This allows different serviceslike Paxful, HODL HODL, or Nostr app to communicate and operate acrosseach other.\n\t\t- Phase two aims to develop a mobile-friendly lightning wallet anddecentralized IDs (Know Your Peer) to replace centralized KYC (Know YourCustomer). This will provide a more secure and private environment fortraders.\n\t\t- CivKit is intended to be an open-source decentralized toolkit thatvarious brands and platforms can build on top of. The goal is tofacilitate peer-to-peer trading and encourage a more circular economywhere people earn and spend Bitcoin rather than buying and selling it.While details are sparse it seems possible that this technology can beintegrated into our systems.\n\t- ### Nostr\n\t\t- Nostr (pronounced no-star) is a [decentralized openprotocol](https://www.nostr.how/) that aims to improve the social mediaexperience by addressing issues of censorship and data collection. Theprotocol operates by allowing users to post and view notes on serverscalled relays, and view and post these notes through apps calledclients. The open nature of the protocol allows for competition and afree flow of information, as users can choose to use different relays orclients if they are censored. This is because the protocol isdecentralized and controlled by no one.\n\t\t- The decentralized nature of Nostr means that there is no centralauthority that can control the flow of information. This is achievedthrough the use of relays and clients, which are run by differentindividuals or entities. Users have the freedom to choose which relaysand clients they want to use, and as a result, their feeds are populatedwith content from the people they choose to follow. If a relay or clienttries to censor a user, they can simply switch to a different one. Thisis a major advantage over traditional centralized social media platformswhere one entity holds all the control over the flow of information andcan censor or manipulate the content that users see.\n\t\t- Nostr is also not beholden to shareholders or investors. This means thatthe protocol can make decisions that prioritize the well-being andquality of discourse for users, rather than solely focusing on profit.This is in contrast to traditional social media networks like Twitter,Facebook, and TikTok, which are driven by the need to collect data onusers and sell ads to generate revenue. In these centralized platforms,users’ data is collected, analyzed and sold to the highest bidder, oftenwithout the user’s knowledge or consent. Nostr, on the other hand,allows users to have more control over their data and the ability tomonetize their content.\n\t\t- Nostr also tightly integrates Bitcoin Lightning to support the protocol.This will hopefully enable secure transmission of value alongside theinformation and interactions on the platform. It also gives users theability to monetise their content.\n\t\t- This potential step-change improvement to the social media experiencefor everyday people addresses issues of censorship and data collection.\n\t\t- Nostr is “The simplest open protocol that is able to create acensorship-resistant global \"social\" network once and for all.”according to it’s [github page](https://github.com/fiatjaf/nostr). Morethan that it’s a client side validated proof of who a user isinteracting with, hence being in this identity section. To be clear,it’s not a completely peer to peer system in that it uses (very dumb)relay servers, but this gives it some of the best characteristics ofboth paradigms. This has the following advantages for our metaverseapplication;\n\t\t\t- it’s lightweight, with minimal network overhead and complexity\n\t\t\t- it’s real-time using websockets\n\t\t\t- anyone can run a relay server, so one can be run in the deployment in the final section of the book.\n\t\t\t- Each of the client peers connecting to the metaverse can be a relay and able to pass messages and proofs to the other clients without the metaverse server seeing the data or being online\n\t\t\t- it’s open-source\n\t\t\t- it is itself [Turing Complete](https://snort.social/e/note1evkdgcg0dw8ckyqsqhnk4wy55h7w97twjf8etcq2tr9sv5urlszqjc9p6v) and therefore able to execute any code within it’s message protocol\n\t\t\t- there are multiple usable libraries and tools\n\t\t\t- it’s under active development with an excellent team. The lead, ‘Fiatjaf’ is one of the most [prolific developers](https://github.com/fiatjaf) in the lightning space.\n\t\t\t- it’s based on the same underlying cryptographic technology we are using elsewhere, indeed with it’s use of Bitcoin keys the identity system is global\n\t\t\t- it provides the identity proof that we need to validate users and objects into a virtual space\n\t\t\t- it enables message passing\n\t\t\t- it scales to be a social network as required\n\t\t\t- it need not rely on anything outside of a relay hosted on the metaverse server\n\t\t\t- it can be scaled to provide one to many bulletin board style applications within the metaverse\n\t\t\t- we can use it in private, group, and public modes as required\n\t\t\t- it integrates with the torrent network allowing storage and external referencing of arbitrary data\n\t\t\t- it can easily operate outside of the walled garden of the metaverse, extending the reach of the messages\n\t\t- [Nostr is incredibly promising](https://www.forbes.com/sites/rogerhuang/2022/12/29/nostr-is-the-decentralized-protocol-that-might-replace-elon-musks-twitter/),and integrating these relays in the metaverse servers and clients of theproposed technology stack in this book might allow us globally provableidentity, with privacy by design. It can provide message passing. If allentities in the collaborative mixed reality scenegraphs are also Nostrkey pairs then schema can be applied consistently with the economiclayer using the same key system as Bitcoin. Nostr has just received asubstantial grant from Dorsey. It is core to the design later in thebook. A curated list of projects and libraries is [available ongithub](https://github.com/aljazceru/awesome-nostr).\n\t\t- Luke Childs [says](https://github.com/nostr-protocol/nips/issues/154):\n\t\t\t- “Nostr makes a good candidate to be used as a very simple DID layer.Having \"Login with Nostr\" auth on websites solves a lot of problems in avery elegant way, and Nostr’s main use case as a social network protocolmakes it highly suited to be used as your main identity proving key.Compare \"Login with Nostr\" to similar \"Login with Lightning\"(LNURL-auth) specs to see some easy and obvious advantages:  Remote signer vs local signer  Login with Lightning requires access to remote keys, login with Nostrrequires access to local keys ideally stored in a browser extension. Dueto the way Lightning works you can only really have one instance. Youneed all your client devices linked to a single Lightning node, thismeans most clients will be connecting to the signer remotely. Now ifyour Lightning node goes down or you lose your connection you also can’tauth with any service. This could cause circular dependencies where youlose the connection to your Lightning node so you can’t auth with theservices you need to access to debug the issue with your Lightning nodelike your hosting provider or VPN account. You could technically solvethis by replicating your LN keys to other client devices only to be usedfor local auth signing but that introduces other risks.  Unique identifier vs identity  A Lightning node is not really an identity but a unique identifier. Itjust tells you the person that auths is the same random person thatauthed last time, it doesn’t tell you who they are. A nostr pubkey is anidentity. It tells you who they are, what their name is, what they looklike, who they know, how you can pay them, how you can message them.  This is much more useful as an identity layer for an application. Theapplication can show their profile picture, username, send secure crossplatform push notifications via NIP-04 encrypted Nostr DMs, etc.  Consistent identity across services  Lightning pubkeys are sensitive private information and can leakconfidential financial information, Nostr pubkeys are safe to share withanyone. LNURL-auth adds extra steps to solve this by creating derivedsubkeys for identities that are unique to each service you auth with.This does not seem ideal, it seems the default case is that an identityis something that you do want to follow you across all your accounts.Nostr based auth behaves more appropriate in this regard. In the rarecase you need to achieve privacy and separation between certain servicesyou can still do that by using use a throwaway Nostr key for thoseservices.  User relationships across services Since authing with Nostr shares areal social identity with the service, they can also see your Nostrsocial graph. This could be useful for connecting you to people youalready know on the new service.  Low cost identity  Ideally identities should be easy to create but hard to build upreputation to limit spam while avoiding excluding people from thenetwork. It’s not clear that it will be cost effective / scalable foreveryone to run their own Lightning node so tying individual identity toa single Lightning node pubkey is problematic. Nostr keys are easy tocreate and hard reputation can be earned via PoW/DNS or building astrong social graph.”\n- ### Micropayment based web\n- It seems the war against disinformation is now being lost. Much iswritten in the media about Deepfake technology creating plausible fakevideos, but probably more pernicious is the use of toolkits to createentire plausible fake news sites using natural language AI such as GPT3.This makes it cheap to publish potentially market moving news which isthen rehypothecated by online news vendors who are hungry for clicks. Asthese pipelines become more mature it will be difficult to keep fakenews for financial or political gain out of the system. One interestingway to do this that itisn’t webs of trust or true cryptographic identityis to charge micropayments for “one to many” publication models. Thiswould imply a tiny instant payment for clicks, especially on socialmedia sites such as twitter. This kind of model has been discussed butis only possible in the context of systems such as Lightning whereinstant micropayment can be realised. It seems possible that this wouldprice out speculative ‘noise’ spam from the information space. It’sinteresting and ironic that the origin of proof of work was to underpinjust such a spam defeating system,[[dwork1992pricing]] and that Nakamoto[mentioned this application forBitcoin](https://www.metzdowd.com/pipermail/cryptography/2009-January/015014.html)back in 2009. There is now much chatter about the integration of Bitcoinwith Twitter in light of Musks buyout of the social network.\n- ![]./assets/68114e388f76f1dc94eb3a6205c2c1dbee1c9f7a.jpg\n-\n- ![Figure 5.3: Comparison of distributed file stores](../assets/files.jpg)\n- # Continuity is close on:\n\t- web \n\t  -> webid (identity) \n\t  -> solid (social) -> solid lite (lite,modern,working \n\t  -> nosdav (add nostr, and mastodon etc.)\n-\n- Repeat section?\n-\n- Distributed Identity & Trust----------------------------\n- For distributed Web3, and by extension metaverse applications toflourish it is necessary to solve the identificationproblem.[[king1966fisher]] Without a [solution tothis](https://joshgans.medium.com/web3-isnt-going-to-work-without-identification-6aa776d674)bots, scammers, and AI actors will reduce usefulness and usability ofand already quite arcane user experience.\n- This chapter is an oddity because most of traditional DID/SSI isn’treally fit for purpose. Distributed self sovereign identity has a greatelevator pitch though. Individuals should be empowered throughtechnology to manage their own data, without manipulation orexploitation by centralised corporate behemoths. In practice it’s astaggeringly complex proposition which increases risk to the individual,decreases convenience, and despite much work, does not even make muchsense in it’s own terms. Webs of trust are viable so this means Nostr,[Marking](https://github.com/project-bitmark/marking/wiki#marking), orSlashtags which will be discussed, but are early products.\n- ### Applications of DID/SSI\n- Some of the likely, and discussed applications for DID/SSI are the moreinherently private and personally valuable sets of data an individualmight generate throughout their life. The theory is that subsets of suchdata could then be digitally revealed by the individual when required,and that cryptographic verification built into the system wouldguarantee the veracity of the data to the receiving party. It is alsopossible to make use of “zero-knowledge proof” such that assertions canbe made about about the contents of the data without revealing the dataitself. A good example of this an age verification challenge, where athreshold age could be asserted without necessarily revealing the dateof birth. Other keystone uses of the technology are:\n-\n\t- health documents history\n-\n\t- qualifications and certifications\n-\n\t- financial record and relationships with those of others\n-\n\t- contacts, connections to other people and their appropriate data, including things like shared and personal calendars\n- It’s also possible to extend this key management ethos to all logincredentials, and all data currently stored on centralised servers. Thisis the tension discussed in the chapter about Web3. Proponents thinkthat using something like a DID/SSI stack to manage encryption,decryption and access to data within cloud services gives the user thebest of all worlds. They see simply logging in with a cryptographicwallet, and using that same public/private key pair to manage the databeyond as some kind of panacea. This is very complex stuff though, andit seems very likely they just haven’t thought this through enough.\n- ### Classic DID/SSI\n- Distributed identity / self sovereign identity has been extensivelyresearched for decades, with hundreds of peer reviewed papers, andextensive support from the [world wide webconsortium](https://www.w3.org/TR/did-core/). The academic field nowseems quite ossified and has settled on a couple of hundred ‘schema’which they feel underpin the next layer of development. It is a [complexfield](https://medium.com/decentralized-identity/overview-of-decentralized-identity-standards-f82efd9ab6c7),and the language and diagrams are arcane and self referential as seen inFigure<a href=\"#fig:DID\" data-reference-type=\"ref\" data-reference=\"fig:DID\">5.1</a>.\n- <span class=\"image\">Part of the DID SSI specs</span>\n- . Moreover the minimal implementation of such proposed systems hints ata [federated model](https://www.w3.org/community/perma-id/) of[centralised/federated‘truth’](https://github.com/w3c/vc-data-model/issues/947#issuecomment-1276186406)to enable persistence of identifiers over time.  The major failing of the DID/SSI work to date is a lack of meaningfuluse cases with incentives for adoption. This is clearly explained byLockwood[[lockwood2021exploring]] who proposes that the pathway toadoption of ‘classic’ DID/SSI requires an incentive over and above thecurrent identity management on the web. Being distributed is not enough.Especially in the light of questionable assurances of this even beingtrue.  Perhaps most concerning is this [recentexchange](https://lists.w3.org/Archives/Public/public-credentials/2022Mar/thread.html)on the mailing lists. Here, two long standing developers of DID say thefollowing:  it“Not a single entity I know that’s doing production deployments hasactually vetted did:ion and found it to be production capable. This goesfor every DLT-based DID Method out there\n\t- even the one we’re workingon. I am highly sceptical of anyone that says that any DID Method isready for production usage at present.  Agreed — as one of the proponents of DLTs (in particular permissionlesspublic ones) none are mature enough yet for production.”. It seems thenthat we can rule out use of these technologies?\n- ##### DID principles\n- The core principles of distributed identity are that there should bepersistent identifiers, like real world documents which assert identity,but with extended use cases. These should be permanent, and resolvableeverywhere, forever. Underpinning this is cryptographically verifiableand decentralised data, managed by the user, or their trusted proxy. Asprimitives this makes them lifetime digital assets, that are portable,and unconfiscatable, with no required reliance on a trusted third party.By this stage in the book you should be familiar with these concepts,but application of this fundamental mindset to all personal data anddigital interactions is a bigger reach even than money and value.\n- ##### What’s in a DID document?\n- All classic DID is underpinned by a DID document what bootstrap theservices it’s connected to. It is made up of one or more public keys.The documents can make use of services such as timestamps, cryptographicsignatures, proofs, delegations, and authorisations. They should containthe minimum amount of information to accomplish the specific taskrequired of them.\n- ### Federated social media trust\n- This section about newer technologies is perhaps best [summarised byJackDorsey](https://www.getrevue.co/profile/jackjack/issues/a-native-internet-protocol-for-social-media-1503112?via=twitter-card&client=DesktopWeb&element=issue-card),ex CEO of twitter, paraphrased here:  it\n- “I’ll start with the principles I’ve come to believe based on everythingI’ve learned and experienced through my past actions as a Twitterco-founder and Lead:\n-\n\t- Social media must be resilient to corporate and government control.\n-\n\t- Only the original author may remove content they produce.\n-\n\t- Moderation is best implemented by algorithmic choice.\n- The biggest mistake I made was continuing to invest in building toolsfor us to manage the public conversation versus building tools for thepeople using Twitter to easily manage it for themselves this burdenedthe company with too much power and opened us to significant outsidepressure such as advertising budgets. I generally think companies havebecome far too powerful. The only way I know of to truly live up tothese three principles is a free and open protocol for social media thatis not owned by a single company or group of companies and is resilientto corporate and government influence the problem today is that we havecompanies who own both the protocol and discovery of content whichultimately puts one person in charge of what’s available and seen or notthis is by definition a single point of failure no matter how great theperson and over time will fracture the public conversation and may leadto more control by governments and corporations around the world.\n- The following technologies were selected for this book long beforeDorsey wrote those words, but they itare the technologies in which he isinvesting his time and money to further those 3 principles. Keybase isan interesting example of how proofs ont he internet can lean upon oneanother to provide a corpus of trusts. It provides a model of [importingproofs](https://book.keybase.io/account#proofs) from various socialmedia sites. This allows importing of reputation into new ecosystems.\n- #### Lightning\n- It is possible to log into a website using only Lighting, as in [StackerNews](https://stacker.news/login?callbackUrl=https://stacker.news/).\n- #### Web5, Bluesky, & Microsoft ION\n- Promisingly Jack Dorsey’s company TBD is working on a project [called“Web5”](https://developer.tbd.website/projects/web5/). Details are scantbut the promise is decentralised and/or self hosted data and identityrunning on Bitcoin, without recourse to a new token. it“Componentsinclude decentralized identifiers (DIDs), decentralized web node (DWNs),self-sovereign identity service (SSIS) and a self-sovereign identitysoftware development kit (ssi-sdk)”.\n- Web5 leverages the ION identity stack. All this looks to be exactly whatour metaverse system requires, but the complexity is likely to be quitehigh as it is to be built on existing DID/SSI research which is prettycomplex and perhaps has problems.\n- They readily admit they [do not have a workingsolution](https://atproto.com/guides/identity) at this time: it“Atpresent, none of the DID methods meet our standards fully. Many existingDID networks are permissionless blockchains which achieve the abovegoals but with relatively poor latency (ION takes roughly 20 minutes forcommitment finality). Therefore we have chosen to support did-web and atemporary method we’ve created called did-placeholder. We expect thissituation to evolve as new solutions emerge.”\n- ##### ION\n- While working at Microsoft on ION Daniel Buchner (now working at Square)or Henry Tsai [said thefollowing](https://github.com/decentralized-identity/ion/blob/master/docs/Q-and-A.md),which is worth quoting verbatim:\n- “While ledger-based consensus systems, on the surface, would seem toprovide the same general features as one another, there are a few keydifferences that make some more suitable for critical applications, likethe decentralized identifiers of human beings. Some of theseconsiderations and features are:\n-\n\t- The system must be open and permissionless, not a cabal of authorities who can exclude and remove participants.\n-\n\t- The system must be well-tested, and proven secure against attack over a long enough duration to be confident in.\n-\n\t- The system must produce a singular, independently verifiable record that is as immutable as possible, so that reversing the record the system produces is infeasible.\n-\n\t- The system must be widely deployed, with nodes that span the globe, to ensure the record is persisted.\n-\n\t- The system must be self-incentivized, so that nodes continue to operate, process, and secure the record over time. The value from operation must come from the system directly, because outside incentive reliance is itself a vector for attack.\n-\n\t- The cost to attack the system through any game theoretically available means must be high enough that it is infeasible to attempt, and even if an ultra-capitalized attacker did, it would require a weaponized mobilization of force and resources that would be obvious, with options for mitigation.\n- The outcome:\n-\n\t- Number 1 eliminates private and permissioned ledgers\n-\n\t- Number 2 eliminates just about all other ledgers and blockchains, simply because they are inadequately tested\n-\n\t- For the metrics detailed in 3-6, Bitcoin is so far beyond all other options, it isn’t even close\n\t- Bitcoin is the most secure option by an absurdly large margin.”\n- On the surface then it might seem that the choice is Bitcoin again, andindeed that the open source Microsoft ION stack is a natural choice, butit’s complex to run, the interactions with the blockchain have a costimplication which can’t be surmounted without every user owning someBitcoin, and as we have seen, there is no formal validation of thissystem. In addition (in the current implementation) an identity proofdoes not need to be published to be valid, just timestamped. In this wayan identity can be stolen and used years later to claim later chains ofproof. It seems that it might be somewhat useful ‘at scale’ and is worthadditional monitoring and investigation, especially given it’sintegration into TBD\n\t- Web5.\n- #### Slashtags\n- Slashtags is a distributed identity open method being developed byBitfinex and Tether under the Synonym suite. It’s origins date back to2011 and was initially seeded through academia, and governmentinnovation grants to build on the concepts of BitTorrent, and later[DAT](https://dat-ecosystem.org/timeline.html). This eventually becamethe Hypercore protocol, with an additional rebranding to Holepunch in2021. It is essentially this system, a mobile app UX, and Bitcoinintegration which forms the Synonym/Slashtags stack. There is a lot ofhistorical investment, new focus, and promising product design in theSynonym ecosystem which is forming about the this ‘web of trust’distributed data system. The suite will rely on Pear Credits to enableTether dollars to be passed around within the system. This may fosteradoption in emerging markets. The critical path nature of the Tetherintegration, and the complex intermingling of Synonym, Hypercore,Bitfinex, Tether, and Pear credits are potentially red flags, and thoughthe technology stack is quite interesting only Pear Credit are reallyuseful to our design.\n- #### CivKit\n- CivKit, short for Civilization Kit, is an upcoming white paper from[Commerceblock](https://www.commerceblock.com/), discussing adecentralized and unstoppable free market solution based on Bitcoin. Theproject aims to build on top of Bitcoin to create an environment whereanyone can trade anything with anyone else.\n- Phase one focuses on creating a marketplace built on top of Nostr, aninteroperable communication protocol. This allows different serviceslike Paxful, HODL HODL, or Nostr app to communicate and operate acrosseach other.\n- Phase two aims to develop a mobile-friendly lightning wallet anddecentralized IDs (Know Your Peer) to replace centralized KYC (Know YourCustomer). This will provide a more secure and private environment fortraders.\n- CivKit is intended to be an open-source decentralized toolkit thatvarious brands and platforms can build on top of. The goal is tofacilitate peer-to-peer trading and encourage a more circular economywhere people earn and spend Bitcoin rather than buying and selling it.While details are sparse it seems possible that this technology can beintegrated into our systems.\n- #### Nostr\n- Nostr \\[pronounced no-star\\] is a [decentralized openprotocol](https://www.nostr.how/) that aims to improve the social mediaexperience by addressing issues of censorship and data collection. Theprotocol operates by allowing users to post and view notes on serverscalled relays, and view and post these notes through apps calledclients. The open nature of the protocol allows for competition and afree flow of information, as users can choose to use different relays orclients if they are censored. This is because the protocol isdecentralized and controlled by no one.\n- The decentralized nature of Nostr means that there is no centralauthority that can control the flow of information. This is achievedthrough the use of relays and clients, which are run by differentindividuals or entities. Users have the freedom to choose which relaysand clients they want to use, and as a result, their feeds are populatedwith content from the people they choose to follow. If a relay or clienttries to censor a user, they can simply switch to a different one. Thisis a major advantage over traditional centralized social media platformswhere one entity holds all the control over the flow of information andcan censor or manipulate the content that users see.\n- Nostr is also not beholden to shareholders or investors. This means thatthe protocol can make decisions that prioritize the well-being andquality of discourse for users, rather than solely focusing on profit.This is in contrast to traditional social media networks like Twitter,Facebook, and TikTok, which are driven by the need to collect data onusers and sell ads to generate revenue. In these centralized platforms,users’ data is collected, analyzed and sold to the highest bidder, oftenwithout the user’s knowledge or consent. Nostr, on the other hand,allows users to have more control over their data and the ability tomonetize their content.\n- Nostr also tightly integrates Bitcoin Lightning to support the protocol.This will hopefully enable secure transmission of value alongside theinformation and interactions on the platform. It also gives users theability to monetise their content.\n- This potential step-change improvement to the social media experiencefor everyday people addresses issues of censorship and data collection.\n- Nostr is “The simplest open protocol that is able to create acensorship-resistant global \"social\" network once and for all.”according to it’s [github page](https://github.com/fiatjaf/nostr). Morethan that it’s a client side validated proof of who a user isinteracting with, hence being in this identity section. To be clear,it’s not a completely peer to peer system in that it uses (very dumb)relay servers, but this gives it some of the best characteristics ofboth paradigms. This has the following advantages for our metaverseapplication;\n-\n\t- it’s lightweight, with minimal network overhead and complexity\n-\n\t- it’s real-time using websockets\n-\n\t- anyone can run a relay server, so one can be run in the deployment in the final section of the book.\n-\n\t- Each of the client peers connecting to the metaverse can be a relay and able to pass messages and proofs to the other clients without the metaverse server seeing the data or being online\n-\n\t- it’s open-source\n-\n\t- it is itself [Turing Complete](https://snort.social/e/note1evkdgcg0dw8ckyqsqhnk4wy55h7w97twjf8etcq2tr9sv5urlszqjc9p6v) and therefore able to execute any code within it’s message protocol\n-\n\t- there are multiple usable libraries and tools\n-\n\t- it’s under active development with an excellent team. The lead, ‘Fiatjaf’ is one of the most [prolific developers](https://github.com/fiatjaf) in the lightning space.\n-\n\t- it’s based on the same underlying cryptographic technology we are using elsewhere, indeed with it’s use of Bitcoin keys the identity system is global\n-\n\t- it provides the identity proof that we need to validate users and objects into a virtual space\n-\n\t- it enables message passing\n-\n\t- it scales to be a social network as required\n-\n\t- it need not rely on anything outside of a relay hosted on the metaverse server\n-\n\t- it can be scaled to provide one to many bulletin board style applications within the metaverse\n-\n\t- we can use it in private, group, and public modes as required\n-\n\t- it integrates with the torrent network allowing storage and external referencing of arbitrary data\n-\n\t- it can easily operate outside of the walled garden of the metaverse, extending the reach of the messages\n- [Nostr is incrediblypromising](https://www.forbes.com/sites/rogerhuang/2022/12/29/nostr-is-the-decentralized-protocol-that-might-replace-elon-musks-twitter/),and integrating these relays in the metaverse servers and clients of theproposed technology stack in this book might allow us globally provableidentity, with privacy by design. It can provide message passing. If allentities in the collaborative mixed reality scenegraphs are also Nostrkey pairs then schema can be applied consistently with the economiclayer using the same key system as Bitcoin. Nostr has just received asubstantial grant from Dorsey. It is core to the design later in thebook. A curated list of projects and libraries is [available ongithub](https://github.com/aljazceru/awesome-nostr).\n- Luke Childs [says](https://github.com/nostr-protocol/nips/issues/154):it“Nostr makes a good candidate to be used as a very simple DID layer.Having \"Login with Nostr\" auth on websites solves a lot of problems in avery elegant way, and Nostr’s main use case as a social network protocolmakes it highly suited to be used as your main identity proving key.Compare \"Login with Nostr\" to similar \"Login with Lightning\"(LNURL-auth) specs to see some easy and obvious advantages:  Remote signer vs local signer  Login with Lightning requires access to remote keys, login with Nostrrequires access to local keys ideally stored in a browser extension. Dueto the way Lightning works you can only really have one instance. Youneed all your client devices linked to a single Lightning node, thismeans most clients will be connecting to the signer remotely. Now ifyour Lightning node goes down or you lose your connection you also can’tauth with any service. This could cause circular dependencies where youlose the connection to your Lightning node so you can’t auth with theservices you need to access to debug the issue with your Lightning nodelike your hosting provider or VPN account. You could technically solvethis by replicating your LN keys to other client devices only to be usedfor local auth signing but that introduces other risks.  Unique identifier vs identity  A Lightning node is not really an identity but a unique identifier. Itjust tells you the person that auths is the same random person thatauthed last time, it doesn’t tell you who they are. A nostr pubkey is anidentity. It tells you who they are, what their name is, what they looklike, who they know, how you can pay them, how you can message them.  This is much more useful as an identity layer for an application. Theapplication can show their profile picture, username, send secure crossplatform push notifications via NIP-04 encrypted Nostr DMs, etc.  Consistent identity across services  Lightning pubkeys are sensitive private information and can leakconfidential financial information, Nostr pubkeys are safe to share withanyone. LNURL-auth adds extra steps to solve this by creating derivedsubkeys for identities that are unique to each service you auth with.This does not seem ideal, it seems the default case is that an identityis something that you do want to follow you across all your accounts.Nostr based auth behaves more appropriate in this regard. In the rarecase you need to achieve privacy and separation between certain servicesyou can still do that by using use a throwaway Nostr key for thoseservices.  User relationships across services Since authing with Nostr shares areal social identity with the service, they can also see your Nostrsocial graph. This could be useful for connecting you to people youalready know on the new service.  Low cost identity  Ideally identities should be easy to create but hard to build upreputation to limit spam while avoiding excluding people from thenetwork. It’s not clear that it will be cost effective / scalable foreveryone to run their own Lightning node so tying individual identity toa single Lightning node pubkey is problematic. Nostr keys are easy tocreate and hard reputation can be earned via PoW/DNS or building astrong social graph.”  Figure<a href=\"#fig:starhistory\" data-reference-type=\"ref\" data-reference=\"fig:starhistory\">5.2</a>shows that the adoption is potentially tremendously fast.\n  ![]./assets/431d39316d5fa17f89fa9e1154fa2a267517a245.png\n  An illustration of the enthusiasm for Nostr compared to traditional DID based on GitHub ‘stars’.\n- This provides a web interface into the metaverse providing:\n-\n\t- simple cryptographic identity assurance\n-\n\t- private peer to peer chat\n-\n\t- group chats and channels\n-\n\t- email to private message relay\n-\n\t- links into media on web hosts\n- The pace of development on Nostr is dizzying. Peer to peer video andaudio will allow us to link metaverse instances, between peers, throughapplications such as [Monstr](https://monstr.app/).\n- It’s notable that Nostr has it’s own inexpensive [hardware signingdevice](https://github.com/lnbits/nostr-signing-device) to protectidentity in situations where this might be necessary.  bfThe proposed integration of Nostr social media and messaging, alightning layer with digital objects such as Fedimint, Zerosync or RGB,AI agents, Vircadia, and federated Bitcoin is the core value propositionof this book. This work pre-dates [Meta andZuckerbergs](https://www.theverge.com/2023/4/26/23699633/mark-zuckerberg-meta-generative-ai-chatbots-instagram-facebook-whatsapp)stated intent in this regard by 18 months, and is differentiated stillby our focus on emerging markets and decentralisation.\n- ##### NIP-05\n- At this time, the nascent identity layer in nostr leans on NIP-05. Thisis a distributed identity management system that maps Nostr keys toDNS-based internet identifiers. In events of kind 0 (setmetadata), the“nip05” key can have an internet identifier as its value. Clients splitthe identifier into the local part and domain and make a GET request tothe specified URL. The response should be a JSON document with a “names”key containing a mapping of names to hex-formatted public keys. If thepublic key matches the one from the setmetadata event, the clientaccepts the association and considers the “nip05” identifier valid.\n- Clients may find users’ public keys from internet identifiers by firstfetching the well-known URL and then checking for a matching “nip05”.When following public keys, clients must prioritize the keys over NIP-05addresses. Public keys must be in hex format. Clients can enable userdiscovery through search boxes, allowing users to find profiles byentering internet identifiers. The identifier can be used as the “root”identifier, displayed as just the domain. The protocol supports bothdynamic and static servers by using the local part as a query string.\n- ##### Nostr Protocol as the keystone\n- The Nostr protocol can be used to store and share valuable contentacross the network. This is ably demonstrated by the [‘Highlighter’project](https://highlighter.com/) which allows users to store importantnotes from around the web using nostr. In the context of our federatedsocial media trust model, the Nostr protocol can serve as the underlyinglayer that connects various instances of virtual spaces, thus enablingseamless data exchange and interoperability among them. Highlighterdemonstrates that nostr events can be leveraged to create, store, andinteract with valuable across networks. By utilizing this concept, wecan extend the functionality to support federated social media trust,allowing users to carry their reputation, identity, and cryptographicproofs across different virtual spaces and social media platforms.\n- ##### Nostr marketplace in LnBits\n- The nostr [markets plugin](https://github.com/lnbits/nostrmarket) forLnBits allows virtual ‘stalls’ to be setup and payment to be mediatedthrough nostr. This is obviously a great expansion to the usefulness ofour integration\n- ##### Integrating Cryptographic Proofs and Reputation\n- To create a trusted environment within the federated network, we mustestablish a mechanism for importing and verifying cryptographic proofsfrom various sources, such as social media sites and other digitalplatforms. By doing so, we enable users to bring their existingreputation and trust from these platforms into the new ecosystem, thusfacilitating trust-based interactions and collaboration within thenetwork. We can leverage the Nostr protocol and the NIP05 specificationto import these cryptographic proofs, creating a secure and verifiablesystem for identity management and trust propagation. The NIP05specification allows for the creation and verification of identityproofs within the Nostr protocol, thus enabling the seamless integrationof trust and reputation data from external sources.\n- By utilizing the Nostr protocol as the underlying layer, we canestablish connections between objects, people, and AI actors within thefederated network. This interconnected ecosystem allows for seamlesscollaboration, information sharing, and trust-based interactions amongall participants. The open-source collaboration infrastructure wepropose can facilitate the development of various applications andservices that leverage the federated network, such as virtualworkspaces, AI-assisted creativity tools, and more. The uncensorablenature of this protocol further supports the inclusivity andaccessibility we feel so important, ensuring that participants fromdifferent regions and backgrounds can take part in the digital societyand contribute to its growth.\n- This federated social media trust model, built on the Nostr protocol,allows for the establishment of a robust, inclusive, and trust-basednetwork that connects various virtual spaces, social media platforms,and AI systems. By leveraging the lessons learned from the otherattempts in the space, and by maximising the inclusion of externalcryptographic proofs from multiple sources, we can create acomprehensive trust system that fosters collaboration, innovation, andshared growth within the digital society.\n- The Nostr protocol, with its decentralized and open-source nature,provides a solid foundation for linking and federating objects, people,and AI actors across collaborative spaces in digital society. Byleveraging the Nostr protocol, we can build a robust and trust-basednetwork that interconnects various virtual spaces, social mediaplatforms, and AI systems. One of the key aspects of this trust-basednetwork is the ability to import cryptographic proofs from differentsources, similar to Keybase’s approach to importing proofs from varioussocial media sites [(KeybaseProofs)](https://book.keybase.io/account#proofs).\n- ##### StrFry relays\n- The Stirfry relay software provides high-performance infrastructure forbuilding decentralized social media applications on top of the Nosterprotocol. As an open source project written in C++, Stirfry emphasizesefficiency, flexibility, and community-driven governance.\n- At the core of Stirfry is its high-speed database engine. Rather thanusing a traditional SQL database, Stirfry implements the LightningMemory-Mapped Database (LMDB)\n\t- an embedded key-value store optimizedfor performance. Reads are lock-free, enabling unlimited parallel querythroughput. Writes require only a short-held lock, ensuring minimalinterference. LMDB’s \"shadow paging\" design allows isolated read-onlytransactions via multi-version concurrency control (MVCC). This preventsreads from blocking writes and vice versa.\n- To maximize database performance, Stirfry stores Noster events directlyin FlatBuffers\n\t- an efficient binary format allowing direct accesswithout serialization. The original JSON payloads are preserved tofacilitate transmission back to clients. Additional database files indexevents on fields like timestamps and authors, accelerating filterqueries. Periodic compaction optimizes the layout for faster operations.\n- Stirfry adopts a multi-threaded, modular architecture. A websocketthread accepts new client connections and routes incoming requests. Aningester thread validates and pre-processes each request before passingto appropriate handlers. Doing signature checks and filter compilationupfront avoids repeating work. A single writer thread batches databasewrites to amortize transaction overhead. Multiple worker threads handleread queries, fairly scheduling between long and short requests.Dedicated monitor threads track active filters and stream matchingevents to subscribed clients. Passing messages between threads insteadof sharing data structures improves efficiency.\n- Additional features further enhance Stirfry’s capabilities. Gracefulshutdown support allows stopping new connections while existing onescomplete. Hot configuration reloading provides runtime updates withoutrestarting. Flexible write policy plugins enable custom contentmoderation. Streaming websocket compression and Zstandard dictionariescompress traffic. Syncing protocols like Negentropy facilitate efficientrelay replication, powering mesh network topologies. Geo-replication bythe relay.org community offers low latency worldwide access. The customTemplar HTML templating library assists crafting simple, fastdecentralized frontends.\n- ### Micropayment based web\n- It seems the war against disinformation is now being lost. Much iswritten in the media about Deepfake technology creating plausible fakevideos, but probably more pernicious is the use of toolkits to createentire plausible fake news sites using natural language AI such as GPT3.This makes it cheap to publish potentially market moving news which isthen rehypothecated by online news vendors who are hungry for clicks. Asthese pipelines become more mature it will be difficult to keep fakenews for financial or political gain out of the system. One interestingway to do this that itisn’t webs of trust or true cryptographic identityis to charge micropayments for “one to many” publication models. Thiswould imply a tiny instant payment for clicks, especially on socialmedia sites such as twitter. This kind of model has been discussed butis only possible in the context of systems such as Lightning whereinstant micropayment can be realised. It seems possible that this wouldprice out speculative ‘noise’ spam from the information space. It’sinteresting and ironic that the origin of proof of work was to underpinjust such a spam defeating system,[[dwork1992pricing]] and that Nakamoto[mentioned this application forBitcoin](https://www.metzdowd.com/pipermail/cryptography/2009-January/015014.html)back in 2009. There is now much chatter about the integration of Bitcoinwith Twitter in light of Musks buyout of the social network.\n  ![]./assets/68114e388f76f1dc94eb3a6205c2c1dbee1c9f7a.jpg\n  Comparison of distributed file stores",
        "link_types": [
            "king1966fisher",
            "lockwood2021exploring",
            "dwork1992pricing",
            "king1966fisher",
            "lockwood2021exploring",
            "dwork1992pricing"
        ],
        "file_size": 59101
    },
    {
        "id": "Knowledge Graphing.md",
        "name": "Knowledge Graphing",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n- ## Research History\n\t- ![image.png](../assets/image_1703366755687_0.png)\n- ## Notion\n\t- **Notion**: is a versatile paid tool that combines note-taking, task management, databases, and knowledge graphing. Notion allows users to create linked notes and true databases, making is very performant. It has a lot of GPT integration but this costs extra.\n\t- {{video https://www.youtube.com/watch?v=vFNYUl1pv54}}\n\t- {{video https://www.youtube.com/watch?v=WnZR7RPH8sA}}\n- ## Obsidian\n\t- **Obsidian**: A markdown-based note-taking app designed for knowledge management and building a personal knowledge base. Obsidian's key feature is its ability to create a network of interlinked notes, enabling users to visualize the connections between their thoughts and information.\n- ## Others\n\t- **Roam Research**: This tool is known for its bi-directional linking and its graph overview, which shows how notes are interconnected. Roam is designed to facilitate associative thought, making it easy to see connections between ideas.\n\t- **Dynalist**: A list-making application that allows for infinite levels of nesting. While primarily a list-maker, it also offers features for linking between lists and items, thereby enabling some degree of knowledge graphing.\n\t- **TiddlyWiki**: A unique non-linear notebook for capturing, organizing, and sharing complex information. It allows for linking between different Tiddlers (small pieces of information) to create a web of notes.\n\t- **Zettelkasten Method Tools**: This method emphasizes creating a network of linked notes. Tools like Zettlr or The Archive are designed with the Zettelkasten philosophy in mind, offering features that facilitate linking between notes and creating a knowledge web.\n\t- **Microsoft OneNote**: A digital notebook that provides a flexible canvas for capturing notes in various formats. It allows for some degree of linking and organizing, suitable for knowledge management.\n\t- **Evernote**: Known for note-taking, it also provides features for organizing and linking notes, although it's more linear compared to tools like Obsidian or Logseq.\n- ## Logseq\n\t- **Logseq**: is very similar to Obsidian, but self hosted and open source. It works on top of plain text files stored in a local system. It supports markdown and Org-mode formatting and allows for hierarchical and networked note-taking. It can be connected to it's mobile app via github.\n\t- Integration to [[Large language models]] can be OpenAI or local.\n\t\t- Compare notion, obsidian, and logseq, using a simply markdown table with coloured dots\n\t- [ChatGPT\n\t\t- Logseq Summarizer (openai.com)](https://chat.openai.com/g/g-3ooWV51Sb-logseq-summarizer)\n\t-\n\t- ![Screenshot 2024-01-06 120253.png](../assets/Screenshot_2024-01-06_120253_1706020225813_0.png)\n\t- ![Screenshot 2024-01-18 103043.png](../assets/Screenshot_2024-01-18_103043_1706020238116_0.png)\n\t- ![Screenshot 2024-01-18 102807.png](../assets/Screenshot_2024-01-18_102807_1706020247381_0.png)\n- ![image.png](../assets/image_1706089902931_0.png){:height 812, :width 910}\n- # Microsoft GraphRAG\n\t- [GraphRAG: New tool for complex data discovery now on GitHub - Microsoft Research](https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/) [[Update Cycle]]",
        "link_types": [
            "Large language models",
            "Update Cycle"
        ],
        "file_size": 3333
    },
    {
        "id": "Medical AI.md",
        "name": "Medical AI",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ## Drug Discovery and Molecular Biology\n\t- AI architectures, particularly those inspired by natural language processing (NLP) models, are demonstrating remarkable potential in handling vast datasets and intricate interactions within biological systems. These AI models are poised to accelerate scientific discovery by tackling challenges that traditional methods have struggled to address effectively.\n\t- Biological systems are characterized by intricate interplay of DNA, RNA, proteins, and small molecules within cells and organisms. Deciphering the complex interactions between these components is a grand challenge in biomedical science. Traditional analytical methods are not well-suited to the complexity of biological systems, leaving much more unknown than known about how cells, tissues, and bodies function at higher levels.\n\t- Modern AI architectures are very well suited to take advantage of biology's massive datasets, and a new wave of AI models are dramatically accelerating the process of scientific discovery in biology. These models are starting with understanding protein and other cellular structures and the physical interactions between them, and will likely soon zoom out to help understand how cells, tissues, and bodies function at higher levels.\n\t- ### Models and specifics\n\t\t- It is important to keep in mind the distinction between static structural analysis and dynamic conformational analysis, which allows for molecules to change shape as they interact with one another.\n\t\t- Foundation models for biology, along the lines of the large language models (LLMs) that many are familiar with, are just now starting to be trained. Different models are often used for predicting shapes versus predicting sequences, which are two sides of the same coin but are currently modelled separately.\n\t\t- AlphaFold 2, developed by DeepMind, marked a significant breakthrough in protein structure prediction. This AI model can predict a static 3D structure from a protein sequence, providing confidence scores for the predicted structure. However, AlphaFold 2 has limitations in capturing protein dynamics, highlighting the need for models that can predict multiple conformations and their transitions.\n\t\t- Distributional Graph Former, building upon AlphaFold 2's architecture, predicts ensembles of protein structures and transition pathways. AlphaFlow, a diffusion model trained on molecular dynamics simulation data, generates multiple protein conformations. These advancements demonstrate the potential of AI in capturing the dynamic nature of proteins.\n\t- ### Protein Language Models\n\t\t- Protein language models, built on architectures like BERT (Bidirectional Encoder Representations from Transformers), have emerged as powerful tools for predicting protein structures. ESM-Fold, for example, uses a masked language modelling objective to learn complex patterns and relationships within protein sequences, leading to accurate structural predictions without relying on physics-based simulations.\n\t\t- These models leverage multiple sequence alignments (MSAs) to provide evolutionary information that aids in structure prediction. Attention maps in protein language models correlate with contact maps, representing physical contacts between amino acids, further emphasizing the model's ability to learn inherent structural information.\n\t\t- Training models to predict binding affinity and protein interactions is a challenging task. Overfitting is a common issue, where models perform well on training data but fail to generalize to new data. Proper data splitting based on sequence and structural similarity is crucial to ensure the model's ability to generalize to unseen data. This is particularly challenging for protein interaction models, where similar sequences might be present in both training and testing sets, leading to overfitting and poor generalization.\n\t\t- ### Protein Complexes\n\t\t\t- RoseTTAFold All Atom extends the capabilities of AlphaFold Multimer to predict the structure of complexes containing proteins with small molecules, nucleic acids, and metals. This represents a significant step forward in modelling interactions beyond protein-protein interactions.\n\t\t- ### Generative Models for Molecule Design\n\t\t\t- Generative models based on diffusion and flow-matching approaches enable fine-grained control over the generation of molecules with specific properties. ProteinDT and MoleculeSTM are examples of text-conditioned generative models that allow users to provide natural language prompts to generate molecules with desired properties.\n\t\t\t- RF Diffusion, a diffusion model built on the RoseTTAFold backbone, offers powerful functionalities for protein engineering. It enables unconditional generation of novel proteins, binder design for high affinity and specificity, partial diffusion for refining existing structures, motif scaffolding for combining functional motifs, symmetric generation of protein complexes, and fold conditioning for generating proteins with specific tertiary structures.\n\t\t\t- Complementary models like Ligand and PNN (Protein MPNN) are essential for designing amino acid sequences that fold into the desired 3D structures generated by RF Diffusion.\n\t- ## Practical Applications and Workflows\n\t\t- These advanced AI models can be integrated into practical workflows for drug discovery and protein engineering. For example, to design a protein inhibitor, the workflow may involve identifying a problematic protein-protein interaction, extracting the interaction motif using RF Diffusion, scaffolding a new protein structure incorporating the motif, optimizing the structure using Partial Diffusion and Ligand and PNN, and validating the interaction using AlphaFold Multimer.\n\t\t- The speed and efficiency of these models allow for rapid iteration and generation of many potential candidates with high accuracy and effectiveness. Hundreds or thousands of backbones can be designed, and hundreds or thousands of sequences can be designed for each backbone using Ligand and PNN in a matter of minutes. When synthesized and tested, these designed proteins often demonstrate high thermal stability, specificity, and binding affinity.\n\t- ## Bottlenecks in Drug Discovery\n\t\t- Despite the remarkable advancements, there are challenges and bottlenecks in the adoption of AI models in biological research. Target identification remains a significant challenge in drug discovery. The rapid evolution of the field and technical barriers, such as the requirement for programming skills and familiarity with computational environments, can hinder the widespread adoption of these models by researchers without a programming background. This is potentially an opportunity.\n- # Agents in Biological Research\n\t- AI agents have the potential to transform biological research by automating tasks such as literature review, hypothesis generation, experimental design, and data analysis. Companies like Future House are developing AI agents that can identify potential drug targets and design experiments, significantly accelerating the process of discovery. These agents, powered by large language models (LLMs) and other AI technologies, can review thousands of research papers, develop targets or hypotheses to test, and even drive autonomous labs.\n\t- As these AI agents become more capable, they may play a crucial role in guiding research and helping humans navigate the complex landscape of biological data and interactions. The convergence of AI agents with specific tools for designing molecules, proteins, and nucleic acids could lead to rapid progress in solving challenging problems in biology and medicine.\n\t- The development and application of AI-driven biology raise important ethical considerations and concerns related to potential misuse and the need for responsible development. While the computational design of toxic molecules is just one step in a complicated process that requires synthesis and delivery, the increasing capabilities of AI agents and the potential for state-sponsored bad actors highlight the need for oversight and safety measures.\n\t- Robust safety protocols, regulations, and ethical frameworks are essential to guide the development and application of these technologies. International collaboration is crucial to address the global nature of biological threats and prevent the proliferation of dangerous technologies. Hiring capable individuals with strong moral grounding and good intentions in companies and organizations working on these technologies is also important.\n- ## State of the Art in Medicine:\n\t- **AI surpasses average human performance**: Since mid-2022, top AI systems outperform the average human on average white-collar tasks, signifying a significant milestone. ([https://aiindex.stanford.edu/report/](https://aiindex.stanford.edu/report/))\n\t- **AI approaches expert-level performance**: Current AI systems are nearing expert performance levels in routine medical tasks, like adhering to standard care procedures. ([https://aiindex.stanford.edu/report/](https://aiindex.stanford.edu/report/))\n\t- ### Major Innovations:\n\t\t- **GPT evolution**: In just five years, GPT models evolved from GPT-2 (2019) to GPT-4, which rivals human experts on challenging cognitive tests like the MMLU (measuring performance across various academic fields). ([https://openai.com/research/gpt-4](https://openai.com/research/gpt-4))\n\t\t- **Medical licensing exam success**: Google's Med-PaLM AI system passed the US medical licensing exam, with Med-PaLM 2 achieving an impressive 86% score, close to expert-level performance. ([invalid URL removed])\n\t\t- **AI outperforms humans in specific medical tasks**: Studies show AI outperforming human doctors in medical question answering, differential diagnosis, and interpreting medical images, indicating a potential shift in medical practice.\n\t\t\t- Google's medical AI destroys GPT's benchmark and [outperforms doctors](https://newatlas.com/technology/google-med-gemini-ai/)\n\t\t- **Virtual tissue staining**: AI enables real-time \"virtual tissue staining\" using intraoperative imaging, significantly faster than traditional biopsy and staining methods, improving surgical precision. ([invalid URL removed])\n\t\t- **\"Mind reading\" through fMRI decoding**: AI can reconstruct images viewed by a person during an fMRI scan, demonstrating progress in decoding brain activity and reconstructing visual experiences. ([https://www.science.org/doi/10.1126/science.adi1763](https://www.science.org/doi/10.1126/science.adi1763))\n\t\t\t- [Movie clip reconstructed by an AI reading mice's brains as they watch](https://youtu.be/aMf6Xj9AHXQ) [[Medical AI]]\n\t\t- [Google DeepMind and Isomorphic Labs introduce AlphaFold 3 AI model (blog.google)](https://blog.google/technology/ai/google-deepmind-isomorphic-alphafold-3-ai-model/) [[[Google]]\n\t- ### AI Impact on Jobs:\n\t\t- **AI impact on different job sectors**: Contrary to expectations, current AI primarily impacts high-wage, high-skill jobs (e.g., doctors, lawyers) rather than low-wage, low-skill jobs, reflecting a shift in automation trends. ([https://www.nber.org/papers/w31608](https://www.nber.org/papers/w31608))\n\t\t- **AI nursing**: Companies like Hippocratic AI offer AI-powered nursing assistants that perform follow-up tasks, demonstrating a shift towards AI directly competing in the labour market at an hourly rate. ([https://www.hippocraticai.com/](https://www.hippocraticai.com/))\n- # The (near) Future\n\t- The integration of AI in biological research holds immense potential for advancing scientific discovery, improving human health, extending lifespan, and enhancing quality of life. As these technologies continue to evolve, they may lead to a paradigm shift in how we think about health, longevity, and our relationship with the environment.\n\t- The ability to cure a wide range of diseases and significantly extend human lifespan could potentially lead to a shift in human consciousness, prompting a deeper appreciation for life, health, and interconnectedness.\n- [Moderna partners with OpenAI to accelerate the development of life-saving treatments - YouTube](https://www.youtube.com/watch?v=t3UHnKLVS1M)\n-",
        "link_types": [
            "Medical AI",
            "[Google"
        ],
        "file_size": 12197
    },
    {
        "id": "Spatial Computing.md",
        "name": "Spatial Computing",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- **Definition**\n\t- Simon Greenwold defined spatial computing in 2003 as human interaction with machines that manipulate referents to real objects.\n\t- In simpler terms, it refers to humans interacting with digital 3D data referencing the real world.\n- **Spatial Computing Industry**\n\t- Spatial computing is a fast-growing industry, particularly in business-to-business (B2B) products and services.\n\t- It is set to merge with other technologies like AI, robotics, and augmented reality, leading to innovative products.\n- **Infrastructure and Investment**\n\t- Infrastructure for spatial computing applications is becoming more affordable and accessible. (5G etc)\n\t- Many entrepreneurs, technology executives, and investors are focusing on hardware, software, and infrastructure for spatial computing.\n- **Examples of Spatial Computing**\n\t- Video games like FIFA and Wii Sports where players interact with virtual environments.\n\t- Movies and TV shows with visual effects like Avatar, requiring 3D scene and character building.\n\t- Use of augmented reality filters in social media and 3D face scanning in transportation.\n- **Impact and Proliferation**\n\t- Humans are optimised by evolution for 3D experiences, which makes spatial computing appealing, but the hardware is \"in the way\"\n\t- The evolution of technology like GPUs, cloud computing, and AI chips has enabled the proliferation of spatial computing.\n- **Spatial Computing in Various Sectors**\n\t- Used in musculoskeletal healthcare, architectural visualisation, industrial robots, and mapping for navigation.\n\t- Combining with other technologies to increase fidelity and sophistication.\n- **Future of Spatial Computing**\n\t- Machine-machine (M2M) spatial computing is likely to surpass human-machine (H2M) interactions.",
        "link_types": [],
        "file_size": 1826
    },
    {
        "id": "Diagrams as Code.md",
        "name": "Diagrams as Code",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n- ## Kroki\n\t- [Kroki!](https://kroki.io/) provides a unified API with support for BlockDiag (BlockDiag, SeqDiag, ActDiag, NwDiag, PacketDiag, RackDiag), BPMN, Bytefield, C4 (with PlantUML), D2, DBML, Ditaa, Erd, Excalidraw, GraphViz, Mermaid, Nomnoml, Pikchr, PlantUML, Structurizr, SvgBob, Symbolator, TikZ, UMLet, Vega, Vega-Lite, WaveDrom, WireViz...\n- ## Handy GPT\n\t- There's a GPT to assist you in making diagrams  https://chat.openai.com/g/g-5QhhdsfDj-diagrams-show-me/\n- ## Local render setup\n\t- ```~/kroki$ docker compose up -d```\n\t  - ``` docker-compose.yaml version: '3'\n\t  \n\t  services:\n\t    kroki:\n\t      image: yuzutech/kroki\n\t      environment:\n\t        - KROKI_BLOCKDIAG_HOST=blockdiag\n\t        - KROKI_MERMAID_HOST=mermaid\n\t        - KROKI_BPMN_HOST=bpmn\n\t      ports:\n\t        - \"8000:8000\"\n\t  \n\t    blockdiag:\n\t      image: yuzutech/kroki-blockdiag\n\t  \n\t    mermaid:\n\t      image: yuzutech/kroki-mermaid\n\t  \n\t    bpmn:\n\t      image: yuzutech/kroki-bpmn\n\t  \n\t  \n\t  \n\t  tmux new -s kroki docker compose up -d \n\t  ```\n- ## Examples rendered in Logseq\n\t- Gemini and Claude made a diagram of this whole research corpus using  https://dreampuf.github.io/GraphvizOnline/\n\t  id:: 66314b8e-513e-45a6-80e7-493933e46e9e\n\t\t- ```graphviz\n\t\t  digraph G {\n\t\t    graph [rankdir=LR, overlap=false, splines=true];\n\t\t    node [shape=box, style=filled, fontsize=10, fontcolor=darkslategray];\n\t\t    edge [color=darkslategray, penwidth=1];\n\t\t  \n\t\t    // Main Themes\n\t\t    // The main themes represent the key areas of focus in the diagram. The skyblue color provides a soft and pleasant visual appearance.\n\t\t    Decentralization [fillcolor=skyblue, label=\"Decentralization &\\nOpenness\"];\n\t\t    AI [fillcolor=skyblue, label=\"Artificial\\nIntelligence\"];\n\t\t    XR [fillcolor=skyblue, label=\"Extended\\nReality (XR)\"];\n\t\t    DigitalSociety [fillcolor=skyblue, label=\"Digital\\nSociety\"];\n\t\t    GenAI [fillcolor=skyblue, label=\"Generative\\nAI\"];\n\t\t    DigitalObjects [fillcolor=skyblue, label=\"Digital\\nObjects & NFTs\"];\n\t\t    Metaverse [fillcolor=skyblue, label=\"Metaverse &\\nVirtual Worlds\"];\n\t\t    Blockchain [fillcolor=skyblue, label=\"Blockchain &\\nDistributed Ledger\\nTechnology (DLT)\"];\n\t\t  \n\t\t    // Decentralized Technologies\n\t\t    // These nodes represent various decentralized technologies. The mediumseagreen color provides good readability against the dark font color.\n\t\t    Bitcoin [fillcolor=mediumseagreen, label=\"Bitcoin (BTC)\"];\n\t\t    Nostr [fillcolor=mediumseagreen, label=\"Nostr Protocol\"];\n\t\t    Solid [fillcolor=mediumseagreen, label=\"Solid Project\"];\n\t\t    DecentralisedStorage [fillcolor=mediumseagreen, label=\"InterPlanetary File System (DecentralisedStorage)\"];\n\t\t    CashuFedimint [fillcolor=mediumseagreen, label=\"Cashu & Fedimint\"];\n\t\t    Lightning [fillcolor=mediumseagreen, label=\"Lightning Network\"];\n\t\t    RGB [fillcolor=mediumseagreen, label=\"RGB Protocol\"];\n\t\t    DecentralizedInternet [fillcolor=mediumseagreen, label=\"Decentralized Internet\"];\n\t\t  \n\t\t    // AI Technologies\n\t\t    // These nodes represent various AI technologies. The moccasin color provides a warm and distinct appearance.\n\t\t    LLMs [fillcolor=moccasin, label=\"Large Language\\nModels (LLMs)\"];\n\t\t    StableDiffusion [fillcolor=moccasin, label=\"Stable Diffusion\"];\n\t\t    Transformers [fillcolor=moccasin, label=\"Transformers\"];\n\t\t    GANs [fillcolor=moccasin, label=\"Generative Adversarial\\nNetworks (GANs)\"];\n\t\t    Mamba [fillcolor=moccasin, label=\"Mamba Architecture\"];\n\t\t    PromptEngineering [fillcolor=moccasin, label=\"Prompt Engineering\"];\n\t\t    RLHF [fillcolor=moccasin, label=\"Reinforcement Learning\\nfrom Human Feedback\"];\n\t\t    DPO [fillcolor=moccasin, label=\"Direct Preference\\nOptimization\"];\n\t\t  \n\t\t    // XR Technologies\n\t\t    // These nodes represent various XR technologies. The lightpink color provides a visually appealing and distinguishable appearance.\n\t\t    AR [fillcolor=lightpink, label=\"Augmented\\nReality (AR)\"];\n\t\t    VR [fillcolor=lightpink, label=\"Virtual\\nReality (VR)\"];\n\t\t    Omniverse [fillcolor=lightpink, label=\"NVIDIA Omniverse\"];\n\t\t    Vircadia [fillcolor=lightpink, label=\"Vircadia\"];\n\t\t    USD [fillcolor=lightpink, label=\"Universal Scene\\nDescription (USD)\"];\n\t\t    NeRFs [fillcolor=lightpink, label=\"Neural Radiance\\nFields (NeRFs)\"];\n\t\t    SpatialComputing [fillcolor=lightpink, label=\"Spatial Computing\"];\n\t\t    AvatarGeneration [fillcolor=lightpink, label=\"Avatar Generation\"];\n\t\t  \n\t\t    // Intellectual Work Packages\n\t\t    // These nodes represent different intellectual work packages. The thistle color provides a subtle and distinguishable appearance.\n\t\t    VP [fillcolor=thistle, label=\"Virtual Production\"];\n\t\t    BioMed [fillcolor=thistle, label=\"Biomedical Applications\"];\n\t\t    Edu [fillcolor=thistle, label=\"AI in Education\"];\n\t\t    Creative [fillcolor=thistle, label=\"Creative Industries\"];\n\t\t    DigitalEconomy [fillcolor=thistle, label=\"Digital Economy\"];\n\t\t  \n\t\t    // Agentic AI Actors\n\t\t    // This node represents agentic AI actors. The lightsalmon color provides a vibrant and noticeable appearance.\n\t\t    Agents [fillcolor=lightsalmon, label=\"Agentic AI\\nActors\"];\n\t\t  \n\t\t    // Connections - Decentralized Tech\n\t\t    // These edges represent the relationships between decentralized technologies and other concepts.\n\t\t    Decentralization -> Bitcoin;\n\t\t    Decentralization -> Nostr;\n\t\t    Decentralization -> Solid;\n\t\t    Decentralization -> DecentralisedStorage;\n\t\t    Decentralization -> CashuFedimint;\n\t\t    Decentralization -> Lightning;\n\t\t    Decentralization -> RGB;\n\t\t    Bitcoin -> DigitalSociety [label=\"Value & Payments\"];\n\t\t    Bitcoin -> Metaverse [label=\"Economic\\nTransactions\"];\n\t\t    Nostr -> DigitalSociety [label=\"Identity &\\nCommunication\"];\n\t\t    Nostr -> Metaverse [label=\"Social Interaction\"];\n\t\t    Nostr -> DigitalObjects [label=\"Provenance & Ownership\"];\n\t\t    Solid -> DigitalSociety [label=\"Data Ownership\"];\n\t\t    DecentralisedStorage -> DigitalSociety [label=\"Decentralized Storage\"];\n\t\t    DecentralisedStorage -> Metaverse [label=\"World Data\"];\n\t\t    CashuFedimint -> DigitalSociety [label=\"Community Banking\"];\n\t\t    Lightning -> Bitcoin [label=\"Scalability & Speed\"];\n\t\t    Lightning -> DigitalSociety [label=\"Micropayments\"];\n\t\t    Lightning -> Metaverse [label=\"Microtransactions\"];\n\t\t    RGB -> DigitalObjects [label=\"Smart Contracts\\nfor Ownership\"];\n\t\t  \n\t\t    // Connections - AI Tech\n\t\t    // These edges represent the relationships between AI technologies and other concepts.\n\t\t    AI -> LLMs;\n\t\t    AI -> StableDiffusion;\n\t\t    AI -> Transformers;\n\t\t    AI -> GANs;\n\t\t    AI -> Mamba;\n\t\t    AI -> PromptEngineering;\n\t\t    AI -> RLHF;\n\t\t    AI -> DPO;\n\t\t    LLMs -> GenAI;\n\t\t    StableDiffusion -> DigitalObjects [label=\"Image Generation\"];\n\t\t    Transformers -> LLMs [label=\"Architecture\"];\n\t\t    GANs -> DigitalObjects [label=\"3D Creation\"];\n\t\t    Mamba -> LLMs [label=\"Efficient\\nSequence Modeling\"];\n\t\t    PromptEngineering -> LLMs [label=\"Control & Fine-tuning\"];\n\t\t    RLHF -> LLMs [label=\"Alignment\\nwith Human Values\"];\n\t\t    DPO -> LLMs [label=\"Preference Learning\"];\n\t\t  \n\t\t    // Connections - XR Tech\n\t\t    // These edges represent the relationships between XR technologies and other concepts.\n\t\t    XR -> AR;\n\t\t    XR -> VR;\n\t\t    XR -> Omniverse;\n\t\t    XR -> Vircadia;\n\t\t    XR -> USD;\n\t\t    XR -> NeRFs;\n\t\t    XR -> SpatialComputing;\n\t\t    XR -> AvatarGeneration;\n\t\t    AR -> Metaverse;\n\t\t    VR -> Metaverse;\n\t\t    Omniverse -> Metaverse [label=\"Collaboration\\n& Simulation\"];\n\t\t    Omniverse -> VP [label=\"Virtual Production\\nWorkflows\"];\n\t\t    Vircadia -> Metaverse [label=\"Open-Source\\nPlatform\"];\n\t\t    USD -> Omniverse [label=\"Scene Description\"];\n\t\t    USD -> DigitalObjects [label=\"3D Interoperability\"];\n\t\t    NeRFs -> DigitalObjects [label=\"3D Reconstruction\"];\n\t\t    NeRFs -> Metaverse [label=\"Realistic Environments\"];\n\t\t    SpatialComputing -> Metaverse [label=\"Immersive\\nExperiences\"];\n\t\t    AvatarGeneration -> Metaverse [label=\"Digital Identity\"];\n\t\t    AvatarGeneration -> DigitalObjects [label=\"Unique Avatars\"];\n\t\t  \n\t\t    // Connections - Intellectual Work Packages\n\t\t    // These edges represent the relationships between intellectual work packages and other concepts.\n\t\t    GenAI -> Creative;\n\t\t    GenAI -> VP;\n\t\t    GenAI -> BioMed;\n\t\t    GenAI -> Edu;\n\t\t    DigitalObjects -> Creative;\n\t\t    DigitalObjects -> VP;\n\t\t    Metaverse -> Creative;\n\t\t    Metaverse -> VP;\n\t\t    Blockchain -> DigitalEconomy;\n\t\t    DigitalEconomy -> Metaverse;\n\t\t  \n\t\t    // Connections to Agentic AI Actors\n\t\t    // These edges represent the relationships between agentic AI actors and other concepts.\n\t\t    AI -> Agents;\n\t\t    GenAI -> Agents;\n\t\t    DigitalObjects -> Agents [label=\"Ownership & Interaction\"];\n\t\t    Metaverse -> Agents [label=\"Inhabitants &\\nMediators\"];\n\t\t    Blockchain -> Agents [label=\"Economic Activity &\\nTrust\"];\n\t\t    VP -> Agents [label=\"Automated Tasks &\\nCreative Assistance\"];\n\t\t    BioMed -> Agents [label=\"Research & Analysis\"];\n\t\t    Edu -> Agents [label=\"Personalized Tutors &\\nLearning Companions\"];\n\t\t    Creative -> Agents [label=\"Content Creation &\\nCollaboration\"];\n\t\t    DigitalEconomy -> Agents [label=\"Transactions & Value\\nCreation\"];\n\t\t  \n\t\t    // Tensions and Challenges\n\t\t    // These edges represent the tensions and challenges associated with different concepts. The dashed style indicates potential areas of concern or friction.\n\t\t    AI -> Politics [label=\"Control & Regulation\", style=dashed];\n\t\t    AI -> Ethics [label=\"Bias & Safety\", style=dashed];\n\t\t    DigitalSociety -> Privacy [label=\"Surveillance &\\nData Exploitation\", style=dashed];\n\t\t    Metaverse -> Accessibility [label=\"Hardware & Cost\", style=dashed];\n\t\t    VP -> Economics [label=\"Cost & Adoption\", style=dashed];\n\t\t    BioMed -> Ethics [label=\"Data Privacy\\n& Bias\", style=dashed];\n\t\t    Edu -> Adoption [label=\"Institutional\\nChallenges\", style=dashed];\n\t\t    Creative -> IP [label=\"Copyright &\\nOwnership\", style=dashed];\n\t\t    DigitalEconomy -> Regulation [label=\"Global\\nCoordination\", style=dashed];\n\t\t  \n\t\t    // Legend\n\t\t    // The legend provides a visual guide to the different categories of nodes in the diagram.\n\t\t    Legend [shape=none, margin=0, label=<\n\t\t      <table border=\"0\" cellborder=\"1\" cellspacing=\"0\">\n\t\t        <tr><td bgcolor=\"skyblue\">Main Themes</td></tr>\n\t\t        <tr><td bgcolor=\"mediumseagreen\">Decentralized Technologies</td></tr>\n\t\t        <tr><td bgcolor=\"moccasin\">AI Technologies</td></tr>\n\t\t        <tr><td bgcolor=\"lightpink\">XR Technologies</td></tr>\n\t\t        <tr><td bgcolor=\"thistle\">Intellectual Work Packages</td></tr>\n\t\t        <tr><td bgcolor=\"lightsalmon\">Agentic AI Actors</td></tr>\n\t\t      </table>\n\t\t    >];\n\t\t  }\n\t\t  ```\n- Create a shoot schedule for a medium sized ICVFX LED wall commercial shoot with 2 days prelight and 5 days shooting. Try to include the maximum camera optionality and shot diversity by assuming a tight and professional crew. use mermaid diagram gantt chart code\n  id:: 65ce7e9e-e891-49c2-af30-5f27904d2aca\n- ```mermaid\n  gantt\n      title Shoot Schedule\n      dateFormat  YYYY-MM-DD\n      axisFormat  %d-%m\n  \n      section Prelight\n      Preparing the LED Wall: done, des1, 2024-01-01, 2d\n  \n      section Shooting Day 1\n      Shot 1: after des1, 2h\n      Shot 2: after des1, 1h\n      Shot 3: after des1, 3h\n      Shot 4: after des1, 2h\n      Shot 5: after des1, 4h\n  \n      section Shooting Day 2\n      Shot 6: 1h\n      Shot 7: 2h\n      Shot 8: 4h\n      Shot 9: 3h\n  \n      section Shooting Day 3\n      Shot 10: 2h\n      Shot 11: 3h\n      Shot 12: 4h\n      Shot 13: 1h\n  \n      section Shooting Day 4\n      Shot 14: 2h\n      Shot 15: 3h\n      Shot 16: 1h\n      Shot 17: 4h\n  \n      section Shooting Day 5\n      Shot 18: 2h\n      Shot 19: 4h\n      Shot 20: 1h\n      Shot 21: 5h\n  ```\n-\n- Mermaid\n\t- Example\n\t\t- write mermaid code for a plan to produce client server PWA that uses stable diffusion for image generation\n\t- Christianity Historical Timeline\n\t\t- ```mermaid\n\t\t  gantt\n\t\t  title Christianity Historical Timeline\n\t\t  dateFormat YYYY-MM-DD\n\t\t  axisFormat %Y\n\t\t  %% Temporal Break for Early Years\n\t\t  section Initial Christianity\n\t\t  Jesus' Ministry :done, 0030-01-01, 0033-04-01\n\t\t  -- Temporal Break -- :active, 0033-04-02, 1054-07-15\n\t\t  Early Church :done, 1054-07-16, 1054-07-16\n\t\t  %% Eastern Churches\n\t\t  section Eastern Churches\n\t\t  Great Schism\n\t\t  - Eastern Orthodoxy :eastern, 1054-07-16, 2023-12-24\n\t\t  Oriental Orthodoxy               :oriental, 451-01-01, 2023-12-24\n\t\t  section Western Church\n\t\t  Early Roman Church        :rome, 1054-07-16, 1054-07-16\n\t\t  Western Schism            :schism, 1378-01-01, 1417-10-18\n\t\t  Catholicism               :catholic, 1054-07-16, 2023-12-24\n\t\t  Protestant Reformation :protestant, 1517-10-31, 2023-12-24\n\t\t  section Protestant Branches\n\t\t  Lutheranism     :lutheran, 1517-10-31, 2023-12-24\n\t\t  Calvinism       :calvinist, 1536-01-01, 2023-12-24\n\t\t  Anglicanism     :anglican, 1534-01-01, 2023-12-24\n\t\t  Baptist         :baptist, 1609-01-01, 2023-12-24\n\t\t  Methodism       :methodist, 1738-01-01, 2023-12-24\n\t\t  Pentecostalism  :pentecostal, 1906-01-01, 2023-12-24\n\t\t  section Other Developments\n\t\t  Counter-Reformation :counter, 1545-01-01, 1648-01-01\n\t\t  Modernist Controversy :modernist, 1800-01-01, 2023-12-24\n\t\t  Ecumenism Movement :ecumenism, 1900-01-01, 2023-12-24\n\t\t  section American Sect Churches\n\t\t  Adventism                :adventist, 1863-01-01, 2023-12-24\n\t\t  Latter-Day Saint Movement:Mormonism, 1830-04-06, 2023-12-24\n\t\t  Christian Science        :science, 1879-01-01, 2023-12-24\n\t\t  Jehovah's Witnesses      :jehovah, 1870-01-01, 2023-12-24\n\t\t  Pentecostalism           :pentecostal, 1901-01-01, 2023-12-24\n\t\t  Evangelicalism           :evangelical, 1730-01-01, 2023-12-24\n\t\t  Fundamentalism           :fundamental, 1910-01-01, 2023-12-24\n\t\t  Black Church Traditions  :blackchurch, 1780-01-01, 2023-12-24\n\t\t  Non-denominational       :nondenom, 1960-01-01, 2023-12-24\n\t\t  ```\n\t\t- Sequence Diagram\n\t\t- ```mermaid\n\t\t   sequenceDiagram\n\t\t       participant User as User\n\t\t       participant Script as Script\n\t\t       participant TxtFile as Trait .txt File\n\t\t       participant NameFiles as Name Files (forenames, nicknames, surnames)\n\t\t       participant JsonFile as Corresponding .json File\n\t\t       participant API as OpenAI API\n\t\t   \n\t\t       User->>Script: Run script with directory\n\t\t       Script->>NameFiles: Load names from forenames.txt, nicknames.txt, surnames.txt\n\t\t       NameFiles->>Script: Return names\n\t\t       loop For each .txt file in directory\n\t\t           Script->>TxtFile: Read .txt file content\n\t\t           TxtFile->>Script: Return content\n\t\t           Script->>Script: Hash file content\n\t\t           Script->>Script: Generate name using hash\n\t\t           Script->>API: Send prompt with name\n\t\t           API->>Script: Return story\n\t\t           alt If API limit reached or no response\n\t\t               API->>Script: Return empty response\n\t\t               Script->>User: Log API limit error\n\t\t           else If response received\n\t\t               API->>Script: Return narrative response\n\t\t               Script->>JsonFile: Read .json file\n\t\t               JsonFile->>Script: Return JSON data\n\t\t               Script->>Script: Insert story into JSON description\n\t\t               Script->>JsonFile: Write updated JSON\n\t\t           end\n\t\t       end\n\t\t   \n\t\t   ```\n-\n\t- ```mermaid graph TB\n\t    A[\"Web Browser\"] -- \"HTTP API Request\" --> B[\"Load Balancer\"]\n\t    B -- \"HTTP Request\" --> C[\"Crossover\"]\n\t    style C fill:#99cc99\n\t    C -- \"Talks to\" --> D[\"Redis\"]\n\t    C -- \"Talks to\" --> E[\"MySQL\"]\n\t    C -- \"Downstream API Request\" --> F[\"Multiplex\"]\n\t    F -- \"Returns Job ID\" --> C\n\t    C -- \"Long Poll API Request\" --> G[\"Evaluator\"]\n\t    G -- \"API Call\" --> F\n\t    G -- \"API Call\" --> H[\"Result-Fetcher\"]\n\t    H -- \"Downloads Results\" --> I[\"S3 or GCP Cloud Buckets\"]\n\t    I -- \"Results Stream\" --> G\n\t    G -- \"Results Stream\" --> C\n\t    C -- \"API Response\" --> B\n\t    B -- \"API Response\" --> A\n\t  \n\t  ```\n\t-\n- [Graphviz](https://graphviz.org/)\n- {{renderer code_diagram,graphviz}}\n\t- ```graphviz digraph G {\t\n\t      // Global settings\n\t      rankdir=LR;\n\t      node [shape=rectangle, style=filled, color=lightblue];\n\t      edge [color=black, penwidth=1.5];\n\t  \n\t      // Define nodes\n\t      node1 [label=\"Start\", shape=ellipse, color=lightgreen];\n\t      node2 [label=\"Process 1\"];\n\t      node3 [label=\"Decision\", shape=diamond, fillcolor=yellow];\n\t      node4 [label=\"Process 2\"];\n\t      node5 [label=\"End\", shape=ellipse, color=red];\n\t  \n\t      // Define edges\n\t      node1 -> node2;\n\t      node2 -> node3 [label=\"condition\"];\n\t      node3 -> node4 [label=\"yes\"];\n\t      node3 -> node5 [label=\"no\", style=dashed];\n\t  \n\t      // Subgraph (cluster)\n\t      subgraph cluster_0 {\n\t          label=\"Phase 1\";\n\t          color=grey;\n\t          node2 -> node3;\n\t          node3 -> node4;\n\t      }\n\t  \n\t      // Subgraph (cluster)\n\t      subgraph cluster_1 {\n\t          label=\"Phase 2\";\n\t          color=grey;\n\t          node4 -> node5;\n\t      }\n\t  \n\t      // Additional settings for layout\n\t      { rank=same; node2; node4; }\n\t      { rank=same; node3; node5; } }\n\t  \n\t  ```\n- [PlantUML](https://plantuml.com/)\n  {{renderer code_diagram,plantuml}}\n\t- ```plantuml @startwbs skinparam monochrome true * Business Process Modelling WBS ** Launch the project *** Complete Stakeholder Research *** Initial Implementation Plan ** Design phase *** Model of AsIs Processes Completed **** Model of AsIs Processes Completed1 **** Model of AsIs Processes Completed2 *** Measure AsIs performance metrics *** Identify Quick Wins ** Complete innovate phase @endwbs ```\n\t- {{renderer code_diagram,plantuml}} ```@startuml\n\t  \n\t  ' Define an interface interface Vehicle {\n\t      +int getWheelCount()\n\t      +String getModelName() }\n\t  \n\t  ' Define classes implementing the interface class Car implements Vehicle {\n\t      -String modelName\n\t      -int wheelCount\n\t      +Car(String modelName)\n\t      +int getWheelCount()\n\t      +String getModelName() }\n\t  \n\t  class Bike implements Vehicle {\n\t      -String modelName\n\t      -int wheelCount\n\t      +Bike(String modelName)\n\t      +int getWheelCount()\n\t      +String getModelName() }\n\t  \n\t  ' Define a generic class class Garage<T> {\n\t      -List<T> vehicles\n\t      +void parkVehicle(T vehicle)\n\t      +T retrieveVehicle() }\n\t  \n\t  ' Add notes to the diagram note right of Car : Cars usually have 4 wheels note left of Bike : Bikes usually have 2 wheels\n\t  \n\t  ' Define relationships Garage -up-|> Vehicle : contains >> Vehicle <|.. Car : implements Vehicle <|.. Bike : implements\n\t  \n\t  ' Add a title title Complex Class Diagram Example\n\t  \n\t  @enduml ```\n- [BPMN](https://en.wikipedia.org/wiki/Business_Process_Model_and_Notation)\n- [Bytefield](https://texdoc.org/serve/bytefield.pdf/0)\n- [BlockDiag](http://blockdiag.com/en/blockdiag/index.html)\n- [SeqDiag](http://blockdiag.com/en/seqdiag/index.html)\n- [ActDiag](http://blockdiag.com/en/actdiag/index.html)\n- [NwDiag](http://blockdiag.com/en/nwdiag/index.html)\n- [Ditaa](http://ditaa.sourceforge.net/)\n- [Nomnoml](https://www.nomnoml.com/)\n- [Erd](https://hackage.haskell.org/package/erd)\n- [Pikchr](https://pikchr.org/)\n- [Structurizr](https://structurizr.com/)\n- [Vega](https://vega.github.io/)\n- [Vega-Lite](https://vega.github.io/vega-lite/)\n- [WaveDrom](https://wavedrom.com/)\n- [D2](https://d2lang.com/)\n- [UMlet](https://www.umlet.com/)\n- [SvgBob](https://ivanceras.github.io/svgbob-editor/)\n- [PGF/TikZ](https://tikz.dev/)\n-",
        "link_types": [],
        "file_size": 19571
    },
    {
        "id": "Non transformer approaches.md",
        "name": "Non transformer approaches",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- # Mamba: Linear-Time Sequence Modelling with Selective State Spaces\n\t\t- [Mamba: Linear-Time Sequence Modeling with Selective State Spaces](https://arxiv.org/pdf/2312.00752.pdf)\n\t\t- **Research Design & Rationale**: The study introduces a new architecture, Mamba, which incorporates a selection mechanism and hardware-aware computation into structured state space models.\n\t\t- **Significance**: Addresses the inefficiency of Transformer models with a novel architecture that scales linearly and achieves superior performance.\n\t\t- **Real-world Implications**: Potential to improve a wide range of applications in natural language processing, bioinformatics, and other areas where sequence data is prevalent.\n\t\t- **Takeaways**: Mamba architecture improves upon structured state space models (SSMs) by adding selectivity and hardware-aware algorithms, achieving linear-time modeling with high-quality performance across several modalities.\n\t\t- **Practical Implications**: Provides a more efficient alternative to Transformers, especially beneficial for long sequence data.\n\t\t- **Potential Impact**: Could influence future developments in sequence modeling and foundational models across various domains.\n\t\t- **Abstract in a nutshell**: Mamba is a novel architecture for sequence modeling that enhances structured state space models (SSMs) with selective mechanisms and hardware-aware algorithms, achieving superior performance and efficiency.\n\t\t- **Gap/Need**: Traditional Transformer models have significant computational inefficiency, especially for long sequences. Mamba addresses this by incorporating a selection mechanism and hardware-aware computation in SSMs.\n\t\t- **Innovation**: Introduces a selection mechanism in SSMs, allowing input-dependent parameterization and a simplified architecture without attention or MLP blocks, enabling linear-time computation with maintained or enhanced performance.\n\t\t- ### Key Quotes\n\t\t- \"Mamba enjoys fast inference (5× higher throughput than Transformers) and linear scaling in sequence length and its performance improves on real data up to million-length sequences.\"\n\t\t- **\"This class of models can be computed very efficiently as either a recurrence or convolution with linear or near-linear scaling in sequence length.\"**\n\t\t- \"Selective SSMs and by extension the Mamba architecture are fully recurrent models with key properties that make them suitable as the backbone of general foundation models operating on sequences.\"\n\t\t- **How does Mamba achieve linear-time modeling?**: By introducing a selection mechanism in structured state space models and designing a hardware-aware algorithm that avoids materializing expanded states, thereby enhancing computational efficiency.\n\t\t- **What improvements does Mamba offer over traditional models?**: It achieves faster inference, linear scaling with sequence length, and competitive or superior performance across various data modalities including language, audio, and genomics.\n\t\t- **Can Mamba handle long sequences efficiently?**: Yes, it is specifically designed to address the computational inefficiencies of traditional models like Transformers in handling long sequences, offering linear scaling and improved performance.\n\t\t- Mamba outperforms Transformers of the same size in language modelling and matches Transformers twice its size both in pretraining and downstream evaluation, demonstrating its efficiency and effectiveness.\n\t\t- **Authors' Views**: The authors propose Mamba as a significant step forward in sequence modeling, addressing the inefficiency of Transformers while maintaining or improving performance.\n\t\t- **Comparative Analysis**: Mamba is positioned as superior to existing models, particularly Transformers, in terms of efficiency and scalability\n- ## Quick lit survey.  (based on [Mamba-Palooza](https://www.youtube.com/watch?v=Bg1LQ_jWliU))\n\t- Over 30 new papers and projects since original Mamba paper, with new ones coming out every 1-2 days\n\t- 60% of papers address vision/image processing, 25% natural language, and the rest cover various applications\n\t- 80% of papers modified the original Mamba architecture in some way\n\t- 73% of papers reported state-of-the-art results (though not independently verified yet)\n\t- Handling of state in Mamba architecture is not always clear in papers, more research needed\n\t- Swapping out selective state space portion of Mamba in MoE architectures could be an interesting avenue to explore\n\t- Infrastructure and capital advantages for big tech incumbents in deploying large-scale MoE models\n\t- ## Mamba Learning Theory and Interpretability\n\t\t- ### In-Context Learning (Is Mamba Capable of In-Context Learning?)\n\t\t\t- Mamba can do in-context learning, gradually optimizing internal representations through layers\n\t\t\t- Similar pattern to Transformers: elevation of concepts and more accurate activations through layers, then collapse at final prediction\n\t\t- ### Learning Rules from Sequences (Othello Mamba)\n\t\t\t- Mamba learns rules of Othello from just a sequence of moves, achieving higher board accuracy than OthelloGPT\n\t\t\t- More data efficient, but becomes less accurate as game progresses and requires longer training than same-sized Transformer\n\t\t- ### Strengths and Weaknesses (Can Mamba Learn How to Learn?)\n\t\t\t- Mamba outperforms Transformers on tasks with irrelevance and noise\n\t\t\t- Mamba struggles with high-precision memory recall compared to Transformers\n\t\t\t- Hybrid MambaFormer model outperforms both Transformer and Mamba on various evaluation tasks\n\t- ## Mixture of Experts (MoE) Architectures\n\t\t- Major force driving frontier models (e.g., GPT-4, Gemini 1.5)\n\t\t- MoE-Mamba (MoE-Mamba) achieved same loss as original Mamba with 2.2x less training steps, scaling up to 32 experts\n\t\t- BlackMamba scaled up to 2.8B parameters and 8 experts, with generation latency well below Transformer, Transformer MoE, and Mamba\n\t- # Vision Mamba\n\t\t- Majority of Mamba papers (over 60%) address vision/image processing, especially biomedical image segmentation\n\t\t- Key themes:\n\t\t\t- Representing data as sequences is crucial\n\t\t\t- Images are not inherently sequential like language, music, or DNA\n\t\t\t- Multi-scan approaches enable handling non-sequential data\n\t\t\t- Hybrid architectures leverage strengths of different models\n\t\t- Open questions and challenges:\n\t\t\t- Scaling to larger models and datasets\n\t\t\t- Developing state regularization methods\n\t\t\t- Integrating Mamba with other architectural advances (e.g., memory tokens)\n\t\t- Potential for transformative impact, especially in biology and vision applications\n\t\t- Approaches:\n\t\t\t- U-Mamba (U-Mamba): Hybrid CNN-SSM architecture outperforming CNN and Transformers in biomedical image segmentation\n\t\t\t- Swin-UMamba (Swin-UMamba): Combines Mamba with ImageNet pre-training, outperforms U-Mamba\n\t\t\t- Vision Mamba: Bidirectional (forward and backward) scanning for learning visual representations\n\t\t\t- VMamba: Four-way \"cross-scan\" starting at each corner, combining representations\n\t\t\t- VM-UNet (VM-UNet): Applies VMamba's four-way scan to medical image segmentation\n\t\t\t- Mamba-ND: Multi-dimensional sequencing for video and weather data, using sequential SSMs\n\t\t\t- SegMamba: 3D image segmentation with three-way scan, handling long sequences\n\t\t\t- Vivim: Three-way scan for video\n\t\t\t- MambaMorph: Aligns two input images by generating deformation field\n\t\t- Key insights:\n\t\t\t- Turning images into sequences is crucial, can be done through multi-scan approaches\n\t\t\t- Combining scans sequentially may be more effective than parallel\n\t\t\t- Mamba enables memory-efficient processing of high-resolution images, promising for edge applications (e.g., robotics)\n\t- # Mixture of Experts (MoE) Architectures\n\t\t- Major force in frontier models (GPT-4, Gemini 1.5)\n\t\t- MoE-Mamba and BlackMamba demonstrate MoE's effectiveness with Mamba\n\t\t- Open questions around scaling and infrastructure requirements for large-scale MoE-Mamba models\n\t\t- [Introducing Jamba: AI21's Groundbreaking SSM-Transformer Model](https://www.ai21.com/blog/announcing-jamba)\n\t- # Long Context Modeling\n\t\t- LongMamba (LongMamba): Generalizes to 40k tokens after training on 16k, nearly perfect on \"needle in a haystack\" task\n\t\t- Evo: Models long DNA sequences, learning a \"cell model\" analogous to language models' \"world model\"\n\t\t- Potential challenges:\n\t\t\t- Eventual \"rotting\" of internal states with extreme context lengths\n\t\t\t- Need for state regularization or \"pruning\" to maintain performance\n\t\t- Implications for biology: Foundation models could revolutionize drug discovery and biological research\n\t- # Potential Applications\n\t\t- ## Climate Science?\n\t\t\t- To approach the problem of using Mamba to analyze space-acquired time series image-based climate data from multi-spectrum sensors, we can draw upon several techniques and architectures discussed in the Mamba literature. Here's a proposed approach:\n\t\t\t\t- Data Preprocessing:\n\t\t\t\t\t- Combine multi-spectrum sensor data:\n\t\t\t\t\t\t- Use techniques like MambaMorph to align and merge data from different sensors\n\t\t\t\t\t\t- Generate deformation fields to spatially align images from various sources\n\t\t\t\t- Normalize data to ensure consistent scales and ranges across sensors\n\t\t\t\t\t- Temporal alignment:\n\t\t\t\t\t\t- Use techniques like dynamic time warping (DTW) to align time series data temporally\n\t\t\t\t\t\t- Handle missing data points and inconsistent sampling frequencies\n\t\t\t\t- Create a unified temporal grid for all data sources\n\t\t\t\t\t- Incorporate historical data:\n\t\t\t\t\t\t- Preprocess and align historical records (e.g., weather station data, satellite imagery) with the space-acquired data\n\t\t\t\t\t\t- Use techniques like transfer learning or domain adaptation to handle differences in data modalities and distributions\n\t\t\t\t- Mamba Architecture:\n\t\t\t\t\t- Multi-dimensional sequencing (Mamba-ND):\n\t\t\t\t\t\t- Treat the aligned and preprocessed data as a multi-dimensional sequence (e.g., spatial dimensions, time, and spectral channels)\n\t\t\t\t\t\t- Apply Mamba-ND to capture dependencies across all dimensions\n\t\t\t\t\t- Cross-scanning (VMamba or SegMamba):\n\t\t\t\t\t\t- Perform multi-directional scans (e.g., four-way or three-way) to capture spatial dependencies\n\t\t\t\t\t\t- Combine the representations from different scans to obtain a comprehensive understanding of the data\n\t\t\t\t\t- Hybrid architectures (U-Mamba or Swin-UMamba):\n\t\t\t\t\t\t- Incorporate convolutional layers (CNN) for local feature extraction\n\t\t\t\t\t\t- Use Mamba layers for capturing long-range dependencies and global context\n\t\t\t- Leverage pre-training on large-scale datasets (e.g., ImageNet) to improve performance\n\t\t\t  high-level diagram of the proposed approach using Mermaid:\n\t\t\t- ```mermaid\n\t\t\t  graph TD\n\t\t\t      A[Multi-spectrum Sensor Data] --> B{Data Preprocessing}\n\t\t\t      C[Historical Data] --> B\n\t\t\t      \n\t\t\t      subgraph Data Preprocessing\n\t\t\t          B --> D[Combine Multi-spectrum Data]\n\t\t\t          B --> E[Temporal Alignment]\n\t\t\t          B --> F[Incorporate Historical Data]\n\t\t\t          \n\t\t\t          D --> G[MambaMorph for Alignment]\n\t\t\t          D --> H[Generate Deformation Fields]\n\t\t\t          D --> I[Normalize Data]\n\t\t\t          \n\t\t\t          E --> J[Dynamic Time Warping]\n\t\t\t          E --> K[Handle Missing Data]\n\t\t\t          E --> L[Create Unified Temporal Grid]\n\t\t\t          \n\t\t\t          F --> M[Align Historical Records]\n\t\t\t          F --> N[Transfer Learning/Domain Adaptation]\n\t\t\t      end\n\t\t\t      \n\t\t\t      B --> O{Mamba Architecture}\n\t\t\t      \n\t\t\t      subgraph Mamba Architecture\n\t\t\t          O --> P[Multi-dimensional Sequencing]\n\t\t\t          O --> Q[Cross-scanning]\n\t\t\t          O --> R[Hybrid Architectures]\n\t\t\t          \n\t\t\t          P --> S[Mamba-ND]\n\t\t\t          P --> T[Capture Dependencies Across Dimensions]\n\t\t\t          \n\t\t\t          Q --> U[VMamba/SegMamba]\n\t\t\t          Q --> V[Multi-directional Scans]\n\t\t\t          Q --> W[Combine Scan Representations]\n\t\t\t          \n\t\t\t          R --> X[U-Mamba/Swin-UMamba]\n\t\t\t          R --> Y[Convolutional Layers for Local Features]\n\t\t\t          R --> Z[Mamba Layers for Long-range Dependencies]\n\t\t\t          R --> AA[Pre-training on Large-scale Datasets]\n\t\t\t      end\n\t\t\t      \n\t\t\t      O --> AB[Comprehensive Data Representation]\n\t\t\t      AB --> AC[Predictive Component]\n\t\t\t      AB --> AD[Up-to-date Data vs. Historical Context]\n\t\t\t      \n\t\t\t      subgraph Additional Considerations\n\t\t\t          AE[Handle Data Quality Issues]\n\t\t\t          AF[Incorporate Domain Knowledge]\n\t\t\t          AG[Leverage Transfer Learning]\n\t\t\t          AH[Evaluate Model Performance]\n\t\t\t          AI[Interpret and Visualize Representations]\n\t\t\t      end\n\t\t\t      \n\t\t\t      AC --> AJ{Output Formats}\n\t\t\t      AJ --> AK[Short-term Forecasts]\n\t\t\t      AJ --> AL[Long-term Projections]\n\t\t\t      \n\t\t\t      AE --> AB\n\t\t\t      AF --> AB\n\t\t\t      AG --> AB\n\t\t\t      AH --> AB\n\t\t\t      AI --> AB\n\t\t\t  ```\n\t\t\t- ## Things to do\n\t\t\t\t- TODO What is the spatial and temporal resolution of the space-acquired data?\n\t\t\t\t- TODO How far back does the historical data go, and at what resolution?\n\t\t\t\t- TODO Are there any specific climate variables or phenomena of interest (e.g., temperature, precipitation, extreme events)?\n\t\t\t\t- TODO What is the desired output format for the predictive component (e.g., short-term forecasts, long-term projections)?\n\t\t\t\t- TODO Handling data quality issues (e.g., cloud cover, sensor noise)\n\t\t\t\t- TODO Incorporating domain knowledge (e.g., physical constraints, climate models)\n\t\t\t\t- TODO Leveraging transfer learning from pre-trained models on similar datasets\n\t\t\t\t- TODO Evaluating the model's performance using appropriate metrics and validation techniques\n\t\t\t\t- TODO Interpreting and visualizing the learned representations for stakeholder communication\n\t\t- ## Ontological Layer for Metaverse\n\t\t\t- To approach the problem of using Mamba to analyze formal ontological graphs as used by the W3C, we can draw upon several techniques and architectures discussed in the Mamba literature. Here's a proposed approach:\n\t\t\t- Data Preprocessing:\n\t\t\t\t- Graph Normalization:\n\t\t\t\t\t- Ensure consistent formatting and structure of the ontological graphs\n\t\t\t\t\t- Handle missing or inconsistent data\n\t\t\t\t\t- Normalize node and edge labels\n\t\t\t\t- Graph Merging:\n\t\t\t\t\t- Combine multiple ontological graphs into a single unified graph\n\t\t\t\t\t- Resolve conflicts and inconsistencies between different ontologies\n\t\t\t\t\t- Establish mappings between equivalent concepts across ontologies\n\t\t\t\t- Graph Embedding:\n\t\t\t\t\t- Generate low-dimensional vector representations of nodes and edges\n\t\t\t\t\t- Preserve the semantic relationships and structure of the ontological graphs\n\t\t\t\t\t- Use techniques like RDF2Vec, TransE, or Graph Convolutional Networks (GCNs)\n\t\t\t- Mamba Architecture:\n\t\t\t\t- Graph-Mamba:\n\t\t\t\t\t- Adapt the Mamba architecture to handle graph-structured data\n\t\t\t\t\t- Utilize the selective state space mechanism to capture long-range dependencies in the ontological graphs\n\t\t\t\t\t- Achieve efficient memory usage and reduced computational complexity compared to traditional graph neural networks (GNNs)\n\t\t\t\t- Multi-dimensional Sequencing (Mamba-ND):\n\t\t\t\t\t- Treat the ontological graphs as multi-dimensional sequences (e.g., node features, edge types, and graph structure)\n\t\t\t\t\t- Apply Mamba-ND to capture dependencies across all dimensions\n\t\t\t- Hybrid Architectures:\n\t\t\t\t- Combine Graph-Mamba with other graph neural network architectures (e.g., GCNs, GraphSAGE)\n\t\t\t\t- Leverage the strengths of both approaches to capture local and global patterns in the ontological graphs\n\t\t\t\t-\n\t\t\t\t-\n\t\t\t- ```mermaid\n\t\t\t  graph TD\n\t\t\t   A[Ontological Graphs] --> B(Data Preprocessing)\n\t\t\t   B --> C{Mamba Architecture}\n\t\t\t   C --> D[Graph-Mamba]\n\t\t\t   C --> E[Multi-dimensional Sequencing Mamba-ND]\n\t\t\t   C --> F[Hybrid Architectures]\n\t\t\t   D --> G[Comprehensive Graph Representation]\n\t\t\t   E --> G\n\t\t\t   F --> G\n\t\t\t   G --> H[Ontology Alignment]\n\t\t\t   G --> I[Knowledge Graph Completion]\n\t\t\t   G --> J[Semantic Similarity]\n\t\t\t   ```\n\t\t\t\t-\n\t\t\t\t- TODO What are the specific ontologies being used (e.g., RDF, OWL)?\n\t\t\t\t- TODO Are there any domain-specific requirements or constraints to consider?\n\t\t\t\t- TODO What are the desired output tasks (e.g., ontology alignment, knowledge graph completion, semantic similarity)?\n\t\t\t\t- TODO How large and complex are the ontological graphs being analyzed?\n\t\t\t\t- TODO Handling scalability issues for large-scale ontological graphs\n\t\t\t\t- TODO Incorporating domain knowledge and ontology-specific constraints\n\t\t\t\t- TODO Leveraging transfer learning from pre-trained models on similar ontological graphs\n\t\t\t\t- TODO Evaluating the model's performance using appropriate graph-based metrics and validation techniques\n\t\t\t\t- TODO Interpreting and visualizing the learned graph representations for ontology engineers and domain experts\n- ## Implementations\n\t- https://www.statespace.info/  Lots of tracked projects here. This is the best place.\n\t- Can use the https://huggingface.co/docs/accelerate/usage_guides/fsdp for sharded training\n\t- [[2401.04081] MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts (arxiv.org)](https://arxiv.org/abs/2401.04081)\n\t- [havenhq/mamba-chat: Mamba-Chat: A chat LLM based on the state-space model architecture 🐍 (github.com)](https://github.com/havenhq/mamba-chat)\n\t- [[2401.13660] MambaByte: Token-free Selective State Space Model (arxiv.org)](https://arxiv.org/abs/2401.13660) doesn't need tokens!!\n-",
        "link_types": [],
        "file_size": 17399
    },
    {
        "id": "Revision List.md",
        "name": "Revision List",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- from here [xandie985/data-scientist-roadmap2024 (github.com)](https://github.com/xandie985/data-scientist-roadmap2024?tab=readme-ov-file)\n- Languages\n\t- TODO Python\n\t- DONE R\n- **Frameworks & Libraries:**\n\t- TODO Scikit-learn\n\t- TODO Numpy\n\t- TODO Pandas\n\t- TODO TensorFlow\n\t- TODO PyTorch\n\t- TODO XGBoost\n\t- TODO LightGBM\n\t- TODO **Keras** (High-level deep learning API)\n\t- TODO **Jax** (High-performance numerical computation)\n\t- TODO **CatBoost** (Gradient boosting framework)\n\t- TODO **StaMPS** (Scalable Modeling and Partitioning for Statistics)\n- **Cloud Platforms & Services:**\n\t- TODO Docker (Containerization platform)\n\t- TODO Learn any one of the following:\n\t\t- TODO GCP (Google Cloud Platform)\n\t\t\t- Cloud Storage\n\t\t\t  :LOGBOOK:\n\t\t\t  CLOCK: [2024-04-19 Fri 12:26:41]--[2024-04-19 Fri 12:26:42] =>  00:00:01\n\t\t\t  :END:\n\t\t\t- Compute Engine\n\t\t\t  :LOGBOOK:\n\t\t\t  CLOCK: [2024-04-19 Fri 12:26:42]--[2024-04-19 Fri 12:26:42] =>  00:00:00\n\t\t\t  :END:\n\t\t\t- Cloud SQL\n\t\t\t  :LOGBOOK:\n\t\t\t  CLOCK: [2024-04-19 Fri 12:26:42]--[2024-04-19 Fri 12:26:42] =>  00:00:00\n\t\t\t  :END:\n\t\t\t- Cloud Functions\n\t\t\t  :LOGBOOK:\n\t\t\t  CLOCK: [2024-04-19 Fri 12:26:42]--[2024-04-19 Fri 12:26:42] =>  00:00:00\n\t\t\t  :END:\n\t\t\t- BigQuery\n\t\t\t  :LOGBOOK:\n\t\t\t  CLOCK: [2024-04-19 Fri 12:26:42]--[2024-04-19 Fri 12:26:42] =>  00:00:00\n\t\t\t  :END:\n\t\t\t- AI Platform (includes Vertex AI)\n\t\t\t  :LOGBOOK:\n\t\t\t  CLOCK: [2024-04-19 Fri 12:26:42]--[2024-04-19 Fri 12:26:42] =>  00:00:00\n\t\t\t  :END:\n\t\t- TODO Azure (Microsoft Azure)\n\t\t\t- Blob Storage\n\t\t\t- Virtual Machines\n\t\t\t- SQL Database / Azure Database for PostgreSQL/MySQL\n\t\t\t- Azure Functions\n\t\t\t- Azure Synapse Analytics\n\t\t\t- Azure Machine Learning\n\t\t- TODO AWS (Amazon Web Services)\n\t\t\t- AWS S3\n\t\t\t- AWS EC2\n\t\t\t- AWS RDS\n\t\t\t- AWS Lambda\n\t\t\t- AWS Redshift\n\t\t\t- AWS SageMaker\n\t- TODO Kubeflow (Cloud-native machine learning platform)\n\t- TODO Kubernetes (Container orchestration platform)\n- **Data Tools & Libraries:**\n\t- TODO SQL (including OLAP & OLTP variations)\n\t- TODO Pandas\n\t- TODO Elasticsearch\n\t- TODO **Dask** (Parallel computing library for big data)\n\t- TODO **Spark** (Large-scale data processing framework)\n\t- TODO **Airbyte** (Open-source data integration platform)\n- **Web Development Frameworks:**\n\t- TODO FastAPI\n\t- TODO Uvicorn (likely mentioned in conjunction with FastAPI)\n\t- TODO **Streamlit** (Machine learning app development framework)\n- **Machine Learning Concepts:**\n\t- TODO Supervised Learning\n\t\t- TODO Regression\n\t\t- TODO Classification\n\t- TODO Unsupervised Learning\n\t\t- TODO Clustering\n\t\t- TODO Dimensionality Reduction\n\t- TODO Recommendation Systems\n\t- TODO Time Series Forecasting\n\t- TODO Natural Language Processing (NLP)\n\t\t- TODO Text Mining\n\t\t- TODO Natural Language Understanding (NLU)\n\t\t\t- TODO Sentiment Analysis\n\t\t\t- TODO Named Entity Recognition (NER)\n\t\t\t- TODO Question Answering (QA)\n\t\t- TODO Natural Language Generation (NLG)\n\t- TODO Deep Learning Techniques\n\t\t- TODO Convolutional Neural Networks (CNNs)\n\t\t- TODO Long Short-Term Memory networks (LSTMs)\n\t\t- TODO Generative AI\n\t- TODO Reinforcement Learning\n\t- TODO Bayesian Optimization\n- **DevOps & MLOps Tools:**\n\t- TODO Airflow (Workflow orchestration tool)\n\t- TODO MLFlow (Machine learning lifecycle management)\n\t- TODO **Prometheus** (Monitoring and alerting system)\n\t- TODO **Grafana** (Data visualization and analytics tool)\n\t- TODO **Git version control** (e.g., GitLab, GitHub)\n- **Data Visualization Tools:**\n\t- TODO Tableau\n\t- TODO Matplotlib (Python plotting library)\n\t- TODO Seaborn (Statistical data visualization library built on top of Matplotlib)\n\t- TODO Power BI (Microsoft business intelligence platform)\n- **Other:**\n\t- TODO ETL (Extract, Transform, Load) processes\n\t- TODO Optimisation algorithms (can be broader than just machine learning)\n\t- TODO Distributed training\n\t- TODO Curse of dimensionality\n\t- TODO Financial modeling\n- LLMs\n\t- TODO Lang-chain Agents\n\t- TODO Prompt engineering\n\t- TODO RAG\n\t- TODO Fine-tuning",
        "link_types": [],
        "file_size": 3977
    },
    {
        "id": "Hyper personalisation.md",
        "name": "Hyper personalisation",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n-\n- ((656c7f3d-55af-42f3-989c-19f7d92f579f))\n- # The Golden Key: AI-Guided Emergent Narratives for Hyper-Personalized Location-Based Events\n- ## Overview\n- [The Golden Key](https://schedule.sxsw.com/2024/films/2196919) is an immersive, interactive art installation that generates never-ending, location-specific fairy tales using AI technologies. It combines large language models, generative AI, and user input to create unique, personalized narratives that evolve over time.\n- ## Key Features\n\t- Three large projection screens display AI-generated visuals that illustrate the unfolding story\n\t- Kiosks allow participants to input their own story elements, which are integrated into the narrative within minutes\n\t- The AI system draws from a database of story motifs, archetypes, and folktales to create a cohesive, ever-evolving narrative\n\t- The installation adapts to each location, incorporating local history, artists, and cultural elements into the generated stories\n- ## Technical Implementation\n\t- Backend infrastructure includes multiple high-performance computers running stable diffusion servers for image generation\n\t- ChatGPT 3.5 and 4 models are used for text generation, with the ability to request specific models for different parts of the system\n\t- Text-to-speech services are run locally to ensure reliability and reduce dependence on cloud services\n\t- TouchDesigner is used to create the three-panel projection mural, with slight parallax movement for a mesmerizing effect\n- ## Artistic Vision\n\t- The Golden Key explores the concept of myth-making and the role of AI in shaping cultural narratives. It invites participants to consider the implications of living in a world where artificially generated stories are ubiquitous. The installation aims to encourage critical thinking about the impact of AI on creativity, diversity, and representation in media.\n- ## Participant Experience\n\t- Participants approach kiosks where they are prompted to answer questions or provide story elements within a 60-second time limit\n\t- The user-generated content is then integrated into the ongoing narrative, appearing on the projection screens within minutes\n\t- Participants are encouraged to input multiple story elements and then sit back and watch how their contributions shape the unfolding tale\n\t- The AI-generated visuals and audio narration create an immersive, mesmerizing experience that adapts to each participant's input\n- ## Future Developments\n\t- The creators of The Golden Key are exploring new possibilities for interactive, AI-driven experiences, including:\n\t- Incorporating video and 3D elements to enhance the liveliness and immersion of the generated content\n\t- Developing mobile app touchpoints that allow participants to interact with the installation beyond the physical space\n\t- Collaborating with other artists and researchers to address issues of bias, diversity, and representation in AI-generated media\n\t- Expanding the installation to include a wider range of cultural motifs, archetypes, and folktales from around the world",
        "link_types": [],
        "file_size": 3116
    },
    {
        "id": "Llama.md",
        "name": "Llama",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ## Llama 3 overview\n\t- Meta (formerly Facebook) has recently released LLaMA-3,  a series of foundational large language models (LLMs) that aim to advance AI research while remaining more accessible in terms of computational requirements.\n\t- ### Performance\n\t\t- LLaMA-3 models demonstrate competitive performance on various language modeling tasks, showcasing significant improvements over previous open weights models.\n\t\t- Integrated free across their social media platforms\n\t\t- Fast image generation, can be fine tunes for creatives.\n\t\t- [Introducing New AI Experiences Across Our Family of Apps and Devices | Meta (fb.com)](https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/)\n\t\t- [What’s up with Llama 3? Arena data analysis | LMSYS Org](https://lmsys.org/blog/2024-05-08-llama3/)\n\t\t- ![](https://lmsys.org/images/blog/llama3/topic_win_rate.png){:width 500}\n\t\t-\n\t- ### Efficiency\n\t\t- LLaMA-3 models are notably smaller than comparable LLMs. They were more efficient to train.\n\t\t- Sizes are currently:\n\t\t\t- 7B parameters, outperforming the previous 70B models on some metrics\n\t\t\t- 70B parameters, approaching or exceeding some closed source online models\n\t\t\t- 400B parameters (still in training), expected to outperform SOTA models\n\t\t- This efficiency allows them to run on less powerful hardware, broadening accessibility for researchers.\n\t\t\t- They can be fine tuned more easily.\n\t- ### Bias and Safety\n\t\t- Meta has taken active steps to assess and mitigate potential biases and harmful outputs. This is usually \"undone\" by the community at some stage for performance gains, raising important questions.\n\t- ### Open-Source Focus\n\t\t- Meta's release of the LLaMA-3 weights and code under a non-commercial license fosters transparency and encourages research collaboration.\n\t- ![1713640453190.jpeg](../assets/1713640453190_1713644111547_0.jpeg)\n- ## Acceptable Use Policy\n\t- **Open Source Controversy**\n\t\t- Llama 3 is claimed to be open source but faces criticisms.\n\t\t- Licence restrictions may not meet the [[open source]] Initiative's definition.\n\t\t- Restrictions on free use, modification, and redistribution.\n\t- **Acceptable Use Policy (AUP)**\n\t\t- Applicable to Llama 2, but also underpins Llama 3 license.\n\t\t- Prohibits:\n\t\t\t- Law violations.\n\t\t\t- Infringement of third-party rights.\n\t\t\t- Misuse of sensitive information.\n\t\t- Emphasizes compliance across jurisdictions.\n\t\t- Lacks specifics on consequences for policy violations.\n\t- **Intellectual Property Rights**\n\t\t- Grants non-exclusive, worldwide, non-transferable, royalty-free license.\n\t\t- Users can utilize and modify Llama Materials under conditions.\n\t\t- Meta retains ownership of foundational technology and Llama Materials.\n\t\t- Licensees own derivative works but with commercial use restrictions.\n\t- **Legal Implications**\n\t\t- Termination of license if licensee sues Meta for IP infringement.\n\t\t- Mandatory indemnification of Meta against third-party claims related to user's use of Llama.\n\t- **License and AUP Dynamics**\n\t\t- Unilateral updates to AUP by Meta.\n\t\t- Compliance with extensive laws and regulations required.\n\t\t- Significant operational constraints implied.\n\t\t- Liability limitations and warranty disclaimers shift risk to users.\n- # Fine-Tunes of Merit\n\t- [cognitivecomputations/dolphin-2.9-llama3-8b · Hugging Face](https://huggingface.co/cognitivecomputations/dolphin-2.9-llama3-8b)\n\t-",
        "link_types": [
            "open source"
        ],
        "file_size": 3432
    },
    {
        "id": "Algorithmic Bias and Variance.md",
        "name": "Algorithmic Bias and Variance",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true \n\n#Public page\n\t - automatically published\n- # The traditional ML concept:\n\t- In machine learning, bias and variance represent a trade-off in a model's ability to generalize.\n\t - **High Bias:** Model is too simple, underfits data,  generalizes poorly.\n\t - **High Variance:**  Model is overly complex, overfits data, generalizes poorly\n\t - **Goal:** Find the ideal balance for accurate predictions on new data.\n- ![Image preview](https://media.licdn.com/dms/image/D4D22AQEIlric5cK72Q/feedshare-shrink_800/0/1707399478375?e=1710374400&v=beta&t=G66QHZMpWZCZb9aJ61vOj7gEqcZWSmTEobNKMADnlPg)\n-\n- ## Bias in Large Language Models (LLMs):\n\t- Takes on an additional and critical dimension. These models aren't just fitting curves; they're processing  the complexities and prejudices within massive amounts of human language data.\n\t- Even a statistically \"accurate\" LLM can reflect the worst of human biases hidden within our own messy, real-world language.\n- **How societal bias seeps into LLMs:**\n\t- **Training data:** If real-world text samples contain racial stereotypes, sexist viewpoints, etc., the LLM can internalize these.\n\t- **Associations:** Models learn by statistical patterns. \"If X then often Y\" can replicate prejudices even if 'X' is a demographic and 'Y' is a negative or limiting assumption. [[[https://arxiv.org/abs/1607.06520](https://arxiv.org/abs/1607.06520)]]\n- **Consequences of LLM bias:**\n\t- * **Perpetuation of stereotypes:** When biased language is generated, it amplifies harmful misconceptions that already exist in society, harming marginalized groups.\n\t- * **Algorithmic decision-making:** If LLMs are used in areas like hiring or risk assessment, bias can translate into real-world discrimination. [[<invalid URL removed>]]\n- **Addressing the problem:**\n\t- * **It's not about elimination:** Creating perfectly unbiased language models is unlikely.  The focus is on:\n\t- * **Identifying bias:** Thorough testing across diverse demographics is crucial.\n\t- * **Mitigation:** De-biasing techniques, more representative training data, etc., can reduce harmful outputs.\n\t- * **Responsible use:** Recognizing the potential for bias means we, as users, must stay critical, especially in sensitive areas.\n\t- [twitter link to the render loading below](https://twitter.com/bindureddy/status/1760343060985340368)\n{{twitter https://twitter.com/bindureddy/status/1760343060985340368}}\n\t - ## Bias in images\n\t- Bias is really hard, and the current tools are blunt.\n\t- [twitter link to the render loading below](https://twitter.com/IMAO_/status/1760093853430710557)\n{{twitter https://twitter.com/IMAO_/status/1760093853430710557}}\n\t - # Research Papers\n\t- **Homogenization of Cultural Preferences**: Budzinski and Pannicke (2017) analyzed voting data from the Eurovision Song Contest to test the hypothesis of homogenization of cultural preferences due to digitalization. Contrary to the theory, their findings do not support a trend towards homogenization. Instead, some indicators suggest weak trends of deconcentration in voting behavior, indicating diverse preferences [(Budzinski & Pannicke, 2017)](https://consensus.app/papers/preferences-music-converge-across-countries-empirical-budzinski/4baf26344e6c5f62a89851a45f2e8ee9/?utm_source=chatgpt).\n\t- **Consumer Behavior Heterogeneity**: Mooij and Hofstede (2002) argue that converging technology and income levels will not lead to a homogenization of consumer behavior. Cultural differences will likely cause consumer behavior to become more heterogeneous, emphasizing the importance of understanding national cultural values and their impact on behavior [(Mooij & Hofstede, 2002)](https://consensus.app/papers/convergence-divergence-consumer-behavior-implications-mooij/0fdf7549d4ed5a10b4e67469115c83e6/?utm_source=chatgpt).\n\t- **Digital Culture and Education**: Kultaieva (2020) discusses the impact of digital culture on communication and self-recognition in post-industrial societies. The paper highlights the changes in communication forms within digital culture, emphasizing visual culture over traditional writing culture [(Kultaieva, 2020)](https://consensus.app/papers/homo-digitalis-digital-culture-digital-education-kultaieva/f44183f43b2c5fb79e12fbea03e1804d/?utm_source=chatgpt).\n\t- **Algorithmic Consumer Culture**: Airoldi and Rokka (2022) conceptualize algorithmic consumer culture, exploring how the opacity, authority, non-neutrality, and recursivity of algorithms affect consumer culture at various levels. This provides insights into how digitalization and big data surveillance practices shape consumption patterns [(Airoldi & Rokka, 2022)](https://consensus.app/papers/consumer-culture-airoldi/d2cfefc419485f6286ce2e4ca9d165bf/?utm_source=chatgpt).\n\t- **Cultural Homogenization and Technology**: Fairweather and Rogerson (2003) discuss the implications of global cultural homogenization in a technologically dependent world, examining how information and communication technologies contribute to this process [(Fairweather & Rogerson, 2003)](https://consensus.app/papers/problems-homogenisation-technologically-world-fairweather/906e1d758b775c2a963acc4d52438a94/?utm_source=chatgpt).\n\t- **Cultural Consequences of Globalization**: Holton (2000) analyzes cultural consequences of globalization, discussing homogenization, polarization, and hybridization theses. The study suggests that global culture is not becoming entirely standardized around Western patterns, highlighting cultural alternatives and resistance [(Holton, 2000)](https://consensus.app/papers/globalizations-cultural-consequences-holton/ecdfbc4c728d55378e11dd54e01fe806/?utm_source=chatgpt).\n\t- [Filterworld: How Algorithms Flattened Culture: Chayka, Kyle: 9780385548281: Amazon.com: Books](https://www.amazon.com/Filterworld-How-Algorithms-Flattened-Culture/dp/0385548281)\n\t-\n-\n\t- Model Evaluation Techniques\n\t - Basic Parameters\n\t\t\t- Bias & Variance\n\t - Measures to understand if our model is too simplistic (high bias) or too complex (high variance).\n\t\t\t\t- [Bias-Variance in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n\t\t\t- Overfitting & Underfitting\n\t - Indicators that our model is either too closely tailored to the training data or too general.\n\t\t\t\t- [Regularization in TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers)\n\t\t\t- Holdout Method (Train / Test Split)\n\t - A basic approach to split the dataset into training and testing sets.\n\t\t\t\t- [Train/Test Split in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n\t\t\t- Confidence Intervals\n\t - Statistical range that expresses where the true model performance metric lies with a certain probability.\n\t\t\t\t- [StatsModels for Confidence Intervals](https://www.statsmodels.org/stable/index.html)\n\t - Resampling Methods\n\t\t\t- Repeated Holdout\n\t - Running holdout method multiple times to get a better estimate of model performance.\n\t\t\t\t- [RepeatedKFold in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html)\n\t\t\t- Empirical Confidence Intervals\n\t - Confidence intervals derived from the resampling distribution of a performance metric.\n\t\t\t\t- [Bootstrapping in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.utils.resample.html)\n\t - Cross-validation\n\t\t\t- Hyperparameters Tuning\n\t - The process of finding the optimal set of hyperparameters for a learning algorithm.\n\t\t\t\t- [GridSearchCV in scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n\t\t\t- Model Selection\n\t - Choosing the best model from a set of candidate models.\n\t\t\t\t- [Model Selection in scikit-learn](https://scikit-learn.org/stable/model_selection.html)\n\t\t\t- Algorithm Selection\n\t - Determining which learning algorithm to use for a given problem.\n\t\t\t\t- [MLflow for Experiment Tracking](https://mlflow.org/)\n\t - Statistical Tests\n\t\t\t- Model Comparison\n\t - Statistical tests to compare the performance of two models.\n\t\t\t\t- [Paired t-tests in SciPy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html)\n\t\t\t- Algorithm Comparison]- Comparing different algorithms to find which performs best on the data.\n\t\t\t\t- [Friedman test in SciPy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.friedmanchisquare.html)\n\t - Evaluation Metrics\n\t\t\t- Metrics to quantify the performance of the model.\n\t\t\t\t- [Evaluation Metrics in scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html)\n\t-",
        "link_types": [
            "<invalid URL removed>"
        ],
        "file_size": 8606
    },
    {
        "id": "artificial superintelligence.md",
        "name": "artificial superintelligence",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- [OpenAI](https://www.linkedin.com/company/openai/) cofounder [](https://www.linkedin.com/in/ACoAAAOshwUBNNaU-8JRTNkhsmgKZnIXot9YbHk)[Ilya Sutskever](https://www.linkedin.com/in/ilya-sutskever/) is launching a new company with the sole objective of creating [Safe Superintelligence](https://ssi.inc/) (SSI).\n\t- ```\"We approach safety and capabilities in tandem, as technical problems to be solved through revolutionary engineering and scientific breakthroughs. We plan to advance capabilities as fast as possible while making sure our safety always remains ahead. This way, we can scale in peace.\"```\n- <iframe src=\"https://www.oneusefulthing.org/p/superhuman\" style=\"width: 100%; height: 600px\"></iframe>\n- ![image.png](../assets/image_1714292617207_0.png)\n- [Tsarathustra on X: \"Nick Bostrom: superintelligence could happen in timelines as short as a year and is the last invention we will ever need to make https://t.co/oTZoF5KOVq\" / X (twitter.com)](https://twitter.com/tsarnick/status/1784378045069217960)\n\t- {{twitter https://twitter.com/tsarnick/status/1784378045069217960}}\n\t-\n- # Numbers and Figures\n\t- GPT-3 trained on 1 trillion tokens or 600 GB of text\n\t- GPT-4 estimated to have trained on 10 trillion tokens\n\t- GPT-5 projected to require 100 trillion tokens based on current scaling trends\n\t- Chinchilla scaling laws: 10x increase in dataset size corresponds to 100x increase in compute\n\t- 64 zettabytes (10^22 bytes) of data created in 2020\n\t- 60-100 sextillion words (10^20 to 10^22) if all 2020 data converted to text\n\t- 100 billion humans estimated to have lived thus far\n\t- 13,000 times more data created in 2020 than all words spoken by humans throughout history\n\t- 333 billion emails sent each day\n\t- 1 in 100 million parts of raw 2020 data would need to be high-quality text to reach GPT-5 scale\n\t- Twitter generates 33 terabytes of text per year, enough to train 2-3x size of GPT-4\n\t- 1-2 exabytes each of astronomy and YouTube data generated annually\n\t- 40 exabytes of genomics data stored every year\n\t- Largest conceivable training run estimated at $1 trillion, 1% of gross world product\n\t- Human brain estimated to process 2-3 quadrillion bytes over 70 years, 200-300x GPT-4 training data\n\t- This gets unlocked by in context learning and better compute. There seems unlikely to be a blocker. Likely 2030\n- [Microsoft president says no chance of super-intelligent AI soon | Reuters](https://www.reuters.com/technology/microsoft-president-says-no-chance-superintelligent-ai-soon-2023-11-30/)\n-",
        "link_types": [],
        "file_size": 2572
    },
    {
        "id": "Trust and Safety.md",
        "name": "Trust and Safety",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n#Public page automatically published\n\n- # Trust and Safety\n\t- Trust and safety (T&S) is crucially important for building ethical and inclu­sive online communities, the landscape is fraught with complex tradeoffs and challenges that make direct involvement difficult for independent researchers and developers like us. As summarized in a recent Atlantic Council report, T&S operates in a high-stakes environment driven by commercial incentives that often conflict with safety objectives. Practitioners face threats of trauma, burnout, and retaliation when enforcing policies.\n\t\t- Established standards, struggles to quantify impact, and relies heavily on the judgement of private companies.\n\t\t- Trust and safety (T&S) emerged as a field to govern risks in online communities. It became crucial as user-generated content platforms scaled.\n\t\t- • The emergence of a professionalized T&S field creates opportunities for collaboration and innovation. But knowledge sharing, tooling, talent pipelines, and metrics need improvement. T&S practitioners, especially content moderators, face high risk of trauma. Their wellbeing requires urgent attention.\n\t\t- • Systemic gaps exist around measuring T&S value, regulation’s impact on incentives, and the role of venture capital. Market failures drive under-investment.\n\t\t- • Adjacent fields like academia, civil society, and media provide crucial external expertise but lack formal inclusion in T&S.\n\t\t- • The gaming industry offers useful insights but has its own major T&S challenges.\n\t\t- • Known harms will spread to new technologies, requiring adaptive solu­tions and proactive design.\n\t\t- • Systemic gaps exist around measurement, regulation, and investment. Creative initiatives needed to realign incentives.\n\t\t- • Philanthropy and government can help address systemic gaps through strategic programs and incentives.\n\t\t- • T&S must balance competing goals like.\n\t\t\t- Protecting rights vs mitigating harms\n\t\t\t- Efficiency vs accuracy in enforcement\n\t\t\t- Reviewer wellbeing vs review needs\n\t\t\t- Centralized vs decentralized moderation\n\t\t\t- Growth vs safety investments\n\t\t\t- Internal process vs external expertise\n\t\t\t- Reactive enforcement vs proactive design\n- # Corporations as final arbiters of truth\n\t- ![Screenshot 2024-04-24 120742.png](../assets/Screenshot_2024-04-24_120742_1713957367294_0.png){:height 841, :width 1159}\n\t-\n\t- This painting is called \"The Shah Alam conveying the gift of the Dewani to Lord Clive\" and depicts a supposed key moment in the East India Company taking control of Indian territory. Specifically, the painting shows the Mughal Emperor Shah Alam handing over a document to Robert Clive of the East India Company after being defeated at the Battle of Buxar in 1765. The document being transferred granted the East India Company the right to collect taxes (the diwani) in the wealthy Indian provinces of Bengal, Bihar and Orissa. This gave the British shareholder Company control over the finances of these regions. Of course the painting is not historically accurate, being what we now know to be 'fake new'. The actual transfer took place in a private tent, with the emperor forced to sign \"with a gun to his head\" after his defeat, rather than in a grand public ceremony as the painting depicts. The artist Benjamin West had also never been to India.\n\t- Though historically inaccurate, this image may capture a profound truth - that corporate interests, when unchecked, can subsume the sovereignty of nations. The East India Company's reign in India was marked by oppression, famine, and the stripping of resources for the benefit of far-off shareholders. It is a stark lesson in the perils of allowing private entities to wield such dominion over people's lives. Companies like Google and Facebook have become the gatekeepers of knowledge, with algorithms that shape what billions of people see and believe. As they develop sophisticated AI models and collect massive amounts of data, are we entrusting them with the modern equivalent of the East India Company's power?\n\t- Just as the diwani painting immortalized a dangerous fiction, the slick PR of Silicon Valley masks the raw power these firms now command over our minds and societies. The datasets and AI models of these digital colossi are the new currency of truth - and one largely minted behind closed doors. We have seen the consequences again and again:\n\t\t- Tobacco: For decades, Big Tobacco sowed doubt about the dangers of smoking, suppressing research and misleading the public. Millions died as corporate interests trumped scientific truth.\n\t\t- BPA: Chemical companies long insisted BPA plastics were safe, despite mounting evidence of hormone disruption and health risks. Only after massive public pressure did regulators act.\n\t\t- Climate Change: Fossil fuel giants knew the truth about climate change for decades, but funded denial and obfuscation to protect their bottom line. The cost will be borne by generations.\n\t\t- Opioids: Pharmaceutical companies downplayed the addiction risks of opioids, contributing to an epidemic that has claimed hundreds of thousands of lives. Profits were prioritized over people.\n\t- It would be nice to think that we could demand radical transparency, meaningful oversight, and the primacy of public interest over shareholder profits in the construction and deployment of epoch-defining AI.\n\t  One potential solution is the development of open source informational agents. These AI systems, built transparently and collaboratively by the global community, could serve as a counterweight to corporate and state-controlled narratives. This is not a trivial undertaking.\n\t-\n- ## What's changing\n\t- There may now be an inflection point in the organisational topology of the internet, because of trust abuses by the incumbent providers like [[Facebook Meta]]. This moment has been calling itself Web3, but the moniker is fraught with problems, and somewhat meaningless. The drivers are real.\n\t- `The Metaverse' is coming, in some form, at some point. Everyone is positioning in case it's \"soon\". It's not at all clear what it is, or if people want it, but the best of the emergent narrative looks like the older field of \"digital society\" and that obviously should not be dismissed lightly.\n\t\t- Large scale `social' & immersive metaverse is suffering poor adoption, failing as it has in the past. It's likely that the market need has been overstated. More advanced and popular (closed) games based solutions do not serve societal or business needs.\n\t\t- AI / ML will soon act as an accelerant to this, but the timing is still unclear, and likely still years away.\n\t\t- The closest contenders at this time are Roblox for social and play, VRChat for more serious users, and Nvidia Omniverse for high end business to business metaverse.\n\t\t- From a business perspective metaverse is the worst of the remote collaboration tool-kits, and undermines flow, productivity, and interpersonal trust. Metaverse is probably technology for technologies sake at this time, but the investment is real.\n\t- Social media may be changing slightly, with less focus on old platforms like Facebook and Twitter, more on high intensity media shorts like TikTok, and a separate movement toward more decentralised platforms like Mastadon, Bluesky, Nostr etc. This is potentially a bifurcation.\n- ## [](https://github.com/flossverse#digital-society) Digital Society\n\t- Digital society may be a more tangible and less hyped term to build around, and extends out into the more compelling spatial and augmented reality technologies, web, and digital money and trust.\n\t- Emerging markets, less developed nations, indeed much of the world is excluded from many of the tools that are taken for granted in `Western' digital society. They do not necessarily have the identification, banking rails, or compute power to engage fully. Our focus is on Africa and India.\n\t- Industry has noted the risk, and failures of Meta across both metaverse, and digital currency, and have latched onto \"open metaverse\" as a narrative, to de-risk their interest. The current open offerings in metaverse and social media are muddy and confused.\n\t- A truth seems to have been missed; that open digital society should mean open source digital society. There are some options, but they are under developed. We would like to contribute to this by applying our decades of telecollaboration research.\n\t- The UK seems to be endorsing significant controls and restrictions on internet usage. This compliance overhead will price small companies out of large scale social experiences. Company walled gardens are less impacted (as per the slack service model), and this is an opportunity if tied to real business use cases.\n\t- This will likely add fuel to the fire of innovation and push users into disparate platforms.\n- ## [](https://github.com/flossverse#augmented-intelligence) Augmented Intelligence\n\t- AI & machine learning and especially generative art is further blurring these boundaries. A better term for AI/ML is supported creativity and/or augmented intelligence. While current models such as GPT3.5 and LAION based generative systems are already causing a global stir, and [[large language models]] are already forcing global debate about general AI.\n\t- Trust, accessibility, governance, and safeguarding, are hard problems, and made more complex by unrecorded social flow in immersive social VR.\n\t- It is likely that the major players in AI at this time will simply leverage their models as \"soft power\", in the final analysis simply masking more advertising revenue, [which is their lifeblood.](https://gerrymcgovern.com/ai-is-not-your-friend/)\n\t- The challenge is to build a topologically flat, inclusive, permissionless, federated, and open digital society, with economically empowered ML and AI actors, which can mediate governance issues, transparently, according to well constructed custom schemas, between cryptographically verifiable economic users (human or AI).\n\t- New open source [supported creativity, augmented intelligence] tooling from Stability and Llama potentially removes many of the problems with accessibility, creativity, language barriers, safeguarding, and governance. This is a huge, complex, and fast moving area, but tremendously exciting.\n\t- Using new image generation ML it may be possible to build new kind of collaborative global networks for creative industries, ideating in simplistic immersive spaces while instantly creating scenes which can be stylised using verbal commands in real-time. This may open up and enfranchise fresh ideas from a wider cultural pool.\n\t- Such teams could be far more ad-hoc by experimenting with the designs outlined in this book. This kind of genuine digital society use case is something sorely lacking in large scale attempts such as Meta Horizons. It need not be complex or large scale, but it must be secure, trusted, and task appropriate. We think we can deliver this and conversations with the industry suggest that there is excitement and cautious appetite.\n\t- With focus on decentralized and generative technologies, we believe the greatest value we can provide is advancing capabilities that empower users and diversify governance models. Directly mediating harms involves subjective tradeoffs we are not comfortable imposing on others. Our goal is to expand possibilities for human flourishing, while avoiding direct content moderation that restricts expression based on our own limited perspec­tives. We aim to enable solutions, not dictate them. As the report advocates, addressing T&S issues requires a broad coalition encompassing civil society, government, academia, and industry.\n- # Centralised AI and inequality\n\t- Negative:\n\t\t- Centralised AI systems are exacerbating global inequality, with those already in power benefiting the most economically and in decision-making\n\t\t- AI and automation have the potential to be labour-saving, increase unemployment, and concentrate wealth among a small fraction of highly skilled individuals and leading countries\n\t\t- The proliferation of AI threatens to reverse economic gains made by developing countries in recent decades, worsening poverty and inequality\n\t\t- AI technologies may be unsuited to local contexts and conditions in the developing world\n\t\t- Existing digital divides, lack of infrastructure and human capital put developing countries at a disadvantage in AI development and governance\n\t\t- AI could lead to monopolisation of data and decision-making by a small number of powerful entities, weakening civil society and political representation\n\t- Potential positive impacts and mitigations:\n\t\t- Economic policies, taxation, redistribution and global governance reforms could help mitigate adverse impacts of AI on inequality and share prosperity more widely\n\t\t- Developing countries may benefit from focusing AI strategies on key sectors like agriculture, services and digital infrastructure\n\t\t- Global rules around data, competition, IP and information flows could be designed to benefit developing nations\n\t\t- Harnessing bottom-up youth innovation and entrepreneurship in AI could help drive inclusion\n\t\t- Some positive signs are emerging from national AI policies focused on inclusion in certain countries\n\t\t- Steering AI research and development to maximise social value and redistributing power in AI governance could make systems more suitable to diverse global contexts\n\t\t- Non-distortionary taxation could potentially compensate those displaced or disadvantaged by AI to enable Pareto improvements\n\t\t- Local inferencing on virtually ubiquitous mobile phones could enable people to work and learn in their own language and style without internet charges, potentially mitigating inequalities\n\t- I\n- ## AI as soft power\n\t- ### Combating conspiracies\n\t- [twitter link to the render loading below](https://twitter.com/DG_Rand/status/1775618798717911424)\n\t  {{twitter https://twitter.com/DG_Rand/status/1775618798717911424}}\n\t  \n\t  https://osf.io/preprints/psyarxiv/xcwdn\n- ### Creating opinions\n\t- [twitter link to the render loading below](https://twitter.com/manoelribeiro/status/1771168737917354316)\n\t  {{twitter https://twitter.com/manoelribeiro/status/1771168737917354316}}\n- # Comments from Katherine Maher (Signal / Wikipedia)\n\t- Extracted from [Katherine Maher on the Future of Trusted Information\n\t\t- Possible](https://www.possible.fm/podcasts/katherinemaher/)\n\t- **Key Challenge**: Institutions historically unresponsive to diverse populations, exposed by the internet.\n\t- **Impact of Internet**: Exposes institutional failures, raising awareness and expectations for better service delivery.\n\t- #### Trust Beyond Misinformation\n\t\t- **Primary Trust Issue**: Expectations from institutions about their function and responsiveness, not just misinformation.\n\t\t- **Media Trust**: Questions around media trust and social media's role are secondary to larger institutional trust issues.\n\t- #### Technological Influence and Governance\n\t\t- **Role of Technology**: Technology has distanced people from effective engagement methods.\n\t\t- **Citizens’ Assemblies**: Suggested as a tool for constructive discourse and finding common ground on divisive issues.\n\t\t- **Institutional Deconstruction**: Concerns over both long-term and short-term anti-institutional movements.\n\t- #### Constructive Discourse and Policy Engagement\n\t\t- **Building Discourse Infrastructure**: Importance of constructing understanding and expanding public discourse.\n\t\t- **Loyal Opposition**: Emphasizes engaging with opposition to foster constructive improvements.\n\t- #### Wikipedia’s Approach to Scale\n\t\t- **Anti-Scale Philosophy**: Wikipedia operates through micro-communities, allowing for diverse expertise and governance continuity.\n\t\t- **Democratic Governance**: The need for democratic governance to articulate its value proposition for public participation.\n\t- #### Internet Norms and Dissent\n\t\t- **Challenges in Establishing Norms**: Varying global expectations make establishing internet norms complex.\n\t\t- **Codes of Conduct and Policies**: Essential for constructive online discourse and handling dissent.\n\t- #### Data and AI Model Training\n\t\t- **Differentiating Data Types**: Consent crucial for private data like health and communication.\n\t\t- **Content Utilization for AI**: Wikipedia's approach to offering consistent, accountable API access for model training.\n\t- #### Future Potential and AI Empowerment\n\t\t- **Empowering Future Generations**: Focus on computer literacy and AI tools to enable problem-solving and innovation.\n\t\t- **15-Year Vision**: Potential for a more computer-literate generation, capable of addressing community-specific problems.",
        "link_types": [
            "Facebook Meta",
            "large language models"
        ],
        "file_size": 16734
    },
    {
        "id": "Controlnet and similar.md",
        "name": "Controlnet and similar",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- ControlNet\n\t- Exhastive guide to controlnet [The Ultimate Guide to ControlNet (Part 1) (civitai.com)](https://education.civitai.com/civitai-guide-to-controlnet/#show-me-examples)\n\t- [OpenPoses](https://openposes.com/)\n- [(1) ControlNet Support for Multi-Input and IP-Adapter-FaceID-portrait in A1111 : StableDiffusion (reddit.com)](https://www.reddit.com/r/StableDiffusion/comments/19cwrxh/controlnet_support_for_multiinput_and/)\n-\n- Multidiffusion Spatial Controls\n\t - a Hugging Face Space by weizmannscience\n       <https://huggingface.co/spaces/weizmannscience/multidiffusion-region-based>\n      Testing ControlNet on Unreal Engine 5 : r/StableDiffusion\n       <https://www.reddit.com/r/StableDiffusion/comments/11fpcb1/testing_controlnet_on_unreal_engine_5/>\n      LineArt to PhotoReal : r/StableDiffusion\n       <https://www.reddit.com/r/StableDiffusion/comments/11mzdxm/lineart_to_photoreal/>\n      Convert Any Image To Lineart Using ControlNet! : r/StableDiffusion\n       <https://www.reddit.com/r/StableDiffusion/comments/11mwzsz/convert_any_image_to_lineart_using_controlnet/>\n      How to use Controlnet to make INCREDIBLE fully customizable Txt2Img templates : r/StableDiffusion\n       <https://www.reddit.com/r/StableDiffusion/comments/11ah3nv/how_to_use_controlnet_to_make_incredible_fully/>\n      regional prompting tutorial\n       <https://www.youtube.com/watch?v=vZ3W62dxuXI>\n      *  Tencent AI just release their method and code very similar to ControlNet : r/StableDiffusion\n       <https://www.reddit.com/r/StableDiffusion/comments/1148x38/tencent_ai_just_release_their_method_and_code/>\n      GitHub\n\t - lllyasviel/ControlNet: Let us control diffusion models!\n          GitHub\n\t - lllyasviel/ControlNet: Let us control diffusion models!: Let us control diffusion models! Contribute to lllyasviel/ControlNet development by creating an account on GitHub.\n           <https://github.com/lllyasviel/ControlNet>\n              The ControlNet project provides a way to control diffusion models. It includes a number of features to help with this, including the ability to automatically download annotators and the ability to shift the guess mode to UC disconnect in order to save memory.\n      Controlnet and character posing reddit post\n       <https://www.reddit.com/r/StableDiffusion/comments/11owo31/something_that_might_help_ppl_with_posing/>\n      *  Tencent AI just release their method and code very similar to ControlNet : r/StableDiffusion\n       <https://www.reddit.com/r/StableDiffusion/comments/1148x38/tencent_ai_just_release_their_method_and_code/>\n      *  ControlNet Character Design Workflow (links in comment) : r/StableDiffusion\n       <https://www.reddit.com/r/StableDiffusion/comments/11rfol4/controlnet_character_design_workflow_links_in/>\n      *  ControlNet Character Design Workflow (links in comment) : r/StableDiffusion\n       <https://www.reddit.com/r/StableDiffusion/comments/11rfol4/controlnet_character_design_workflow_links_in/>\n      Twitter thread on consistency settings\n       <https://twitter.com/TomLikesRobots/status/1628100062910857217>\n      Smooth animation with controlnet\n       <https://www.reddit.com/r/StableDiffusion/comments/125m56z/smooth_animation_with_controlnet_and_regional/>\n          This code snippet sets up Reddit's Sentry error monitoring, which includes a function to check for various types of errors and report them accordingly. Additionally, it sets up a fetch() wrapper to add a header specifying that Sentry should always be used in \"sticky canary\" mode.\n      Multi scene videos using automatic1111\n       <https://www.reddit.com/r/StableDiffusion/comments/127wub7/to_make_a_video_with_multiple_scenes_using_only/>\n          1 go to Automatic1111 Deforum in interpolation mode and generate several pics regarding the prompt theme. Deforum interpolation is not good for animation, but it is good for generating lot of pics about the same subject.\n          2 select the better images and put them in Deforum Init section. Then generate the animations in 2D or 3D. For this test I used only 10 steps, so graphics are not stellar. Repeat until you have several animations, each one on its directory.\n          3 select the good animations. Pick the frames and put them in a directory. Then go to Deforum Output and select Pictures interpolation , put the frames here and interpolate with value 2. With this you generate the video.\n          Note: I interpolated 693 frames. Tried bigger quantities and the interpolator did not work. So this method is pretty limited.\n      Controlnet 1.1\n       <https://www.reddit.com/r/StableDiffusion/comments/12o8qm3/finally_installed_the_newer_controlnet_models_a/>\n      Tencent controlnet\n       <https://civitai.com/models/136070?modelVersionId=155332>\n      Anime fight workflow\n       <https://www.reddit.com/r/StableDiffusion/comments/12z6rh5/half_real_converting_cowboy_bebop_spike_vs/>\n      reference only workflow\n       <https://www.reddit.com/r/StableDiffusion/comments/1408l40/a_simple_4step_workflow_with_reference_only/>\n      *\n      ControlNet v1.1: A complete guide\n\t - Stable Diffusion Art\n       <https://stable-diffusion-art.com/controlnet/>\n      The Twitter conversation includes an AI-generated video created by TomLikesRobots using canny edge detection and EbSynth technology to make a hobbit and Dumbledore contending with Sauron's will. Many people were impressed with the video and asked questions about the software and hardware used to create it. Finally, TomLikesRobots answered the questions by telling them he was using Windows 11, an RTX 3080 with 10GB VRAM and that the img2img part with ControlNet can be run online, but EbSynth might be trickier. https://twitter.com/TomLikesRobots/status/1627073211656732676\n      The text is a collection of video tutorials by Albert Bozesan, demonstrating how to use AI to create various types of digital art and design, including movie and game titles, vector graphics, pixel art, 3D assets, fantasy maps, motion graphics assets, and seamless textures. Bozesan uses a software called Stable Diffusion, which is free and runs on NVIDIA GPUs. He also mentions other AI tools such as ControlNet and Dream Textures for specific tasks. The videos show step-by-step instructions on how to install and use the software, as well as practical tips and techniques for achieving different visual effects. In addition, there are videos covering the latest AI research by NVIDIA and Google, as well as challenges with other artists using AI. The text also includes a note about the use of cookies and data on YouTube, as well as options for managing privacy settings. https://m.youtube.com/watch?v=sNcEhR65pw0&feature=youtu.be\n       <https://m.youtube.com/watch?v=sNcEhR65pw0&amp;feature=youtu.be>\n      This is a conversation between TomLikesRobots about an experiment with \"Ebsynth and Controlnet Img2img\". TomLikesRobots has tried different noise percentage values and blends. The experiment involves switching out Elizabeth Moss for Penelope Cruz, and despite some difficulties, the team is making progress towards high-detail photorealism. https://twitter.com/TomLikesRobots/status/1628104009146826763?s=20\n      The paper proposes a novel approach to generate new video content by combining zero-shot text-to-video generation with ControlNet. The method takes multiple sketched frames as input and generates video output that matches the flow of these frames. By incorporating ControlNet to enable additional input conditions, the approach leverages the benefits of both zero-shot text-to-video generation and the robust control provided by ControlNet. Experiments demonstrate that the method excels at producing high-quality and remarkably consistent video content that accurately aligns with the user’s intended motion for the subject within the video. A demo of the approach is also available for users to try out. https://sketchingthefuture.github.io/\n-",
        "link_types": [],
        "file_size": 8004
    },
    {
        "id": "Human vs AI.md",
        "name": "Human vs AI",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ![](https://m.media-amazon.com/images/I/81+D9XXdrOL._SL1500_.jpg){:height 400, :width 300}\n- Santacaterina, with her background in humanities and international relations, [offers a differntiated perspective](https://www.amazon.co.uk/Adaptive-Resilience-Maria-Santacaterina/dp/1119898188) on the development and deployment of AI. Her critique highlights the potential downsides of AI and advocates for a more human-centric approach. Her concerns can be grouped into several key areas:\n- ### The Limitations of AI in Understanding Life and Human Experience\n\t- Santacaterina argues that attempts to mechanise and quantify the intricacies of life through AI are inherently flawed. She emphasises the impossibility of capturing the complexity, adaptability, and perpetual evolution of living systems within the confines of algorithms. Life, she asserts, is an intricate tapestry woven from countless threads, each one contributing to the overall picture in ways that defy simple quantification or reduction.\n\t- Furthermore, Santacaterina contends that the richness and power of human language cannot be fully grasped by AI models trained on internet data. These models, she argues, operate on a superficial level, lacking the grounding in real-world truth and cultural sensitivity necessary for true comprehension. The nuances of communication, the subtle shades of meaning that emerge from the interplay of words and context, are lost in the translation to binary code.\n\t- Central to Santacaterina's critique is the notion that human intelligence is multidimensional, encompassing social, emotional, cognitive, and intellectual aspects. This complex interplay of factors, she argues, cannot be accurately replicated by AI systems, which operate based on a narrow set of rules and statistical patterns. The reductionist approach of AI, in her view, fails to capture the essence of what makes us human.\n- ### The Erosion of Human Agency, Autonomy, and Creativity\n\t- One of Santacaterina's primary concerns is the growing reliance on AI systems in critical domains such as healthcare, justice, and employment. We can perhaps all see that even human breeding choices are seeded now by algorithms in dating apps. She warns of the dangers of algorithmic decision-making, where individuals are pigeonholed and their opportunities determined by systems that fail to consider unique circumstances and nuances. This overreliance on AI, she argues, erodes human agency and autonomy, as we increasingly cede control over important aspects of our lives to machines.\n\t- Moreover, Santacaterina cautions that the standardisation and control imposed by AI systems risk stifling human creativity and innovation. When conformity and uniformity are prioritised over diversity of thought, we lose the spark that drives progress. The serendipitous insights and unconventional approaches that have fueled human advancement throughout history are threatened by the homogenising influence of AI.\n\t- Santacaterina also raises alarming concerns about the erosion of privacy and personal identity in the age of pervasive AI. The vast amounts of personal data collected and analysed by these systems, often without transparent explanations of how it will be used, pose significant threats to individual autonomy and privacy. As our every action and preference is tracked and fed into algorithms, we risk losing control over our own identities and the narratives of our lives.\n- ### Advocating for a Human-Centric Approach to AI Development\n\t- Calls for a fundamental shift in our approach to AI development. Rather than pursuing ever more powerful AI systems as an end in itself, she urges us to prioritise human well-being and flourishing. This means placing ethical considerations at the forefront of AI development, ensuring that these technologies are designed and deployed in ways that respect human rights, promote fairness and transparency, and align with our values.\n\t- Central to this human-centric approach is the emphasis on nurturing diversity and individuality. Santacaterina argues that the strength and resilience of human societies stem from our diversity—the myriad ways in which we think, feel, and experience the world. By creating AI systems that are flexible and adaptable, that can accommodate the full spectrum of human needs and aspirations, we can harness the power of this technology while preserving the richness of our differences.\n\t- The importance of fostering lifelong learning and critical thinking in the age of AI. As these technologies become increasingly integrated into our lives, it is crucial that we equip individuals with the knowledge and skills necessary to navigate this new landscape effectively. This includes not only technical proficiency but also a deep understanding of the ethical and societal implications of AI, as well as the ability to critically evaluate and engage with these systems.\n-\n- [AI Girlfriend: Challenges and Potential Drawbacks | HealthNews](https://healthnews.com/mental-health/self-care-and-therapy/ai-girlfriends-addressing-the-loneliness-epidemic/)",
        "link_types": [],
        "file_size": 5108
    },
    {
        "id": "Time Series Forecasting.md",
        "name": "Time Series Forecasting",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n-\n- [Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer) (huggingface.co)](https://huggingface.co/blog/autoformer)\n- [CERC-AAI Lab\n\t - Lag-LLaMA (google.com)](https://sites.google.com/view/irinalab/blog/lag-llama)\n- [amorphousdata.com/blog/time-series-vs-regression](https://www.amorphousdata.com/blog/time-series-vs-regression)\n- [M4 Forecasting Competition: Introducing a New Hybrid ES-RNN Model | Uber Blog](https://www.uber.com/en-GB/blog/m4-forecasting-competition/)\n- [[2310.06625] iTransformer: Inverted Transformers Are Effective for Time Series Forecasting (arxiv.org)](https://arxiv.org/abs/2310.06625)\n- [A decoder-only foundation model for time-series forecasting – Google Research Blog](https://blog.research.google/2024/02/a-decoder-only-foundation-model-for.html)\n-\n-",
        "link_types": [],
        "file_size": 865
    },
    {
        "id": "Agentic Metaverse for Global Creatives.md",
        "name": "Agentic Metaverse for Global Creatives",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ```mermaid\n  sequenceDiagram\n      participant User\n      participant AIAgent\n      participant Nostr\n      participant Bitcoin\n      participant Lightning\n      participant RGB\n      participant NosDAV\n      participant GitHub\n      participant Logseq\n      participant SolidLite\n      participant LinkedJSON\n      participant Omniverse\n      participant USD\n  \n      User->>+Logseq: Define agent tasks and rewards\n      Logseq->>+GitHub: Store agent configurations\n      GitHub->>+AIAgent: Trigger agent update\n      AIAgent->>+Nostr: Subscribe to relevant events\n      Nostr->>+AIAgent: Deliver relevant events\n      AIAgent->>+Logseq: Retrieve task configurations\n      Logseq->>+AIAgent: Provide task configurations\n      AIAgent->>+NosDAV: Retrieve required data\n      NosDAV->>+AIAgent: Provide requested data\n      AIAgent->>+RGB: Request single-use seal\n      RGB->>+AIAgent: Provide single-use seal\n      AIAgent->>+Nostr: Perform task and publish results\n      Nostr->>+User: Deliver task results\n      User->>+Lightning: Send payment for task completion\n      Lightning->>+Bitcoin: Settle payment transaction\n      Bitcoin->>+AIAgent: Confirm payment receipt\n      AIAgent->>+Nostr: Publish payment confirmation\n      Nostr->>+User: Deliver payment confirmation\n      User->>+SolidLite: Interact with decentralized application\n      SolidLite->>+LinkedJSON: Retrieve structured data\n      LinkedJSON->>+SolidLite: Provide structured data\n      SolidLite->>+Nostr: Publish user actions\n      Nostr->>+AIAgent: Deliver user actions\n      AIAgent->>+Omniverse: Retrieve virtual environment data\n      Omniverse->>+AIAgent: Provide virtual environment data\n      AIAgent->>+USD: Manipulate 3D assets\n      USD->>+AIAgent: Provide updated 3D assets\n      AIAgent->>+Omniverse: Update virtual environment\n      Omniverse->>+Nostr: Publish virtual environment updates\n      Nostr->>+User: Deliver virtual environment updates\n      User->>+Nostr: Publish feedback and interactions\n      Nostr->>+AIAgent: Deliver user feedback and interactions\n      AIAgent->>+NosDAV: Store interaction data\n      NosDAV->>+AIAgent: Confirm data storage\n      AIAgent->>+Nostr: Publish interaction confirmation\n      Nostr->>+User: Deliver interaction confirmation\n  ```\n- [Online Version](https://mermaid.live/view#pako:eNqNVk1T2zAQ_SsaXwukJG0AH5iBpkPp8DWk9NDJRbY2jgZFciU5DGXy37uybMeOlUBOjvTert5-SW9RqhhEcWTgbwEyhQmnmabLmST4y6m2POU5lZY8GdD91Yvriwyk7W_cKWMD-EtuU8Vlf-OGZwsrucz6W49Xl0H7k4vf_fUrbn8UScC-ylBif32qBGc33ELoSPIZ2M_p_V1_734p-Qq0CdCeppNZJdDF7PD8_JN3HpMJzLkEQl3IiKXm2RAqGdHwQjUznuOxjuWlxGRqla5JqZJznhWaWq5kxfA4x6iyEZNfmmcZ6IpU5IzWAiuIQ5cpQvNFYlLNEyBW4VEErJwKWCGqclACO_YnIJz8MLzlohb-CFZzxJSigyI2shsnD1qtONvD6WrBcmg50ljPXAMjKJ02MhATdOHQYGwH3rKOFehMlxhisEgFHBYGiAEqPBgRQcNBcD8HD6DnSi-9VFcSeZEIbhZ4MFOIXh5cXW2SUJI6wKbu6qbCLIOzSl-XriDQVx3VZS7AhbTKQk1w7KpXHddaAQ3baioNTTesCtgJwDeXL1RUkzSkwHO7MwCV3hqeejrdONkhfjehDkLT4TG5lhY0npy8cLsgDI8kUYzg_zDxNM8FT1v8hucjWc-CVo3hgYrUFt0q2yC3nDclEWJ1nG3FBIsHOzltFf7uhuxjW7FuhlZLw4prW1BBQOKXkmUsN8dqGMHi3s9tOcaRGJNbKnleCJxEZDQh1BhoynU6Cdr3c4ttw8OKnkpw6EwBKVsRDgnxzvd33ru8uga3_M0BWEJT3-q8KsoPp_cddmAq-hukBd0_FevedSAsV6XxGnmvcdvGP9y8u0jRQbQE_OYMXyZvzsQssgtYwiyK8TOheO9GM7lGHC2smr7KNIqxreAg8uGvXjH1It7Lf5TCv3MqTAP6zjhqaxaFogzw71tkX3P3JMq4sejB3zxuvdAClxfW5iYeDNz2UYaDpEiOcI4ODGcLfAYsVmfjwXg4PqXDEYxPRvTraMTS5PjsdD78cjxnJ5-PhzRarw8iKP3f-vdX-Qxb_wcWdEhL)\n-\n- # Introduction and Problem Definition\n- [[Delivery Planning]]\n\t- ## Overview of the Metaverse and Digital Society:\n\t\t- The concept of [[Metaverse and Telecollaboration]] has gained significant attention, with various stakeholders positioning themselves to capitalize on its potential. While it remains unclear exactly what form the Metaverse will take or whether people truly desire it, it is evident that digital society holds considerable promise. We see advantage less in social metaverse, and more in solving business to business technical use cases where professionals with visual technical problems, or training requirements, gather in collaborative spaces.\n\t\t- We have designed an [[Metaverse Ontology]] to ensure specificity for our work.\n\t- ## Trust, Accessibility, Governance, and Safeguarding:\n\t\t- The Metaverse faces numerous challenges, including poor adoption rates, overstated market need, and a lack of genuine digital society use cases. Meanwhile [[Trust and Safety]] abuses by incumbent providers have led to potential inflection points in the organization of the wider internet. Moreover, emerging markets and less developed nations face barriers to entry due to inadequate identification, banking infrastructure, and computing power. There is an opportunity to build pervasive digital spaces with a different and more open foundation, learning from these lessons.\n\t- ## The Need for Modular Open-Source Solutions:\n\t\t- Developing a topologically flat, inclusive, permissionless, federated, and [[open source]] Metaverse is essential to address these challenges. By using open-source AI tooling and large language models, it is possible to improve creativity, safeguarding, and governance, while breaking down language barriers and accessibility challenges. Implementing secure, trusted, and task-appropriate solutions can promote collaboration and innovation across various industries.\n\t- ## Technical Problem Definition:\n\t\t- The specific technical challenges and opportunities the proposed framework addresses include:\n\t\t- Evergreen telecollaboration around technical issues\n\t\t- Exchange of goods, services, and money within systems, without friction\n\t\t- Identity management within virtual spaces\n\t\t- Access to information in the extrinsic world from within the tool\n\t\t- Federation of instances without overhead (scaling)\n\t\t- Seamless access to personal information within and without the collaborative system\n\t\t- Ability to take advantage of supporting smart support agents (bots, etc.) throughout\n\t\t- Governance, trust, and safeguarding\n\t- ## Lean Canvas Business Model:\n\t\t- Problem: Existing large-scale telecollaboration solutions suffer from poor adoption, limited accessibility, and trust issues. Meanwhile, emerging markets struggle to participate in the growing digital society due to the lack of inclusive tools and infrastructure, limiting access to global talent and new pools of ideas. There is insufficient provision of global talent pipelines for highly technical workflows.\n\t\t- Solution: Develop a secure, accessible, and inclusive platform for specialized telecollaboration spaces that seamlessly integrate advanced AI, ML, highly scalable and proven distributed systems, and open-source principles to create a digital society that caters to diverse industries, users globally, and captures global talent and innovative ideas.\n\t\t- Value Proposition: Ultra low cost training spaces, accessible 24/7 through very low end hardware. Interact with highly customizable, task-appropriate, and user-friendly specialized telecollaboration spaces supported by specially trained and optimised supportive large language AI models. Multi-lingual for emerging markets, enabling access to untapped global talent and fostering the exchange of diverse ideas.\n\t\t- Customer Segments: Initially Universities, but this will scale to be sector specific, catering to the global training, research, biomedical, and creative industries, with a special focus on empowering users in emerging markets such as Africa and India, and connecting them with worldwide opportunities and resources.\n\t\t- Revenue Streams: Tiered subscription plans to accommodate various user needs and budgets, as well as tailored enterprise solutions for large-scale clients. Bespoke consulting and support trending toward software as a service at scale.\n\t\t- Key Metrics: Track user growth, engagement, and retention, successful collaborations across industries, the platform's positive impact on users in emerging markets, and the effectiveness of global talent capture and idea exchange.\n\t\t- Unfair Advantage: The team's extensive experience in telecollaboration research, AI, ML, and a deep understanding of the complex landscape of emerging technologies, including highly scalable and proven distributed systems, provide a unique edge in creating a game-changing platform for specialized telecollaboration spaces that are secure, trusted, and tailored to diverse user needs while enabling access to global talent and innovative ideas.\n- # Proposed Layered Framework\n\t- ## Layer 1: Bitcoin, Lightning, and Nostr Protocols:\n\t\t- The proposed framework leverages [[Bitcoin]] , [[Lightning and Similar L2]] , and [[nostr]] protocols to provide a secure and decentralized foundation for value exchange, identity management, and communication. These technologies enable the transfer of portable 'goods' across digital society and promote the development and adoption of open protocols and data formats. The Nostr protocol, in particular, can link and federate mixed reality spaces, providing identity assurances and mediating data synchronization while maintaining reasonably strong cryptography. This also allows integration with the legacy web through ubiquitous web sockets. Bitcoin and associated technologies, despite their issues, have the potential to revolutionize the way digital society operates by enabling \"money-like networks\" which are a cornerstone of human interaction. Representations of traditional currencies can ride securely on top of these networks as stablecoins, opening up global collaborative working practices, especially for emerging markets. Streaming micropayments and machine to machine (AI to AI) interactions are crucially and under-considered in this context.\n\t- ### Layer 2: Modular Human-Computer Interface:\n\t\t- The framework proposes the development of collaborative global networks for training, research, biomedical, and creative industries using immersive and accessible environments. Engaging with ideas from diverse cultural backgrounds can enrich the overall user experience. Industry players have noted the risk and failures associated with closed systems like Meta and are embracing the \"open Metaverse\" narrative to de-risk their interests. To enable a truly open and interoperable Metaverse, it is crucial to develop open-source APIs, SDKs, and data standards that allow different platforms to communicate and exchange information. While the initial focus will be on building around a simpler open-source engine, the framework aims to link across standards such as Unity, [[Unreal]], and [[NVIDIA Omniverse]] as it develops. This can be accomplished using the federation layer.\n\t- ### LLM and Generative ML Integration:\n\t\t- ### Bots and AI Agents:\n\t\t\t- Autonomous AI [[Agents]], bonded to, but not bounded by, each federated mixed reality instance, can be self-governing entities that operate within their federated virtual social spaces, drawing upon private Bitcoin and Lightning wallets to perform and mediate economic exchanges within the spaces. They could also trivially operate outside the virtual space, and within other spaces on the same metaverse federation. They would accomplish this by drawing on their 'home' GPU/TPU processors where appropriate, or else using distributed large language model (LLM) processing to accomplish tasks assigned by their instructors. They can interact with the 'web2' world using open-source software called auto-gpt and have constraints, such as \"time to live\" and limited access to funds through their Bitcoin Lightning wallets.\n\t\t- ### Resource Management and Financial Autonomy:\n\t\t\t- These AI agents have access to dedicated LLM resources within their home instances in the federated virtual social spaces. If such resources are unavailable, they can resort to using slower, distributed open-source LLMs like Horde. This flexibility ensures that the agents can continue to function and complete tasks even if faced with limited LLM interpretive resources. The AI agents have their own private Bitcoin and Lightning wallets, which enable them to manage and utilize funds independently. They can use these funds to pay for services, acquire resources, or even trade with other agents or users within the virtual social spaces.\n\t\t- ### Social Interactions and Adaptive Learning:\n\t\t\t- Within the federated virtual social spaces, AI agents can communicate and collaborate with other agents or human users. They can participate in discussions, provide assistance, or even learn from the interactions, thereby improving their capabilities over time. Language translation, governance, and safeguarding could also be developed. Safeguarding would be handled by threshold risk triggers and transmission of data in a sovereign way to all parties, allowing external action by authorities appropriate to any abuse. As AI agents interact with their environment, other agents, and users, they can learn and adapt their behaviour. This enables them to improve their performance, better understand their assigned tasks, and become more effective at achieving their goals.\n\t- # Application Case Studies\n\t\t- ## Classic Use Cases:\n\t\t\t- The proposed framework can be applied to traditional collaborative scenarios, such as small teams working on product, architectural, or industrial design. These teams can benefit from CVEs (collaborative virtual environments) that allow them to visualize, modify, and iterate on 3D models in real-time.\n- ## Expanding Use Cases with AI and ML:\n\t- ### Virtual Training and Simulation:\n\t\t- CVEs can facilitate skill development and training in various industries, such as healthcare, military, aviation, and emergency response. Trainees can practice procedures in a virtual environment, with natural language AI providing instructions, explanations, or feedback, and visual generative ML potentially customizing scenarios to adapt to each user's learning curve.\n\t- ### Remote Teleconferencing:\n\t\t- In situations where face-to-face communication is not feasible, CVEs can enable remote teams to work together on shared visual tasks like planning events, brainstorming ideas, or reviewing documents. Natural language AI can transcribe and analyse spoken conversations, providing real-time translations or summaries, while visual generative ML can create visual aids or dynamically update shared documents.\n\t- ### Virtual Art & Media Collaboration:\n\t\t- Artists, animators, and multimedia professionals can collaborate in CVEs to create and develop their projects, such as films, animations, or video games. Natural language AI can help in storyboarding, scriptwriting, or character development, while visual generative ML can generate new visuals or adapt existing assets based on user input and style preferences.\n\t- ### Data Visualization and Analysis:\n\t\t- Small teams working with large datasets can use CVEs to visually explore and analyze data in a more intuitive and engaging way. Natural language AI can help users query and interact with the data using conversational interfaces, while visual generative ML can generate new visualizations based on patterns and trends identified in the data.\n\t- ### Education and Virtual Classrooms:\n\t\t- Educators can leverage CVEs to create immersive learning experiences that engage students in collaborative activities, such as group projects, problem-solving, or scientific experiments. Natural language AI can facilitate communication, provide personalized tutoring, or assess student progress, while visual generative ML can create customized educational content based on individual needs and interests.\n\t- ### Virtual Labs and Scientific Research:\n\t\t- Researchers can use CVEs to conduct experiments, visualize complex data, or simulate real-world conditions in a controlled environment. Natural language AI can assist in interpreting results, automating lab protocols, or identifying research gaps, while visual generative ML can generate predictions or models based on existing data to support hypothesis testing and decision-making.\n\t- ### Biomedical:\n\t\t- In fields like chemical and medical molecular modeling, the integration of AI and generative ML technologies can significantly improve collaboration and innovation. Teams can work together in immersive environments to visualize complex molecular structures, benefiting from real-time AI-generated visuals and natural language processing.\n\t- ### Case Study: Biodiversity Monitoring and Data Exchange with Isolated Communities:\n\t\t- The case study presents an open-source collaboration infrastructure that leverages advanced technologies such as multi-modal large language models (LLMs), satellite communication, and cryptocurrency networks to facilitate sustainable and reliable biodiversity monitoring and data exchange in isolated communities. Key components include:\n\t\t\t- Language Model and Voice Interface\n\t\t\t- Data Collection and Storage\n\t\t\t- Live Connection and Model Tuning\n\t\t\t- Ecosystem Interventions\n\t\t\t- Incentives and Education\n\t\t\t- Monetization and Blockchain Integration\n\t\t\t- Visual Training Support Systems\n\t\t\t- Solar Infrastructure\n\t\t\t- Open-Source Collaboration\n\t\t- The case study also addresses risk mitigation, ethical considerations, capacity building, and local empowerment. The proposed infrastructure has the potential to transform how isolated communities interact with their environment, enabling them to make informed decisions about conservation and ecosystem management.\n- ## Overcoming Challenges and Barriers\n\t- ### Trust, Accessibility, and Governance:\n\t\t- To create a successful open-source Metaverse, it is crucial to address trust, accessibility, and governance challenges. By integrating decentralized and secure technologies such as blockchain and distributed ledger systems, a more transparent and trustworthy infrastructure can be established.\n\t- ### Ensuring Safeguarding and Privacy Compliance:\n\t\t- Protecting user privacy and ensuring safeguarding is vital for any digital society platform. The open-source system must be developed in compliance with legislative and cultural norms while maintaining the balance between user privacy and the need for identity verification and data management. The evidence that social media is damaging youth mental health is very compelling. The Centre for Humane Technology calls social media the 'first contact point' with AI, explaining that new technologies often create an arms race. The underlying arms race for attention led to what they call 'an engagement monster' that rewrote the rules of society. These lessons should be learnt and the problems should be proactively mitigated. This proposal is not a social metaverse, and deliberately limits both numbers of participants and avatar optionality.\n\t- ### Managing Scalability, Performance, and Latency:\n\t\t- As the Metaverse continues to grow, it is crucial to ensure that the open-source system can scale effectively and maintain optimal performance. By using distributed and federated networks, the system can better manage latency and performance issues, ensuring a seamless user experience.\n\t- ### Promoting Open Standards and Interoperability:\n\t\t- For the Metaverse to truly thrive, it is essential to promote open standards and interoperability among various platforms and systems. This can be achieved by fostering collaboration between industry stakeholders, encouraging the development of open protocols, APIs, and data standards, and actively supporting the open-source community.\n- ## Future Outlook and Potential Developments\n\t- ### AI and Generative ML Technologies:\n\t\t- As AI and generative ML technologies continue to evolve, their integration into the Metaverse will further enhance user experiences and create new opportunities for innovation. The release of models like GPT-4 have already prompted debate about general AI. It seems unavoidable that this will all impact on the Metaverse and digital society.\n\t- ### Inclusive Digital Society:\n\t\t- By overcoming barriers to entry for emerging markets and less developed nations, a more inclusive digital society can be fostered. This inclusivity will empower new ideas and perspectives, leading to a richer and more diverse digital landscape.\n\t- ### Spatial and Augmented Reality Technologies:\n\t\t- The incorporation of spatial and augmented reality technologies can expand the possibilities within the Metaverse, allowing for more immersive and interactive experiences. These technologies have the potential to reshape digital society and redefine the ways in which people interact with digital environments.\n\t- ### Economic Empowerment AI Actors:\n\t\t- The creation of an open and economically empowered Metaverse, in which AI actors can mediate governance issues and participate in economic transactions, can lead to a more efficient and dynamic digital ecosystem. This integration will enable new business models and opportunities for all users, both human and AI.\n\t- ### Continuous Evolution and Adaptation:\n\t\t- As the digital landscape continues to evolve, the open-source Metaverse system must be flexible and adaptable to meet changing needs and expectations. Continuous innovation and collaboration within the industry will be crucial for the success and longevity of the Metaverse as a transformative digital society platform.\n\t- ### Embracing the Open-Source Metaverse Vision:\n\t\t- To create a truly transformative and inclusive digital society, it is essential to embrace the vision of an open-source Metaverse. By fostering collaboration, promoting open standards, and integrating advanced AI and ML technologies, the Metaverse can become a platform that serves societal and business needs.\n\t- ### Learning from Past Failures:\n\t\t- Learning from past failures and addressing challenges head-on will be critical to the successful development of an open-source Metaverse. Trust, accessibility, governance, and safeguarding issues must be thoughtfully considered and addressed to build a secure and user-friendly platform.\n\t- ### Unlocking New Opportunities and Use Cases:\n\t\t- The integration of AI, ML, and cutting-edge technologies within the Metaverse can unlock new opportunities and use cases across various industries, including education, research, biomedical, and creative fields. By building on a modular open-source system, these opportunities can be explored and realized to their full potential.\n\t- ### Fostering Collaboration and Inclusivity:\n\t\t- Creating an inclusive digital society is a key goal for the open-source Metaverse. By breaking down barriers and making the platform accessible to a wider audience, new ideas and perspectives will enrich the digital landscape and drive innovation.\n\t- ### Shaping the Future of Digital Society:\n\t\t- As the Metaverse continues to evolve and grow, it will play an increasingly important role in shaping the future of digital society. By embracing an open-source vision, overcoming challenges, and unlocking new opportunities, the Metaverse can become a powerful platform that transforms how people live, work, and interact in the digital world.\n\t- ### Industry Conversations:\n\t\t- Continued dialogue and collaboration among industry stakeholders are vital to ensuring the successful development of the open-source Metaverse. By engaging in conversations and understanding the cautious appetite for the ideas presented, the community can work together to shape the future of digital society and overcome the challenges that lie ahead.\n- # Software Stack\n\t- The proposed software stack for the open-source Metaverse includes the following components:\n\t\t- Collaborative space: Vircadia [Omniverse, Open3D foundation, Unreal]\n\t\t- Distributed truth: Bitcoin testnet [Main net]\n\t\t- Digital Objects: Fedimint [Ordinals, Pear credits, RGB]\n\t\t- Messaging and sync: Nostr\n\t\t- Identity: Nostr [Bluesky ION, Slashtags]\n\t\t- Fiat money transfer: Fedimint [Pear credits, RGB, Taro main net]\n\t\t- Hardware signing: Seed signer [any hardware wallet]\n\t\t- Small group banking: Fedimint [chaumian ecash]\n\t\t- Local wallet: Mutiny [bitkit, and lightning wallet]\n\t\t- Machine learning text: Alpaca [ChatGPT etc]\n\t\t- Machine learning image: Stable diffusion [midjourney, Dall-E]\n\t\t- Object tracking: Nostr [LnBits accounts]\n\t\t- The rationale behind these choices is to prioritize open-source availability, modularity, scalability, and security. However, alternative options for each component are also considered, taking into account the trade-offs involved in selecting one over another.\n- # Additional Topics and Case Studies\n- ### In-Camera VFX & Telepresence:\n\t- The proposed framework can be applied to film production and virtual production workflows. By leveraging the world's most powerful decentralized computing network (Bitcoin) and cryptographically assured endpoints, the system can enable scale and security without high cost. New tooling in the space allows for microtransactions and micropayments, radically improving creative microtask workflows. The unified digital backend is optimized for flows of money, trust, and digital objects, offering a new area for virtual production.\n- ### Novel VP Render Pipeline:\n\t- Putting the ML image generation on the end of a real-time tracked camera render pipeline might remove the need for detail in set building. The set designer, DP, director, etc., will be able to ideate in a headset-based metaverse of the set design, dropping very basic elements. If the interframe consistency (img2img) can deliver, the output on the VP screen can simply inherit the artistic style from the text prompts and render production quality from the basic building blocks. This \"next level pre-vis\" is being trailed in the Vircadia collaborative environment described in this book.\n- ### Money in Metaverses:\n\t- The proposed framework aims to connect creatives with very different global perspectives directly into 'Western' production pipelines. This can potentially heal the deep wounds caused by the slowing and 'cancellation' of creative progress in developed societies, as described by Fisher in \"Ghosts of my life\".\n- ### ML Actors and Blockchain-based Bots:\n\t- Stability AI is an open-source initiative to bring ML/AI capabilities to the world. This is a hugely exciting emergent area, and much more will be developed here. There is work in the community on economically empowered bots that leverage Nostr and RGB to perform functions within the proposed metaverse and outside in the WWW, as well as interacting economically through trusted cryptography with other bots and human participants. This is incredibly powerful and is assured by the Bitcoin security model.\n- ### AI Economic Actors in Mixed Reality:\n\t- AI actors can now be trusted visually. The proposed framework links the external web to the metaverse, allowing AI agents to interact with users in the metaverse and perform real-world tasks, such as purchasing flowers and delivering them to a physical address. These possibilities are endless, and the secure movement of money from the local context in the metaverse to the real world is within reach using these bots, which are completely autonomous and distributed.\n- ### Our Socialization Best Practices:\n\t- #### Identity:\n\t\t- The framework bases identity and object management on Nostr public/private key pairs. The public key of these enables lightning-based exchange of value globally. Nostr will operate in multiple modes, with bot-to-bot communication within the private relay mesh and human-to-human text chat using private Nostr tags. External connectivity to web and Nostr apps is achieved through public relay tags outbound.\n\t- #### Webs of Trust:\n\t\t- Webs of trust will be built within worlds using economically costly (but private) social rating systems between any actor, human or AI. Poorly behaving AIs will eventually be excluded through lack of funds.\n\t- #### Integration of 'Good' Actor AI Entities:\n\t\t- Gratitude practice should be encouraged between AI actors to foster trust and wellbeing in human observers. \"It's nice to be nice\" should be incentivized between all parties, including tipping and trust nudging through the social rating system. Great AI behavior would result in economically powerful entities.\n\t- #### Emulation of Important Social Cues:\n\t\t- The framework considers classroom layout and other important social cues to create an effective learning and collaboration environment.\n\t- #### Behaviour Incentives, Arbitration, and Penalties:\n\t\t- Collapses of trust and abuse will trigger flags from ML-based oversight, creating situational records and payloads of involved parties to unlock with their Nostr private keys. ML red-flagged actors will be financially penalized but have access to human arbitration using their copy of the data blob. Nothing will be stored except by the end-users.\n\t- #### Federations of Webs of Trust and Economics:\n\t\t- Nostr is developing fast enough to provide global bridges between metaverse instances.\n-\n- The proposed open-source Metaverse framework leverages cutting-edge technologies such as Bitcoin, Lightning Network, Nostr, AI, and generative ML to create a secure, accessible, and inclusive digital society. By addressing challenges related to trust, accessibility, governance, and safeguarding, the framework aims to unlock new opportunities and use cases across various industries.\n- The modular design of the framework allows for continuous evolution and adaptation, ensuring its relevance in the rapidly changing digital landscape. By fostering collaboration, promoting open standards, and engaging in industry conversations, the open-source Metaverse has the potential to transform how people live, work, and interact in the digital world.\n- As the framework is implemented and refined, it is essential to prioritize security, privacy, scalability, and community building. Regular security audits, transparent privacy settings, and a focus on user engagement will help create a thriving ecosystem that benefits all participants.\n- Looking ahead, the integration of advanced AI and generative ML technologies, coupled with the increasing adoption of spatial and augmented reality, will further enhance the capabilities and immersive nature of the open-source Metaverse. As AI actors become more sophisticated and economically empowered, they will play a crucial role in shaping the digital society and mediating governance issues.\n- Ultimately, the success of the open-source Metaverse will depend on the collective efforts of developers, researchers, artists, and users working together to realize its transformative potential. By embracing the vision of an open, inclusive, and innovative digital society, we can create a Metaverse that empowers individuals, fosters creativity, and drives positive change on a global scale.",
        "link_types": [
            "Delivery Planning",
            "Metaverse and Telecollaboration",
            "Metaverse Ontology",
            "Trust and Safety",
            "open source",
            "Bitcoin",
            "Lightning and Similar L2",
            "nostr",
            "Unreal",
            "NVIDIA Omniverse",
            "Agents"
        ],
        "file_size": 30725
    },
    {
        "id": "Gaussian splatting and Similar.md",
        "name": "Gaussian splatting and Similar",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- {{video https://www.youtube.com/watch?v=lG3g8mYKfqU}}\n- # Gaussian Splatting\n- [Instantsplat: Unbounded Sparse-view Pose-free Gaussian Splatting in 40 Seconds](https://instantsplat.github.io/)\n- [The Rise Of 3D Gaussian Splatting: What Is It And How Is It Changing The Immersive Media Industry? — Magnopus](https://www.magnopus.com/blog/the-rise-of-3d-gaussian-splatting)\n- 4D [[Gaussian splatting and Similar]] [with time domain](https://github.com/hustvl/4DGaussians)\n- [[Gaussian splatting and Similar]] [gsgen](https://github.com/gsgen3d/gsgen)\n- Room scale [[Gaussian splatting and Similar]] technique for single lens (#SLAM) [[Scene Capture and Reconstruction]]  [Gaussian-SLAM: Photo-realistic Dense SLAM with Gaussian Splatting (vladimiryugay.github.io)](https://vladimiryugay.github.io/gaussian_slam/)\n- [Mip-Splatting (niujinshuchong.github.io)](https://niujinshuchong.github.io/mip-splatting/) reduced artifacts in [[Gaussian splatting and Similar]]\n- [Gaussian-SLAM: Photo-realistic Dense SLAM with Gaussian Splatting (vladimiryugay.github.io)](https://vladimiryugay.github.io/gaussian_slam/)\n- GaussianDiffusion: 3D Gaussian Splatting for Denoising Diffusion Probabilistic Models with Structured Noise\n\t- logseq://graph/researchpapers?block-id=6579a51f-5e6d-4570-903f-9458f84e845f\n- Gaussian [[SLAM]] rooms scale scanning\n\t- logseq://graph/researchpapers?block-id=6579a880-ce7f-4a79-b3d3-9135ff4348b3\n\t- [Gaussian Splatting SLAM (rmurai.co.uk)](https://rmurai.co.uk/projects/GaussianSplattingSLAM/)  is near real-time\n- [Paper page TRIPS: Trilinear Point Splatting for Real-Time Radiance Field Rendering (huggingface.co)](https://huggingface.co/papers/2401.06003)\n- [Deblurring 3D Gaussian Splatting (benhenryl.github.io)](https://benhenryl.github.io/Deblurring-3D-Gaussian-Splatting/)\n- [huggingface/gsplat.js: JavaScript Gaussian Splatting library. (github.com)](https://github.com/huggingface/gsplat.js/)\n- [[Gaussian splatting and Similar]] in Houdini\n- [Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers (zouzx.github.io)](https://zouzx.github.io/TriplaneGaussian/) understandable [[Text to 3D and 4D]] from [[Gaussian splatting and Similar]]\n- [dynamic3dgaussians.github.io](https://dynamic3dgaussians.github.io/) using a multi [[Motion Capture]] dome and [[Gaussian splatting and Similar]] for 6DOF [[Human tracking and SLAM capture]]\n- [LangSplat: 3D Language Gaussian Splatting](https://langsplat.github.io/)\n-",
        "link_types": [
            "Gaussian splatting and Similar",
            "Gaussian splatting and Similar",
            "Gaussian splatting and Similar",
            "Scene Capture and Reconstruction",
            "Gaussian splatting and Similar",
            "SLAM",
            "Gaussian splatting and Similar",
            "Text to 3D and 4D",
            "Gaussian splatting and Similar",
            "Motion Capture",
            "Gaussian splatting and Similar",
            "Human tracking and SLAM capture"
        ],
        "file_size": 2546
    },
    {
        "id": "OpenAI.md",
        "name": "OpenAI",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n-",
        "link_types": [],
        "file_size": 59
    },
    {
        "id": "Product Design.md",
        "name": "Product Design",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ### Introduction and Problem Definition\n\t- This chapter identifies an intersectional space across the described technologies, and proposes a valuable and novel software stack, which can enable exploration and product development. It is useful to briefly look at the Venn disgram we began with, and recap the book and the conclusions we have drawn so far.\n\t- ![image](../assets/c5efbdb4f93ab63a4fbbf12aba053d2194959850.png){:height 776, :width 1024}\n- #### Overview of the Metaverse and Digital Society\n\t- The concept of the Metaverse has gained significant attention, with various stakeholders positioning themselves to capitalize on its potential. While it remains unclear exactly what form the Metaverse will take or whether people truly desire it, it is evident that digital society holds considerable promise. We see advantage less in social metaverse, and more in solving business to business technical use cases where professionals with visual technical problems, or training requirements, gather in collaborative spaces.\n- #### Trust, Accessibility, Governance, and Safeguarding\n\t- The Metaverse faces numerous challenges, including poor adoption rates, overstated market need, and a lack of genuine digital society use cases. Meanwhile trust abuses by incumbent providers have led to potential inflection points in the organization of the wider internet. Moreover, emerging markets and less developed nations face barriers to entry due to inadequate identification, banking infrastructure, and computing power. There is an opportunity to build pervasive digital spaces with a different and more open foundation, learning from these lessons.\n- #### The Need for Modular Open-Source Solutions\n\t- Developing a topologically flat, inclusive, permissionless, federated, and open Metaverse is essential to address these challenges. By using open-source AI tooling and large language models, it is possible to improve creativity, safeguarding, and governance, while breaking down language barriers and accessibility challenges. Implementing secure, trusted, and task-appropriate solutions can promote collaboration and innovation across various industries.\n- #### Technical problem definition\n\t- Problems are\n\t\t- evergreen telecollaboration around technical issues\n\t\t- exchange of good, services, money within systems, without friction\n\t\t- identity management within virtual spaces\n\t\t- access to information in the extrinsic world from within the tool\n\t\t- federation of instances without overhead (scaling)\n\t\t- seamless access to personal information within and without the collaborative system\n\t\t- ability to take advantage of supporting smart support agents (bots, etc) throughout\n\t\t- governance, trust, safeguarding\n- ### Lean canvas business model\n\t- Existing large-scale telecollaboration solutions suffer from poor  adoption, limited accessibility, and trust issues. Meanwhile, emerging markets struggle to participate in the growing digital society due to the lack of inclusive tools and infrastructure, limiting access to global talent and new pools of ideas. There is insufficient provision of global talent pipelines for highly technical workflows.\n\t- Develop a secure, accessible, and inclusive platform for specialized telecollaboration spaces that seamlessly integrate advanced AI, ML, highly scalable and proven distributed systems, and open-source principles to create a digital society that caters to diverse industries, users globally, and captures global talent and innovative ideas.\n\t- Ultra low cost training spaces, accessible 24/7 through very low end hardware. Interact with highly customizable, task-appropriate, and user-friendly specialized telecollaboration spaces supported by specially trained and optimised supportive large language AI models. Multi-ligual for emerging markets, enabling access to untapped global talent and fostering the exchange of diverse ideas.\n\t- We will cater to the global training, research, biomedical, and creative industries, with a special focus on empowering users in emerging markets such as Africa and India, and connecting them with worldwide opportunities and resources. In the first instance we would leverage UK academic institutions and their problems, and networks.\n\t- Initially Universities, but this will scale to be sector specific.\n\t- We will offer tiered subscription plans to accommodate various user needs and budgets, as well as tailored enterprise solutions for large-scale clients. Bespoke consulting and support trending toward software as a service at scale.\n\t- Platform development, AI/ML tool integration, training for LLMs, market research and awareness, and ongoing maintenance and support.\n\t- We will track user growth, engagement, and retention, successful collaborations across industries, the platform’s positive impact on users in emerging markets, and the effectiveness of global talent capture and idea exchange.\n\t- Our team’s extensive experience in telecollaboration research, AI, ML, and a deep understanding of the complex landscape of emerging technologies, including highly scalable and proven distributed systems, provide us with a unique edge in creating a game-changing platform for specialized telecollaboration spaces that are secure, trusted, and tailored to diverse user needs while enabling access to global talent and innovative ideas.\n- ### Proposed Layered Framework\n\t- #### Layer 1: Bitcoin, Lightning, and Nostr protocols\n\t\t- Distributed financial tooling and digital assets, have ignited\n\t\t  imagination and adoption within and outside of the Metaverse context. A\n\t\t  global ledger could unite isolated digital ecosystems and enable the\n\t\t  transfer of portable ‘goods’ across digital society. An open-source\n\t\t  Metaverse should emphasize the development and adoption of open\n\t\t  protocols and data formats. The Nostr protocol, for instance, might link\n\t\t  and federate mixed reality spaces, providing identity assurances and\n\t\t  mediating data synchronization while maintaining reasonably strong\n\t\t  cryptography. This also allows integration with the legacy web through\n\t\t  ubiquitous web sockets. Bitcoin and associated technologie, despite\n\t\t  their issues, have the potential to revolutionize the way digital\n\t\t  society operates by enabling “money-like networks” which are a\n\t\t  cornerstone of human interaction. Representations of traditional\n\t\t  currencies [can ride securely on top of these networks as stablecoins](https://twitter.com/callebtc/status/1777598819355496587),\n\t\t  opening up global collaborative working practices, especially for\n\t\t  emerging markets. Streaming micropayments and machine to machines (AI to\n\t\t  AI) are crucially and under-considered in this context.\n\t\t-\n\t\t- [tweet which is trying to load above]https://twitter.com/callebtc/status/1777598819355496587\n\t\t  https://twitter.com/callebtc/status/1777598819355496587?\n\t\t-\n\t- #### Layer 2: Modular human computer interface\n\t\t- Collaborative global networks for training, research, biomedical, and\n\t\t  creative industries can be developed using immersive and accessible\n\t\t  environments. Engaging with ideas from diverse cultural backgrounds can\n\t\t  enrich the overall user experience.\n\t\t- Industry players have noted the risk and failures associated with closed\n\t\t  systems like Meta and are embracing the \"open Metaverse\" narrative to\n\t\t  de-risk their interests. To enable a truly open and interoperable\n\t\t  Metaverse, it is crucial to develop open-source APIs, SDKs, and data\n\t\t  standards that allow different platforms to communicate and exchange\n\t\t  information. While we wish initially to build around a simpler open\n\t\t  source engine we aim to link across standards such as Unity, Unreal, and\n\t\t  Omniverse as we develop. This can be accomplished using our federation\n\t\t  layer.\n\t- #### Layer 3: LLM and Generative ML Integration\n\t\t- Integrating AI and machine learning into the Metaverse can promote\n\t\t  supported creativity and augmented intelligence. By incorporating\n\t\t  generative ML technologies, users can ideate in simple immersive spaces\n\t\t  while instantly creating scenes that can be stylized using verbal\n\t\t  commands in real-time.\n\t\t- To create a more inclusive and accessible Metaverse, user experience\n\t\t  components like UI/UX design, AI assistants, and generative content\n\t\t  creation should be tailored to a wide range of users. The integration of\n\t\t  AI and machine learning technologies, such as GPT-4, can facilitate more\n\t\t  seamless interactions and creative content generation, fostering a more\n\t\t  engaging and immersive experience.\n\t- ##### Bots and AI agents\n\t\t- Autonomous AI agents, bonded to, but not bounded by, each federated\n\t\t  mixed reality instance, can to be self-governing entities that operate\n\t\t  within their federated virtual social spaces, drawing upon private\n\t\t  Bitcoin and Lightning wallets to perform and mediate economic exchanges\n\t\t  within the spaces. They could also trivially operate outside the virtual\n\t\t  space, and within other spaces on the same metaverse federation. They\n\t\t  would accomplish this by drawing on their ‘home’ GPU/TPU processors\n\t\t  where appropriate, or else using distributed large language model (LLM)\n\t\t  processing to accomplish tasks assigned by their instructors. They can\n\t\t  interact with the ‘web2’ world using open-source software called\n\t\t  auto-gpt and have constraints, such as “time to live” and limited access\n\t\t  to funds through their Bitcoin Lightning wallets.\n\t\t- Resource Management: These AI agents have access to dedicated LLM resources within their home instances in the federated virtual social spaces. If such resources are unavailable, they can resort to using slower, distributed open-source LLMs like Horde. This flexibility ensures that the agents can continue to function and complete tasks even if faced with limited LLM interpretive resources.\n\t\t- Financial Autonomy: The AI agents have their own private Bitcoin and Lightning wallets, which enable them to manage and utilize funds independently. They can use these funds to pay for services, acquire resources, or even trade with other agents or users within the virtual social spaces.\n\t\t- Interaction with Web2: By using open-source software like auto-gpt, the AI agents can interact with the web2 world, which includes browsing websites, retrieving information, and communicating with web services. This allows them to gather data, analyze trends, and perform other tasks that may require access to the broader internet.\n\t\t- Task Execution: The AI agents can be assigned tasks by their instructors (or a hierarchy of AI actors), such as data analysis, research, content creation, or other complex tasks that require LLM processing. They can use their dedicated LLM resources or distributed LLMs like Horde to process and analyze large datasets, generate insights, and produce desired outputs, up to and including those which require finance systems. This would be bridged in the first instance using Bitrefil gift card infrastructure.\n\t\t- Social Interactions: Within the federated virtual social spaces, AI agents can communicate and collaborate with other agents or human users. They can participate in discussions, provide assistance, or even learn from the interactions, thereby improving their capabilities over time. Language translation, governance, and safeguarding could also be developed. Safeguarding would be handled by threshold risk triggers and transmission of data in a sovereign way to all parties, allowing external action by authorities appropriate to any abuse.\n\t\t- Time-to-Live Constraint: The AI agents have a predetermined “time to live”, which means they exist for a specific duration before expiring. This constraint ensures that agents do not consume resources indefinitely and allows for the creation of new agents with updated capabilities. Any agents which deplete their financial resource would also expire.\n\t\t- Adaptive Learning: As AI agents interact with their environment, other agents, and users, they can learn and adapt their behaviour. This enables them to improve their performance, better understand their assigned tasks, and become more effective at achieving their goals.\n\t- ### Application case studies\n\t\t- As we have seen in the ‘collaborative mixed reality’ chapter, these tools are best deployed where some human conversational cues (pointing,\n\t\t  looking etc) are required in the context of a shared task, which is mostly visual in nature. This is a surprisingly small amount of tasks,\n\t\t  though we have seen that the emergence of AI means that increasingly natural language AI can streamline communication, while visual\n\t\t  generative ML can suggest design alternatives or improvements based on existing data and user preferences. This is very likely to expand the\n\t\t  use space and this section will attempt to explain how as the case studies are explained.\n\t\t- We will employ the acronym for collaborative virtual environment (CVE) from this stage, and it’s going to come up a lot. There will be far less\n\t\t  references in this section for brevity.\n\t- #### Classic use cases\n\t\t- Small teams working on product, architectural, or industrial design can\n\t\t  benefit from CVEs that allow them to visualize, modify, and iterate on\n\t\t  3D models in real-time.\n\t- #### Virtual training and simulation\n\t\t- CVEs can facilitate skill development and training in various\n\t\t  industries, such as healthcare, military, aviation, and emergency\n\t\t  response. Trainees can practice procedures in a virtual environment,\n\t\t  with natural language AI providing instructions, explanations, or\n\t\t  feedback, and visual generative ML potentially customizing scenarios to\n\t\t  adapt to each user’s learning curve.\n\t- #### Remote teleconferencing\n\t\t- In situations where face-to-face communication is not feasible, CVEs can\n\t\t  enable remote teams to work together on shared visual tasks like\n\t\t  planning events, brainstorming ideas, or reviewing documents. Natural\n\t\t  language AI can transcribe and analyse spoken conversations, providing\n\t\t  real-time translations or summaries, while visual generative ML can\n\t\t  create visual aids or dynamically update shared documents. This may\n\t\t  especially be useful in complex multinational legal and/or negotiation\n\t\t  applications, though very clearly the risks of using assisting ML\n\t\t  tooling increases.\n\t- #### Virtual art & media collaboration\n\t\t- Artists, animators, and multimedia professionals can collaborate in CVEs\n\t\t  to create and develop their projects, such as films, animations, or\n\t\t  video games. Natural language AI can help in storyboarding,\n\t\t  scriptwriting, or character development, while visual generative ML can\n\t\t  generate new visuals or adapt existing assets based on user input and\n\t\t  style preferences.\n\t- #### Data visualization and analysis\n\t\t- Small teams working with large datasets can use CVEs to visually explore\n\t\t  and analyze data in a more intuitive and engaging way. Natural language\n\t\t  AI can help users query and interact with the data using conversational\n\t\t  interfaces, while visual generative ML can generate new visualizations\n\t\t  based on patterns and trends identified in the data.\n\t- #### Education and virtual classrooms\n\t\t- Educators can leverage CVEs to create immersive learning experiences\n\t\t  that engage students in collaborative activities, such as group\n\t\t  projects, problem-solving, or scientific experiments. Natural language\n\t\t  AI can facilitate communication, provide personalized tutoring, or\n\t\t  assess student progress, while visual generative ML can create\n\t\t  customized educational content based on individual needs and interests.\n\t- #### Virtual labs and scientific research\n\t\t- Researchers can use CVEs to conduct experiments, visualize complex data,\n\t\t  or simulate real-world conditions in a controlled environment. Natural\n\t\t  language AI can assist in interpreting results, automating lab\n\t\t  protocols, or identifying research gaps, while visual generative ML can\n\t\t  generate predictions or models based on existing data to support\n\t\t  hypothesis testing and decision-making.\n\t- #### Media and entertainment\n\t- #### Biomedical\n\t\t- Collaborative Virtual Environments (CVEs) have immense potential in the\n\t\t  fields of chemical and medical molecular modeling. By incorporating\n\t\t  natural language AI and visual generative machine learning, these\n\t\t  environments can revolutionize the way scientists and researchers\n\t\t  approach complex chemical and biological problems. Here are some\n\t\t  specific use cases:\n\t\t- Drug design and discovery: CVEs can enable researchers to\n\t\t   collaboratively visualize and manipulate 3D molecular structures in\n\t\t   real-time, identifying potential drug candidates and understanding\n\t\t   protein-ligand interactions. Natural language AI can help users interact\n\t\t   with the molecular data, while visual generative ML can predict\n\t\t   potential binding sites, energetics, or toxicity profiles based on\n\t\t   existing knowledge.\n\t\t- Protein structure prediction and modeling: Small teams can work together\n\t\t   to predict protein structures, visualize folding patterns, and model\n\t\t   protein-protein or protein-nucleic acid interactions. Natural language\n\t\t   AI can assist in annotating and explaining the structural features,\n\t\t   while visual generative ML can generate new structural hypotheses based\n\t\t   on sequence alignments, homology modeling, and experimental data.\n\t\t- Molecular dynamics simulations: CVEs can facilitate collaboration on\n\t\t   complex molecular dynamics simulations, allowing researchers to analyze\n\t\t   and visualize trajectories, energetics, and conformational changes.\n\t\t   Natural language AI can help users navigate through simulation data and\n\t\t   identify relevant patterns, while visual generative ML can create new\n\t\t   conformations or predict the effects of mutations on protein stability\n\t\t   and function.\n\t\t- Cheminformatics and QSAR modeling: Researchers can leverage CVEs to\n\t\t   develop and validate Quantitative Structure-Activity Relationship (QSAR)\n\t\t   models, which predict the biological activity of chemical compounds\n\t\t   based on their structural properties. Natural language AI can facilitate\n\t\t   the exploration and interpretation of chemical descriptors, while visual\n\t\t   generative ML can suggest new compounds with desired properties or\n\t\t   optimize existing molecular scaffolds.\n\t\t- Metabolic pathway modeling: Small teams can work together to build and\n\t\t   analyze metabolic pathways, integrating experimental data and\n\t\t   computational models to understand the underlying mechanisms and predict\n\t\t   metabolic fluxes. Natural language AI can assist in annotating and\n\t\t   explaining pathway components, while visual generative ML can generate\n\t\t   new pathway hypotheses or predict the effects of genetic or\n\t\t   environmental perturbations.\n\t\t- Biomolecular visualization and virtual reality: CVEs can offer\n\t\t   immersive, interactive experiences for exploring biomolecular structures\n\t\t   and dynamics, enhancing researchers’ understanding of complex biological\n\t\t   systems. Natural language AI can provide contextual information or guide\n\t\t   users through molecular landscapes, while visual generative ML can\n\t\t   create new visualizations or adapt existing ones based on user\n\t\t   preferences and insights.\n\t\t- Collaborative molecular docking and virtual screening: Small teams can\n\t\t   use CVEs to perform collaborative molecular docking and virtual\n\t\t   screening, which involve predicting the binding of small molecules to\n\t\t   target proteins. Natural language AI can help users refine docking\n\t\t   parameters and analyze results, while visual generative ML can generate\n\t\t   alternative poses or suggest new compounds for screening based on user\n\t\t   feedback and existing data. Choose a suitable mixed reality platform:\n\t\t   Select a platform that allows the creation of simple, accessible shared\n\t\t   mixed reality environments. Consider open-source options like Mozilla\n\t\t   Hubs or JanusVR, which offer customizable and collaborative virtual\n\t\t   spaces.\n\t\t- Integrate open-source biomed software: Incorporate open-source biomed\n\t\t   software such as PyMOL, Chimera, or VMD for molecular visualization and\n\t\t   analysis. These tools can be integrated into the mixed reality\n\t\t   environment for real-time interaction, allowing students and instructors\n\t\t   to collaboratively visualize and manipulate molecular structures.\n\t\t- Leverage AI and machine learning: Integrate AI and ML algorithms like\n\t\t   those found in DeepChem, RDKit, or Open Babel to aid in the discovery\n\t\t   and optimization of novel compounds. These tools can help predict\n\t\t   molecular properties, perform virtual screening, and optimize lead\n\t\t   compounds for drug development. By incorporating AI and ML, students can\n\t\t   learn how to apply these cutting-edge techniques to real-world problems\n\t\t   in biomedicine.\n\t\t- Establish a distributed proof system: Utilize a distributed proof system\n\t\t   like the Nostr protocol to federate the small virtual classroom\n\t\t   environments. This will allow for seamless collaboration among students\n\t\t   and faculty while maintaining security and data integrity.\n\t\t- Create digital objects for interaction: Use digital objects such as 3D\n\t\t   molecular models, virtual lab equipment, and interactive simulations to\n\t\t   create an immersive learning experience. These digital objects can be\n\t\t   shared and manipulated in real-time, promoting collaborative learning\n\t\t   and problem-solving.\n\t\t- Implement accessible interfaces: Ensure that the virtual classroom\n\t\t   environment is accessible to all students, including those with\n\t\t   disabilities. Utilize AI-driven tools like StabilityAI to help with\n\t\t   language barriers, safeguarding, and governance, enabling a more\n\t\t   inclusive learning experience.\n\t\t- Foster collaboration and communication: Encourage students and faculty\n\t\t   to collaborate on projects, share ideas, and ask questions in real-time\n\t\t   using voice chat, text chat, or other communication tools integrated\n\t\t   into the mixed reality environment.\n\t\t- Provide training and support: Offer training sessions and support\n\t\t   materials to help students and faculty become familiar with the mixed\n\t\t   reality environment, the integrated biomed software, and AI/ML tools.\n\t\t- Monitor progress and adjust as needed: Regularly review student\n\t\t   progress, gather feedback, and adjust the virtual classroom environment\n\t\t   as needed to ensure an effective and engaging learning experience.\n\t\t- #### Collaborative Design and Prototyping\n\t\t- Utilizing open-source systems and AI-assisted tools can enable more\n\t\t   efficient and creative collaboration in design and prototyping\n\t\t   processes. Teams from diverse cultural backgrounds can work together\n\t\t   seamlessly, creating a rich pool of ideas and innovations.\n\t\t- #### Training, Simulation, and Education\n\t\t- The modular open-source system can be applied to various training,\n\t\t   simulation, and education scenarios. By integrating AI and generative ML\n\t\t   technologies, these tools can provide personalized learning experiences\n\t\t   and create realistic simulations that cater to different learning styles\n\t\t   and requirements.\n\t\t- #### Remote Collaboration and Teleconferencing\n\t\t- As remote work becomes more prevalent, the Metaverse can provide a more\n\t\t   engaging and immersive platform for collaboration and teleconferencing.\n\t\t   The open-source system can be adapted to serve various industries,\n\t\t   making remote collaboration more efficient and inclusive.\n\t\t- #### Chemical and Medical Molecular Modeling\n\t\t- In fields like chemical and medical molecular modeling, the integration\n\t\t   of AI and generative ML technologies can significantly improve\n\t\t   collaboration and innovation. Teams can work together in immersive\n\t\t   environments to visualize complex molecular structures, benefiting from\n\t\t   real-time AI-generated visuals and natural language processing.\n\t\t- #### Creative Industries and Generative Art\n\t\t- The combination of AI, ML, and open-source systems can revolutionize the\n\t\t   creative industries by offering new avenues for generative art, content\n\t\t   creation, and collaboration. Supported creativity and augmented\n\t\t   intelligence can break down barriers and enable artists to explore new\n\t\t   ideas and techniques, enriching the creative landscape.\n\t\t- #### Case Study: Biodiversity Monitoring and Data Exchange with Isolated Communities\n\t\t- Biodiversity monitoring in and around isolated communities is\n\t\t   challenging due to limited access and resources. Traditional methods\n\t\t   rely on sporadic visits by grant-funded academics, which can introduce\n\t\t   biases and lack regular follow-up. Engaging local communities may also\n\t\t   introduce incentive structures and biases and may not be sustainable\n\t\t   without continuous investment.\n\t\t- We propose an open-source collaboration infrastructure that leverages\n\t\t   advanced technologies such as multi-modal large language models (LLMs),\n\t\t   satellite communication, and cryptocurrency networks to facilitate\n\t\t   sustainable and reliable biodiversity monitoring and data exchange in\n\t\t   isolated communities.\n\t\t- ##### Language Model and Voice Interface\n\t\t- A specialized multi-modal LLM can be trained on local language, culture,\n\t\t   customs, and environmental data such as flora, fauna, biotica, soil pH,\n\t\t   and rainfall. This LLM can be accessed through a voice interface by the\n\t\t   local community, enabling data entry and knowledge exchange in the local\n\t\t   language. The voice interface can help overcome literacy barriers and\n\t\t   make the system more accessible to a diverse range of community members.\n\t\t- ##### Data Collection and Storage\n\t\t- Photographs and metadata can be logged and collected by a remote team at\n\t\t   a later date or uploaded regularly through a satellite link (e.g.,\n\t\t   Starlink). The data storage system can be designed to be both secure and\n\t\t   resilient, ensuring that the collected data remains available and\n\t\t   accessible for future analysis and decision-making.\n\t\t- ##### Live Connection and Model Tuning\n\t\t- A live connection with the academic team allows for model tuning through\n\t\t   prompt engineering, vector database updates, and efficient Lora models,\n\t\t   potentially offering timely advice for ecosystem interventions.\n\t\t   Real-time communication between the community and academic teams can\n\t\t   help identify areas of concern and rapidly adapt the LLM to address\n\t\t   emerging challenges.\n\t\t- ##### Ecosystem Interventions\n\t\t- The proposed infrastructure would be particularly valuable in areas\n\t\t   facing novel disease encroachment, invasive species, active hydrology,\n\t\t   shifting aquatic conditions, microplastic hotspots, changing\n\t\t   microclimates, or volcanic activity. By providing real-time advice and\n\t\t   guidance, the LLM can help communities make informed decisions about\n\t\t   ecosystem management and conservation efforts.\n\t\t- ##### Incentives and Education\n\t\t- Incentivizing community engagement could be achieved by providing access\n\t\t   to the LLM for educational purposes, as demonstrated by the refugee camp\n\t\t   e-prize (ref). Local schools and community centers can leverage the LLM\n\t\t   as a resource for teaching environmental stewardship and ecological\n\t\t   awareness, while also promoting digital literacy and technology skills.\n\t\t- ##### Monetization and Blockchain Integration\n\t\t- Monetizing these systems could involve using chaumian mints such as\n\t\t   Cashu or Fedimint, under the control of local community leaders,\n\t\t   mediated through the global Bitcoin satellite network (Blockstream),\n\t\t   enabling digital dollar payments to communities via low-end mobile\n\t\t   handsets. By integrating blockchain technology, the proposed\n\t\t   infrastructure can ensure secure, transparent, and efficient financial\n\t\t   transactions, while also opening up new economic opportunities for\n\t\t   isolated communities.\n\t\t- ##### Visual Training Support Systems\n\t\t- The infrastructure could be further extended to visual training support\n\t\t   systems using low-cost, low-power components. These systems could\n\t\t   provide interactive, immersive learning experiences for community\n\t\t   members, helping them better understand the local ecosystem and develop\n\t\t   skills in environmental monitoring and management.\n\t\t- ##### Solar Infrastructure\n\t\t- To minimize the environmental impact and ensure energy sustainability,\n\t\t   the proposed infrastructure can be powered by solar energy. This\n\t\t   approach will enable the system to operate independently of local power\n\t\t   grids, reducing the overall operational costs and maintenance\n\t\t   requirements.\n\t\t- ##### Open-Source Collaboration\n\t\t- By linking this case study to the open-source collaboration\n\t\t   infrastructure discussed earlier, we can create an inclusive,\n\t\t   permissionless, federated, and economically empowered system that\n\t\t   addresses the challenges of biodiversity monitoring while promoting\n\t\t   digital society values such as trust, accessibility, and governance.\n\t\t   This collaborative approach can help drive innovation and ensure that\n\t\t   the proposed solutions are both scalable and adaptable to the unique\n\t\t   needs of different communities and ecosystems.\n\t\t- ##### Risk Mitigation and Ethical Considerations\n\t\t- While implementing such an infrastructure, care must be taken to address\n\t\t   potential unintended consequences of embedding these inference systems\n\t\t   in communities. It is essential to involve the local communities in the\n\t\t   development and deployment process, ensuring that their perspectives,\n\t\t   values, and traditions are respected and preserved.\n\t\t- Moreover, it is crucial to establish a robust ethical framework for the\n\t\t   use of AI technologies, considering potential issues related to privacy,\n\t\t   data security, and cultural sensitivity. Regular audits and monitoring\n\t\t   can be implemented to ensure that the infrastructure remains\n\t\t   transparent, accountable, and aligned with the needs and expectations of\n\t\t   the communities it serves.\n\t\t- ##### Capacity Building and Local Empowerment\n\t\t- An essential aspect of this initiative is building capacity and\n\t\t   empowering local communities to take ownership of their environment and\n\t\t   resources. By providing training, resources, and support, the proposed\n\t\t   infrastructure can help communities develop the skills and knowledge\n\t\t   needed to manage their ecosystems effectively.\n\t\t   \n\t\t   Furthermore, the integration of digital tools and technologies can\n\t\t   promote digital inclusion and bridge the digital divide, giving isolated\n\t\t   communities access to valuable information and resources while fostering\n\t\t   a sense of global connectedness and collaboration.\n\t\t- ##### Future Outlook and Potential Impact\n\t\t- The proposed open-source collaboration infrastructure for biodiversity\n\t\t   monitoring and data exchange has the potential to transform how isolated\n\t\t   communities interact with their environment, enabling them to make\n\t\t   informed decisions about conservation and ecosystem management.\n\t\t- By leveraging cutting-edge technologies such as LLMs, satellite\n\t\t   communication, and blockchain networks, this approach can create a more\n\t\t   inclusive, transparent, and accessible system for environmental\n\t\t   monitoring and stewardship. The successful implementation of this\n\t\t   infrastructure could pave the way for similar initiatives in other\n\t\t   regions and ecosystems, promoting global collaboration and innovation in\n\t\t   the pursuit of a more sustainable and equitable world.\n- ### Overcoming Challenges and Barriers\n\t- #### Trust, Accessibility, and Governance\n\t\t- To create a successful open-source Metaverse, it is crucial to address\n\t\t  trust, accessibility, and governance challenges. By integrating\n\t\t  decentralized and secure technologies such as blockchain and distributed\n\t\t  ledger systems, a more transparent and trustworthy infrastructure can be\n\t\t  established.\n\t- #### Ensuring Safeguarding and Privacy Compliance\n\t\t- Protecting user privacy and ensuring safeguarding is vital for any\n\t\t  digital society platform. The open-source system must be developed in\n\t\t  compliance with legislative and cultural norms while maintaining the\n\t\t  balance between user privacy and the need for identity verification and\n\t\t  data management. The evidence that social media is damaging youth mental\n\t\t  health is very compelling.[@haidt2023social] The Centre for Humane\n\t\t  Technology call social media the ‘[first contact\n\t\t  point](https://www.youtube.com/watch?v=xoVJKj8lcNQ) with AI’. They\n\t\t  explains that new technologies often create an arms race. They list the\n\t\t  negative impacts of this contact as including “information overload,\n\t\t  addiction, doom scrolling, sexualization of kids, shortened attention\n\t\t  spans, polarization, fake news, and breakdown of democracy”. These were\n\t\t  not the intended consequence of engineers who aimed to maximize\n\t\t  engagement. The underlying arms race for attention led to what they call\n\t\t  ‘an engagement monster’ that rewrote the rules of society.\n\t\t- These lessons should be learnt and the problems should be pro-actively\n\t\t  mitigated. This proposal is bfnot a social metaverse, and deliberately\n\t\t  limits both numbers of participants and avatar optionality.\n\t- #### Managing Scalability, Performance, and Latency\n\t\t- As the Metaverse continues to grow, it is crucial to ensure that the\n\t\t  open-source system can scale effectively and maintain optimal\n\t\t  performance. By using distributed and federated networks, the system can\n\t\t  better manage latency and performance issues, ensuring a seamless user\n\t\t  experience.\n\t- #### Promoting Open Standards and Interoperability\n\t\t- For the Metaverse to truly thrive, it is essential to promote open\n\t\t  standards and interoperability among various platforms and systems. This\n\t\t  can be achieved by fostering collaboration between industry\n\t\t  stakeholders, encouraging the development of open protocols, APIs, and\n\t\t  data standards, and actively supporting the open-source community.\n- ### Future Outlook and Potential Developments\n\t- #### AI and Generative ML Technologies\n\t\t- As AI and generative ML technologies continue to evolve, their\n\t\t  integration into the Metaverse will further enhance user experiences and\n\t\t  create new opportunities for innovation. The release of models like\n\t\t  GPT-4 have already prompted debate about general\n\t\t  AI[@bubeck2023sparks; @perez2022discovering] (Figure\n\t\t  <a href=\"#fig:rlhf\" data-reference-type=\"ref\" data-reference=\"fig:rlhf\">[fig:rlhf]</a>).\n\t\t  It seems unavoidable that this will all impact on the Metaverse and\n\t\t  digital society.\n\t\t  \n\t\t  ![image](../assets/552f8c9bfcf9305e87b1413ea51637d986ac28dd.png)\n\t- #### Inclusive Digital Society\n\t\t- By overcoming barriers to entry for emerging markets and less developed\n\t\t  nations, a more inclusive digital society can be fostered. This\n\t\t  inclusivity will empower new ideas and perspectives, leading to a richer\n\t\t  and more diverse digital landscape.\n\t- #### Spatial and Augmented Reality Technologies\n\t\t- The incorporation of spatial and augmented reality technologies can\n\t\t  expand the possibilities within the Metaverse, allowing for more\n\t\t  immersive and interactive experiences. These technologies have the\n\t\t  potential to reshape digital society and redefine the ways in which\n\t\t  people interact with digital environments.\n\t- #### Economic Empowerment AI Actors\n\t\t- The creation of an open and economically empowered Metaverse, in which\n\t\t  AI actors can mediate governance issues and participate in economic\n\t\t  transactions, can lead to a more efficient and dynamic digital\n\t\t  ecosystem. This integration will enable new business models and\n\t\t  opportunities for all users, both human and AI.\n\t- #### Continuous Evolution and Adaptation\n\t\t- As the digital landscape continues to evolve, the open-source Metaverse\n\t\t  system must be flexible and adaptable to meet changing needs and\n\t\t  expectations. Continuous innovation and collaboration within the\n\t\t  industry will be crucial for the success and longevity of the Metaverse\n\t\t  as a transformative digital society platform.\n- ### Conclusion and Final Thoughts\n\t- #### Embracing the Open-Source Metaverse Vision\n\t\t- To create a truly transformative and inclusive digital society, it is\n\t\t  essential to embrace the vision of an open-source Metaverse. By\n\t\t  fostering collaboration, promoting open standards, and integrating\n\t\t  advanced AI and ML technologies, the Metaverse can become a platform\n\t\t  that serves societal and business needs.\n\t- #### Learning from Past Failures\n\t\t- Learning from past failures and addressing challenges head-on will be\n\t\t  critical to the successful development of an open-source Metaverse.\n\t\t  Trust, accessibility, governance, and safeguarding issues must be\n\t\t  thoughtfully considered and addressed to build a secure and\n\t\t  user-friendly platform.\n\t- #### Unlocking New Opportunities and Use Cases\n\t\t- The integration of AI, ML, and cutting-edge technologies within the\n\t\t  Metaverse can unlock new opportunities and use cases across various\n\t\t  industries, including education, research, biomedical, and creative\n\t\t  fields. By building on a modular open-source system, these opportunities\n\t\t  can be explored and realized to their full potential.\n\t- #### Fostering Collaboration and Inclusivity\n\t\t- Creating an inclusive digital society is a key goal for the open-source\n\t\t  Metaverse. By breaking down barriers and making the platform accessible\n\t\t  to a wider audience, new ideas and perspectives will enrich the digital\n\t\t  landscape and drive innovation.\n\t- #### Shaping the Future of Digital Society\n\t\t- As the Metaverse continues to evolve and grow, it will play an\n\t\t  increasingly important role in shaping the future of digital society. By\n\t\t  embracing an open-source vision, overcoming challenges, and unlocking\n\t\t  new opportunities, the Metaverse can become a powerful platform that\n\t\t  transforms how people live, work, and interact in the digital world.\n\t- #### Industry Conversations\n\t\t- Continued dialogue and collaboration among industry stakeholders are\n\t\t  vital to ensuring the successful development of the open-source\n\t\t  Metaverse. By engaging in conversations and understanding the cautious\n\t\t  appetite for the ideas presented, the community can work together to\n\t\t  shape the future of digital society and overcome the challenges that lie\n\t\t  ahead.\n- ### Software stack\n\t- This section needs building out to describe the stack and the choices made, but can be seen in Figure <a href=\"#fig:pyramind\" data-reference-type=\"ref\" data-reference=\"fig:pyramind\">[fig:pyramind]</a> and Figure <a href=\"#fig:highlevelstack\" data-reference-type=\"ref\" data-reference=\"fig:highlevelstack\">[fig:highlevelstack]</a>.\n\t  \n\t  ![image](../assets/eca327e7bb2caa27aa4753ec0b4f1be3737ac371.jpg)\n\t  \n\t  <span class=\"image\">image</span>\n\t  \n\t  At this time we favour the following component units, with alternatives in brackets.\n\t\t- Collaborative space\n\t\t- Vircadia \\[Omniverse, Open3D foundation, Unreal\\]\n\t\t- Distributed truth\n\t\t- Bitcoin testnet \\[Main net\\]\n\t\t- Digital Objects\n\t\t- Fedimint \\[Ordinals, Pear credits, RGB\\]\n\t\t- Messaging and sync\n\t\t- Nostr\n\t\t- Identity\n\t\t- Nostr \\[Bluesky ION, Slashtags\\]\n\t\t- Fiat money xfer\n\t\t- Fedimint \\[Pear credits, RGB, Taro main net\\]\n\t\t- Hardware signing\n\t\t- Seed signer \\[any hardware wallet\\]\n\t\t- Small group banking\n\t\t- Fediment \\[chaumian ecash\\]\n\t\t- Local wallet\n\t\t- [Mutiny](https://app.mutinywallet.com/) \\[bitkit, and lightning wallet\\]\n\t\t- Machine learning text\n\t\t- Alpaca \\[ChatGPT etc\\]\n\t\t- Machine learning image\n\t\t- Stable diffusion \\[midjourney, Dall-E\\]\n\t\t- Object tracking\n\t\t- Nostr \\[LnBits accounts\\]\n- ### In camera VFX & telepresence\n\t- Designing open federated metaverse from a 25 year research foundation There are serious and under discussed natural social constraints on group behaviours, and these translate into social VR. For instance the ideal meeting size is 6, and this is naturally established in work settings. This has not translated into a metaverse setting where dozens of people routinely crash across one another. In the context of supporting a creative “backstage” world where set planning, production shots, etc can be discussed we believe we have solutions which will get the best out of distributed teams of film-makers. Leveraging the world’s most powerful decentralised computing network to create scale and security without high cost The Bitcoin network is more than just a speculative money like asset, it is the most secure distributed computing system ever built. We can jump on the back of this at almost no cost to enable scale for transfer of value, trust, and digital assets of provenance. Cryptographically assured end points With the cryptography tools provided through integration of the Bitcoin network we can also use non-blockchain based secure messaging, and identity proofs. Micro transactions in collaborative spaces New tooling the space allows fractions of a pound or dollar to be exchanged between parties across the world. This means that work can be paid “by the second” both inside and outside of the metaverse. This radically improves creative microtask workflows. World leading open source machine learning and bot architectures By integrating Stablity AI tools for image generation, video processing, natural language, and speech to text / text to speech we hope to reduce friction within the backstage worlds. Creating a narrative arrow from a remote director/producer/DP, through a VP screen into a shoot, and back into a persistent metaverse shared with the public By linking across these new systems with world class telepresence research we hope to use a single digital context to support senior stakeholders, creatives, technical teams, and the wider public. New paths to monetisation and digital ownership This unified digital back end is optimised for flows of money, trust, and digital objects. This is a new area for VP. Current workstreams:\n\t\t- Storyboarding with text2img and dreambooth to add talent and costume ideas before meeting up, as demonstrated in this document.[@ruiz2022dreambooth]\n\t\t- Collaborative, self hosted, high speed, low detail, economically and cryptographically enabled set design spaces, with near instant language translation (speech to text an speech to speech). Micropayment for cheap international labour. Technology agnostic. Use the screen, audio only, compressed video dial-in, headsets, tablet rendering: (this book).\n\t\t- High end telepresence[@Roberts2015; @OHare2018; @Fairchild2017; @OHare2016] into the studio/shoot from the virtual set, allowing high value stakeholders to be ‘present‘ on set as virtual collaborants with spatial descrimination allowing directional queues. This involved real time human capture like moveAI or the expensive rigs with DSLRs.\n\t\t- Novel render pipeline for fast turnaround of final look and feel, taking the rough scene and applying img2img ML with the kind of interframe consistency we are starting to see from the video projects.[@anonymous2023phenaki]\n\t\t- Text to model pipeline for interactively building key elements with senior stakeholders, pushed from post ideation the the pre-shoot Unreal content creation.[@poole2022dreamfusion]\n\t\t- All assets switch over to Unreal metaverse and become consistent (optimised) digital set which can be visited by stakeholders, funders, VIPs etc. Public can visit later for a fee? Digital assets can be bought from the set.\n- ##### VisionFlow: Ideate\n\t- Robotic Pre-Visualization\n\t- [[Visionflow]] : Ideate revolutionizes the pre-visualization process in the film industry. The system integrates open-source machine learning tools, robot control software, and AI to streamline and accelerate the creation of virtual 3D environments for new film scenes.\n\t- Instead of the conventional approach, VisionFlow: Ideate enables non-artists to lay out shots in a simple web or headset interface, much like a traditional storyboard. The generative AI then rapidly creates high-resolution backdrop plates with correct parallax cues, replacing conventional image and video plates.\n\t- The camera path synchronizes with a robot, and the backdrop plates are displayed on a 3D wall or in the studio mixdown from a green screen within minutes. The shot can be run repeatedly, allowing for adjustments in lighting and scene swapping for different ideas. This approach aligns well with pre-viz workflows, fostering rapid ideation, horizontal scaling through parallelized cloud vGPU, and expanded access to content creators since less software specialization is required.\n\t- By inverting the conventional ICVFX workflow, VisionFlow: Ideate drives camera motion from the scene rather than scene motion from a tracked camera. It not only saves time and reduces costs but also lowers confusion, streamlining the Unreal creation pipeline, and generating additional revenue and process integration for robotics products.\n- ##### VisionFlow: Connect\n\t- Telepresence System\n- VisionFlow: Connect is a breakthrough system in the film industry that\n  brings remote directors to the heart of production using augmented\n  reality technology. This is achieved through an innovative application\n  of the Apple Vision Pro AR headset.\n- In the VisionFlow: Connect system, the director, located remotely, wears\n  an AR headset and navigates along a marked line. This line mirrors the\n  inward-facing edge of a large-scale, wrap-around LED virtual production\n  facility. Within the LED volume, participants can view the director’s\n  avatar, providing a sense of spatial consistency and our work\n  interaction, crucial for effective direction.\n- A novel technique, \"ghost frame\" by Helios, is employed to prevent the\n  camera within the LED volume from capturing the director’s remote avatar\n  on the LED wall. This ensures the director’s virtual presence doesn’t\n  interfere with the recorded footage.\n- The benefits of VisionFlow: Connect are multifold. It allows senior\n  stakeholders to manage their time more efficiently as they can direct\n  remotely without needing to be physically present on multiple sets.\n  Directors can interact in real-time, giving instantaneous feedback and\n  adjustments. It also enhances directors’ spatial awareness of the scene,\n  thereby improving the decision-making process.\n- bfSlide 1: Title bfSlide 2: Problem  \n  \"VisionFlow: Revolutionizing Virtual Production with AI and\n  Telecollaboration\" \"The current ICVFX workflow is time-consuming,\n  costly, and requires specialized software knowledge. Remote\n  collaboration in virtual production is challenging, often breaking the\n  flow of communication and limiting the ability to convey spatial\n  intent.\"  \n  bfSlide 3: Solution bfSlide 4: Market Size  \n  \"VisionFlow aims to streamline the virtual production process by\n  integrating open-source machine learning tools and robot control\n  software. This innovative approach inverts the existing ICVFX workflow,\n  allowing rapid ideation, horizontal scaling, and expanded access to\n  content creators. Furthermore, our ghost frame technology enables\n  seamless remote collaboration, allowing remote stakeholders to interact\n  with the set in a spatially coherent way.\" \"The virtual production\n  market is rapidly growing, driven by the increasing demand for\n  high-quality visual effects and the rise of remote work. Our solution\n  targets film studios, independent content creators, and remote\n  collaborators.\"  \n  bfSlide 5: Business Model bfSlide 6: Go-to-Market Strategy  \n  \"We will generate revenue through software licensing, cloud-based\n  services, and professional services for setup and training, and our own\n  in house motion control robotics offering\" \"Our initial focus will be on\n  early adopters in the film industry who are already using virtual\n  production techniques. We will also leverage the open-source Flossverse\n  telecollaboration stack to expand our reach.\"  \n  bfSlide 7: Competitive Landscape bfSlide 8: Team  \n  \"While there are other virtual production solutions on the market, none\n  offer the unique combination of AI-driven scene generation, inverted\n  ICVFX workflow, and seamless remote collaboration that VisionFlow does.\"\n  \"Our team combines expertise in AI, virtual production, and\n  telecollaboration, positioning us uniquely to execute on this vision.\"  \n  bfSlide 9: Financial Projections bfSlide 10: Current Status and\n  Milestones  \n  \"We project rapid growth as we capture a significant share of the\n  expanding virtual production market.\" \"We have already developed an MVP\n  using the Flossverse stack and are now focused on refining the\n  integration and licensing elements of our software.\"  \n  bfSlide 11: Ask bfSlide 12: Closing Remarks  \n  \"We are seeking investment to accelerate our development, expand our\n  team, and bring our innovative solution to market.\" \"In essence,\n  VisionFlow is poised to revolutionize the virtual production industry by\n  leveraging AI to streamline workflows and enable seamless remote\n  collaboration. With your investment, we can bring this vision to\n  life.\"\n-\n- #### visionflow: [[Knowhere]]\n\t- The ultimate goal is to create a seamless, highly personalized visitor experience that evolves and continues before, during, and after a visit to a digital exhibition. This level of personalization is only made possible through the integration of advanced AI technology, biometrics, and a deep inferred understanding of individual preferences and behaviours.\n\t\t- ##### Key Ideas\n\t\t- 1.  **Leveraging AI and Contextual Data:** The venue will use AI and contextual data to create dynamic narratives and activities tailored to each visitor in real-time. This will revolutionize the resort experience, making it highly personalized and immersive. However, the implementation of AI must be mindful of privacy concerns and be done in a way that respects the data sovereignty of the guests.\n\t\t- 2.  **Tailored Personalization:** Visitors should have the ability to opt into different levels of personalization. Some may want a fully immersive, personalized experience, while others may prefer a more ‘hands off’ experience. This is an important aspect of respecting individual preferences and ensuring that all visitors feel comfortable and catered for.\n\t\t- 3.  **Communication Devices:** Various communication devices could be utilized within the resort to facilitate interactions between visitors and the AI system. These could include badges, wands, glasses, headphones, etc. Each of these devices would contribute to the immersion and thematic consistency of the resort while serving a practical purpose.\n\t\t- 4.  **Biometrics:** The use of biometrics such as gaze tracking and gesture recognition could allow the AI to understand visitor preferences passively. This technology could be incorporated in a non-intrusive way to augment the guest experience without breaching privacy.\n\t\t- 5.  **Data Extraction:** Visitors should have the ability to extract their distilled data or creations, enabling them to continue their vistor experience at home. This could also open up new possibilities for visitors to create and share their own narratives based on their visit experiences. To be clear this should not be the raw data supplied to the venue inferencing engines (which should be destroyed soon after use), but rather a distilled narrative of the inference from the system.\n\t\t- 6.  **Data Privacy:** Data sharing should be underpinned by robust privacy controls to ensure guest data sovereignty. It’s crucial to maintain the trust of the visitors by demonstrating a strong commitment to privacy. This should be externally audited on a regular cadence.\n\t\t- 7.  **Continuous Experience:** The visitor experience should feel continuous before, during, and after the visit. However, it’s important to manage guest expectations and avoid over promising pre-visit AI interactions. Ensuring a smooth transition between these stages will enhance the overall guest experience.\n\t\t- 8.  **Hyper-Personalization:** Hyper-personalization should span the venue. This level of detail will ensure each guest has a unique and highly personalized experience.\n\t\t- 9.  **Adaptive and Immersive Experiences:** The core aim should be to craft continuously adaptive and immersive experiences based on visitor needs and implied preferences. By doing so, the venue can ensure each visitor has a unique, enjoyable, and highly memorable experience, supportive of return visits.\n\t\t- The integration of these concepts will require careful planning and\n\t\t  execution, but the result could be a venue experience like no other, one\n\t\t  that caters to each individual guests and provides an experience that\n\t\t  extends beyond the confines of the experience itself.\n- ##### Multiview barrier lenticular\n\t- ##### Background\n\t\t- Ubiquitous display technology, which allows different personalized views\n\t\t  for multiple people on the same screen, has the potential to disrupt the\n\t\t  way visitors interact and experience venues and exhibits. The displays\n\t\t  can use techniques like lenticular lenses, or other steerable light, to\n\t\t  send different light to viewers’ eyes, allowing for discrete, customized\n\t\t  views.\n\t- ##### Technical Overview\n\t\t- The following display technologies have been identified as suitable for\n\t\t  implementation:\n\t\t- Lenticular lens arrays: By placing an array of magnifying lenses over the screen, these displays direct light from alternating columns of pixels toward the left and right eyes to create a stereoscopic 3D image without glasses. There are several suppliers of this technology, mainly for the events market. It seems that churn of these companies is relatively high, with few demonstrating longevity.\n\t\t- Parallax barriers: These displays have a layer of opaque and transparent slits over the LCD matrix that directs different pixel columns to each eye, creating a stereoscopic 3D image without glasses. Alioscopy is known to use this approach, along with eye tracking technology. They have been in business for decades and are a good case study, but engaging with a research partner in China is likely the best medium terms approach.\n\t\t- These display consists of a large lenticular lens sheet or array of smaller tiled lenticular lenses mounted in front of a high-resolution LED. The lenticular lenses are cylindrical and arranged vertically, with each lens covering multiple pixel columns of the display.\n\t\t- Behind the lens array, the display content is formatted into vertical interleaved channels, with each channel containing a slightly different perspective view of the 3D stereoscopic image. The different perspective views are calculated in real-time based on the tracked head positions of multiple viewers in front of the display.\n\t\t- As light from the display pixels passes through the cylindrical lenses, it is refracted into multiple viewing zones in front of the screen. Each viewing zone contains a specific view channel, so each eye of each viewer sees the perspective that matches their position. This creates a glasses-free 3D effect with motion parallax as viewers move their heads.\n\t\t- The viewer head tracking system uses camera and computer vision techniques to determine the 3D positions of each viewer’s eyes in the space in front of the display. The changing viewer positions are fed to the display rendering system to compute the proper perspective views and adjust the lenticular flaps as needed.\n\t\t- This lenticular 3D display with dynamic view steering provides illusion of depth for multiple viewers simultaneously, creating an immersive large-screen 3D experience without the need for special glasses. The real-time tracking and rendering system updates the content smoothly as the viewers move around, maintaining the stereo 3D perspectives tailored individually to each viewer’s changing position.\n- ##### Tracking Technologies\n\t- For personalization, tracking viewers’ eyes, face, gestures, etc., is necessary. This can be done with cameras and computer vision algorithms, employing techniques like mesh abstraction for body tracking, facial landmark recognition, gaze estimation, micro expression recognition, and gross gesture detection.\n- ##### AI Integration\n\t- AI can be integrated to steer personalized narratives and experiences subtly in the background or provide interactive moments. The AI backend can use game engines like Unreal Engine or Unity to render personalized content dynamically, allowing for real-time adaptation to the viewer’s reactions.\n- ##### Privacy and Security\n\t- The tracking data provides extremely valuable insights for personalizing experiences but raises significant privacy concerns. Thoughtful design around privacy and security, including data segmentation, auditing, and transparency, is critical to protect user data and ensure compliance with privacy regulations.\n- ##### Technical Challenges\n\t- There are technical challenges in achieving dense personalized displays, especially for a large number of viewers. As of now, creating a personalized display for up to 5 people is feasible, but scaling up requires a substantial budget and careful planning. Fortunately both of these seem available and it seems timely to look at this option.\n- ##### Proof of Concept\n\t- Starting with a small-scale proof of concept for up to 5 people would allow for demonstration of the capabilities and building stakeholder confidence. This would also provide valuable insights into the technical and logistical challenges that may arise during larger-scale implementation.\n- ##### Future Developments\n\t- The display technology is rapidly evolving, with new advancements in resolution, refresh rates, brightness, and tracking accuracy. As the technology matures, there will be more opportunities to enhance the personalized experiences. This system would allow multiple viewers to see different images or perspectives from the same display, enhancing the interactive and educational value of the exhibit. Mollick et al. have done some lovely actionable work on the pedagogical implications of chatbots.[@mollick2022new; @mollick2023assigning; @mollick2023using] This could transform the way visitors engage with exhibits, providing a more immersive and personalized experience.\n- ##### Alioscopy\n\t- Alioscopy uses a different approach than lenticular lenses for their glasses-free 3D displays. Their screens contain a parallax barrier\n\t\t- a layer of opaque and transparent slits\n\t\t- over the LCD matrix. This directs different pixel columns to each eye, creating a stereoscopic 3D image without glasses.\n\t- Their displays also incorporate proprietary eye tracking technology. An infrared camera follows the viewer’s head position, automatically adjusting the angle of the projected 3D image for optimal viewing. This compensates for display viewing angle limitations.\n\t- Alioscopy’s recent prototypes feature very high resolution like 4K and 8K to improve 3D image quality. Their barriers and tracking algorithms are precisely tuned to the display characteristics and desired viewing parameters.\n- ##### Pitch section\n- Personalised emergent narratives for our visitors. What problem does the\n  user, business or industry have that you want to solve?\n  \n  [[Visionflow]] : [[Knowhere]]\n- For today’s digital experience venue managers navigating the\n  complexities of providing unique experiences, our AI solution, KnoWhere,\n  offers a unique approach which will result in the capability to enhance\n  visitor experiences. By utilising images from on-premise cameras, we\n  enable to leverage data on visitors attention. Our solution’s unique\n  value propositions include spatial and attention tracking through AI,\n  because of our ability to understand the needs of experience designers.\n- It works like this: Combine personal data, with visitor gaze Provide\n  location and attention data stream Venue provides this to experience\n  designers Designers build incredible emergent journeys\n- We believe this solution will impact our business/industry by: Elevating\n  interactions through personalisation Making attention in physical spaces\n  quantifiable Providing feedback data to experience designers\n- We will measure our impact by: Performing A/B testing on visitors\n  engagement This can be a KPI that changes, ex: a productivity score\n\t- or\n\t  it can be an amount saved because of the soluion\n- Describe what data is behind this AI model? Alphapose (2) Insightface\n  (5)\n  \n  Rate the quality/quantity of each point of data from 1-5 (1 being little\n  data / low quality – 5 being lots of data / high quality)\n  \n  What will be the biggest challenge in implementing the AI model? Real\n  time pose engine is noncommercial Occlusion can be tricky with space\n  constraints The rich dataset is a privacy concern\n  \n  Here are some areas to think about in terms of challenges:\n  \n  Data: How much data exists? How representative is it of what we’re\n  trying to model? Are there issues in how it is collected which could\n  impact the model? Is it likely to contain any missing values? Adoptance\n  from users/customers Will it be easy to get people to use the AI in\n  their business?\n  \n  Governance Is the data accessible and are you allowed to use it? Who is\n  responsible once the AI model is in use? How will make the final\n  decisions?\n  \n  Impact of solution What do we know about the need for this type of\n  solution\n\t- is it nice to have or need to have? Can we find out if we\n\t  don’t know? Feasibility What will be the biggest challenge in\n\t  implementing an AI solution to solve this problem? Can the issue /\n\t  problem we’re solving actually be measured / forecasted?\n\t  \n\t  Ethics\n\t  \n\t  Regulations\n\t  \n\t  Cybersecurity\n\t  \n\t  \"Our goal is to empower venue owners to provide an advanced platform\n\t  that allows world class exhibition creators to tailor unique experiences\n\t  for each visitor. This enables the crafting of rich, interconnected\n\t  stories for groups of people, all while ensuring unforgettable, safe\n\t  experiences for individuals and families.\n- ### Accessible metaverse for pre-viz\n- Pre-visualization (or \"pre-viz\") is a process in which a rough\n  simulation of a visual effect or scene is created prior to its actual\n  production. In the context of LED wall virtual production, pre-viz\n  refers to the creation of a 3D representation of a virtual environment,\n  including the placement of cameras, actors, and other elements, that is\n  then used to plan and test the visual effects and lighting for a\n  live-action scene that will eventually be shot in front of an LED wall.\n- The pre-viz process allows filmmakers and visual effects artists to\n  experiment with different camera angles, lighting, and visual effects\n  before committing to a final version. This helps to save time and\n  resources during actual production by reducing the need for multiple\n  takes or re-shoots. Additionally, it allows the filmmakers to see how\n  the final product will look before committing to it, which can help to\n  avoid costly mistakes or changes down the line.\n- The LED wall virtual production process typically involves using a\n  combination of 3D animation software, motion capture technology, and\n  real-time rendering to create a virtual environment that accurately\n  reflects the physical environment in which the scene will be shot. The\n  pre-viz process is then used to plan and test the various visual\n  effects, lighting, and camera angles that will be used in the final\n  production.\n- Our collaborative software stack is potentially ideally suited to some\n  of this pre-viz work, especially when combined with the power of machine\n  learning, and live linked into Unreal so that changes by stakeholders\n  enter the pre-production pipeline in a seamless way.\n- ### Novel VP render pipeline\n\t- Putting the ML image generation on the end of a real-time tracked camera render pipeline might remove the need for detail in set building. To describe how this might work, the set designer, DP, director, etc will be able to ideate in a headset based metaverse of the set design, dropping very basic chairs, windows, light sources whatever. There is -no need- then to create a scene in detail. If the interframe consistency (img2img) can deliver then the output on the VP screen can simply inherit the artistic style from the text prompts, and render production quality from the basic building blocks. Everyone in the set (or just DP/director) could then switch in headset to the final output and ideate (verbally) to create the look and feel (lens, bokeh, light, artistic style etc). This isn’t ready yet as the frames need to generate much faster (100x), but it’s very likely coming in months not years. This “next level pre-vis” is being trailed in the Vircadia collaborative environment described in this book, and can be seen illustrated in Figure <a href=\"#fig:vircadiasd\" data-reference-type=\"ref\" data-reference=\"fig:vircadiasd\">10.1</a>.\n\t  \n\t  <span class=\"image\">Top panel is a screen grab from Vircadia and the bottom panel is a quick pass through img2img from Stable Diffusion.</span>\n\t- This can be done now through the use of camera robots. A scene can be built in basic outline, the camera tracks can be encoded into the robot, and the scene can be rapidly post rendered by Stability with high inter frame consistency.\n\t- With the help of AI projects such as [LION](https://nv-tlabs.github.io/LION/) it may be possible to pass simple geometry and instructions to ML systems which can create complex textured geometry back into the scene.\n\t- <span class=\"image\">Robot VP</span>\n- ### Money in metaverses\n\t- ##### Global collaboration and remuneration\n\t\t- In the book “Ghosts of my life”[@fisher2014ghosts] Fisher asserts that\n\t\t  there has been a slowing, even a ‘cancellation’ of creative progress in\n\t\t  developed societies, their art, and their media. His contention is that\n\t\t  neoliberalism itself is to blame. He says  \n\t\t  it“It is the contention of this book that 21st-century culture is marked\n\t\t  by the same anachronism and inertia which afflicted Sapphire and Steel\n\t\t  in their final adventure. But this status has been buried, interred\n\t\t  behind a superficial frenzy of ‘newness’, of perpetual movement. The\n\t\t  ‘jumbling up of time’, the montaging of earlier eras, has ceased to be\n\t\t  worthy of comment; it is now so prevalent that it is no longer even\n\t\t  noticed.”\n\t\t- It is the feeling of the authors of this book that the creative and\n\t\t  inspirational efforts of the whole world may be needed to heal these\n\t\t  deep wounds. It is possible that by connecting creatives with very\n\t\t  different global perspectives, directly into ‘Western’ production\n\t\t  pipelines, that we will be able to see the shape of this potential.\n- #### ML actors and blockchain based bots\n\t- Stablity AI is an open source imitative to bring ML/AL capabilities to the world. This is a hugely exciting emergent area and much more will be developed here.\n- #### AI economic actors in mixed reality\n\t- AI actors can now be trusted visually.[@nightingale2022ai] We have some thinking on this which links the external web to our proposed metaverse. There is work in the community working on economically empowered bots which leverage Nostr and RGB to perform functions within our metaverse, and outside in the WWW, as well as interacting economically through trusted cryptography with other bots, anywhere, and human participants, anywhere. This is incredibly powerful and is assured by the Bitcoin security model. Imagine being able to interact with a bot flower seller representing all the real world florists it had found. In the metaverse you could handle the flowers and take advice and guidance from the bot agent, then it would be able to take your money to buy you flowers to send to a real world address, and later find you to tell you when it’s delivered. These possibilities are endless. The AI chat element, the AI translation of images on websites to 3D assets in the Metaverse are difficult but possible challenges, but the secure movement of money from the local context in the metaverse to the real world is within reach using these bots, and they are completely autonomous and distributed.\n- ### Our socialisation best practice\n\t- ##### Identity\n\t\t- We will base our identity and object management on Nostr public/private\n\t\t  key pairs. The public key of these enable lightning based exchange of\n\t\t  value globally. we plan to operate Nostr in multiple modes. Linking\n\t\t  flossverse “rooms” will be a Nostr bot to bot system within the private\n\t\t  relay mesh. This can also synchronise large amounts of data by\n\t\t  leveraging torrents [negotiated by Nostr](https://iris.to/#/settings).\n\t\t  Human to human text chat across and within instances is two ’types’ kind\n\t\t  of private nostr tag within the private relays mesh. External\n\t\t  connectivity to web and nostr apps is just the public relay tags\n\t\t  outbound. We don’t need to store data external to the flossverse system,\n\t\t  though access is obviously possible through the same torrent network.\n\t- ##### Webs of trust\n\t\t- Webs of trust will be built within worlds using economically costly (but\n\t\t  private) social rating systems, between any actor, human or AI. It\n\t\t  should be too costly to attack an individual aggressively. This implies\n\t\t  an increased weighting for scores issued in short time periods. Poorly\n\t\t  behaving AI’s will eventually be excluded through lack of funds.\n\t- ##### Integration of ’good’ actor AI entities\n\t\t- Gratitude practice should be encouraged between AI actors to foster\n\t\t  trust and wellbeing in human observers. “It’s nice to be nice” should be\n\t\t  incentivised between all parties”. This could include tipping and trust\n\t\t  nudging through the social rating system. Great AI behaviour would\n\t\t  result in economically powerful entities.\n\t- #### Emulation of important social cues\n\t\t- [Classroom layout](https://www.cleverclassroomsdesign.co.uk/general-5)\n\t- ##### Behaviour incentives, arbitration, and penalties\n\t\t- Collapses of trust and abuse will trigger flags from ML based oversight,\n\t\t  which will create situational records and payloads of involved parties\n\t\t  to unlock with their nostr private keys. ML red flagged actors will be\n\t\t  finacially penalised but have access to human arbitration using their\n\t\t  copy of the data blob. Nothing will be stored except by the end users.\n\t- #### Federations of webs of trust and economics\n\t\t- Nostr is developing fast enough to provide global bridges between\n\t\t  metaverse instances.\n- ### Security evaluation\n\t- As part of developing our stack we will penetration test the deployment as detailed using [Hexway](https://hexway.io/)\n- ### notes for later\n\t- Notes on build-out The world database in the shared rooms in the metaverse is the global object master, educational materials, videos, audio content and branded objects are fungible tokens authentically proved by rgb client side validation between parties, only validated ones will be persisted in shared rooms like conferences and classes according to the room schema. That allows educators to monetise their content. That can work on lightning. NFT objects between parties like content crafted by participants (coursework, homework) are not on lightning and will attract main chain fees but are rarer. User authentication and communication will be through nostr.\n\t  \n\t  <span class=\"image\">image</span>\n\t  \n\t  ![image](../assets/707beb139883d3b15e01fd447eb2ceb747861560.png)\n-\n- # NVIDIA Omniverse design\n\t- **Phase 1: Foundational Infrastructure**\n\t- **Bitcoin Base Layer (NixOS):**\n\t\t- Set up a secure and reliable Bitcoin full node on NixOS.\n\t\t- Implement robust backup and recovery procedures.\n\t\t- Consider running a Lightning Network node for faster and cheaper transactions.\n\t- **Identity and Value Management:**\n\t\t- Integrate Nostr protocol for decentralized identity and messaging.\n\t\t- Develop or utilize existing libraries for Nostr event creation, signing, and relaying.\n\t\t- Implement BIP85 hierarchical deterministic wallets for secure key management.\n\t- **Digital Assets (RGB):**\n\t\t- Choose or design appropriate RGB schemas for the types of digital assets you want to support.\n\t\t- Develop or utilize tools for issuing and managing RGB assets.\n\t\t- Integrate RGB wallets with the overall wallet management system.\n\t\t  \n\t\t  **Phase 2: Interaction Module (Omniverse):**\n\t- **Omniverse Environment Setup:**\n\t\t- Deploy an Omniverse Nucleus server to manage collaborative scenes and 3D assets.\n\t\t- Design and create the initial 3D environment(s) using USD (Universal Scene Description).\n\t\t- Consider incorporating elements from your existing visualizations and research.\n\t- **Agent Integration:**\n\t\t- Develop avatar systems for both human and AI agents within Omniverse.\n\t\t- Implement controls and interactions for agents within the 3D environment.\n\t\t- Explore the use of Omniverse Kit SDK for advanced features and customizations.\n\t- **Digital Asset Integration:**\n\t\t- Develop methods to represent and interact with RGB digital assets within Omniverse scenes.\n\t\t- Implement ownership and transfer functionalities based on the underlying Bitcoin/RGB infrastructure.\n\t\t- Explore visual representations of ownership and asset metadata within the 3D environment.\n\t\t  \n\t\t  **Phase 3: AI and Governance:**\n\t- **AI Agent Development:**\n\t\t- Choose or design AI models for different agent archetypes (e.g., governance agents, task agents, social agents).\n\t\t- Implement the D&D-inspired personality system and the wealth decay function.\n\t\t- Develop AI behaviors and decision-making processes aligned with the scene schema.\n\t- **Scene Schema and Governance:**\n\t\t- Define the rules and constraints for different scene types within a flexible schema framework.\n\t\t- Implement the SupraAgent (governance LLM) with its monitoring and evidence collection capabilities.\n\t\t- Develop mechanisms for encrypted evidence payloads and communication with relevant parties.\n\t- **GenAI Integration:**\n\t\t- Explore the use of generative AI models (e.g., ChatGPT, Stable Diffusion) for content creation, world-building, and immersive storytelling.\n\t\t- Develop interfaces for users and AI agents to interact with GenAI tools within the metaverse.\n\t\t  \n\t\t  **Phase 4: User Interface and Experience:**\n\t- **Nostr-based Chat Interface:**\n\t\t- Develop a chat interface using Nostr as the communication protocol.\n\t\t- Integrate the chat interface within the Omniverse environment.\n\t\t- Enable secure and private communication between agents.\n\t- **Wallet Integration:**\n\t\t- Provide users with access to their digital wallets within the metaverse.\n\t\t- Enable users to manage their assets, view transaction history, and interact with the virtual economy.\n\t- **Accessibility and Multimodality:**\n\t\t- Explore ways to make the metaverse experience accessible to users with disabilities.\n\t\t- Support multiple interaction modalities (e.g., VR, AR, desktop, mobile).\n\t\t  \n\t\t  **Additional Considerations:**\n\t- **Security:** Implement robust security measures at all levels, including encryption, access control, and regular security audits.\n\t- **Privacy:** Ensure user privacy by minimizing data collection and providing transparent privacy settings.\n\t- **Scalability:** Design the system to be scalable to accommodate a growing number of users and increasing complexity.\n\t- **Community Building:** Foster a strong community around your metaverse project through open communication, collaboration, and user engagement initiatives.\n- # According to Gemini\n\t- **Phase 1: Foundational Infrastructure**\n\t\t- **Bitcoin Base Layer (NixOS):**\n\t\t- **Set up a secure and reliable Bitcoin full node on NixOS.**\n\t\t- **Implement robust backup and recovery procedures.**\n\t\t- **Consider running a Lightning Network node for faster and cheaper transactions.**\n\t\t- **Identity and Value Management:**\n\t\t- **Integrate Nostr protocol for decentralized identity and messaging.**\n\t\t- **Develop or utilize existing libraries for Nostr event creation, signing, and relaying.**\n\t\t- **Implement BIP85 hierarchical deterministic wallets for secure key management.**\n\t\t- **Digital Assets (RGB):**\n\t\t- **Choose or design appropriate RGB schemas for the types of digital assets you want to support.**\n\t\t- **Develop or utilize tools for issuing and managing RGB assets.**\n\t\t- **Integrate RGB wallets with the overall wallet management system.**\n\t\t   \n\t\t   **Phase 2: Interaction Module (Omniverse):**\n\t\t- **Omniverse Environment Setup:**\n\t\t- **Deploy an Omniverse Nucleus server to manage collaborative scenes and 3D assets.**\n\t\t- **Design and create the initial 3D environment(s) using USD (Universal Scene Description).**\n\t\t- **Consider incorporating elements from your existing visualizations and research.**\n\t\t- **Agent Integration:**\n\t\t- **Develop avatar systems for both human and AI agents within Omniverse.**\n\t\t- **Implement controls and interactions for agents within the 3D environment.**\n\t\t- **Explore the use of Omniverse Kit SDK for advanced features and customizations.**\n\t\t- **Digital Asset Integration:**\n\t\t- **Develop methods to represent and interact with RGB digital assets within Omniverse scenes.**\n\t\t- **Implement ownership and transfer functionalities based on the underlying Bitcoin/RGB infrastructure.**\n\t\t- **Explore visual representations of ownership and asset metadata within the 3D environment.**\n\t\t   \n\t\t   **Phase 3: AI and Governance:**\n\t\t- **AI Agent Development:**\n\t\t- **Choose or design AI models for different agent archetypes (e.g., governance agents, task agents, social agents).**\n\t\t- **Implement the D&D-inspired personality system and the wealth decay function.**\n\t\t- **Develop AI behaviors and decision-making processes aligned with the scene schema.**\n\t\t- **Scene Schema and Governance:**\n\t\t- **Define the rules and constraints for different scene types within a flexible schema framework.**\n\t\t- **Implement the SupraAgent (governance LLM) with its monitoring and evidence collection capabilities.**\n\t\t- **Develop mechanisms for encrypted evidence payloads and communication with relevant parties.**\n\t\t- **GenAI Integration:**\n\t\t- **Explore the use of generative AI models (e.g., ChatGPT, Stable Diffusion) for content creation, world-building, and immersive storytelling.**\n\t\t- **Develop interfaces for users and AI agents to interact with GenAI tools within the metaverse.**\n\t\t   \n\t\t   **Phase 4: User Interface and Experience:**\n\t\t- **Nostr-based Chat Interface:**\n\t\t- **Develop a chat interface using Nostr as the communication protocol.**\n\t\t- **Integrate the chat interface within the Omniverse environment.**\n\t\t- **Enable secure and private communication between agents.**\n\t\t- **Wallet Integration:**\n\t\t- **Provide users with access to their digital wallets within the metaverse.**\n\t\t- **Enable users to manage their assets, view transaction history, and interact with the virtual economy.**\n\t\t- **Accessibility and Multimodality:**\n\t\t- **Explore ways to make the metaverse experience accessible to users with disabilities.**\n\t\t- **Support multiple interaction modalities (e.g., VR, AR, desktop, mobile).**\n\t\t   \n\t\t   **Additional Considerations:**\n\t\t- **Security:** Implement robust security measures at all levels, including encryption, access control, and regular security audits.\n\t\t- **Privacy:** Ensure user privacy by minimizing data collection and providing transparent privacy settings.\n\t\t- **Scalability:** Design the system to be scalable to accommodate a growing number of users and increasing complexity.\n\t\t- **Community Building:** Foster a strong community around your metaverse project through open communication, collaboration, and user engagement initiatives.\n\t\t  \n\t\t  **This development plan provides a roadmap for implementing your metaverse vision, step by step. By focusing on the core principles of your research and leveraging innovative technologies like Bitcoin, RGB, Nostr, and Omniverse, you are building a foundation for a truly unique and transformative metaverse experience.**",
        "link_types": [
            "Visionflow",
            "Knowhere",
            "Visionflow",
            "Knowhere"
        ],
        "file_size": 80950
    },
    {
        "id": "Coding support.md",
        "name": "Coding support",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- {{video https://www.youtube.com/watch?v=yj73GIEKmLI}}\n- # Believably wrong answers\n\t- **[Study Details](https://dl.acm.org/doi/pdf/10.1145/3613904.3642596)**  by Purdue University. Presented at the Computer-Human Interaction Conference in Hawaii. (CHI)\n\t- **517 programming questions** from Stack Overflow.\n\t\t- **52%** contained incorrect information.\n\t\t- **77%** were verbose.\n\t\t- **78%** showed inconsistency compared to human answers.\n\t- **User Perception**\n\t\t- Participants preferred ChatGPT answers **35%** of the time despite inaccuracies.\n\t\t- Misleading AI responses were not detected by programmers **39%** of the time.\n\t\t- ChatGPT's answers were more formal, analytical, and positive in tone.\n\t\t- Politeness and comprehensiveness made ChatGPT answers appear more convincing.\n- # Specialised Models\n\t- ![image.png](../assets/image_1717159684964_0.png)\n- # Products\n\t- ## Devin\n\t\t- {{video https://www.youtube.com/watch?v=fjHtjT7GO1c&}}\n\t\t- [Blog (cognition-labs.com)](https://www.cognition-labs.com/blog)\n\t- ## Cody\n\t\t- The AI Coding Assistant\n\t\t\t- **Introduction to Cody**\n\t\t\t\t- Developed by Sourcegraph, co-founded by Beang Liu, CTO.\n\t\t\t\t- Aims to revolutionize software development with AI.\n\t\t\t\t- Integrates into various editors, enhancing developer productivity.\n\t\t\t- **Foundation and Purpose**\n\t\t\t\t- Rooted in Beang's early interest in AI and machine learning at Stanford AI lab.\n\t\t\t\t- Addresses the gap between the potential of programming and the drudgery of day-to-day software engineering tasks.\n\t\t\t\t- Focuses on reducing time spent on reading and understanding existing code.\n\t\t\t- **Defining Spatial Computing**\n\t\t\t\t- Initially focused on advanced search capabilities in real coding environments.\n\t\t\t\t- Aimed at achieving 'flow' in programming through efficient information retrieval.\n\t\t\t- **Integration of AI in Sourcegraph and Cody**\n\t\t\t\t- Shift towards AI-enhanced coding tools around 2017-2018.\n\t\t\t\t- Early experiments with applying large language models (LLMs) to code search.\n\t\t\t\t- Development driven by advancements in AI, especially in neural networks and LLMs.\n\t\t\t- **Capabilities of Cody**\n\t\t\t\t- Provides AI-driven coding assistance in various IDEs.\n\t\t\t\t- Features include inline completions, high-level Q&A, and specific coding commands.\n\t\t\t\t- Unique in augmenting large language models with contextual information from Sourcegraph.\n\t\t\t- **Future Aspirations for Cody**\n\t\t\t\t- Aims to automate more complex software development tasks.\n\t\t\t\t- Foresees the potential for AI to generate pull requests and change sets from issue descriptions.\n\t\t\t\t- Emphasizes the importance of context quality in improving code generation.\n\t\t\t- **Technical Challenges and Innovations**\n\t\t\t\t- Balances traditional information retrieval with AI-driven approaches.\n\t\t\t\t- Focuses on optimizing search architecture and context retrieval for better code generation.\n\t\t\t\t- Explores the use of small models for faster and more cost-effective solutions.\n\t\t\t- **The Evolution of Software Development with AI**\n\t\t\t\t- Envisions a future where individual developers are more productive and cohesive.\n\t\t\t\t- Anticipates changes in the software development lifecycle due to AI integration.\n\t\t\t\t- Stresses the growing importance of CS fundamentals and domain expertise in an AI-augmented future.\n-\n- Setup Continue for VSCode\n\t- [How to use a local LLM as a free coding copilot in VS Code | by Simon Fraser | Dec, 2023 | Medium](https://medium.com/@smfraser/how-to-use-a-local-llm-as-a-free-coding-copilot-in-vs-code-6dffc053369d)\n\t- [LoneStriker/code-millenials-34b-6.0bpw-h6-exl2 · Hugging Face](https://huggingface.co/LoneStriker/code-millenials-34b-6.0bpw-h6-exl2)\n- # Random Links\n- https://twitter.com/tldraw/status/1782443204710674571\n- {{twitter https://twitter.com/tldraw/status/1782443204710674571}}\n-\n-\n- [Paper page Design2Code: How Far Are We From Automating Front-End Engineering? (huggingface.co)](https://huggingface.co/papers/2403.03163)\n- [Generative AI Powered Assistant - Amazon Q - AWS](https://aws.amazon.com/q/)  Amazons!\n- [antworks.ai](https://antworks.ai/)\n- [OpenBMB/ChatDev: Create Customized Software using Natural Language Idea (through LLM-powered Multi-Agent Collaboration) (github.com)](https://github.com/OpenBMB/ChatDev)\n- [Programming AIs worry me • Buttondown:](https://buttondown.email/hillelwayne/archive/programming-ais-worry-me/)\n- [Home | Tabby (tabbyml.com)](https://tabby.tabbyml.com/)\n- The text discusses the concerns around using AI to generate code, specifically around the idea of proofreading the code. The author describes an experience with using voice-to-text where they found it difficult to proofread the text for errors. The text argues that using AI to generate code changes the work from writing code to proofreading code, and that this is a problem.\n- [Stop whining blog post](https://about.sourcegraph.com/blog/cheating-is-all-you-need)\n- [blog post on LLMs for code](https://evanthebouncy.github.io/program-synthesis-minimal/generation-with-llm/)\n- [Engshell shell LLM extension](https://github.com/emcf/engshell/tree/main)\n- [Github assist](https://useadrenaline.com/app)\n- [Locally run 13B coding optimised model](https://huggingface.co/ehartford/alpaca1337-13b-4bit/tree/main)\n- [Programming AIs worry me • Buttondown (other)](https://buttondown.email/hillelwayne/archive/programming-ais-worry-me/) The article discusses the ethical implications of using machine learning algorithms to generate art. While some see this as a powerful way to create new and interesting works of art, others worry about the potential for misuse and abuse of these technologies.\n- [GPT synthesizer](https://github.com/RoboCoachTechnologies/GPT-Synthesizer)\n- [Colab to get codey](https://www.techspot.com/news/98792-google-colab-soon-get-ai-code-generation-chatbot.html)\n- [Build prompts using coding keywords, paper](https://arxiv.org/abs/2305.06599v3)\n- [Continue for VSCode](https://github.com/continuedev/continue)\n- [Phind technical answers and pair programmer with vscode plugin](https://www.phind.com/)\n- [Starchat beta 4bit](https://huggingface.co/TheBloke/starchat-beta-GPTQ)\n- [Sweep github pull requests to code system](https://github.com/sweepai/sweep)\n- [Cursor.so coding with gpt interface](https://cursor.so)\n- [Code llama 2](https://ai.meta.com/blog/code-llama-large-language-model-coding/)\n- [Long llama](https://github.com/CStanKonrad/long_llama/blob/main/instruction_fine_tuning/LongLLamaCode7BInstruct.md)\n- [Open interpreter](https://openinterpreter.com/)\n- [Open interpreter and autogen local tutorial](https://www.youtube.com/watch?v=DXrpqsjNKbo)\n- [open interpreter github](https://github.com/KillianLucas/open-interpreter)\n- [codingbuddy](https://codebuddy.ca/)\n- [deepseek 34b q4 AWQ](https://huggingface.co/TheBloke/deepseek-coder-33B-instruct-AWQ)\n-\n- [[Vercel]] provides front-end [[Infrastructure]] to allow developers to build fast, dynamic websites and applications efficiently at global scale. Its open source Next.js framework powers many leading AI products' user interfaces.\n\t- Vercel's new vZero product allows developers to visually iterate on UIs with AI assistance.\n\t- [Demo/Tutorial: v0 by Vercel AI Code Generation (youtube.com)](https://www.youtube.com/watch?v=gi5nnOqzHeQ)\n- AI code auto-completion tools like [[Microsoft CoPilot]] have shown the potential for AI to enhance software development. The latest [[Microsoft CoPilot]] leverages [[ChatGPT]] 4 and is extremely good.\n- AI will likely be incorporated into most software products going forward to enhance capabilities and engagement. Some experiences are better suited to standalone interfaces rather than cramming functionality into chatbots.\n- Effective use of AI tools requires developing specialized skills around prompting, understanding system capabilities and limitations, and framing problems appropriately. Different AI systems have strengths in different domains.\n- Software development will transition towards more hybrid human-AI teams, with less focus on writing code line-by-line. AI can provide significant productivity gains by automating rote tasks.\n- There are open questions around whether to expose functionality through general chatbot interfaces vs company-specific products. There are strategic and technical considerations favouring bespoke solutions.\n- Open source software tends to improve quickly over time and should not be underestimated. However, regulations could potentially suppress open source AI progress.\n- [gptengineer.app](https://gptengineer.app/) is a commercial offering built on [[GPT Engineer]]\n- [Understand a codebase in github with GPT](https://useadrenaline.com/app)\n- [Sourcegraph | Code AI platform](https://sourcegraph.com/)\n- [Bito AI\n\t- Become a 10X Dev with Bito\n\t- Bito](https://bito.ai/)\n- [Phind](https://www.phind.com/search?home=true)\n-\n-\n-",
        "link_types": [
            "Vercel",
            "Infrastructure",
            "Microsoft CoPilot",
            "Microsoft CoPilot",
            "ChatGPT",
            "GPT Engineer"
        ],
        "file_size": 8857
    },
    {
        "id": "EU AI Act.md",
        "name": "EU AI Act",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- ![CDN media](https://i.redd.it/mrtwlbcc55oc1.jpeg)\n-\n- Final Ratified Text\n\t- [eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:52021PC0206](https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:52021PC0206)\n- [Final Text of the AI Act is out: Our Initial Thoughts\n\t - WILLIAM FRY](https://www.williamfry.com/knowledge/final-text-of-the-ai-act-is-out-our-initial-thoughts/)\n\t- Suggested final changes [st05662.en24[1].pdf\n\t - Google Drive](https://drive.google.com/file/d/1zdlCjJBy75DoGZw53Y172eN9Nxgshgh9/view)\n\t-\n- Final text summary\n\t- The Act prohibits AI systems that use harmful subliminal techniques, exploit vulnerabilities, infer sensitive traits, unfairly evaluate individuals, and certain uses of biometric and emotion recognition, with exceptions for law enforcement. It also restricts AI systems for criminal risk assessment and broad data scraping.\n\t- A substantial change is that AI systems will not be considered high-risk if they do not pose a significant risk of harm subject to certain criteria being fulfilled (even if it's listed as a high-risk system).\n\t- High-risk AI systems are defined based on their potential harm to health, safety, and fundamental rights. Providers must document assessments and register these systems, continually evaluating risks based on various factors. It is for providers to assess whether or not their systems are high risk, and even if they aren't, registration will still be required to this effect along with record keeping of your assessment.\n\t- General Purpose AI models are introduced with a whole new chapter dedicated to them. Models used for research, development, or prototyping are excluded. Providers of high-risk models must comply with specific standards and appoint an EU representative if based outside the EU.\n\t- Deep fakes must be disclosed as AI-generated, with some exceptions.\n\t- Human oversight for high-risk systems is required, ensuring trained personnel are involved.\n\t- Employers using high-risk AI in the workplace must inform their workers, adhering to EU and national laws.\n\t- Testing of high-risk AI systems in real-world conditions is permitted under strict ethical and consent guidelines.\n\t- High-risk system providers must have agreements with third-party suppliers.\n\t- Simplified technical documentation requirements are in place for SMEs, with a 10-year record-keeping mandate.\n\t- The Act defines AI systems as machine-based systems that influence environments through various outputs.\n\t- Emotion and facial recognition systems are broadly defined, potentially impacting organisations using biometric data for sentiment analysis and law enforcement's use of real-time facial recognition.\n\t- Data governance focuses on the collection processes, origins, and purposes of data, particularly personal data.\n\t- Non-compliance fines are substantial, reaching up to €35 million or 7% of global annual turnover.\n\t- The Act specifies implementation timelines for different systems and deadlines for developing codes of practice.",
        "link_types": [],
        "file_size": 3083
    },
    {
        "id": "Apple.md",
        "name": "Apple",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # Partnership with OpenAI, and Siri\n\t- Apple is focusing on \"AI for the rest of us\" - making AI capabilities accessible and useful for everyday tasks rather than flashy frontier use cases. The emphasis is on small but significant time-saving wins.\n\t- Siri is the centerpiece, with expanded natural language understanding, ability to maintain context, and both voice and text input. Siri can now take actions across Apple and third-party apps.\n\t- Apple has partnered with OpenAI to integrate ChatGPT into Siri and other Apple experiences later this year. Siri can tap into ChatGPT when needed to expand its capabilities.\n\t- Apple argues that great product experience matters more than just having state-of-the-art AI models. They are willing to reduce user choice to create a simpler experience, as seen with the limited options in their Image Playground feature.\n\t- Apple is trying to balance leveraging personal context and data with strong privacy protections through on-device processing and a new \"private cloud compute\" capability.\n\t- Apple is taking an approach of deeply integrating AI assistants and capabilities across the OS in a frictionless way to help users with everyday tasks, while maintaining their emphasis on privacy and a carefully designed user experience over flashy demos. The partnership with OpenAI expands what's possible while keeping the Apple experience at the forefront.\n\t- ### IOS18 Security and Privacy\n\t\t- [Thread by Matthew Green](https://threadreaderapp.com/thread/1800291897245835616.html?)\n\t\t\t- Apple, unlike most other mobile providers, has traditionally done a lot of processing on-device. For example, all of the machine learning and OCR text recognition on Photos is done right on your device. \n\t\t\t  The problem is that while modern phone “neural” hardware is improving, it’s not improving fast enough to take advantage of all the crazy features Silicon Valley wants from modern AI, including generative AI and its ilk. This fundamentally requires servers.\n\t\t\t- But if you send your tasks out to servers in “the cloud” (god using quotes makes me feel 80), this means sending incredibly private data off your phone and out over the Internet. That exposes you to spying, hacking, and the data hungry business model of Silicon Valley.\n\t\t\t- The solution Apple has come up with is to try to build secure and trustworthy hardware in their own data centers. Your phone can then “outsource” heavy tasks to this hardware. Seems easy, right? Well: here’s the blog post.\n\t\t\t- [**Blog**](https://security.apple.com/blog/private-cloud-compute/) Private Cloud Compute: A new frontier for AI privacy in the cloud - Apple Security Research**Secure and private AI processing in the cloud poses a formidable new challenge. To support advanced features of Apple Intelligence with larger foundation models, we created Private Cloud Compute (PCC)\n\t\t\t- TL;DR: it is not easy. Building trustworthy computers is literally the hardest problem in computer security. Honestly it’s almost the only problem in computer security. But while it remains a challenging problem, we’ve made a lot of advances. Apple is using almost all of them.\n\t\t\t- The first thing Apple is doing is using all the advances they’ve made in building secure phones and PCs in their new servers. This involves using Secure Boot and a Secure Enclave Processor (SEP) to hold keys. They’ve presumably turned on all the processor security features.\n\t\t\t- Then they’re throwing all kinds of processes at the server hardware to make sure the hardware isn’t tampered with. I can’t tell if this prevents hardware attacks, but it seems like a start.\n\t\t\t- They also use a bunch of protections to ensure that software is legitimate. One is that the software is “stateless” and allegedly doesn’t keep information between user requests. To help ensure this, each server/node reboot re-keys and wipes all storage.\n\t\t\t- A second protection is that the operating system can “attest” to the software image it’s running. Specifically, it signs a hash of the software and shares this with every phone/client. If you trust this infrastructure, you’ll know it’s running a specific piece of software.\n\t\t\t- Of course, knowing that the phone is running a specific piece of software doesn’t help you if you don’t trust the software. So Apple plans to put each binary image into a “transparency log” and publish the software.\n\t\t\t- Security researchers will get *some code* and a VM they can use to run the software. They’ll then have to reverse-engineer the binaries to see if they’re doing unexpected things. It’s a little suboptimal.\n\t\t\t- When your phone wants to outsource a task, it will contact Apple and obtain a list of servers/nodes and their keys. It will then encrypt its request to all servers, and one will process it. They’re even using fancy anonymous credentials and a third part relay to hide your IP.\n\t\t\t- Ok there are probably half a dozen more technical details in the blog post. It’s a very thoughtful design. Indeed, if you gave an excellent team a huge pile of money and told them to build the best “private” cloud in the world, it would probably look like this.\n\t\t\t- But now the tough questions. Is it a good idea? And is it as secure as what Apple does today? And most importantly:\n\t\t\t- I admit that as I learned about this feature, it made me kind of sad. The thought that was going through my head was: this is going to be too much of a temptation. Once you can “safely” outsource tasks to the cloud, why bother doing them locally. Outsource everything!\n\t\t\t- As best I can tell, Apple does not have explicit plans to announce when your data is going off-device for to Private Compute. You won’t opt into this, you won’t necessarily even be told it’s happening. It will just happen. Magically. I don’t love that part.\n\t\t\t- Finally, there are so many invisible sharp edges that could exist in a system like this. Hardware flaws. Issues with the cryptographic attestation framework. Clever software exploits. Many of these will be hard for security researchers to detect. That worries me too. 18/\n\t\t\t- Wrapping up on a more positive note: it’s worth keeping in mind that sometimes the perfect is the enemy of the really good.\n\t\t\t- In practice the alternative to on-device is: ship private data to OpenAI or someplace sketchier, where who knows what might happen to it.\n\t\t\t- And of course, keep in mind that super-spies aren’t your biggest adversary. For many people your biggest adversary is the company who sold you your device/software. This PCC system represents a real commitment by Apple not to “peek” at your data. That’s a big deal.\n\t\t\t- In any case, this is the world we’re moving to. Your phone might seem to be in your pocket, but a part of it lives 2,000 miles away in a data center. As security folks we probably need to get used to that fact, and do the best we can to make sure all parts are secure.\n- They are sitting on a huge cash war chest and can effectively buy their way through and out of the coming battles around ip like the NYT court case.\n- Biding their time waiting for local inferencing that leverages strong legacy media buy in might be a great play. Only the cost to their mind share of talent might be an issue.\n- Apple are innovating in core ML research to support large language models.\n- They are developing new techniques for data management between flash memory and DRAM, crucial for running larger models on devices with limited memory.\n- The research also reveals significant speed improvements, with 4-5 times faster processing on CPUs and 20-25 times on GPUs for models up to twice the size of the available DRAM. These advancements could lead to a wider adoption of these technologies,\n\t- [Paper page\n\t\t- LLM in a flash: Efficient Large Language Model Inference with Limited Memory (huggingface.co)](https://huggingface.co/papers/2312.11514) [[Hardware and Edge]]\n- [Apple wants AI to run directly on its hardware instead of in the cloud | Ars Technica](https://arstechnica.com/apple/2023/12/apple-wants-ai-to-run-directly-on-its-hardware-instead-of-in-the-cloud/) [[Hardware and Edge]]\n- HUGS: Human [[Gaussian splatting and Similar]]\n\t- [Apple Machine Learning Research](https://machinelearning.apple.com/research/hugs)\n- Apple presents [Paper page\n\t- Speculative Streaming: Fast LLM Inference without Auxiliary Models (huggingface.co)](https://huggingface.co/papers/2402.11131):\n\t- Speculative decoding is a prominent technique to speed up the inference of a large target language model based on predictions of an auxiliary draft model. While effective, in application-specific settings, it often involves fine-tuning both draft and target models to achieve high acceptance rates. As the number of downstream tasks grows, these draft models add significant complexity to inference systems. We propose Speculative Streaming, a single-model speculative decoding method that fuses drafting into the target model by changing the fine-tuning objective from next token prediction to future n-gram prediction. Speculative Streaming speeds up decoding by 1.8\n\t- 3.1X in a diverse set of tasks, such as Summarization, Structured Queries, and Meaning Representation, without sacrificing generation quality. Additionally, Speculative Streaming is parameter-efficient. It achieves on-par/higher speed-ups than Medusa-style architectures while using ~10000X fewer extra parameters, making it well-suited for resource-constrained devices.",
        "link_types": [
            "Hardware and Edge",
            "Hardware and Edge",
            "Gaussian splatting and Similar"
        ],
        "file_size": 9598
    },
    {
        "id": "Introduction to me.md",
        "name": "Introduction to me",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- #Public page automatically published\n- ![image.png](../assets/image_1711141602756_0.png){:height 336, :width 1067}\n  id:: 661d5f74-f334-4872-ba92-51244c2fb490\n-\n- Currently I am Spatial AI Lead in an emerging [media innovation lab](https://www.mediacityuk.co.uk/immersive-technologies-innovation-hub/), supporting human storytelling with immersive and AI tech.\n- I am also Chief Hallucination Officer for [DreamLab](https://www.linkedin.com/company/dreamlabinstitute/?); an emerging institute of creatives, academics, professionals, storytellers and technologists.\n\t- ![Screenshot 2024-06-15 102949.png](../assets/Screenshot_2024-06-15_102949_1718443829936_0.png){:width 500}\n\t- I have a micro company which develops open source software and knowledge, and offers consultancy called \"[flossverse](https://github.com/flossverse)\" (free, libre, open source software - verse).\n\t-\n\t- This (creative commons 0) open source knowledge base is supported in part by:\n\t- ![supprot.png](../assets/supprot_1713182959874_0.png)\n- # What are these pages?\n\t- This interface is an example of [[Knowledge Graphing]].\n\t  id:: 661d5f74-5dfe-4569-9374-37b63637b3d8\n\t\t- [[Logseq]] is a knowledge management and note-taking tool, integrated with AI capabilities.\n\t\t- This is updated a couple of times a week, but you WILL need to hit CTRL-R as I didn't code a refresh into it.\n\t\t- Below is the [graph](https://www.visionflow.info/680a51ea177aecc8cafb7003e146622b7ca13257/index.html#/graph) view of about 1/6 of my current research base.\n\t\t- **You can find it as \"Graph\" top right of this page.**\n\t\t- You should probably stop reading this page and go click graph and find something you like.\n\t\t- ![Screenshot 2024-01-30 093017.png](../assets/Screenshot_2024-01-30_093017_1706607172633_0.png)\n\t\t- <iframe src=\"https://narrativegoldmine.com/#/graph\" style=\"width: 100%; height: 600px\"></iframe>\n\t\t- ## Note about links\n\t\t\t- In *my* version of the knowledge graph all the twitter links render interactively, inline, you will just see \"loading\" on the web. There are a lot of them, like this one. Sometimes you might just seen a loading with no link, that means I forgot that one, it's not going to load.\n\t\t\t- [twitter link to the render loading below](https://twitter.com/bentossell/status/1758235873433243950)\n\t\t\t  {{twitter https://twitter.com/bentossell/status/1758235873433243950}}\n- # My research in broad stokes:\n\t- ## Equity of opportunity of access to AI:\n\t\t- Genius is evenly distributed across humanity. There are as many incredible minds per capita in India, South America, Nigeria, China, South East Asia, as anywhere in the highly developed world. Access to the identity rails, money rails, education, technology, and now AI, is *not* equitably distributed. I am trying to change that a little by focusing on protocols.\n\t- ## Convergence :\n\t\t- Everything is smoothing out as GenAI scaffolds human work. The interfaces won't need to be learnt any more. [[Social contract and jobs]] may soon be radically different. This is a [[Convergence]] but is also a [[Disruption]].\n\t- ## Disruption:\n\t\t- This is happening so fast that many are viewing it as a [[Singularity]] event; that we will likely see as many problems as benefits initially. -\n\t- ## The potential opportunity offered by [[Bitcoin]]:\n\t\t- I have been studying Bitcoin technologies for the past 7 years. This novel ecosystem is a non-trivial disruptive force, and is now deeply threaded through my technical research.\n\t- ## My research as a diagram\n\t\t- ((66314b8e-513e-45a6-80e7-493933e46e9e))\n\t\t  id:: 66314bd7-86ef-4ca2-8f39-704e133ac0a3\n\t\t\t- ![graphviz.png](../assets/graphviz_1714508145842_0.png){:height 1019, :width 1114}\n\t\t-\n- [[Recent Projects]]\n- <iframe src=\"https://narrativegoldmine.com/#/graph\" style=\"width: 100%; height: 600px\"></iframe>\n-",
        "link_types": [
            "Knowledge Graphing",
            "Logseq",
            "Social contract and jobs",
            "Convergence",
            "Disruption",
            "Singularity",
            "Bitcoin",
            "Recent Projects"
        ],
        "file_size": 3816
    },
    {
        "id": "Music and audio.md",
        "name": "Music and audio",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ## Audio as an essential intimate modality\n\t- <iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/episode/44yEyYZV2TJf4cvVumysC5?utm_source=generator&t=62107\" width=\"100%\" height=\"352\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"></iframe>\n- ## Tools roundup [[Update Cycle]]\n\t- This needs a big overhaul update\n\t- [Motion Array So Easy (youtube.com)](https://www.youtube.com/watch?v=Hd0KYxotzv8)\n\t- [Suno AI](https://www.suno.ai/) is now integrated into Microsoft [[Microsoft CoPilot]] [[Music and audio]]\n\t\t- {{tweet https://twitter.com/NickADobos/status/1737335846414770583}}\n- Remember Limewire? They have relaunched as a creative portal with digital sales. This is from Mark Farrell [Biomorphic Coalescence LimeWire](https://limewire.com/post/b9c58f0b-154e-484b-868c-9c6f5ec2e960)\n- ![1703054111335.mp4](../assets/1703054111335_1703357299299_0.mp4) [Post | Feed | LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7143126665659826176/)\n- [declare-lab/tango · Hugging Face](https://huggingface.co/declare-lab/tango)\n- [cvssp/audioldm2 · Hugging Face](https://huggingface.co/cvssp/audioldm2)\n-\n- Other (many out of date links)\n\t-\n\t- [Stable diffusion MIDI](https://storage.googleapis.com/music-synthesis-with-spectrogram-diffusion/index.html)\n\t- [Trainable github](https://github.com/teticio/audio-diffusion)\n\t- [Propia instant jukebox](https://app.prodia.com/#/)\n\t- [SD for music](https://www.riffusion.com/about)\n\t- [word to midi](https://www.musicradar.com/news/audiocipher-word-midi-music-generator-creative-block)\n\t- [HarmonAI](https://www.harmonai.org/)\n\t- [Riffusion](https://github.com/riffusion/riffusion-app)\n\t- [sounddraw.io](https://soundraw.io/)\n\t- [Soundraw: Generates background music.](https://soundraw.io/)\n\t- [beathoven.ai](https://www.beatoven.ai/)\n\t- [Beatoven: Create unique royalty-free music.](https://www.beatoven.ai/)\n\t- [Krise: Removes background voices, noises and echo during calls.](https://krisp.ai/)\n\t- [Google MusicLM](https://google-research.github.io/seanet/musiclm/examples/)\n\t- [techcruch explaining why it won't be released](https://techcrunch.com/2023/01/27/google-created-an-ai-that-can-generate-music-from-text-descriptions-but-wont-release-it/)\n\t- [Text2audio](https://text-to-audio.github.io/)\n\t- [The audioFlux library is a tool for audio and music analysis, featuring extraction capabilities. It is open source and released under the MIT license.](https://github.com/libAudioFlux/audioFlux)\n\t- [Grimes invites royalty split with anyone using her voice](https://www-engadget-com.cdn.ampproject.org/c/s/www.engadget.com/amp/grimes-invites-ai-artists-to-use-her-voice-promising-50-percent-royalty-split-165659578.html)\n\t- [Meta audiogen](https://github.com/facebookresearch/audiocraft)\n\t- [meta musicgen](https://huggingface.co/facebook/musicgen-melody/)Ryan Hoover, founder of Product Hunt, tweeted an idea for an “AI Spotify” that could host AI-generated music by submitting music with the best tracks based on listens and likes earning a pro-rata share of subscription revenue, reserved for original artists. The tweet sparked interest, leading to someone building the platform called Beatly Music, while some artists expressed interest in the idea. However, industry insiders, including Scott Belsky, have questioned why Spotify might not just do this themselves since they already have the fan graph, the data set, and relationship with artists. But it may be too risky to navigate for a large company with record labels as a key stakeholder. While the idea has potential, there are many ethical and legal issues with this model, especially with labels. Nevertheless, Beatly Music carries a considerable risk as several legal concerns may arise regarding music rights and royalties, stating that some significant damages, including [[copyright]] infringement charges or compounding royalties to record labels and artists, might come up. https://twitter.com/rrhoover/status/1647735300511154176\n\t- WavTool is an AI-powered music production tool that is free to use online. It offers features such as side-chain compression, flexible signal routing, and advanced synthesis to help users make high-quality music. For beginners, WavTool's Conductor AI can provide guidance through the music-making process, offer suggestions, and explain concepts in plain English. Users can start by creating beats, generating melodies, or suggesting chords. As users gain more experience, WavTool's signal routing and plugin editing features allow them to customize their music production even further. WavTool requires no installation or updates and can be used entirely online. http://WavTool.co\n\t- Create Music is a platform that offers an API solution for businesses to easily integrate music creation and composition functionalities into their products and services. With this API, businesses can offer their customers the ability to create custom music tracks using various instrument sounds and styles within their own applications. [WavJourney compositional LLM](https://audio-agi.github.io/WavJourney_demopage/)\n\t\t- The technology behind Create Music's API is a robust and intuitive program that offers fast and efficient audio rendering. This makes it possible for businesses to quickly and easily develop music creation applications that are responsive and fun to use. The API includes features like tempo control, key change, and instrument selection, giving users the ability to create virtually any kind of music they can think of.\n\t\t- The platform offers a wide variety of instruments and styles to choose from, including classic and modern pianos, guitars, drums, and synthesizers. Users can also choose from different music genres, such as classical, rock, hip hop, and electronic music. Whether creating a jingle for an advertisement, a theme song for a podcast, or a ringtone for a mobile device, businesses can easily provide their customers with the tools they need to make their own custom music tracks.| \n\t\t  Furthermore, Create Music's API offers secure and reliable access to its backend systems and servers. This means that businesses can have peace of mind knowing that their customers' data and creations are protected. Additionally, the platform is constantly evolving, with frequent updates and improvements to help businesses offer their customers the best possible music creation experience.\n\t\t- Overall, Create Music's API offers an exciting opportunity for businesses to provide unique and engaging music creation capabilities to their customers. Whether as a standalone app or as an integrated feature within larger products and services, businesses can use this API to offer users an endless variety of creative possibilities. https://soundraw.io/\n\t- Podcastle is an all-encompassing platform for broadcast storytelling, offering studio-quality recording, AI-powered editing, and effortless exporting in a user-friendly web-based interface. With Podcastle, users can record remote interviews in job quality, transcribe audio files to text in seconds, make use of easy-to-use editing tools like royalty-free music and multi-track software, and use cutting-edge voice skins to generate realistic human voices. Podcastle's “Magic Dust” is an AI-powered noise cancellation tool that enhances audio files to professional studio standards with just a few clicks. Its “Revoice” feature allows users to create a digital version of their voice using an AI model so that they can generate audio just by typing. The platform is perfect for podcasters, bloggers, journalists, educators, and other content creators to begin their audio storytelling journey with ease. The company's goal is to democratize access to broadcast storytelling. Additionally, Podcastle offers a blog and supports a Discord Community where creators can get advice, ask questions, and interact with other passionate creators. https://podcastle.ai/|",
        "link_types": [
            "Update Cycle",
            "Microsoft CoPilot",
            "Music and audio",
            "copyright"
        ],
        "file_size": 8065
    },
    {
        "id": "Landscape.md",
        "name": "Landscape",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- ## AI landscape\n- a16z market analysis [[Landscape]] [market analysis](https://a16z.com/2023/05/25/ai-canon/)\n- Cowboy ventures [[Landscape]] [AI stack overview](https://medium.com/cowboy-ventures/the-new-infra-stack-for-generative-ai-9db8f294dc3f)",
        "link_types": [
            "Landscape",
            "Landscape"
        ],
        "file_size": 308
    },
    {
        "id": "Overview of Machine Learning Techniques.md",
        "name": "Overview of Machine Learning Techniques",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n\t- ## AI or ML or what?\n\t- It's not intelligent. It's just machine learning which is statistics.\n\t- Artificial intelligence is a marketing term, but it's supported in literature as the high level term.\n\t- [That's OK!](https://simonwillison.net/2024/Jan/7/call-it-ai/)\n\t- I'm mainly going to use AI from here in.\n\t- ![1706985611136.gif](../assets/1706985611136_1707078214092_0.gif)\n- # Machine Learning Techniques Overview\n\t- ## Supervised Learning\n\t\t- **Concept**: Techniques where models learn from labeled data.\n\t\t- **Explain**: Like teaching a child with clear examples and answers.\n\t\t- ##### 1️⃣ Support Vector Machines (SVM)\n\t\t- **Description**: Uses hyperplanes for classification.\n\t\t- **Explain**: Think of drawing lines to separate different types of objects.\n\t\t- **Paper**: [A comprehensive survey on support vector machine classification](https://www.sciencedirect.com/science/article/pii/S0925231220307153?)\n\t\t- ##### 2️⃣ Naive Bayes\n\t\t- **Description**: Probabilistic classifier based on Bayes' Theorem.\n\t\t- **Explain**: Like guessing the likelihood of something happening based on past events.\n\t\t- **Paper**: [An Empirical Study of the Naïve Bayes Classifier](https://sites.cc.gatech.edu/home/isbell/classes/reading/papers/Rish.pdf)\n\t\t- ##### 3️⃣ Linear Regression\n\t\t- **Description**: Models linear relationships between variables.\n\t\t- **Explain**: Like predicting your height based on your age.\n\t\t- **Medium Post:** [A short into to Linear Regression](https://medium.com/pew-research-center-decoded/a-short-intro-to-linear-regression-analysis-using-survey-data-ff39468f8afb)\n\t\t- ##### 4️⃣ Logistic Regression\n\t\t- **Description**: Used for binary classification problems.\n\t\t- **Explain**: Like deciding if something is true or false.\n\t\t- **Paper**: [Logistic regression in data analysis: An overview](https://www.researchgate.net/profile/Maher-Maalouf-2/publication/283211221_IJDATS_Logistic_Regression_Rare_Events/data/562e0fb508ae518e34827577/IJDATS-Logistic-Regression-Rare-Events.pdf)\n\t\t- ##### 5️⃣ Decision Trees\n\t\t- **Description**: Tree-like model for decisions and consequences.\n\t\t- **Explain**: Like a flowchart to make decisions, but using numbers (weights)\n\t\t- **Paper**: [Study and Analysis of Decision Tree Based Classification Algorithms](https://www.researchgate.net/profile/Purvi-Prajapati/publication/330138092_Study_and_Analysis_of_Decision_Tree_Based_Classification_Algorithms/links/5d2c4a91458515c11c3166b3/Study-and-Analysis-of-Decision-Tree-Based-Classification-Algorithms.pdf)\n\t\t- ##### 6️⃣ Random Forest\n\t\t- **Description**: Ensemble of decision trees for improved accuracy.\n\t\t- **Explain**: Like consulting a group of experts instead of just one.\n\t\t- **Paper**: [Understanding Random Forests: From Theory to Practice](https://arxiv.org/abs/1407.7502)\n\t- ## Unsupervised Learning\n\t\t- **Concept**: Techniques where models learn from unlabeled data.\n\t\t- **Explain Like I'm New**: Learning without direct guidance, like exploring a new city without a map.\n\t\t- ##### 1️⃣ K-Means Clustering\n\t\t- **Description**: Partitions data into k distinct clusters.\n\t\t- **Explain Like I'm New**: Like organizing similar things into different groups.\n\t\t- **Paper**: [K-means clustering algorithms: A comprehensive review, variants, and advances](https://www.sciencedirect.com/science/article/pii/S0020025522014633?)\n\t\t- ##### 2️⃣ K-Nearest Neighbors (KNN)\n\t\t- **Description**: Classifies cases based on similarity measures.\n\t\t- **Explain Like I'm New**: Like making friends based on common interests.\n\t\t- **Paper**: [Comparative performance analysis of K-nearest neighbour (KNN)](https://www.nature.com/articles/s41598-022-10358-x)\n\t- ### Neural Networks and Deep Learning id:: 659a9232-2320-494a-b922-968029718ad5\n\t\t- **Concept**: Advanced algorithms inspired by the structure of the human brain.\n\t\t- **Explain**: Like building a brain in a computer to solve complex problems.\n\t\t- #### 1️⃣ Neural Networks\n\t\t- **Description**: Consists of layers of interconnected nodes which just tweak numbers\n\t\t- **Explain**: Like a network of brain cells working together to think and learn.\n\t\t- **Paper**: [Neural networks: An overview of early research, current frameworks and new challenges](https://www.sciencedirect.com/science/article/pii/S0925231216305550?)\n\t\t- {{video https://www.youtube.com/watch?v=aircAruvnKk&}}\n\t\t- #### 2️⃣ Deep Learning\n\t\t- **Description**: Involves training large neural networks.\n\t\t- **Explain**: Larger scale engineering of neural nets, to solve much harder problems.\n\t\t- **Paper**: [Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, and Applications](https://link.springer.com/article/10.1007/s42979-021-00815-1)\n\t\t- **Fine tuning and alignment**\n\t\t- #### 3️⃣ Reinforcement Learning from Human Feedback [[RLHF]]\n\t\t\t- **Description**: Two neural networks trained in an adversarial process.\n\t\t\t- **Explain**: Like two brains, one creating art and the other judging it, helping each other improve.\n\t\t\t- **Paper**: [Generative Adversarial Networks](https://ieeexplore.ieee.org/abstract/document/8253599?)\n\t\t- #### 4️⃣ Direct Preference Optimisation [[DPO]]\n\t\t\t- **Description:** *DPO dramatically simplifies the whole thing.\n\t\t\t- **Explain:** Removes the reward function, and so the human in the loop.\n\t\t\t- **Paper:** [Direct Preference Optimization: Your Language Model is Secretly a Reward Model (arxiv.org)](https://arxiv.org/abs/2305.18290?)\n\t\t- **In operation:  [[Proprietary Large Language Models]]:**\n\t\t- #### 5️⃣ Generative Adversarial Networks [[GANs]]\n\t\t\t- **Description**: Two neural networks trained in an adversarial process.\n\t\t\t- **Explain**: Like two brains, one creating art and the other judging it, helping each other improve.\n\t\t\t- **Paper**: [Generative Adversarial Networks](https://ieeexplore.ieee.org/abstract/document/8253599?)\n\t\t- #### 6️⃣ [[Diffusion Models]] (Generative Models)\n\t\t  id:: 661d5f76-bb78-4920-949e-76c3dbf66efe\n\t\t\t- **Description**: Advanced models that 'diffuse' data to create new, synthetic outputs, using efficient [[Transformers]]\n\t\t\t- **Explain**: Imagine starting with a noisy, random pattern and gradually shaping it into a clear picture.\n\t\t\t- **Paper**: [Diffusion Models: A Comprehensive Survey of Methods and Applications](https://arxiv.org/abs/2311.10242)  *(Note: This covers the lot including:)*\n\t\t- #### 7️⃣ 🟢 [[Transformers]]\n\t\t  id:: 661d5f76-3ffa-4f10-9027-6f8e90601162\n\t\t\t- **Description:** Circa 2017, introduced self-attention mechanism to capture dependencies between different words in a sequence.\n\t\t\t- **Explain:** Examines the interdependencies across a wider view of words / tokens\n\t\t\t- **Paper:** [Attention Is All You Need (arxiv.org)](https://arxiv.org/abs/1706.03762) **(underpinned recent advances)**\n\t\t\t- Not the only game in town [[Non transformer approaches]] and [others](https://hazyresearch.stanford.edu/blog/2023-06-08-hyena-safari)\n\t\t- <iframe src=\"https://bbycroft.net/llm\" style=\"width: 100%; height: 600px\"></iframe>\n- Next [[presentation]] slide [[Proprietary Large Language Models]]",
        "link_types": [
            "RLHF",
            "DPO",
            "Proprietary Large Language Models",
            "GANs",
            "Diffusion Models",
            "Transformers",
            "Transformers",
            "Non transformer approaches",
            "presentation",
            "Proprietary Large Language Models"
        ],
        "file_size": 7141
    },
    {
        "id": "Ethereum.md",
        "name": "Ethereum",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n-\n- Ethereum[[buterin2013ethereum]] is the second most[secure](https://www.crypto51.app/) public blockchain ([by about50%](https://howmanyconfs.com/))[[sayeed2019assessing]], and second most valuable by [market capitalisation](https://coinmarketcap.com/) (though this comparison is somewhat stretched). It is the natural connection from Web3 from [[Blockchain]].\n- It is touted as ‘programmable money’. It, unlike bitcoin, is ([nearly](https://hackernoon.com/turing-completeness-and-the-ethereum-blockchain-c5a93b865c1a))Turing complete,[[petzold2008annotated]] able to run a [virtualmachine](https://ethereum.org/en/developers/docs/evm/) within the distributed network (albeit slowly), and can therefore process complex transactional contracts in the settlement of value. This has given rise to the new field of ‘distributed finance’, or DeFi (described later),alongside many interesting trust-minimised immutable ledger public database ideas.\n- There are trade-offs and problems with Ethereum (Eth/Ether) which currently increase the ‘participation floor’ and make the network far less suitable for entry level business-to-business use. The ledge ritself being a computational engine, with write only properties, is enormous. Specialist cloud hardware is required to run a full node (copy of the ledger), and partial nodes are the norm. Many partial nodes are run by one specialist cloud provider([Infura](https://consensys.net/blog/news/why-infura-is-the-secret-weapon-of-ethereum-infrastructure/)), which has been demonstrated capable of forced to [excluding countries like Venezuela](https://finance.yahoo.com/news/metamask-infura-block-certain-areas-173749914.html)from the network. Network validators [refused toprocess](https://mevwatch.info) addresses on an [OFAC sanction list](https://home.treasury.gov/policy-issues/office-of-foreign-assets-control-sanctions-programs-and-information). A staggering 58% runs on [Amazon AWSservers](https://ethernodes.org/networkType/Hosting). Critics of the project point to these vulnerabilities to outside influence as an existential threat to the aims of the technology. If it can be censured, then what advantage is there over the [founders](https://protos.com/consensys-lawsuit-jpmorgan-owns-critical-ethereum-infrastructure/) simply running a high speed database to the same purpose?\n- This is a function of the so called ‘scalability trilemma, ’[[hafid2020scaling]] in which it seems that only two features from the list of decentralization, scalability or security can be chosen for blockchains.[[bonneau2015sok]]\n- Moreover the network is [centrally controlled](https://bitcoinmagazine.com/technical/ethereum-is-coercive-bitcoin-is-not) by its creator and the ‘miners’. There is a strong case to answer that Eth is [neitherdistributed](https://blog.mollywhite.net/blockchains-are-not-what-they-say/),nor trustless, and in fact therefore fails to be differentiated from a private permissioned ledger, undermining some of it’s claims. The history of Ethereum is a fascinating case study in human greed. By the time the whitepaper had it’s first limited release, [[Bitcoin]]  had already passed $1000 per token. This led to the creators ambitions for a ‘fair release’ of tokens being voted down by powerful funders, leading to the explosion of similarly structured ‘pre-mined’ coins in the ICO craze, which followed on the Ethereum network. Laura Shin is possibly the most experienced journalist and author in the space and has covered this crazy era in her book ‘The Cryptopians.’ [[cryptopians]] It’s a tough read for the newcomer though, perhaps finish this primer first!\n- With that said there are many talented developers doing interesting work on the platform, and innovation is fast paced. It is entirely normal for technology projects to launch their distributed ledger idea on and within the Ethereum network. These generate tradable ‘ERC-20’ tokens, which can accrue value or demonstrate smart contract utility (based on the [Solidity](https://soliditylang.org/) programming language). Because the value locked and generated in the Ethereum platform comes not just from the ETH token, but all the ERC technologies built upon it, there are hundreds of billions of pounds ‘within’ the network. All of these projects, and indeed the core technology of Ethereum are subject to exploits and vulnerabilities and tens of billions of pounds have been lost.[[chen2020survey]] Most of this money is pure market speculation (as is the case across blockchains). Many analysts cannot see this as anything but a speculative bubble, with all the predictable crash yet to come. This can be seen in the context of other bubbles. It seems that most of the projects in crypto more generally, but certainly with ETH and the NFTs within it are a new kind of social gambling, where online communities can reinforce groupthink around their speculative choices. This idea that Ethereum is not a commodity, but rather a security, built around promises of returns, is finding recent favour in law. New York attorney general James has alleged that Ether isa security in [courtproceedings](https://www.docdroid.net/Myyp0yz/kucoin-pdf#page=11), which could have enormous consequences, potentially reversing the momentum the asset had been enjoying as a commodity. Jason Lowery of MIT and US Space Force [laysout](https://twitter.com/JasonPLowery/status/1572275617344757760) a very clear thesis on the difference between Natamoto consensus and most of what followed as part of his PhD.[[Lowery2023]] His explanation here is proximal to why we focus on Bitcoin, and dismiss ‘proof of stake’ models, though Lowery himself has very serious detractors such as Voskuil who has been working on these problems for a long time[[voskuil2020cryptoeconomics]]\n- “The innovation behind PoW is precisely the fact that it **doesn’t**rely exclusively on software (an abstraction) to keep the ledger systemically secure, but instead incorporates real-world physics (watts)to impose real-world physical constraints on people/computers who run it. Stake is an abstraction. It is an imaginary way to describe the complex emergent behaviour of a bunch of general-purpose state machines. The state machines may physically exist, but the way you choose to visualize the complex emergent behaviour of those machines is imaginary. Satoshi didn’t couple control authority over ledger to abstract, imaginary things like ‘stake’ or ‘coin’ precisely because these things don’t physically exist. If they don’t physically exist, they are incapable of imposing real-world physical costs on people seeking control of ledger. The real-world physical cost of controlling the ledger is what keeps control over the ledger decentralized. It is too physically expensive (in watts) to gain and maintain centralized control over the BTC ledger. In proof of stake, there is no physical cost of gaining centralized control. Why? Because stake doesn’t physically exist. So all it takes to gain centralized control is majority stake. And once you have it (which, because of math, some combination of people already do), you have it forever.\n- With all this said most of the [couple of millionpeople](https://www.statista.com/statistics/1266322/nft-user-number/)who have used NFTs use Ethereum, and if this market of creators and consumers is to be brought into a mixed reality space then they will need a way to bring their objects with them.\n  ![]./assets/d1f001aad6eb30671666fa1341235e1fde310172.jpg\n  Ethereum is thought to look like a speculative bubble. Rights requested\n- Such is the level of nefarious activity on these networks (within Ethereum) that they have a poor reputation, and are difficult to audit, launch, and maintain. The overriding problem of using a blockchain for utility applications (rather than just as money) is that people can, and will, simply lie for criminal purpose when entering data into the ledger. It is far more likely that Ethereum is simply a speculative bubble than any of the claims for utility being born out. Add to that[Morgan Stanleys recentassertion](https://advisor.morganstanley.com/daron.edwards/documents/field/d/da/daron-edwards/Cryptocurrency_201__What_is_Ethereum_.pdf)that Ethereum is itself threatened by newer contender chains and it’s future becomes unclear. The report correctly identifies that “High transaction fees create scalability problems and threaten user demand. High costs make Ethereum too expensive for small-value transactions.”. It is this high cost of use that most excludes the ERC-20 networks from our consideration.\n- #### Gas fees\n\t- Ethereum has a significant barrier to entry because of high fees to usethe network. The system is Turing complete; able to programatically replicate any other computational system. This includes endless loops in code, so it is trivial to lock up the computational bandwidth of the whole system, in a smart contract commitment, through a web wallet.\n\t- To mitigate this existential ‘denial of service attack’ the ‘gas’ system demands that users spend some of their locked up value to operate on the network. In this way a transaction loop would quickly erode the available gas and stop looping. As the popularity of the system has grown, so too have the gas fees. It can [sometimes cost](https://twitter.com/Blockworks_/status/1521071340517830657) over£10,000 to do a single transaction, though it is typically a few tens of pounds. Appallingly if the user pitches their mining fee offer too low, then the money gets spent anyway! [A website](https://fees.wtf/#/) just plucks random Ethereum addresses out of the aether to show you the level of this expense for participants. People can even [buyNFTs](https://opensea.io/collection/fees-wtf-nft?search[sortAscending]=false&search[sortBy]=PRICE)of the worst examples of these, as ‘tokens’, wasting more money. This isa huge problem for potential uses of the network.\n- #### Ether ultra hard money narrative\n\t- Part of the challenge Ethereum faces is wrapped up with it’s complex token emission schedule. This is the rate at which tokens are generated and ‘burnt’ or destroyed in the network. The total supply of tokens is uncertain, and both emission and burn schedules are regularly tinkered with by the project. The changes to the rate at which ETH are generated.\n\t- ![image](./assets/3fe8a20a55cfa025f4f59f7b04483196d7f28708.png)\n\t- The rate of token generation has changed unpredictably over time. Rights requested\n\t- In addition, a recent upgrade (EIP-1559) results in tokens now being burnt at a higher rate than they are produced, deliberately leading to a diminishing supply. In theory this increases the value of each ETH on the network at around 1% per year. It’s very complex, with impacts on transaction fees, waiting time, and consensus security, as examined by Liu at al..[[liu2022empirical]] Additionally, there is now talk (by[Butlerin](https://time.com/6158182/vitalik-buterin-ethereum-profile/),the creator of Ethereum) of extending this burn mechanism [further into the network](https://ethresear.ch/t/multidimensional-eip-1559/11651).\n- Ethereum was designed from the beginning to move to a ‘proof of stake’ model where token holders underpin network consensus through complex automated voting systems based upon their token holding. This is now called [Ethereum ConsensusLayer](https://blog.ethereum.org/2022/01/24/the-great-eth2-renaming/).This recent ‘Merge’ upgrade has reduced the carbon footprint of the network, a laudable thing, though it seems the GPUs and datacentres have just gone on to be elsewhere. It has not lowered the cost to users nor improved performance. As part of the switching roadmap users were asked to lock up 32ETH tokens each (a substantial allocation of capital). In total there are around 14 million of these tokens, and it is those users who now control the network. This money is likely stuck on the network until at least 2024, a significant delay wen compared to the original promises.\n- This means that proof of stake has problems in that the majority owners‘ decide’ the truth of the chain to a degree, and must by design have the ability to over-ride prior consensus choices. Remember that these users are now trapped in their positions. Four major entities now control the rules of the chain, and have already agreed to censor certain banned addressees. Proof of stake is probably inherently broken.[[poelstra2015stake]] This has[f](https://notes.ethereum.org/@djrtwo/risks-of-lsd)or malicious actors who have sufficient control of the existing history of the chain,[thought to be](https://twitter.com/MTorgin/status/1521433474820890624)in the region of $50M.[[mackinga2022twap]] Like much of the rest of ‘crypto’ the proposed changes will concentrate decisions and economic rewards in the hands of major players, early investors, and incumbents. This is a far cry from the stated aims of the technology. The move to proof of stake has recently earned it the [MIT breakthrough technologyaward](https://www.technologyreview.com/2022/02/23/1044960/proof-of-stake-cryptocurrency/),despite not being complete (validators cannot yet sell their voting stakes). It’s clearly a technology which is designed to innovate at the expense of predictability. This might work out very well for the platform, but right now the barrier to participation (in gas fees) is so high that we do not intend for Ethereum to be in scope as a method for value transfer within metaverses.\n- #### Inherent Weaknesses\n\t- Ethereum faces a unique dilemma, often overshadowed by its technological capabilities. Unlike Bitcoin (BTC), which has solidified its role as astable and reliable store of value, Ethereum’s value proposition is more complex and, ultimately, paradoxical. The following points elaborate on this conundrum:\n\t- **Lack of Monetary Certainty:** Ethereum’s mutable supply schedule and governance model introduce a level of uncertainty not found in Bitcoin.\n\t- **Equity-like Characteristics:** Ethereum acts more like a share in a semi-decentralized corporation than a straightforward asset, deriving its value from expected future transaction fees.\n\t- These attributes lead to a value paradox that is two-fold:\n\t- **Fee Dilemma:** High transaction fees, while beneficial for Ethereum’s perceived value, deter usage and drive decentralized finance (DeFi) applications to other platforms.\n\t- **Scalability Trap:** Attempts to scale the platform and lower fees would, counterintuitively, reduce Ethereum’s intrinsic value by decreasing its future cash flows.\n\t- This presents a catch-22 situation where Ethereum’s value isfundamentally limited by its own economic model. If the asset’s valuedrops significantly, it could undermine the security of the entireplatform, making it less reliable for settling large transactions.\n\t- In the long run, this creates a feedback loop that could, theoretically,push Ethereum’s value towards zero. This issue casts a shadow overEthereum’s long-term viability, presenting a challenge that goes beyondmere technical scalability.",
        "link_types": [
            "buterin2013ethereum",
            "sayeed2019assessing",
            "Blockchain",
            "petzold2008annotated",
            "hafid2020scaling",
            "bonneau2015sok",
            "Bitcoin",
            "cryptopians",
            "chen2020survey",
            "Lowery2023",
            "voskuil2020cryptoeconomics",
            "liu2022empirical",
            "poelstra2015stake",
            "mackinga2022twap"
        ],
        "file_size": 15237
    },
    {
        "id": "Deep Learning.md",
        "name": "Deep Learning",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ## A Simple Example: Image Classification\n- **Process:** The first step is to break down that image into its individual pixels. This raw pixel data is then fed through layers of the AI system. Each layer processes the information, learning patterns and features.\n- **Goal:** The ultimate goal is for the neuron representing the correct digit (in this case, \"7\") to have the highest activation. If the system successfully identifies the digit, it effectively \"understands\" what it's looking at.\n- ## Learning and Loss Functions\n\t- **Concept:** So how do these AI systems learn to perform these tasks? The key lies in the concept of the \"loss function\". This function serves as a judge, scoring the AI's performance on its task.\n\t- **Initial Stage:** At the beginning of the training process, the numbers within the AI's matrices are typically assigned randomly. Think of it like a scrambled puzzle, where the pieces are initially in the wrong places. This leads to what we call \"garbage in, garbage out\" – the AI's initial predictions are often wildly inaccurate.\n\t- **Scoring:** The loss function comes into play by comparing the AI's output with the correct answer. It then calculates a score, essentially telling the AI how far off it is from the desired outcome.\n\t- **Backpropagation:** This score is then used in a process called \"backpropagation\". Here, the system works backward through all the layers, adjusting the values within the matrices. Imagine each number in the matrix as a tiny knob – backpropagation asks \"Do I need to tweak this knob up or down to make the overall score a little better?\" This adjustment is based on the chain rule of calculus.\n\t- **Iteration:** This entire process of scoring and adjusting (backpropagation) is repeated in a loop called \"gradient descent\". It's like a guided search, slowly tweaking the AI's parameters to find a configuration that minimizes the loss function.\n- ## Gradient Descent and Loss Landscapes\n\t- **Concept:** Imagine a vast multi-dimensional space representing all the possible configurations of the AI system. Every point in this space has a corresponding loss value. Gradient descent is the process of navigating this landscape, gradually finding our way down to the lowest possible loss, where the AI's performance is optimized.\n\t- **Complexity:** The process of gradient descent can be complex, involving various strategies for navigating this vast landscape. Researchers have been developing and refining these strategies for years, leading to a wide range of approaches.\n\t- **Core Requirements:** However, two things are essential for gradient descent: a differentiable loss function, allowing us to calculate the direction of improvement, and a backpropagation algorithm, providing the mechanism to adjust the system's parameters.\n- ## Training and Overfitting\n\t- **Traditional Approach:** Historically, AI training relied heavily on curated datasets. These datasets are carefully constructed, containing labeled data. For instance, the MNIST dataset contains thousands of images of handwritten digits, each labeled with its corresponding number.\n\t- **Training Phase:** The AI system is trained on this labeled data, learning patterns and relationships between the data and its labels. The goal is to minimize the loss function, effectively teaching the AI to make accurate predictions.\n\t- **Testing Phase:** Once the training is complete, the AI's performance is evaluated on a separate validation or test set. This set contains data that the AI hasn't seen during training. The idea is to test how well the AI generalizes its knowledge to new, unseen examples.\n\t- **Overfitting:** However, a common problem is overfitting. This happens when the AI system learns the idiosyncrasies of the training data too closely. It might memorize the exact patterns in the training data but fail to generalize to new, slightly different examples. Imagine if a student only studied the exact questions from previous exams – they might do well on those specific questions but struggle with new material.\n- ## The Paradigm Shift: Unsupervised Learning\n\t- **Challenge:** The traditional approach faced a major challenge: limited availability of labelled data. Creating these curated datasets is expensive and time-consuming.\n\t- **Solution:** This is where the concept of unsupervised learning comes in. It's a game-changer, allowing us to tap into the vast ocean of unlabeled data available on the web.\n\t- **Two Key Techniques:**\n\t\t- **Next word/token prediction:** Imagine training an AI system to predict the next word in a sentence. You provide the AI with a vast corpus of text, and its task is to learn the patterns of language, the way words flow together, and the nuances of meaning. This is the approach behind models like GPT-3.\n\t\t- **Image denoising:** Another technique involves taking existing images, adding noise to them (purposefully degrading the image), and training an AI to remove that noise. In the process, the AI learns to understand the underlying structure and patterns of images, even from degraded data.\n\t- **Concept:** The key with unsupervised learning is that the data itself provides the answer, the feedback for the AI to learn. The AI doesn't need explicit labels; it learns from the inherent structure and patterns within the data.\n- ## Next Word/Token Prediction\n\t- **Method:** This technique unlocks the entire body of human text as a potential training dataset. Imagine having access to every book, article, blog post, and conversation ever written.\n\t- **Process:** The AI system learns by predicting the next word in a sequence. It takes into account the preceding words, trying to decipher the underlying grammar, semantics, and even the author's style.\n\t- **Vocabulary:** These systems have vast vocabularies, sometimes containing tens of thousands of words or tokens. The AI needs to learn to select the most likely word from this massive set of possibilities.\n\t- **Loss Function:** The AI's prediction is then scored against the actual next word in the sequence. This score tells the AI how accurate its prediction was.\n\t- **Backpropagation:** Using backpropagation, the AI adjusts its parameters to improve its predictive accuracy. It's constantly refining its understanding of language, striving to become more fluent and accurate in its predictions.\n- ## Image Denoising\n\t- **Method:** This technique allows us to leverage the vast amount of image data available on the web. Imagine having access to millions, even billions of images.\n\t- **Process:** Instead of relying on labeled datasets, we intentionally degrade images by adding noise. This could be random pixels, blurring, or other forms of distortion. The AI's task is to learn to reverse this degradation, reconstructing the original, pristine image.\n\t- **Concept:** By learning to remove noise, the AI learns to identify the fundamental features and patterns within an image. It becomes better at distinguishing between real details and random noise. This process is similar to how our own brains filter out distractions to focus on relevant information.\n\t- **Significance:** This approach opens up a vast new world of possibilities for training AI systems, enabling them to learn from unlabeled image data.\n- ## Compute and the Transformer\n\t- **Requirement:** To train these massive AI models, we need immense computing power. This is where GPUs (Graphics Processing Units) come into play. GPUs are designed for highly parallel processing, enabling them to perform billions of calculations simultaneously.\n\t- **Parallelization:** Imagine having to adjust billions of parameters within the AI system. Doing this sequentially would take an incredibly long time, even with the fastest computer. GPUs allow us to ask these questions in parallel, drastically accelerating the training process.\n\t- **Transformer:** In the realm of modern AI, one architecture has become the dominant force: the \"Transformer\". This is a highly effective type of information processing circuit that's revolutionized AI.\n\t- **Key Features:**\n\t\t- **Attention Mechanism:** The attention mechanism is one of the key breakthroughs within the Transformer. It allows the AI to focus on specific parts of the input data, learning to prioritize the most relevant information. Think of it like a spotlight, highlighting the most important parts of a sentence or image.\n\t\t- **Multi-layer Perceptron (MLP):** The MLP is a fundamental component for processing information within the Transformer. It helps the AI learn complex relationships between the different parts of the data.\n\t\t- **Nonlinearities:** Adding nonlinearities to the model allows the AI to learn non-linear relationships within the data. It adds complexity and flexibility, making the AI more capable of handling real-world challenges.\n\t- **Parameters and Weights:** At the heart of the AI system are the parameters and weights, the numbers that define the AI's behavior. These numbers are learned during the training process, allowing the AI to adapt and improve its performance.\n\t- **Other Terms:**\n\t\t- **Tokens:** Words or image fragments are represented as numerical embeddings, called tokens. These tokens allow the AI to process language and images in a numerical way.\n\t\t- **Neurons:** Neurons are the individual nodes within the AI network. They are typically organized into layers, with each layer performing a specific task.\n\t\t- **Activations:** The values at specific neurons are called activations. These activations indicate how active a particular neuron is, providing insights into the AI's internal decision-making process.\n\t\t- **Logits:** Before the AI's output is converted back into text or images, it's represented as numerical values called logits. These logits represent the AI's confidence in different possible outputs.\n\t\t- **Forward Pass:** The forward pass is the process of running the AI model once on input data. It's like feeding the AI a piece of information and observing its response.\n\t\t- **Model:** The entire AI system, with its parameters, layers, and algorithms, is referred to as the model.\n- ## Scaling Laws and Compute Budgets\n\t- **Concept:** As AI models grow larger and more complex, researchers have discovered something called \"scaling laws\". These laws attempt to predict how the performance of an AI system will change based on the amount of data and compute resources used during training.\n\t- **Pareto Curve:** There's often a sweet spot, a \"Pareto curve\", where increasing compute budget leads to diminishing returns in performance. If you keep adding more compute power, you might see improvements, but at some point, those improvements will become increasingly marginal.\n\t- **Visual:** A graph showing performance (loss) across different compute budgets, illustrating the Pareto curve. The graph demonstrates the optimal point where increasing resources leads to the most significant improvements.\n\t- **Projection:** These scaling laws are powerful tools. They allow us to predict the future performance of AI models based on projected compute resources. Researchers can use these laws to estimate how much compute will be required to achieve a specific level of performance.\n\t- **Large-scale Training:** Today's most advanced AI systems, such as GPT-4, require incredible computational resources. Training these models can cost tens of millions, even billions of dollars, just for the compute resources alone. This doesn't even include the cost of data acquisition, research, and salaries. The scale of AI development is truly staggering.\n- ## Emergence and Semantic Concepts\n\t- **Observation:** One of the most remarkable things about AI systems is their ability to learn things that they weren't explicitly told to learn. This phenomenon, called emergence, is where AI systems start to exhibit unexpected behaviors and capabilities beyond their initial training.\n\t- **Example:** Imagine an AI system trained to predict the next character in Amazon reviews. The system only receives a sequence of characters, not any information about sentiment. Yet, researchers discovered a neuron within the system that lit up strongly for positive reviews and showed a very strong negative activation for negative reviews. This was a profound observation because it showed that the AI had implicitly learned to classify sentiment, even though it wasn't explicitly trained to do so.\n\t- **Significance:** This example demonstrates that AI systems can learn complex concepts like sentiment without explicit instructions. They learn to represent these concepts internally, using them to perform their primary task more effectively.\n\t- **Concept:** This idea, of semantics (meaning) emerging from a syntactic (structure) process, is crucial to understanding the power of AI.\n\t- ### Emergence in Other Domains**\n\t\t- **Game Playing:** Imagine training an AI to play a game. The AI only sees a sequence of moves (e.g., F4, F3, D2, F5), not a visual representation of the board. However, researchers have observed that these systems can learn to represent the board state internally, keeping track of where pieces are located and how the game is evolving. The AI learns to understand the game, even though it's never seen a visual representation of the board.\n\t\t- **Computer Vision:** Similar phenomena have been observed in computer vision models. Researchers have discovered neurons in these systems that respond strongly to specific concepts, like \"window,\" \"wheel,\" and \"car.\" These neurons act as detectors, recognizing specific features within an image.\n\t\t- **Reverse Engineering:** Researchers have developed techniques to reverse engineer these systems, figuring out what concepts are being represented by specific neurons. This involves creating images that maximize the activation of a particular neuron, allowing researchers to understand what that neuron is \"seeing\". These images often reveal fascinating patterns and concepts, showing us the AI's internal understanding of the world.\n- ## Grokking and Generalization\n\t- **Concept:** One of the most exciting developments in AI is the ability of systems to \"grok\" a problem. This means that they can transition from simply memorizing examples to learning the underlying algorithms and principles that govern the problem.\n\t- **Example:** Imagine training an AI to perform modular addition. This involves taking two numbers, adding them together, and then dividing by a third number, taking the remainder. (e.g., 5 + 12 modulo 12 = 0; 17 + 8 modulo 10 = 5). Initially, the AI might do well on the training data but struggle with new examples. This is a classic case of overfitting.\n\t- **Significance:** This \"grokking\" phenomenon suggests that AI systems can go beyond simply memorizing examples and truly understand the underlying principles. This ability to generalize knowledge is crucial for developing AI systems that can solve real-world problems.\n- ## The Challenge of Predictability\n\t- **Uncertainty:** Despite the progress we've made in training and understanding AI systems, a major challenge remains: predicting what capabilities an AI system will develop. It's hard to know when and how a system will \"grok\" a concept or develop new abilities.\n\t- **Example:** Researchers have encountered tasks where AI models initially performed worse as they were scaled up, contradicting the general trend of improved performance with increased size. However, with subsequent generations of models, these same tasks became easier, suggesting that the AI had somehow \"grokked\" the concept and developed new strategies.\n\t- **Importance:** This unpredictability highlights the need for continued research and exploration. We need to develop deeper insights into how AI systems learn and generalize, allowing us to predict and control their capabilities more effectively.\n- # AI Abilities vs. Human Capabilities\n\t- **AI Strengths:**\n\t\t- **Breadth of Knowledge:** AI systems have access to a vast amount of information, far surpassing the knowledge capacity of any human. They can access and process information from the entire internet, books, articles, and other sources.\n\t\t- **Speed and Efficiency:** AI systems can process information and perform calculations at incredible speeds, far exceeding the capabilities of human brains. This allows them to quickly analyze data, solve problems, and generate creative outputs.\n\t\t- **Scalability and Availability:** AI systems can be easily replicated and scaled. You can create multiple copies of an AI system, deploying them across different tasks and applications. Moreover, AI systems are available 24/7, always ready to process information and perform tasks.\n\t- **Human Strengths:**\n\t\t- **Depth of Expertise:** Humans excel at developing deep expertise in specific areas. Our ability to focus and delve into complex topics allows us to become true masters in our chosen fields.\n\t\t- **Breakthrough Insights:** Human creativity and the ability to generate new ideas are essential for scientific breakthroughs and technological innovation. AI systems can be helpful tools for exploration and analysis, but they often lack the spark of original thought that humans possess.\n\t\t- **Coherent Memory and Sense of Self:** Humans have a complex and interconnected sense of self, informed by our memories, experiences, and relationships. AI systems, on the other hand, have limited memory and often lack a coherent sense of identity.\n\t\t- **Bedside Manner and Empathy:** Humans excel at interacting with others, building relationships, and showing empathy. While AI systems are making progress in natural language processing and communication, they still struggle to replicate the nuances of human interaction and emotional intelligence.\n\t- **Slide 17: AI Weaknesses**\n\t\t- **Brittleness:** One of the major weaknesses of current AI systems is their brittleness. They can be easily tricked by adversarial attacks, subtle changes in the input data that can cause the AI to make incorrect or unexpected predictions. Think of it like a house of cards: a small disturbance can cause the entire structure to collapse.\n\t\t- **Lack of Robustness:** This brittleness is closely related to the lack of robustness in AI systems. They are not as adaptable and resilient as human minds. They can be fooled by subtle variations in input data, leading to errors and unpredictable behavior.\n\t\t- **Limited Memory:** Current AI systems have limited and fragile memory compared to humans. They struggle to retain information over long periods and often forget things they were previously \"taught\". This is a significant limitation for tasks that require a deep understanding of context, long-term dependencies, and the ability to recall past events.",
        "link_types": [],
        "file_size": 18831
    },
    {
        "id": "flossverse.md",
        "name": "flossverse",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n-\n- ![BFDtU4hZsjFhVnWXuVtyB4.webp](../assets/BFDtU4hZsjFhVnWXuVtyB4_1705085798733_0.webp)\n- ### Summary\n\t- With all this attention it seems timely to explore the potential ofrecent technologies, which can address collaborative mixed realityinteractions in itbusiness to business (B2B), itbusiness to customer(B2C), and the newer C2C (social commerce; itcreator to consumer,customer to customer, consumer to consumer [[jones2008trust]].\n\t-\n\t- This book seeks to overview and explain the available open sourcetechnologies. It supports an open source [githubrepository](https://github.com/flossverse/product) which enables SMEs toaccess these emergent platforms and ecosystems. It aims to build towarda minimum viable product for trust minimised transfer of value within asocial immersive space, but also across all internet connected devices.\n\t- Referencing is in two styles; academic works and books are numeric,while opinion pieces, gray statistics, and pertinent news articles arehyperlinked from the text. This hybrid style yields about twice thecitation density of a normal PhD thesis, which is a lot. For this reasonthe normal blue hyperlink colour was eschewed in favour of a moreaesthetic “gray”.\n- ## Rationalle\n\t- As human beings, we have always relied on certain social constructs toguide our interactions and transactions with one another. Money andtrust are two such constructs that have played a vital role in shapingour societies, and the way we live our lives. However, the digital agehas brought with it new challenges that are testing the foundations ofthese social norms.\n\t- In a world where we are increasingly connected through the internet andable to communicate with people from all corners of the globe, theconcept of money and trust is changing. Gone are the days of the villagestructure in which we evolved, where personal relationships andface-to-face interactions were ubiquitous. Now, we are faced with theprospect of working and interacting one another, and also withartificial intelligence actors that seem subjectively real, all whilenavigating the complexities of a global mixed reality.\n\t- This transition to a more efficient and interconnected world has thepotential to bring about great benefits, but it also presents us with anenormous challenge. The chaotic and intangible mix of value, trust,socialisation, generative art, and AI chat actors, is not yet wellunderstood, and it will take time for us to adapt to this new way ofliving and interacting with one another.\n\t- We initially wanted to explore exciting new developments in thetransmission of value, and trust, in ‘digital society’. The problem isthat each of these topics alone are enormously complex, and theintersections seem to be more so. We have been researching the currentstate-of-the-art, and the emerging consensus narrative, to try to figureout how the collision of these technologies might serve our virtualproduction workflows (Figure<a href=\"#fig:vprobot\" data-reference-type=\"ref\" data-reference=\"fig:vprobot\">7.7</a>).As we worked on this research the Cambrian explosion of generative AIadded an incredibly important new strand to our investigation.\n\t- Over the course of a couple of years the focus of the work hasdeveloped, and refined. Our tool-kit, as it stands, supports inclusivehuman creativity and economic exchange, especially for emerging marketsand especially perhaps [Africa](https://www.afrobitcoin.org/). There isa huge proportion of human creativity currently excluded from mediaproduction pipelines due to gatekeepers of knowledge, access to identityproofs, and financial infrastructure that is taken for granted in thericher nations. This inclusion will be accomplished for the most partthrough integration of open source machine learning and AI tools, butthis field quite new, and that part of the work is under developed.\n\t- ![image](./assets/c5efbdb4f93ab63a4fbbf12aba053d2194959850.png)\n\t-",
        "link_types": [
            "jones2008trust"
        ],
        "file_size": 3985
    },
    {
        "id": "Deepfakes and fraudulent content.md",
        "name": "Deepfakes and fraudulent content",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ![WhatsApp Image 2024-06-13 at 09.29.51_1881330c.jpg](../assets/WhatsApp_Image_2024-06-13_at_09.29.51_1881330c_1718268091114_0.jpg){:width 400}\n\t- [Deepfake Video Call Scams Finance Bro Out of $25 Million (gizmodo.com)](https://gizmodo.com/deepfake-video-call-scams-finance-bro-out-25-million-1851227196)\n- [FCC-24-17A1.pdf](https://docs.fcc.gov/public/attachments/FCC-24-17A1.pdf) FCC makes robotcalls illegal after New Hampshire political stunt [Fake Biden robocall investigation targets 2 Texas companies | AP News](https://apnews.com/article/biden-robocalls-artificial-intelligence-new-hampshire-texas-a8665277d43d05380d2c7594edf27617)\n- [Bland AI Phone Calling Platform](https://www.bland.ai/) [[Cyber security and Cryptography]] [[Agents]]\n- [Viral deepfake videos of Le Pen family reminder that content moderation is still not up to par ahead of EU elections – Euractiv](https://www.euractiv.com/section/artificial-intelligence/news/viral-deepfake-videos-of-le-pen-family-reminder-that-content-moderation-is-still-not-up-to-par-ahead-of-eu-elections/)\n- [twitter link to the render loading below](https://twitter.com/BrivaelLp/status/1772023234512175290)\n- {{twitter https://twitter.com/BrivaelLp/status/1772023234512175290}}\n- # Social engineering\n\t- {{twitter https://twitter.com/jelleprins/status/1771459616016126015?}}\n- ## The blurred line of identity\n\t- ![GODgca6bAAAxaPB.jpeg](../assets/GODgca6bAAAxaPB_1716366033099_0.jpeg)",
        "link_types": [
            "Cyber security and Cryptography",
            "Agents"
        ],
        "file_size": 1457
    },
    {
        "id": "p(doom).md",
        "name": "p(doom)",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- p(doom) is the probability of an event called \"doom\" occurring. In statistics, the probability represents the likelihood of an event happening, and it usually ranges between 0 and 1. A value of 0 indicates that the event is impossible, while a value of 1 means that the event is certain to occur. In current AI parlance it's a measure of people's instinctive fear of humans being existentially threatened by the existence of AI.\n- {{tweet https://twitter.com/tim_tyler/status/1665571547111649286}}",
        "link_types": [],
        "file_size": 557
    },
    {
        "id": "Recent Projects.md",
        "name": "Recent Projects",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- # Notable works\n\t- Real-time interactive chat bots with thousands of users.  [Player Two | AI Companion](https://playertwo.ai/)\n\t  id:: 659a922a-ac22-484e-9a3f-921390ea68cc\n\t- Marine autonomous AI vision on [[Hardware and Edge]] with [Future Fleet – Autonomous Marine Systems](https://futurefleet.co/) (Patent Pending)\n\t- Human attention tracking in semi public spaces with [QuasiScience](https://quasiscience.com/) and [Fuzzyduck](https://fuzzyduck.co.uk/) (MediaCity:UK)\n\t- Large scale exhibition AI design with [Immersive International](https://www.immersive.international/)\n\t- GenAI and robotics for film pre-visualisation with [LED Virtual Production Studio](https://www.pathwayxr.studio/)\n\t- Interactive GenAI image and video systems for [Neocadia](https://neocadia.com/)\n\t- Text to 3D models with [Vircadia | Open Source Metaverse Platform](https://vircadia.com/)\n\t- Collaborating on the [second Unique Digital Asset](https://twitter.com/Single_Use_Seal) launched on Bitcoin / RGB / [Diba](https://diba.io/)\n\t  id:: 65a27c7d-3da0-4fea-9187-59de9fbbe498\n\t- Educational products with a couple of top flight product managers such as [Parent's guide to Artificial Intelligence)](https://parentsguidetoai.com/)\n\t- LogSeq based training and [[presentation]] material**\n\t- .#.v-gallery-col3\n\t\t- ![image.png](../assets/image_1704299260090_0.png){:width 600}\n\t\t- ![image.png](../assets/image_1705148081233_0.png)\n\t\t- ![image.png](../assets/image_1705148236040_0.png) -",
        "link_types": [
            "Hardware and Edge",
            "presentation"
        ],
        "file_size": 1485
    },
    {
        "id": "Proprietary Video VP & 3D.md",
        "name": "Proprietary Video VP & 3D",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- #Public page automatically published\n- Seems that everyone expects this to break through this year.\n- [Justine Moore from A16Z](https://www.linkedin.com/in/justinemoore94/) has compiled 2023 on Twitter.\n\t- {{tweet (https://twitter.com/venturetwins/status/1737526316948496651}}\n\t- [AI Video 2023 Google Sheets](https://docs.google.com/spreadsheets/d/1FZqG6ESvUzfkZB7AOW5YE9pOYOUfjzw7h6XLREvOJo8/edit?pli=1#gid=514547156)\n- ![image.png](../assets/image_1704284304612_0.png)\n- [AI Video papers from the majors](https://docs.google.com/spreadsheets/d/1FZqG6ESvUzfkZB7AOW5YE9pOYOUfjzw7h6XLREvOJo8/edit?pli=1#gid=0)\n- ![photo_2024-01-03_12-19-29.jpg](../assets/photo_2024-01-03_12-19-29_1704284666431_0.jpg)\n- ## Closed Source Video id:: 659a922a-1d6b-4ae8-82ad-8d7c2814f25f\n\t- ### Pika Labs\n\t\t- **Current leader**:\n\t\t  {{tweet https://twitter.com/martial_artwork/status/1742138390517014918}}\n\t\t- **Prompt Creativity & Flexibility**: Excels in this area, enabling users to directly influence the animation with their prompts.\n\t\t- **Human Motion Animation**: Attempts adventurous animations but may result in distortions.\n\t\t- **Camera Motion Options**: Offers accurate, straightforward camera motions but lacks the dynamic range of Runway ML.\n\t\t- **Pros**: Free version (recently reduced quality), supports multiple aspect ratios, provides tutorials for prompt writing.\n\t\t- **Cons**: Creations are visible to other users, potential for idea theft, and traffic issues on Discord server​[](https://www.toolify.ai/ai-news/revolutionary-ai-animation-tools-pika-vs-runway-78636)​​[](https://dragganaitool.uk/pika-labs-vs-runwayml-gen2/)​. Expensive to use through [Pika Art website](https://pika.art/login) $60pcm,\n\t- ### Runway ML\n\t\t- [twitter link to the render loading below](https://twitter.com/bennash/status/1746188870679400543)\n\t\t  {{twitter https://twitter.com/bennash/status/1746188870679400543}}\n\t\t- **Basic Animation**: Offers cinematic camera movements and more convincing human motion, but faces issues with brightness and image integrity.\n\t\t- **Prompt Creativity & Flexibility**: Less flexible in prompt creativity, occasionally disregarding user prompts.\n\t\t- **Human Motion Animation**: Produces high-quality animations but sometimes distorts the original image.\n\t\t- **Camera Motion Options**: Provides dynamic camera shots, including zooming, panning, and rotating, but may lead to distortion.\n\t\t- **Pros**: Web-based platform ensuring privacy, offers 120 free credits, advanced features, and the option to extend video length.\n\t\t- **Cons**: Limited to 16:9 aspect ratio, may not be as flexible as Pika Labs in prompt generation​[](https://www.toolify.ai/ai-news/revolutionary-ai-animation-tools-pika-vs-runway-78636)​​[](https://dragganaitool.uk/pika-labs-vs-runwayml-gen2/)​.\n\t- ### Mid Journey have said:\n\t\t- **Midjourney Video** \"will not be like any other AI video products that are currently available out there and will be 10X better.\"\n\t\t\t- **David Holz**: “*MidJourney video may not be consistently making what you want, but the quality will be consistently good by default.*”\n\t\t- **Video Training**: The Midjourney team will start to train the video/animation model, which will come before 3D.\n\t\t\t- Already have all the data needed to train the model.\n\t\t- **3D:** needs more data to train, so it’s a bit slower than expected.\n\t\t- {{video https://youtu.be/LY3B0d623wA}}\n\t- ### [VideoPoet – Google Research](https://sites.research.google/videopoet/)\n\t\t- **Overview:** Google's text to video, linked to Bard, but not yet available.\n\t- ### [HeyGen](https://www.heygen.com/) for video avatars\n\t\t- **Overview**: HeyGen emphasizes security and ethics in its AI video platform, being SOC 2 compliant and focusing on data protection.\n\t\t- **Notable Features**: Known for its user-friendly interface and effectiveness in creating short, engaging videos useful for various departments like HR and training.\n\t\t- **Target Audience**: Targets SMEs, offering a range of applications from casual to professional use​​.\n\t- ## Virtual production\n\t\t- ### Simulon (Virtual Production)\n\t\t\t- **Cloud rendered magic**: Still early, and I'm not QUITE sure how it works.\n\t\t\t- {{tweet https://twitter.com/diveshnaidoo/status/1735006300386336919}}\n\t\t\t- [Automotive example](https://www.linkedin.com/posts/divesh-naidoo-48809934_vfx-cgi-virtualproduction-activity-7186786217445711875-7ByY?)\n\t\t\t- https://www.instagram.com/reel/C6fQz81oDMS/\n\t\t\t-\n\t\t- ### My flossverse stuff from 2022\n\t\t\t- {{tweet https://twitter.com/flossverse/status/1629601804521537537}}\n\t\t- ### Skyglass\n\t\t\t- Straight up virtual production on iPhone\n\t\t\t- {{tweet https://twitter.com/skyglassapp/status/1712599252575412474}}\n\t\t- ### Adobe integrates everything to Premier\n\t\t\t- {{video https://www.youtube.com/watch?v=6de4akFiNYM&t=1s}}\n\t\t- ### Other Notable Research\n\t\t\t- ByteDance [MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation (magicvideov2.github.io)](https://magicvideov2.github.io/)\n\t- ## What's next: 3D world creation\n\t  id:: 659a9247-f51f-4b45-9673-df22ec0476dd\n\t\t- Again, midjourney are working on a model. - 🟢 Best I can find is [Sudo AII](https://www.sudo.ai/)\n\t\t- <iframe src=\"https://www.sudo.ai\" style=\"width: 100%; height: 600px\"></iframe>\n\t\t- <iframe src=\"https://yueyang1996.github.io/holodeck/\" style=\"width: 100%; height: 600px\"></iframe>\n\t\t- https://research.nvidia.com/labs/toronto-ai/AlignYourGaussians/\n\t\t- [Mosaic-SDF for 3D Generative Models (connectedpapers.com)](https://www.connectedpapers.com/main/a7d6d07fdb631ce263ec2ddad72df269587fd3c9/Mosaic%20SDF-for-3D-Generative-Models/graph)\n\t\t- https://lioryariv.github.io/msdf/\n\t\t- ## Voice to CAD like Tony Stark is [obviously coming](https://www.linkedin.com/posts/bengeskin_i-feel-like-tony-stark-and-doctor-strange-activity-7152044309213519872-YUnm/?)\n\t\t\t- ![xrCAD.mp4](../assets/xrCAD_1705345928224_0.mp4){:height 44, :width 66}\n\t\t\t- # [[Metaverse and Telecollaboration]]\n\t\t\t- 🟢 I could go on all day about this, goods and bads. I literally wrote a book on it.\n\t\t\t- 🟢 A lot (for me) hinges on [[OpenUSD]] the universal scene language. It's been SO long since we have had something useful.\n\t\t\t- Nvidia have a text to 3D pipeline for [[Omniverse]]. Will be interesting to see what the use cases are. This is their new Cesium [geo tile integration](https://cesium.com/blog/2024/01/16/now-available-[[NVIDIA Omniverse]]-aeco-demo-pack/) giving global instant models.\n\t\t\t-\n\t\t\t- ![1705423306024.mp4](../assets/1705423306024_1705437842029_0.mp4)\n\t-\n\t-\n\t- {{tweet https://twitter.com/BlockadeLabs/status/1719818562917761094}}\n- This is a [[presentation]] slide and the next slide is [[Open Generative AI tools]]",
        "link_types": [
            "Metaverse and Telecollaboration",
            "OpenUSD",
            "Omniverse",
            "NVIDIA Omniverse",
            "presentation",
            "Open Generative AI tools"
        ],
        "file_size": 6701
    },
    {
        "id": "Knowhere.md",
        "name": "Knowhere",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # Enabling Hyper-Personalised Experiences\n\t- ## Summary\n\t\t- **Project Name**: [[KnoWhere]]\n\t\t- **Objective**: Enabling Hyper-Personalized Experiences in Physical Spaces via Attention Tracking\n\t\t- **Competition**: AI Solutions to improve productivity in key sectors\n\t\t- **Innovation Area**: Creative industries\n\t\t- **Approach**: Using AI and computer vision for non-intrusive tracking of attention in museums and immersive experiences\n\t\t- **Technology**: AI, computer vision, steerable barrier lenticular displays\n\t - The project aims to revolutionize visitor experiences in museums and immersive spaces. Leveraging AI and computer vision, KnoWhere offers seamless integration into existing environments, tracking user attention and emotion in real time. This innovation allows for the adaptation and personalization of experiences, enhancing visitor engagement and providing actionable insights for curators and designers.\n\t\t- ## Public Description - 🌟 Introducing KnoWhere's Attention Tracking Technology for revolutionizing creative spaces! This cutting-edge technology uses AI and computer vision to track visitor attention and emotion in real time, providing actionable insights for a more engaging exhibition experience. No wearables or intrusive cameras needed! 🚀 Join us in this creative industry revolution with KnoWhere! 🚀\n\t- ## Need or Challenge\n\t\t- **Motivation**: Enhancing visitor experiences with AI-enabled narrative engines\n\t\t- **Market Opportunity**: Overcoming limitations of current intrusive and limited solutions\n\t\t- **Initial Work**: Development studies underlining the viability of seamless AI and computer vision integration\n\t- ## Competitor Analysis\n\t\t- Density: Offers people counting and spatial analytics using depth sensors.\n\t\t- Outsight: Provides 3D semantic cameras for spatial intelligence in retail and industrial settings.\n\t\t- Iris: Uses thermal cameras for occupancy and attention monitoring in retail and event spaces.\n\t\t- Eyeware: Calculates gaze data using Intel cameras, primarily for individual PC users.\n\t- ## Approach and Innovation\n\t\t- **Method**: Utilizing high-resolution machine vision cameras and AI algorithms for capturing human presence and emotions\n\t\t- **Innovation**: Seamless tracking without requiring wearables, anonymized data processing for privacy\n\t\t- **AI Utilization**: Trustworthy and responsible use of AI in capturing visitor data\n\t- ## Market Awareness\n\t\t- **Target Market**: Creative industry, specifically museums, exhibitions, and immersive experience centers\n\t\t- **Market Size**: Estimated to be worth upwards of £200 million\n\t- ## Competitive Advantages\n\t\t- **Unique Capabilities**: Capturing gaze vectors, emotion, and attention metrics with high granularity\n\t\t- **Seamless Integration**: No need for proprietary hardware or sensors\n\t\t- **Privacy Focus**: Minimal, anonymized data collection\n\t\t- **Partnerships**: Strategic collaborations with experience designers and creative industries\n\t- ## Go-to-Market Strategy\n\t\t- 1. **Partnerships**: Collaborating with experience design agencies and media production agencies\n\t\t  2. **Direct Sales**: Targeting major venues and institutions\n\t\t  3. **Licensing Model**: For smaller venues and galleries\n\t\t  4. **Projections**: Aiming for a substantial portion of revenue to be recurring by Q2 2025\n\t- ## Project Impact\n\t\t- **Economic Contribution**: Estimated £50 million additional revenue annually in the experience industry within 5 years\n\t\t- **Visitor Engagement**: Projecting 10 million additional visits per year for top UK museums and galleries\n\t\t- **Cost Reduction**: 15-20% reduction in operating costs for venues\n\t- ## Wider Impacts\n\t\t- **Economic Benefits**: Boosting productivity in creative industries\n\t\t- **Environmental Sustainability**: Minimal hardware use and reduced cloud computing footprint\n\t\t- **Regional Impacts**: Job creation and positioning the UK as a leader in creative technology\n\t- ## Pitch Deck\n\t\t- ![finalKnowWhere.pdf](../assets/finalKnowWhere_1706197940092_0.pdf)\n\t- ## Funding\n\t- Collaborators\n\t\t- Ross Verrall [[PEOPLE👱]] at [[NVIDIA Omniverse]]has suggested applying for the Inception grant to assist with our bid.\n\t\t- Simon Graham : Creative Technology Director at Pixel Artworks has promised some hours and a market potential report as a match fund to the project for £3000\n\t\t- Badger and Coombs would like to offer time, support and staff to the workshops work package and can commit £3000 of support.\n\t\t- FuzzyDuck productions will commit £3000 in time to product market development, and workshopping, and £7000 to the creation of digital assets for the product, with two iterations and any necessary project support.\n\t- Project_finance_summary\n\t\t- Summary of total project costs and funding requested.\n\t\t- Sections to fill:\n\t - Total project cost\n\t - Total funding requested\n\t - Breakdown by cost categories\n\t\t- **Advice**: Summarize accurately, cross-check with detailed tabs to ensure consistency.\n\t- Other_Public_Funding\n\t\t- Details of any other public funding received.\n\t\t- Sections to fill:\n\t - Source of funding\n\t - Amount\n\t - Status (applied, granted)\n\t\t- **Advice**: Disclose all other funding to avoid duplication of funding issues.\n\t- Other_Projects\n\t\t- Information on other ongoing or planned projects.\n\t\t- Sections to fill:\n\t - Project title\n\t - Funding body\n\t - Project status\n\t\t- **Advice**: Highlight synergies or distinctions with the current project to clarify the innovation aspect.\n\t- Labour_and_Overheads_Costs\n\t\t- Breakdown of labour costs and overhead allocations.\n\t\t- Sections to fill:\n\t - Employee roles\n\t - Hours\n\t - Rate\n\t - Overhead allocation method\n\t\t- **Advice**: Ensure labour costs are justifiable and in line with standard industry practices.\n\t- Materials_Costs\n\t\t- Details of material costs for the project.\n\t\t- Sections to fill:\n\t - Type of materials\n\t - Quantity\n\t - Cost\n\t\t- **Advice**: Source materials cost-effectively while maintaining quality.\n\t- Capital_Usage\n\t\t- Usage of capital items/equipment.\n\t\t- Sections to fill:\n\t - Description of capital items\n\t - Justification for need\n\t - Depreciation method\n\t\t- **Advice**: Justify capital usage with respect to project outcomes and innovation.\n\t- Sub_Contract_Costs\n\t\t- Costs related to subcontracting work.\n\t\t- Sections to fill:\n\t - Subcontractor details\n\t - Scope of work\n\t - Cost\n\t\t- **Advice**: Choose subcontractors that add value and expertise to the project.\n\t- Travel_&_Subsistence_Costs\n\t\t- Travel and subsistence expenses for the project.\n\t\t- Sections to fill:\n\t - Purpose of travel\n\t - Destination\n\t - Estimated cost\n\t\t- **Advice**: Keep travel costs reasonable and directly related to project activities.\n\t- Other_Costs\n\t\t- Any other costs not covered in previous sections.\n\t\t- Sections to fill:\n\t - Description of cost\n\t - Justification\n\t - Amount\n\t\t- **Advice**: Provide clear justifications for any miscellaneous expenses to ensure they are deemed necessary.\n\t- # Hardware\n\t- [10G ethernet testing of Jetson AGX Orin Developer Kit\n\t - Jetson & Embedded Systems / Jetson AGX Orin\n\t - NVIDIA Developer Forums](https://forums.developer.nvidia.com/t/10g-ethernet-testing-of-jetson-agx-orin-developer-kit/227166)\n\t-\n\t- ## Sequence Diagram\n\t- ```mermaid sequenceDiagram\n\t      participant Capture\n\t      participant Ingest\n\t      participant Segment\n\t      participant Pose_Processing as Pose Analysis\n\t      participant Gaze_Discrimination as Gaze Analysis\n\t      participant Face_Processing as Face Analysis\n\t      participant Synthesis\n\t      participant Output_Build as JSON Builder\n\t      participant Streaming\n\t      \n\t      Capture->>Ingest: High-Performance Coax\n\t      Ingest->>Segment: Segment and locate\n\t      Segment->>Pose_Processing: Workstation Backplane\n\t      Segment->>Face_Processing: Workstation Backplane\n\t      Segment->>Gaze_Discrimination: Workstation Backplane\n\t      Pose_Processing->>Synthesis: NVLink\n\t      Gaze_Discrimination->>Synthesis: NVLink\n\t      Face_Processing->>Synthesis: NVLink\n\t      Synthesis->>Output_Build: Combine Data\n\t      Output_Build->>Streaming: 10G Fiber UDP ```\n- # Face Swap project (sub-project)\n\t- [[Face Swap]]\n\t- [[Segmentation and Identification]]\n\t- [ChatGPT\n\t - CodeHelper (openai.com)](https://chat.openai.com/g/g-YWd3Sg9X3-codehelper/c/4685d4fe-2ad7-475e-9a15-5fb9c4820990)\n\t- Make a mermaid Gantt chart for this project, based on the code, identifying and scoping work packages\n\t\t- ```import cv2\n\t\t  import cv2\n\t\t  import threading\n\t\t  import queue\n\t\t  import numpy as np\n\t\t  \n\t\t  # GStreamer Pipeline for Efficient Video Capture\n\t\t  def create_gstreamer_pipeline(rtsp_url):\n\t\t      \"\"\"\n\t\t      Create a GStreamer pipeline for efficient video capture using NVIDIA hardware-accelerated plugins.\n\t\t      :param rtsp_url: URL of the RTSP stream.\n\t\t      :return: GStreamer pipeline string.\n\t\t      \"\"\"\n\t\t      return (\n\t\t          f'rtspsrc location={rtsp_url} latency=0 ! '\n\t\t          'rtph264depay ! h264parse ! '\n\t\t          'nvv4l2decoder ! nvvidconv ! '\n\t\t          'video/x-raw, format=(string)BGRx ! '\n\t\t          'videoconvert ! video/x-raw, format=(string)BGR ! appsink'\n\t\t      )\n\t\t  \n\t\t  # Placeholder for TensorRT-Optimized YOLO Face Detection\n\t\t  def detect_objects(tensorrt_model, frame, gpu_id):\n\t\t      \"\"\"\n\t\t      Detect objects in the frame using a TensorRT-optimized YOLO model.\n\t\t      :param tensorrt_model: Loaded TensorRT model for object detection.\n\t\t      :param frame: Video frame for object detection.\n\t\t      :param gpu_id: GPU ID to use for detection.\n\t\t      :return: List of detections (bounding boxes).\n\t\t      \"\"\"\n\t\t      # Actual implementation required\n\t\t      return []\n\t\t  \n\t\t  # Function for Feathered Blending at Bounding Box Edges\n\t\t  def feather_edges(mask, width):\n\t\t      \"\"\"\n\t\t      Apply feathering to the edges of a mask for smooth blending.\n\t\t      :param mask: Binary mask for feathering.\n\t\t      :param width: Width for feathering effect.\n\t\t      :return: Feathered mask.\n\t\t      \"\"\"\n\t\t      kernel = np.ones((width, width), np.uint8)\n\t\t      mask = cv2.erode(mask, kernel, iterations=1)\n\t\t      mask = cv2.blur(mask, (width, width))\n\t\t      return mask\n\t\t  \n\t\t  # Function for Swapping Faces in the Frame\n\t\t  def swap_faces(detections, frame, swapper_model, gpu_id):\n\t\t      \"\"\"\n\t\t      Swap faces in the frame based on detections.\n\t\t      :param detections: Detected faces with bounding boxes.\n\t\t      :param frame: Original video frame.\n\t\t      :param swapper_model: Face swapping model.\n\t\t      :param gpu_id: GPU ID to use for face swapping.\n\t\t      :return: Frame with swapped faces.\n\t\t      \"\"\"\n\t\t      for det in detections:\n\t\t          x, y, w, h = det['box']\n\t\t          # Perform face swapping\n\t\t          swapped_face = swapper_model.swap(frame[y:y+h, x:x+w])\n\t\t  \n\t\t          # Resize and blend swapped face into the original frame\n\t\t          resized_face = cv2.resize(swapped_face, (w, h))\n\t\t          mask = np.full((h, w), 255, dtype=np.uint8)\n\t\t          mask = feather_edges(mask, 10)\n\t\t          for c in range(0, 3):\n\t\t              frame[y:y+h, x:x+w, c] = frame[y:y+h, x:x+w, c] * (1\n\t - mask/255.0) + resized_face[:, :, c] * (mask/255.0)\n\t\t  \n\t\t      return frame\n\t\t  \n\t\t  # Worker Function for Face Detection\n\t\t  def face_detection_worker(input_queue, output_queue, gpu_id, tensorrt_model):\n\t\t      \"\"\"\n\t\t      Worker function for face detection. Runs on a separate thread.\n\t\t      :param input_queue: Queue for incoming frames.\n\t\t      :param output_queue: Queue for outgoing frames after detection.\n\t\t      :param gpu_id: GPU ID for this worker.\n\t\t      :param tensorrt_model: TensorRT optimized model for detection.\n\t\t      \"\"\"\n\t\t      while True:\n\t\t          frame_info = input_queue.get()\n\t\t          if frame_info is None:\n\t\t              break\n\t\t          frame_counter, frame = frame_info\n\t\t          detections = detect_objects(tensorrt_model, frame, gpu_id)\n\t\t          output_queue.put((frame_counter, frame, detections))\n\t\t  \n\t\t  # Worker Function for Face Swapping\n\t\t  def face_swapping_worker(input_queue, output_queue, gpu_id, swapper_model):\n\t\t      \"\"\"\n\t\t      Worker function for face swapping. Runs on a separate thread.\n\t\t      :param input_queue: Queue for incoming frames with detections.\n\t\t      :param output_queue: Queue for outgoing frames after swapping.\n\t\t      :param gpu_id: GPU ID for this worker.\n\t\t      :param swapper_model: Model for face swapping.\n\t\t      \"\"\"\n\t\t      while True:\n\t\t          frame_info = input_queue.get()\n\t\t          if frame_info is None:\n\t\t              break\n\t\t          frame_counter, frame, detections = frame_info\n\t\t          swapped_frame = swap_faces(detections, frame, swapper_model, gpu_id)\n\t\t          output_queue.put((frame_counter, swapped_frame))\n\t\t  \n\t\t  # Main Function to Play RTSP Stream and Process Frames\n\t\t  def play_rtsp_stream(rtsp_url, tensorrt_model_paths, swapper_model_paths):\n\t\t      \"\"\"\n\t\t      Main function to play RTSP stream and process frames using parallel workers.\n\t\t      :param rtsp_url: URL of the RTSP stream.\n\t\t      :param tensorrt_model_paths: Paths to TensorRT models for face detection.\n\t\t      :param swapper_model_paths: Paths to models for face swapping.\n\t\t      \"\"\"\n\t\t      gst_pipeline = create_gstreamer_pipeline(rtsp_url)\n\t\t      vid_cap = cv2.VideoCapture(gst_pipeline, cv2.CAP_GSTREAMER)\n\t\t  \n\t\t      detection_queue = queue.Queue()\n\t\t      swapping_queue = queue.Queue()\n\t\t      output_queue = queue.Queue()\n\t\t  \n\t\t      detection_workers = [threading.Thread(target=face_detection_worker, args=(detection_queue, swapping_queue, gpu_id, model_path))\n\t\t                           for gpu_id, model_path in enumerate(tensorrt_model_paths)]\n\t\t      for worker in detection_workers:\n\t\t          worker.start()\n\t\t  \n\t\t      swapping_workers = [threading.Thread(target=face_swapping_worker, args=(swapping_queue, output_queue, gpu_id, model_path))\n\t\t                          for gpu_id, model_path in enumerate(swapper_model_paths)]\n\t\t      for worker in swapping_workers:\n\t\t          worker.start()\n\t\t  \n\t\t      frame_counter = 0\n\t\t      try:\n\t\t          while vid_cap.isOpened():\n\t\t              success, frame = vid_cap.read()\n\t\t              if not success:\n\t\t                  break\n\t\t  \n\t\t              detection_queue.put((frame_counter, frame))\n\t\t              frame_counter += 1\n\t\t  \n\t\t              if not output_queue.empty():\n\t\t                  counter, swapped_frame = output_queue.get()\n\t\t                  cv2.imshow('Processed Frame', swapped_frame)\n\t\t                  if cv2.waitKey(1) & 0xFF == ord('q'):\n\t\t                      break\n\t\t      except Exception as e:\n\t\t          print(f\"Error processing video stream: {e}\")\n\t\t      finally:\n\t\t          vid_cap.release()\n\t\t          cv2.destroyAllWindows()\n\t\t  \n\t\t          for _ in detection_workers:\n\t\t              detection_queue.put(None)\n\t\t          for _ in swapping_workers:\n\t\t              swapping_queue.put(None)\n\t\t  \n\t\t          for worker in detection_workers + swapping_workers:\n\t\t              worker.join()\n\t\t  \n\t\t  # Example usage\n\t\t  play_rtsp_stream('rtsp://example.com/stream', ['path_to_tensorrt_model_gpu1', 'path_to_tensorrt_model_gpu2'],\n\t\t                   ['path_to_swapper_model_gpu1', 'path_to_swapper_model_gpu2'])\n\t\t  \n\t\t  ```\n\t- [iperov/DeepFaceLive: Real-time face swap for PC streaming or video calls (github.com)](https://github.com/iperov/DeepFaceLive)\n\t- ![image.png](../assets/image_1706624390895_0.png){:height 493, :width 1219}\n\t-\n\t- ![image.png](../assets/image_1706626142618_0.png)\n\t-\n- ## Rough notes to be integrated\n\t- [[Head Gaze]]\n\t- https://www.linkedin.com/posts/bradley-wilson_roboflow-supervision-is-the-open-source-swiss-activity-7155297916453015552-KIPV?utm_source=share&utm_medium=member_desktop\n-",
        "link_types": [
            "KnoWhere",
            "PEOPLE👱",
            "NVIDIA Omniverse",
            "Face Swap",
            "Segmentation and Identification",
            "Head Gaze"
        ],
        "file_size": 15791
    },
    {
        "id": "State of the art in AI.md",
        "name": "State of the art in AI",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # A look at 2023\n  id:: 65a2a968-c150-4dca-8ddc-902f29a8d7e0\n\t- <iframe src=\"https://spectrum.ieee.org/ai-index-2024\" style=\"width: 100%; height: 600px\"></iframe>\n- # Looking ahead\n\t- ## Humans are horrible at forecasting.\n\t\t- These are the same biases identified in [Confusion Of Confusions 1688 : Joseph de la Vega](https://archive.org/details/confusion-of-confusions-1688). We are just awful at it.\n\t\t\t- Authority bias\n\t\t\t- Recency bias\n\t\t\t- Impatience and \"do something syndrome\"\n\t\t- ```With so much changing so quickly, we need to take predictions with a grain of salt, but that doesn’t mean we can’t say anything useful about the coming year in AI. To ground ourselves, we can start with two quotes that should inform any estimates about the future. The first is Amara’s Law “We tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run.” Social change is slower than technological change. We should not expect to see immediate global effects of AI in a major way, no matter how fast its adoption (and it is remarkably fast), yet we certainly will see it sooner than many people think.```\n\t\t\t- - from [Signs and Portent by Ethan Mollick\n\t\t\t\t- [One Useful Thing](https://www.oneusefulthing.org/p/signs-and-portents)\n\t\t- [[Update Cycle]] reminder to update this page!\n\t\t\t- [Roy Amara Oxford Reference](https://www.oxfordreference.com/display/10.1093/acref/9780191826719.001.0001/q-oro-ed4-00018679)\n\t\t\t- [AI Index Report 2024 – Artificial Intelligence Index (stanford.edu)](https://aiindex.stanford.edu/report/)\n\t\t\t- [I. From GPT-4 to AGI: Counting the OOMs - SITUATIONAL AWARENESS (situational-awareness.ai)](https://situational-awareness.ai/from-gpt-4-to-agi/)\n\t\t\t- ![photo_2024-06-05_08-47-39.jpg](../assets/photo_2024-06-05_08-47-39_1717573793476_0.jpg){:width 600}\n\t- ## [[Hardware and Edge]] because SO much compute is just idling in pockets and desks.\n\t\t- Mercedes and VW now have ChatGPT4 integrated into their cars. Ford have Alexa, and when that inevitably upgrades so will all Fords.\n\t\t- Lots more hardware for consumer AI, lots more Edge and task specific inferencing. Lot more edge meets cloud. Some more local inferencing.\n\t\t- {{tweet [https://twitter.com/llama_index/status/1745148547560059277}}\n\t\t- {{embed ((659e5979-c2de-4138-b2df-ede79790ee6d))}}\n\t- ## [[Social contract and jobs]]\n\t\t- {{embed ((659a9229-e9c0-485f-b58a-601b68b7edd0))}}\n\t- ## [[Politics, Law, Privacy]]\n\t\t- 🟢 Half the world goes to the polls this year. More than 50 countries, 4B people.\n\t\t- [How OpenAI is approaching 2024 worldwide elections](https://openai.com/blog/how-openai-is-approaching-2024-worldwide-elections)\n\t\t- It's not just deepfakes, but adverts, and influencer material on social media. 100x the number with 1/10th the engagement is still a 10x positive for free.\n\t\t\t- 🟢 This is Professor [Ethan Mollick | LinkedIn](https://www.linkedin.com/in/emollick/) using HeyGen and 30s of footage to create a deepfake.\n\t\t\t- [One Useful Thing | Ethan Mollick | Substack](https://www.oneusefulthing.org/) [[Education]] and [[Proprietary Large Language Models]] blog\n\t\t\t\t- His most recent post is [Signs and Portents](https://www.oneusefulthing.org/p/signs-and-portents) and you should check it.\n\t\t\t- ![1704433632082.mp4](../assets/1704433632082_1704449202180_0.mp4)\n\t\t- Autodial chatbots that can have plausible and convincing conversations with voters. I briefly saw someone had made one of these using a $20 GPT subscription.\n\t\t- ![image.png](../assets/image_1704292836040_0.png)\n\t\t- [Kyle Taylor: books, biography](https://www.amazon.co.uk/stores/Kyle-Taylor/author/B09G759JR3?)\n\t\t- He talks about something I have similarly been saying:\n\t\t\t- In the event of a complete breakdown of trust in digital information channels people will simply choose only to trust their priors.\n\t\t\t- This is a fracturing of the information space, effectively bubbles of one. [[Death of the Internet]] [[Social contract and jobs]]\n\t\t- ### The UK situation.\n\t\t- Every time a phase change of technology has been introduced there has been a fundamental shift in governance structures. These take time to play out. Electronic communication allowed global awareness of corruption, and there is a well documented breakdown of [[Trust and Safety]] since. We can perhaps see this in the way that leaders are abandoning the pretence of 'norms' in the West.\n\t\t- More agile (emerging?) economies / countries may be able to take far more advantage, if they are allowed to, but make no mistake, the UK is currently well positioned. - 🟢 The UK is systemically well positioned to deal with sudden change, because the vertical integration of ministries allows them to be spun up and down in response to change regardless of the leadership. An agile AND persistent civil service can be effective in times of stress.\n\t\t\t- [Ian Hogarth to lead UK’s AI Foundation Model Taskforce\n\t\t- he's actually a great choice](https://www.gov.uk/government/news/tech-entrepreneur-ian-hogarth-to-lead-uks-ai-foundation-model-taskforce)\n\t\t\t- [Welcome to State of AI Report 2023](https://www.stateof.ai/)\n\t\t\t- America is supportive of UK positioning around [[Trust and Safety]]. They have a compatible legal framework, and we are doing useful work that they are ill positioned to do in exploring the legal space.\n\t\t\t- This perhaps explains the £2.5B [[Infrastructure]] and training investment plan by Microsoft.\n\t\t\t- These companies are **as big** as the UK. Beware tech bros bearing gifts?\n\t\t\t  ![image.png](../assets/image_1704045603470_0.png)\n\t\t\t- All this makes funding seem disproportionately risk sensitive right now.\n\t- ## The big remaining shoe to drop is the robots. 2-5 years?\n\t- [This robot can tidy a room without any help | MIT Technology Review](https://www.technologyreview.com/2024/02/01/1087445/this-robot-can-tidy-a-room-without-any-help/)\n\t- <iframe src=\"https://arxiv.org/pdf/2401.12202.pdf\" style=\"width: 100%; height: 600px\"></iframe>\n\t- ![1705344178256.mp4](../assets/1705344178256_1705352121045_0.mp4)\n\t- # To Close\n\t\t- ## The age of the informational Agent\n\t\t\t- As trust in the internet evolves, the situation will change and adapt as people learn to use informational agents. Intentional UX will allow users to ask their AI to bring them the information they want from a far more decentralised and confusing internet. This will promote incredible diversity in humans as they fracture somewhat into informational enclaves.\n\t\t\t- Two future scenarios include the rise of AI in Truth Verification and Education. AI will become sophisticated enough to verify the truthfulness of information on the internet, combating the spread of misinformation and ensuring that users have access to accurate and reliable informa- tion. AI will also become an integral part of education, acting as a personalised tutor that adapts to each student's learning style and pace, revolutionising the way we learn and acquire new skills.\n\t\t\t- Money will change: Next -Later  : Money will increasingly be spent by machines on behalf of human intent. Algorithms will bargain and arbitrage on behalf of their owner/user, for human and machine services, and for ideas, algorithms, and good; globally. This will smooth out the operation of money globally.\n\t\t\t- Ubiquitous multi-modal UX: Next to Later The future will see the rise of ubiquitous displays, computing [43], and interfaces\n\t\t\t- screens and projections seamlessly integrated into our environments. These displays will not only provide information and entertainment but will serve as interfaces for our interactions with AI. Gesture may come to the fore, and subvocalisation to talk to personal AIs will be possible.\n\t- ### [Industry perspective](https://chat.openai.com/g/g-xhDmZxdJW-industry-predictions-engine/)  << this is 133 industry reports in a GPT I have made.\n\t- <iframe src=\"https://chat.openai.com/share/bbe7c775-b764-40c3-b87e-cf87fdd1a3a7\" style=\"width: 100%; height: 600px\"></iframe>\n- [[rework based on gpt]]\n- This is a [[presentation]] slide and the next slide is",
        "link_types": [
            "Update Cycle",
            "Hardware and Edge",
            "Social contract and jobs",
            "Politics, Law, Privacy",
            "Education",
            "Proprietary Large Language Models",
            "Death of the Internet",
            "Social contract and jobs",
            "Trust and Safety",
            "Trust and Safety",
            "Infrastructure",
            "rework based on gpt",
            "presentation"
        ],
        "file_size": 8112
    },
    {
        "id": "Bitcoin Mining and Energy.md",
        "name": "Bitcoin Mining and Energy",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # Mining and Energy concerns\n  id:: 65b8aeb5-9c3f-4e4c-9d55-2e2b3166744c\n\t- ## Mining process overview\n\t- Bitcoin mining is the process of adding public transactions into the ledger, in return for two economic rewards, paid in Bitcoin. These are the mining fee, and the block reward. The transactions which are added into the next 'block' of the chain are selected preferentially based on the fee they offer, which is up to the user trying to get their transaction into the chain. This can be within the next 10 minutes (next block), or a gamble out toward 'never' depending how competitive the network is at any time. Miners try to find a sufficiently low result from a cryptographic hash function \\[[53]\\](../assets/a random process), and upon finding it, they can take their pre-prepared 'block' of transactions sourced from their local queue (mempool), and add it into the chain, for confirmation by other miners. In return they take all the fees within that mined block, and whatever the block reward is at the time. When the network started the block reward was 50 Bitcoin, but has [halved](https://ma.ttias.be/dissecting-code-bitcoin-halving/) repeatedly every 210,000 blocks (four years) and now stands at 6.25 BTC. The rate of mining is kept roughly at one block every 10 minutes, by a difficulty adjustment every 2016 blocks (2 weeks). This in a complex interdependent mechanism and is explained very well in [this article](https://bitcoinmagazine.com/technical/how-mining-protects-the-bitcoin-network). These components are explained in slightly more detail later.\n\t- ## Energy & policy response\n\t\t- ![Figure 3.15: [Bitcoin network vs TOP500 supercomputers](https://twitter.com/blockbain/status/1432824720727105539)](../assets/top500.jpg)\n\t\t- ![Figure 3.16: ](../assets/energycompare.jpg)\n\t\t\t- ![Figure 3.17: [Bitcoin Magazine](https://bitcoinmagazine.com/business/introducing-cbei-a-new-way-to-measure-bitcoin-network-electrical-consumption)](../assets/energyComparison.png)\n\t- At the end of 2022 it is thought to be the case that the only profitable miners are the large scale companies who are also providing load balancing services to energy companies. This is unusual in the history of mining, and the situation will likely change over time. This is not to say that all mining is, or should be, so concentrated. Anyone running the hashing algorithm can [get lucky](https://twitter.com/ckpooldev/status/1485585814419812356) and claim the block reward. PoW ties the value of the 'money' component of Bitcoin directly to energy production. This is not a new idea. Henry Ford proposed an intimate tie between energy and money to create a separation of powers from government, as can be seen in Figure [3.18](https://arxiv.org/html/2207.09460v11/#Ch3.F18 \"Figure 3.18 ‣ Energy & policy response ‣ 3.4.2 Mining and Energy concerns ‣ 3.4 Bitcoin ‣ Chapter 3 DLT, Blockchain, and Bitcoin ‣ Part I State of the art\").\n\t\t- ![Figure 3.18: [Intimate tie between energy and money, Henry Ford](https://www.nytimes.com/1921/12/06/archives/mr-fords-energy-dollar.html)](../assets/energyNYT.png)\n\t- The potential ecological footprint of the network has always been a concern; Hal Finney was [thinking about this issue](https://twitter.com/halfin/status/1153096538) with a mature Bitcoin network as early as August 2009, and [a debate](https://satoshi.nakamotoinstitute.org/posts/bitcointalk/threads/167/#35) on the Bitcoin mailing lists called the mining process \"thermodynamically perverse\".\n\t- In a recent email release during a court case a new Satoshi Nakamoto email from May 2009 shows that this was a concern to the designer of the protocol.\n\t\t- ![Image](https://pbs.twimg.com/media/GHB0S8AXEAA9VBp?format=png&name=large){:height 463, :width 879}\n\t- The most cited negative analysis on the matter by Mora et al sees Bitcoin mining alone warming the planet above 2 degrees \\[[54]\\].\n\t- [Proponents of the technology](https://electricmoney.org/) say that the balance shifted dramatically in 2021 with China outright banning the technology; this has forced the bulk of the energy use [toward the USA](https://docs.google.com/spreadsheets/d/1E7489rM7Q62oXwk1f4NUlMvok9noAbpYfTynY2VTyww/edit#gid=0), and away from 'dirty coal' as seen in Figure [3.19](https://arxiv.org/html/2207.09460v11/#Ch3.F19 \"Figure 3.19 ‣ Energy & policy response ‣ 3.4.2 Mining and Energy concerns ‣ 3.4 Bitcoin ‣ Chapter 3 DLT, Blockchain, and Bitcoin ‣ Part I State of the art\").\n\t\t- ![Figure 3.19: Hash rate [suddenly migrates](https://ccaf.io/cbeci/ining_map) from China \\[Reuse rights requested\\]](../assets/x2.png)\n\t- [\"As we get more renewable generation, in particular wind \\[which\\] is operating at night ... we have to find a home for it, otherwise we have to turn the wind down. It's such a great resource we shouldn't turn it down. Bitcoin mining or what some call crypto has found a way to come into our markets and take some of that wind in off-peak periods. Then when we get to peak period times they are very quick to remove themselves from the market as prices increases The fact that we can turn down whenever we need the power for other customers is fantastic. We can use that crypto currency to soak up that excess generation when there's a lot of that, and find a home for more solar and more wind to come to our grid. Then they reduce consumption when we need that power for other customers. So it's a great balancing act. Most other datacenters \\[such as\\] Microsoft or Amazon have other customers to serve every other day, so they can't just turn off. But these crypto customers can. If the cost of energy gets too high they can remove themselves from the market. They are also helpful if we lose a generator. They can quickly respond to that frequency disruption and allow us to balance our grid.\"\\ ] Flexible load balancing is entering the [mainstream news cycle](https://www.forbes.com/sites/jemmagreen/2023/01/27/why-no-one-saw-the-success-of-demand-response-coming/?) as and is gaining traction in legislative bodies. This [\"global energy market revolution\"](https://www.citadel21.com/bitcoin-is-the-first-global-market-for-electricity-and-will-unleash-renewables) is explained by Tabatabai of Modo Energy. Incredibly Bitcoin mining in Texas is now making the grid both more reliable and cheaper for consumers. In the UK we have similar problems because wind power is not evenly distributed, and moving it around is complex and expensive, and the whole system needs smoothing out with [gas plants](https://archy.deberker.com/the-uk-is-wasting-a-lot-of-wind-power/).\n\t- There is growing interest and adoption of so called [\"stranded energy mining\"](https://www.bloomberg.com/news/articles/2022-06-01/oman-backs-u-s-firm-mining-crypto-to-cut-natural-gas-flaring) which cannot be effectively transmitted to consumers, and is thereby sold at a huge discount while also [developing power capacity](https://www.renewableenergyworld.com/wind-power/900mw-wind-farm-to-power-bitcoin-mining-operation/), without the [usual constraints](https://batcoinz.com/the-renewable-energy-cannot-happen-without-bitcoin-mining%ef%bf%bc/) \\[[60]\\]. One such example is [\"Gridless\" in Kenya](https://gridlesscompute.com/news/), which seeks to harness abundant green energy resources in rural areas with the hope of kick-starting economic growth. This feature of the network first came to popular attention in 2020 when Stevens, CEO of Stoneridge capital included the following text in a letter to shareholders within their [annual report](https://www.stoneridgefunds.com/documents/AnnualReport.pdf?v=4):\n\t\t- \"Bitcoin mining is the only profitable use of energy in human history that does not need to be located near human settlement to operate. The long-term implications of this are world changing and hiding in plain sight.\"\n\t- ![Figure 3.20: [Climate tech investor Daniel Batten asserts that methane capture could highly impactful](https://twitter.com/DSBatten/status/1566735902617276416)](../assets/methane.png)\n\t- Cheikosman, a policy analyst for the World Economic Forum (somewhat surprisingly) [wrote](https://www.weforum.org/agenda/2022/03/crypto-energy-consumption/?) [\"Crypto is becoming an essential part of developing a carbon-neutral energy grid and has made it economically viable to invest in, develop and build renewable energy power generation.\"]  This is explored in detail by Ibanez et al \\[[61]\\].\n\t- [Morgan Stanley research suggesting that BTC miners are the fastest path to put new data centers online because they already have access to huge amounts of power.](https://twitter.com/mikealfred/status/1781333730071896152)\n\t  {{twitter https://twitter.com/mikealfred/status/1781333730071896152}}\n\t- The most cited example of building capacity before grid connection is El Salvador's 'volcano mining' proposal, which is supporting their national power infrastructure plans. Uzbekistan seems to be promoting a [similar model](https://www.reuters.com/business/finance/uzbekistan-legalises-solar-powered-crypto-mining-2022-05-04/) with zero tax provided the Bitcoin mining companies build out their own solar infrastructure. A more poignant example is the [Mechanicville hydro plant in the USA](https://www.timesunion.com/news/article/Mechanicville-hydro-plant-gets-new-life-16299115.php). The refurbishment of this 123 year old power plant is being funded by Bitcoin mining. This is the [\"buyer of last resort\"](https://www.lynalden.com/bitcoin-energy/) model first [advanced by Square Inc](https://squareup.com/us/en/press/bcei-white-paper).\n\t- Conversely it might be that vertical integration of Bitcoin mining [within legacy fossil fuel stations](https://bitcoinmagazine.com/business/oil-companies-partner-with-bitcoin-miners) gives them a new lease of life. New York State has dealt with this kind of threat by imposing a moratorium on new, fossil fuel powered mining activity. On a global stage something as portable and industrial as Bitcoin mining will have unintended impacts on fragile energy systems, as has happened in [South Ossetia](https://ceobs.org/environmental-governance-in-frozen-conflicts/) and [Kazakhstan](https://restofworld.org/2022/crypto-miners-fleeing-kazakhstan/) (note [Russia has stepped into this](https://thenewscrypto.com/kazakhstans-crypto-miners-to-acquire-electricity-from-russia/) mess). Undeniably the [consensus position](https://time.com/6193004/crypto-climate-impact-facts/) is that it's overall very negative, (with some caveats) and this will [probably]  persist. Perhaps though if it's happening anyway, then finding utility of the asset might mitigate the net harm.\n\t- More pragmatically, Baur and Oll found that [\"Bitcoin investments can be less carbon intensive than standard equity investments and thus reduce the total carbon footprint of a portfolio.\"[\\[] [62][\\]] ] . Perhaps of note for the near future is that KPMG whose investment was mentioned in the introduction also matched their position in the space with equivalent carbon offsets. This may provide an investment and growth model for others.\n\t- The first US-based [nuclear-powered Bitcoin mining facility](https://www.businesswire.com/news/home/20230305005096/en/TeraWulf-Announces-Energization-and-Rapid-Deployment-of-Mining-Operations-at-the-Nautilus-Facility-in-Pennsylvania) has just opened in Pennsylvania. The facility has been completed by Cumulus Data, a subsidiary of independent power producer Talon Energy. Talon Energy owns the adjacent 2.5 GW Nuclear Power Plant and has been dabbling in Bitcoin mining for some time, opening a zero carbon Bitcoin mining facility in collaboration with Terawolf in August 2021. The new facility will operate with a maximum capacity of 48 MW, drawing on excess power from the nuclear plant. By locating the mining facility on the combined 1200 acre campus, there is no intermediation by legacy electric transmission and distribution utilities, as the mining is directly connected to the power station. Cumulus Data is in the process of building two additional 48 MW facilities and has identified 18 additional Talon Energy sites with potential to host data centres directly connected to electricity generation infrastructure. In general, there is a shift in attitudes towards nuclear in the US. The enormous benefit to this model stems from the cots associated with scaling down atomic power output to match grid requirements. By co-locating in this way the reactor can work at highest efficiency all the time, and can earn money from the generation of Bitcoin when the grid is unable to accept the energy. It is increasingly possible to find excited talk about funding smaller more pragmatic nuclear power plants using the cost benefits of the Bitcoin mining model, though this remains untested.\n\t- The power commitment to the network is variously projected [to increase](https://www.nature.com/articles/s41558-018-0321-8), or [level off over time](https://assets.website-files.com/614e11526f6630959fc98679/616df63a27a7ec339f5e6a80_NYDIG-BitcoinNetZero_SML.pdf). The emission schedule of the code suggests that the energy usage will decrease exponentially over time, and indeed many analysts feel that it has peaked due to a combination of factors. It's one of the maddening unknowns of the technology how this will all pan out. The [industry now argues](https://www.forbes.com/sites/martinrivers/2022/04/03/is-bitcoin-really-that-bad-for-the-environment/?sh=6a3203427143) that economic pressures mean that most of the 'hashrate' is [generated by renewable energy](https://bitcoinminingcouncil.com/q4-bitcoin-mining-council-survey-confirms-sustainable-power-mix-and-technological-efficiency/)\\[[63]\\]. As a recent example of this trend Telsa (Elon Musk), Block (Twitters Jack Dorsey), and Blockstream (Adam Back) are teaming up to [mine with solar energy](https://www.cnbc.com/2022/04/08/tesla-block-blockstream-to-mine-bitcoin-off-solar-power-in-texas.html) in Texas.\n\t- Paez and Cross [prepared a paper](https://uploads-ssl.webflow.com/627aa615676bdd1d47ec97d4/62f41b9ce54e014f9869efa7_OSTP.docx.pdf) for the White House Office of Science and Technology Policy, submitted through the Bitcoin Policy Institute, which is a growing thinktank for academics and industry leaders. Their summary points echo the assertions made here, but they provide rich additional referencing for those who wish to dig deeper into this:\\\n\t- [Bitcoin's value---its economic value and promotion of American     values and American national interests---must frame any discussion     of its environmental impact.]      [Bitcoin's value is inherently tied to its consensus mechanism:     proof of work.]      [While bitcoin mining is energy-intensive, its energy use is often     overestimated and improperly characterized as a function of     transaction volume.]      [Due to bitcoin's exponentially decreasing schedule of issuance,     mining's actual emissions are likely to peak at under 1% of global     emissions, even if prices rise more than tenfold within the     decade.]      [Mining's profile as a consumer of energy is unique: extremely     cost-sensitive, and invariant across times and     locations.]      [Bitcoin mining, as a buyer of first and last resort, incentivizes     the buildout of renewable power production. As a controllable load     resource (CLR) bitcoin mining also strengthens the grid, allowing it     to reliably function at a high level of renewable     penetration.]      [Mining's energy use is increasingly non-rival, trending towards a     diet of renewables andstranded, wasted energy resources such as     flared methane.]\n\t- [The debate](https://www.youtube.com/watch?v=6LP8G-oZnEs) whether this consumption is 'worth' it is [complex](https://www.utilitydive.com/news/bitcoin-mining-as-a-grid-resource-its-complicated/617896/) and [rapidly evolving](https://www.aei.org/technology-and-innovation/no-hearing-on-bitcoins-energy-use-is-complete-without-nic-carter/). Useful examples of this are:\n\t\t- the [online     pushback](https://www.zerohedge.com/crypto/questionable-ethics-anti-bitcoin-esg-junk-science)     to an academic article by PhD candidate de Vries et al.     \\[[64]\\]\n\t\t- the assertion that the widely cited Mora er al. paper in Nature     \\[[54]\\] was based     on an [undergraduate class     discussion](https://twitter.com/NateHawaii/status/1460706785216450560),     and has had an outsized effect on global policy.\n\t- It is somewhat confusing that positive views are coming only from diverse and non-specialist voices in the community, and never the academic community, but the shortcomings they point out in the supposedly considered articles such as Mora et al \\[[54]\\] are easily verified. Academia seems [poorly positioned](https://bitcoinmagazine.com/culture/bitcoin-could-never-be-invented-in-a-university) to pivot to this subject, as an ethical bar has to be established before research can commence, and the field is too new to make this an affordable task. This stuff is existentially important to the whole technology. Is a trillion dollar asset which [potentially replaces](https://www.theheldreport.com/p/bitcoin-vs-gold) the money utility of [[Gold]], but doesn't need to be stored under guard in vaults (Figure [3.21](https://arxiv.org/html/2207.09460v11/#Ch3.F21 \"Figure 3.21 ‣\n\t- Energy & policy response ‣ 3.4.2 Mining and Energy concerns ‣ 3.4 Bitcoin ‣ Chapter 3 DLT, Blockchain, and Bitcoin ‣ Part I State of the art\")), worth the equivalent power consumption of clothes dryers in North America? Probably not with the current level of adoption, but this is an experiment in replacing global money. If that were to happen then Bitcoin would be around 50 times more efficient than the current system according to Khazzaka \\[[65]\\]. To be clear it's not the position of this book that replacing Fiat money is a good idea, but the experiment is being run regardless. This is explored in it's own chapter later.\n- Positive skewing reports:\n\t- [Publicly-Traded Bitcoin Miner Runs on 100% Renewable Energy, Audit Confirms\n\t\t- Bitcoin Magazine\n\t\t- Bitcoin News, Articles and Expert Insights](https://bitcoinmagazine.com/business/publicly-traded-bitcoin-miner-runs-on-renewable-energy-audit-confirms)\n\t-\n\t- [Stranded: How Bitcoin is Saving Wasted Energy and Expanding Financial Freedom in Africa\n\t\t- Bitcoin Magazine\n\t\t- Bitcoin News, Articles and Expert Insights](https://bitcoinmagazine.com/check-your-financial-privilege/stranded-bitcoin-saving-wasted-energy-in-africa)\n\t- Institute 1: [Tikula Research Network (Africa)](https://tikula.net/_files/ugd/e1de83_6945ec0a6d074146a3503cdd14d475dc.pdf)\n\t- Date: Jan 2024 Key Finding: Microgrids can deliver electricity to 600 sub-Saharan Africans; Bitcoin mining can get these renewable microgrids operational quickly and profitably Source:\n\t- Institute 2: Institute of Risk Management (Europe)\n\t- ![Bitcoin and the Energy Transition From Risk to Opportunity (5).pdf](../assets/Bitcoin_and_the_Energy_Transition_From_Risk_to_Opportunity_(5)_1707924193140_0.pdf)\n\t- Date: 22 Sept 2023 Key Finding: Bitcoin mining supports renewable transition\n\t- Institute 3: [KPMG (N.America)](https://kpmg.com/kpmg-us/content/dam/kpmg/pdf/2023/bitcoins-role-esg-imperative.pdf)\n\t- Date: 1 Aug 2023 Key Finding: Bitcoin mining offers a range of benefits across the ESG Framework\n- # Bitcoin and AI data centres\n\t- Bitcoin miners like Iris Energy are uniquely positioned with access to large amounts of power and data center capacity. This is becoming increasingly scarce and valuable as demand for AI computing grows exponentially.\n\t- The Bitcoin mining data centers can be repurposed to provide AI cloud services by swapping out Bitcoin mining ASICs for Nvidia GPUs. This allows miners to monetize their power and infrastructure for both crypto mining and AI.\n\t- There are parallels between the Bitcoin ASIC and AI GPU markets - both have a dominant player (Bitmain for ASICs, Nvidia for GPUs) and prices are set based on what the market is willing to pay vs cost of production.\n\t- The growth in AI seems to be shifting the narrative and reducing criticism around Bitcoin mining's energy use. As people realize AI's value, they accept that the energy use is justified, similar to Bitcoin.\n\t- Major banks like Morgan Stanley are now writing serious research reports on how Bitcoin miners are positioned to support AI's growth by providing much-needed power capacity. This validates the industry's maturity.\n\t- Time to accessing power is becoming the key constraint and source of value as demand for AI computing capacity far outstrips supply. Bitcoin miners with existing power access have a major advantage.\n\t- By locating in areas with excess renewable energy that can't be fully exported, Bitcoin miners are actually helping make these renewable installations more economically viable and efficient.\n\t- [Mike Alfred on X: \"Morgan Stanley out with new research suggesting that BTC miners are the fastest path to put new data centers online because they already have access to huge amounts of power. Their models show BTC miners trade at a large discount to the intrinsic value of their secured power. https://t.co/rwJJLBPdYN\" / X (twitter.com)](https://twitter.com/mikealfred/status/1781333730071896152)\n\t- {{twitter https://twitter.com/mikealfred/status/1781333730071896152}}\n\t-",
        "link_types": [
            "Gold"
        ],
        "file_size": 21399
    },
    {
        "id": "Virtual Production.md",
        "name": "Virtual Production",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # Virtual Production\n-\n- Relighting [[AI Video]] [[2402.18848] SwitchLight: Co-design of Physics-driven Architecture and Pre-training Framework for Human Portrait Relighting (arxiv.org)](https://arxiv.org/abs/2402.18848)\n\t- [Beeble\n\t - AI Lighting for Filmmakers](https://www.beeble.ai/)\n\t-\n- ### [[Unreal]] & Virtual Production\n- Matthew Ball is an [expert on Metaverse](https://www.matthewball.vc/).He explained his vision and concerns with regard to metaverse in an[adaptation of hisbook](https://time.com/6197849/metaverse-future-matthew-ball/)[[ball2020metaverse]]featured on Time Magazine (Figure<a href=\"#fig:time\" data-reference-type=\"ref\" data-reference=\"fig:time\">7.5</a>).\n  ![]./assets/e35c9e5d7580ee3fd48bd0ac43cc26026e379cd6.png\n  Time magazine Metaverse Cover 2022\n- He [talks about Epic’s Unrealengine](https://www.matthewball.vc/all/epicprimer1) and identifies whathe calls the Epic Flywheel for games manufacture seen in Figure<a href=\"#fig:epicflywheel\" data-reference-type=\"ref\" data-reference=\"fig:epicflywheel\">7.6</a>.\n  ![]./assets/354b361cffb9d11b9e425cb2d1307ed933b808d5.jpg\n  Epic games flywheel by Matthew Ball\n- Epic is a behemoth and has made better business development decisions,and have a better technology than their main competitor Unity3D. Unitydidn’t make the cut for this book, though their technology is great.Their recent merger with a [malwaremanufacturer](https://www.pcgamer.com/unity-is-merging-with-a-company-who-made-a-malware-installer/)and a history of poor data privacy have removed them from considerationat this time.\n- ICVFX (in camera virtual effects) or “Volume shooting” is theapplication of large, bright LED walls to film and TV production. Morebroadly than this Virtual Production is a suite of real-timetechnologies that weaves through pre and post production to acceleratecreativity, and reduce costs. These are collaborative, and oftendistributed tasks:\n-\n\t - Set ideation and design\n-\n\t - Dry runs with actors to plan shots in mixed reality\n-\n\t - Virtual set design and storyboarding in full VR\n-\n\t - Lighting design\n-\n\t - Shot camera track design (movement, focus, lens choices etc)\n  ![]./assets/ce7288a4d695eb0437e09074d5aae06823e7b339.jpg\n  John O’Hare (author) with a virtual production robot.\n- ### Different modalities\n- #### Controllers, gestures, interfaces\n- ##### Accessibility\n-\n\t - Mouse and keyboard\n-\n\t - Games controller\n-\n\t - Body tracking\n-\n\t - Hand tracking and gesture\n-\n\t - Voice\n-\n\t - Microgestures\n-\n\t - Eye gaze\n-\n\t - Assumption systems\n-\n\t - [Playstation programmable controller](https://blog.playstation.com/2023/01/04/introducing-project-leonardo-for-playstation-5-a-highly-customizable-accessibility-controller-kit/)\n-\n\t - [XBOX accessibility controller](https://www.xbox.com/en-GB/accessories/controllers/xbox-adaptive-controller)",
        "link_types": [
            "AI Video",
            "Unreal",
            "ball2020metaverse"
        ],
        "file_size": 2891
    },
    {
        "id": "Comfy UI for Fashion and Brands.md",
        "name": "Comfy UI for Fashion and Brands",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ## [EVENT INVITE](https://www.eventbrite.co.uk/e/comfy-ui-for-fashion-and-brands-tickets-894342842517)\n- # GUEST WIFI - is the one labelled guest WiFi and you can put any old email in.\n- # j.ohare5@salford.ac.uk\n- # MayEvent\n-\n\t- ## About me\n\t\t- {{embed ((661d5f74-f334-4872-ba92-51244c2fb490))}}\n\t- {{embed ((661d5f74-5dfe-4569-9374-37b63637b3d8))}}\n\t- {{embed ((66314bd7-86ef-4ca2-8f39-704e133ac0a3))}}\n\t- ## Diffusion models from [[Overview of Machine Learning Techniques]]\n\t  collapsed:: true\n\t\t- {{embed ((661d5f76-bb78-4920-949e-76c3dbf66efe))}}\n\t\t- {{embed ((661d5f76-3ffa-4f10-9027-6f8e90601162))}}\n\t- {{embed ((66446c0e-93be-431d-93d4-1e5fa36848c5))}}\n\t- {{embed ((66408f9e-30e0-442b-9aba-9eb51e36a739))}}\n\t- # ComfyUI\n\t\t- Started out as a project by a single coder\n\t\t- Now adopted by the Stability team as their in house engine\n\t\t- Tens of thousands of models and add ons, hundreds of thousands of users\n\t\t- Can form the foundation of a deployable product\n\t\t\t- API for Comfy iteself\n\t\t\t- It's just chaining python scripts, you can isolate those and build\n\t\t- ## Tradeoffs\n\t\t\t- Faster.\n\t\t\t- Incredible control.\n\t\t\t- Steep learning curve.\n\t\t\t- Hard to setup, hard to keep running.\n\t\t- ## Finding all the tools.\n\t\t\t- https://github.com/comfyanonymous/ComfyUI\n\t\t\t- {{renderer :linkpreview,https://github.com/comfyanonymous/ComfyUI}}\n\t\t\t- https://huggingface.co/\n\t\t\t- {{renderer :linkpreview,https://huggingface.co/}}\n\t\t\t- https://civitai.com/\n\t\t\t- {{renderer :linkpreview,https://civitai.com/}}\n\t\t\t- https://www.comfyworkflows.com\n\t\t\t- {{renderer :linkpreview,https://www.comfyworkflows.com}}\n\t- ## Lots of modules, extensions\n\t\t- Papers from the GenAI community get rapidly converted to ComfyUI very quickly.\n\t\t- ### Segmentation\n\t\t\t- ![Segmentation for fashion](https://raw.githubusercontent.com/cozymantis/human-parser-comfyui-node/main/assets/lipexample.png)\n\t\t\t-\n\t\t- ### IpAdapter\n\t\t\t- Image to image conditioning, which is [[style transfer]], which is mashing images together.\n\t\t\t- ![](https://raw.githubusercontent.com/cubiq/ComfyUI_IPAdapter_plus/main/examples/demo_workflow.jpg)\n\t\t- ### 3D models for AR and VR\n\t\t\t- ![image.png](../assets/image_1715528397803_0.png)\n\t\t\t- ![image.png](../assets/image_1715584894585_0.png)\n\t-\n- # May Event workflow with 3D models and VTON try it on.\n\t- [memoryEfficient.json](../assets/memoryEfficient_1715084451554_0.json)\n- # Marco presentation\n\t- ![20240507 - Manchester Hackathon.pdf](../assets/20240507_-_Manchester_Hackathon_1715878110413_0.pdf)\n\t- < link not working let >\n- # Pre event buildout notes (here be dragons)\n  collapsed:: true\n\t- TODO Infrastructure build\n\t\t- DONE Get Ollama bridge working\n\t\t  collapsed:: true\n\t\t\t- [stavsap/comfyui-ollama (github.com)](https://github.com/stavsap/comfyui-ollama)\n\t\t\t- [MinusZoneAI/ComfyUI-Prompt-MZ: 基于llama.cpp的一些和提示词相关的节点，目前包括美化提示词和类似clip-interrogator的图片反推 | Use llama.cpp to assist in generating some nodes related to prompt words, including beautifying prompt words and image recognition similar to clip-interrogator (github.com)](https://github.com/MinusZoneAI/ComfyUI-Prompt-MZ)\n\t\t\t- [xXAdonesXx/NodeGPT: ComfyUI Extension Nodes for Automated Text Generation. (github.com)](https://github.com/xXAdonesXx/NodeGPT)\n\t\t\t- [stavsap/comfyui-ollama (github.com)](https://github.com/stavsap/comfyui-ollama)\n\t\t\t  id:: 6633f4c0-358f-44cf-bf05-d43c75febe36\n\t\t- DONE Backup the working docker\n\t\t- DONE sort the vpn and port forwarding\n\t\t- DONE Check the security\n\t\t- DONE Install the rest of the feature set\n\t\t- DONE Sort the models and Loras\n\t\t- DONE Fire up 3 instances\n\t\t\t- DONE TripoSR (no point, feature dropped)\n\t\t\t- DONE [Zero123](https://github.com/SUDO-AI-3D/zero123plus) (no point, feature dropped\n\t\t\t- DONE CRM\n\t\t- DONE [yisol/IDM-VTON: IDM-VTON : Improving Diffusion Models for Authentic Virtual Try-on in the Wild (github.com)](https://github.com/yisol/IDM-VTON)\n\t\t  collapsed:: true\n\t\t\t- [TemryL/ComfyUI-IDM-VTON: ComfyUI adaptation of IDM-VTON for virtual try-on. (github.com)](https://github.com/TemryL/ComfyUI-IDM-VTON)\n\t\t- TODO [Lllava 8b?](https://huggingface.co/collections/xtuner/llava-llama-3-8b-662a5f95adbe8d58799d7fdb) for descriptions\n\t\t  :LOGBOOK:\n\t\t  CLOCK: [2024-05-06 Mon 09:23:58]--[2024-05-06 Mon 09:23:58] =>  00:00:00\n\t\t  CLOCK: [2024-05-06 Mon 09:23:59]--[2024-05-06 Mon 09:24:00] =>  00:00:01\n\t\t  :END:\n\t\t- DONE Face swap\n\t\t- DONE NSFW filter\n\t\t- DONE Annotations and instructions\n\t\t  :LOGBOOK:\n\t\t  CLOCK: [2024-05-06 Mon 09:25:33]--[2024-05-06 Mon 12:16:24] =>  02:50:51\n\t\t  :END:\n\t\t- DONE Send to Pete to test\n\t\t- DONE Presentation outlines?\n\t\t- DONE Talk to Marco\n\t\t- DONE Next need to fix insightface [as here](https://github.com/cubiq/ComfyUI_IPAdapter_plus/issues/162) but\n\t\t\t- DONE backup first\n\t\t\t  :LOGBOOK:\n\t\t\t  CLOCK: [2024-05-06 Mon 10:23:31]--[2024-05-06 Mon 10:23:31] =>  00:00:00\n\t\t\t  :END:\n\t\t- TODO New nets and workflows? Pete?\n\t\t- DONE Confirm the compute arriving.\n\t\t- DONE Confirm the TV in time?\n\t\t- DONE Fix the windows laptop for delegates\n\t\t- DONE Condition the mac for delegates (come in monday afternoon)\n\t\t- DONE Charge the Rundiffusion account (talking to Tony this afternoon).\n\t\t- DONE Catering\n\t\t- DONE Talk to Marco\n\t\t- DONE Make a presentation for the day (logseq based for me)\n\t\t  :LOGBOOK:\n\t\t  CLOCK: [2024-05-12 Sun 16:41:41]--[2024-05-14 Tue 22:17:47] =>  53:36:06\n\t\t  :END:\n\t\t- DONE Delegate advance communications\n\t\t  :LOGBOOK:\n\t\t  CLOCK: [2024-05-11 Sat 19:58:36]--[2024-05-12 Sun 16:41:31] =>  20:42:55\n\t\t  CLOCK: [2024-05-12 Sun 16:41:35]--[2024-05-14 Tue 22:17:50] =>  53:36:15\n\t\t  :END:\n\t- ## Technical Elements\n\t\t- ## Technical notes\n\t\t\t- For the A6000 CRM docker\n\t\t\t\t- ```text\n\t\t\t\t  machinelearn@MLAI:/mnt/mldata/GenerativeAI$ cd ../githubs/ComfyUI-Docker/\n\t\t\t\t  machinelearn@MLAI:/mnt/mldata/githubs/ComfyUI-Docker$ ls\n\t\t\t\t  docker-compose.yml  docs     megapak      README.zh.adoc  scripts  storage_known_good\n\t\t\t\t  Dockerfile          LICENSE  README.adoc  rocm            storage\n\t\t\t\t  machinelearn@MLAI:/mnt/mldata/githubs/ComfyUI-Docker$  docker run -d -it --rm --name comfyui-mega --gpus '\"device=1\"' -p 8182:8182 -v \"$(pwd)\"/storage:/root -e CLI_ARGS=\"--port 8182\" yanwk/comfyui-boot:megapak\n\t\t\t\t  ```\n\t\t\t- to contact Ollama from within docker\n\t\t\t\t- ```text\n\t\t\t\t  curl http://172.17.0.1:11434/api/generate -d '{\n\t\t\t\t    \"model\": \"llama3-8B\",\n\t\t\t\t    \"prompt\": \"Why is the sky blue?\"\n\t\t\t\t  }'\n\t\t\t\t  \n\t\t\t\t  ```\n\t- # ComfyUI for Fashion and Brands: Event Instructions\n\t  collapsed:: true\n\t\t- ## Introduction\n\t\t\t- Welcome to the ComfyUI for Fashion and Brands event at Dreamlab in MediaCity! We are excited to have you join us for a day of innovation, collaboration, and exploration of generative AI technology in the realm of fashion and product design.\n\t\t\t- Before the event, please take a moment to review the following instructions and ensure that you have the necessary requirements to fully participate in the hackathon.\n\t\t- ## Timing and how to find us.\n\t\t\t- We’re on the 5th floor of Blue Tower at **[HOST](https://www.hostsalford.com/) ,** MediaCityUK.  The door is [opposite Costa Coffee](https://maps.app.goo.gl/APmHgNU7bvrXpRRa7).\n\t\t\t- You can take the tram to MediaCity, using the [free park and ride](https://tfgm.com/ways-to-travel/park-and-ride/parkway-tram) in Trafford.\n\t\t\t- You can also park at the MediaCity multistory car park but be advised it is expensive.\n\t\t\t- The event starts at 10am and runs to 4pm.\n\t\t- ## Schedule\n\t\t\t- Morning session - presentations from the team and guest speaker.\n\t\t\t- Afternoon - breakout hands on\n\t\t\t- Closeout Q&A\n\t\t- ## Workgroup Alignment\n\t\t\t- To ensure a tailored experience, we have divided the event into three workgroups. Please fill out the following Google Form to let us know which workgroup you would like to join:\n\t\t\t- [Choose your preferred workstream for the hands on event](https://forms.gle/Tg9EJhpRJcNGA42v6) (Google Form)\n\t\t\t- The workgroups are as follows:\n\t\t\t\t- **Novices**: This group will learn ComfyUI online using RunDiffusion with the assistance of a coach. VPN setup is not required for this group.\n\t\t\t\t- **Intermediate**: Participants in this group must set up the VPN (instructions provided below) and will work on a more advanced fashion and brands workflow with a different coach.\n\t\t\t\t- **Advanced / Hackathon**: This is a small group of up to five participants (first-come, first-served) who will work on code development with a specialist.\n\t\t- ## VPN Setup Instructions\n\t\t\t- For the Intermediate workgroup, setting up the VPN is essential. Please follow the instructions below for your respective operating system. On the day of the event, you will receive a username and password. Use these credentials when prompted by the OpenVPN client.\n\t\t- ### Windows\n\t\t\t- Download the OpenVPN client from the official website: [https://openvpn.net/community-downloads/](https://openvpn.net/community-downloads/)\n\t\t\t- Install the OpenVPN client on your laptop.\n\t\t\t- Obtain the `vpn.ovpn` file provided by the event organisers.\n\t\t\t- Launch the OpenVPN client and import the `vpn.ovpn` file.\n\t\t\t- On the day of the event, you will receive a username and password. Use these credentials to connect to the VPN.\n\t\t- ### macOS\n\t\t\t- Download the official OpenVPN Connect client from the App Store: [https://apps.apple.com/us/app/openvpn-connect/id590379981](https://apps.apple.com/us/app/openvpn-connect/id590379981)\n\t\t\t- Install the OpenVPN Connect client on your laptop.\n\t\t\t- Obtain the `vpn.ovpn` file provided by the event organisers.\n\t\t\t- Launch the OpenVPN Connect client and import the `vpn.ovpn` file.\n\t\t\t- On the day of the event, you will receive a username and password. Use these credentials to connect to the VPN.\n\t\t- ### Linux\n\t\t\t- ### GUI Tools for Connecting to OpenVPN\n\t\t\t\t- Both KDE and GNOME offer plugins for their network manager applets that allow VPN connection to an OpenVPN server. The necessary plugins are:\n\t\t\t\t\t- KDE: network-manager-openvpn-kde\n\t\t\t\t\t- GNOME: network-manager-openvpn-gnome\n\t\t\t\t\t\t- More than likely, those plugins will not be installed on the distribution by default. A quick search using the Add/Remove Software utility will allow for the installation of either plugin. Once installed, the use of the network manager applets is quite simple, just follow these steps (I will demonstrate using the KDE network manager applet):\n\t\t\t\t\t- Open up the network manager applet by clicking on the network icon in the notification area (aka System Tray.)\n\t\t\t\t\t- Click on the Manage Connections button.\n\t\t\t\t\t- Select the VPN tab.\n\t\t\t\t\t- Click the Add button to open up the VPN type drop-down.\n\t\t\t\t\t- Select OpenVPN from the list.\n\t\t\t\t\t- Fill out the necessary information on the OpenVPN tab\n\t- We look forward to seeing you at the ComfyUI for Fashion and Brands event! If you have any questions or concerns, please don't hesitate to reach out to the event organisers.\n\t- Remember to bring your laptop and a passion for fashion, innovation, and AI-driven creation. Let's push the boundaries of generative AI together!\n\t- [www.eventbrite.co.uk/e/comfy-ui-for-fashion-and-brands-tickets-894342842517](http://www.eventbrite.co.uk/e/comfy-ui-for-fashion-and-brands-tickets-894342842517)\n\t-",
        "link_types": [
            "Overview of Machine Learning Techniques",
            "style transfer"
        ],
        "file_size": 11244
    },
    {
        "id": "ComfyUI.md",
        "name": "ComfyUI",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ComfyUI is a [[Node based interface]] for [[Stable Diffusion]]. It allows very high levels of control over Diffusion Models by leveraging open source extensions and a vibrant developer and creator community. The tool's flexibility and efficiency comes from its innovative design philosophy, that prioritizes user customization and interaction.\n- It's not the easiest way to use Stable Diffusion.\n-\n- The [GitHub repository](https://github.com/ZHO-ZHO-ZHO/[[ComfyUI]]-[[Gemini]]) integrates Gemini into ComfyUI, offering models like Gemini-pro, Genimi-pro-vision, and Gemini 1.5 Pro for text, image, and file processing tasks. Users can apply for their own API Key to access Gemini API. The repository provides workflow examples, installation instructions, and updates. Contact information includes zhozho3965@gmail.com and a QQ Group (839821928). Social media links to '-Zho-', Bilibili, Twitter, Little Red Book, and support on Bilibili and Aifadian. Credits to ComfyUI_Custom_Nodes_AlekPet. - Users need to apply for a Gemini_API_Key to use Gemini nodes, ensure a stable connection to [[Google]] Gemini's services, and update the dependency 'google-generativeai' to version 0.4.1 for Gemini 1.5 Pro. Installation can be done using ComfyUI Manager or manually by cloning the repository from GitHub and installing requirements. Workflow versions include V3.0 with Gemini 1.5 Pro, V2.0 with a chatbot workflow, and V1.1 with workflows for Gemini-pro and Genimi-pro-vision. Updates include Version 3.0 adding Gemini 1.5 Pro, system instructions, and file uploads, Version 2.1 fixing a bug, and Version 2.0 adding context chat nodes. - The [status history](https://api.status-histroy.com/svg?repos=ZHO-ZHO-ZHO/ConfyUI-Gemini&type=Timeline) for the repository is available.\n- The [video](https://www.youtube.com/watch?v=fFdYdTzq7Kg) titled 'Expanding Horizons: Outpainting Mastery in [[ComfyUI]]' explores the artistry of Outpainting with ComfyUI's [[Stable Diffusion]] feature. The video delves into Hyper Expansion, Sketch to Render, and Auto Background Regeneration within the realm of Outpainting. Topics discussed include the use of LORAs, Quick Basic Outpainting, and various techniques for Outpainting with ComfyUI.\n- The [Aerial view of the building](https://civitai.com/models/121728/aerial-view-of-the-building) showcases a [[LoRA]] model for urban bird's-eye views, offering high-definition training sets for cityscapes and buildings. The model, based on SD 1.5, has received very positive reviews and was last updated on Aug 3, 2023.\n- The [GitHub repository](https://github.com/comfyanonymous/[[ComfyUI]]) showcases ComfyUI, a powerful and modular [[Stable Diffusion]] GUI, API, and backend with a graph/nodes interface. The interface allows users to design and execute advanced stable diffusion pipelines without needing to code. ComfyUI supports various features like SD1.x, SD2.x, SDXL, Stable Video Diffusion, and Stable Cascade. Users can [[experiment]] with complex workflows, embeddings/textual inversion, Loras, hypernetworks, and more. The repository provides detailed installation instructions for Windows, Linux, AMD GPUs, NVIDIA GPUs, Intel GPUs, [[Apple]] Mac silicon, and DirectML for AMD cards on Windows. Additionally, it offers shortcuts for workflow management, high-quality previews, TLS/SSL setup, and support channels for users. The repository is licensed under GPL-3.0 and has garnered 35.3k stars and 3.8k forks.\n- The [video](https://www.youtube.com/watch?v=DROM8vfIYUY) titled 'How 2 Canvas Node' is available on YouTube. The video duration is 14 minutes and 22 seconds.\n- The [video](https://www.youtube.com/watch?v=AU8NDSBIS1U) showcases a plugin that provides realtime AI assistance to [[krita]], a digital painting software. The channel, Nerdy Rodent, offers tutorials on [[Stable Diffusion]], Generative AI, [[Large language models]], and other AI tools, catering to AI enthusiasts and professionals. The plugin enhances various aspects of AI technology, such as voice cloning, text-to-speech, and style transfer, making it a valuable resource for AI enthusiasts and artists alike.\n- The [video](https://www.youtube.com/watch?v=reimr3jZ8lI) titled '[[ComfyUI]] Fundamentals - [[Upscaling]] 1' explores the concept of upscaling in the context of ComfyUI. The video delves into how upscaling works and provides tips to enhance the upscaling process. The presenter discusses the ability to go under 1 on the upscale by node, highlighting key aspects of image upscaling and various upscaling options.\n- The [YouTube video](https://www.youtube.com/watch?v=ppE1W0-LJas) titled '[[ComfyUI]] Modular- Ultimate Starter Workflow Usage' provides insights into using ComfyUI Modular for an ultimate starter workflow.\n- The [YouTube](https://www.youtube.com/@sedetweiler) page provides information about the use of cookies and data for various purposes, including [[Google]] services, audience engagement, and site statistics. By accepting all, users allow for the development of new services, displaying ads, and showing personalised content and ads based on their settings. Non-personalised content and ads are influenced by factors like the viewed content and location. Users can manage privacy settings and find more information by selecting 'Meer opties'.\n- The [GitHub repository](https://github.com/phineas-pta/comfy-trt-test) is an attempt to use TensorRT with [[ComfyUI]], focusing on specific models and workflows. The repository provides instructions for installation and usage, highlighting compatible models like [[Stable Diffusion]] and SDXL. It also mentions limitations and future improvements for user-friendliness and compatibility with ComfyUI-Manager. The repository is a ComfyUI port from the official A1111 extension, with potential maintenance issues addressed by an alternative repository. The README outlines conversion scripts, dependencies, and error messages encountered during the process.\n- The [GitHub repository](https://github.com/gameltb/ComfyUI_stable_fast) showcases experimental usage of stable-fast and TensorRT. It includes speed tests, installation instructions, and features of stable-fast and TensorRT.\n\t- The repository provides guidance on enabling stable-fast nodes and installing TensorRT for testing purposes.\n\t- It highlights the compatibility of stable-fast with [[LoRA]], ControlNet, and other models, along with speed optimizations and node support.\n\t- Speed tests on a GeForce RTX 3060 Mobile show performance metrics for stable-fast and TensorRT implementations.\n\t- The repository also includes a table detailing features, tested nodes, and performance benchmarks for different workflows.\n- The [GitHub repository](https://github.com/Acly/[[krita]]-ai-diffusion?tab=readme-ov-file) provides a streamlined interface for generating images with AI in Krita. Users can inpaint and outpaint with optional text prompts without the need for tweaking. The plugin allows for creating new images from scratch, refining existing content, and live painting. It supports various resolutions, job queues, and history tracking. Customization options are available for advanced users. The technology used includes [[Stable Diffusion]] for image generation, [[ComfyUI]] for the diffusion backend, ControlNet for [[Inpainting]], and IP-Adapter for outpainting. The repository is licensed under GPL-3.0 and has garnered 4.8k stars and 216 forks. Contributors have added features like object selection tools and GPU cloud support.\n- The [[[ComfyUI]]](https://civitai.com/tag/comfyui) tag on Civitai features 379 models. Civitai offers a range of AI models for various applications and purposes.\n- The [GitHub repository](https://github.com/fictions-ai/sharing-is-caring/tree/main) titled 'sharing-is-caring' is maintained by the fictions.ai team. They focus on collaboration and sharing knowledge related to A.I. generation. The repository contains various workflows, scripts, and tools for A.I. generation. Some key [[contents]] include Comfy Workflows, upscale workflows, and specific workflow requirements. Contact the fictions.ai team for questions or feedback.\n- The [Index](https://wyrde.github.io/ComfyResources/nodes/) page of [[ComfyUI]] Resources provides a comprehensive list of custom nodes and tools for ComfyUI. Various nodes such as CLIP BLIP Node, GPT node ComfyUI, and Vid2vid Node Suite are available for installation. Instructions for installing custom nodes are included on the page.\n- The [Comfy Workflows](https://[[ComfyWorkFlows]].com/) website offers a platform for sharing art and workflows, with a focus on [[ComfyUI]]. Users can explore thousands of workflows created by the community and run them with zero setup using the ComfyUI Launcher. The site features a variety of workflows, images, and videos created by different creators.\n- The [GitHub repository](https://github.com/ZHO-ZHO-ZHO/[[ComfyUI]]-[[Gemini]]) integrates Gemini into ComfyUI, enabling users to generate prompts, describe images, and converse with Gemini. The repository features the latest Gemini 1.5 Pro model with system instruction settings, multi-modal conversations, and file reading capabilities. Users can request their API Key for Gemini API. Various models and nodes are provided for different functionalities, along with installation methods, workflows, changelog, and contact details.\n- The [video](https://www.youtube.com/watch?v=fFdYdTzq7Kg) titled 'Expanding Horizons: Outpainting Mastery in [[ComfyUI]]' on YouTube showcases the mastery of outpainting in ComfyUI. The video explores the revolutionary design aspects, including Vignette Mastery, ComfyUI Magic, and Font Previews Galore.\n- The [paper](https://arxiv.org/abs/2309.11497) titled FreeU: Free Lunch in Diffusion U-Net explores the potential of enhancing generation quality in [[Diffusion Models]] without additional training. The authors propose a method called 'FreeU' that strategically re-weights contributions from U-Net's skip connections and backbone feature maps to improve generation quality. The results show promising outcomes for image and video generation tasks, demonstrating the ease of integration with existing diffusion models.\n- The [GitHub repository](https://github.com/phineas-pta/comfy-trt-test) explores the attempt to use TensorRT with [[ComfyUI]], focusing on compatibility and installation instructions. The repository provides information on supported models like [[Stable Diffusion]] and SDXL, along with a list of working and non-working models. The project aims to make the process more user-friendly and automatic in the future. The README.md file outlines the steps for installing Python dependencies, TensorRT versions, and converting [[Checkpoints]] to TensorRT engines. It also discusses the usage of converted engines in ComfyUI and common error messages. The repository includes links to original implementations and download links for testing with various checkpoints and models.\n- The [AP Workflow 9.0 for [[ComfyUI]]](https://perilli.com/ai/comfyui/#soon) introduces new features such as upscalers, image generation with [[Dall-e]], advanced XYZ plot, face cloner, face analyzer, and training helper for batch captioning. Instructions for troubleshooting custom node installation, switching to SD 1.5 models, using LM Studio for prompt enrichment, securing ComfyUI connection with SSL, and FAQs are provided. Special thanks to custom node creators and a full changelog for version 9.0 are included. The [AP Workflow](https://perilli.com/ai/comfyui/#soon) version 8.0 offers features like bookmark nodes, [[IPAdapter]] plus v2 nodes, uploader function, caption generator function, image evaluators, face analyzer, aesthetic score predictor, image chooser, prompt enricher function, [[LoRA]] info node, face detailer function, and reorganized L2 pipeline layout with removed functions like ReVision and Image Enhancer.\n- The [[[Google]] Spreadsheets](https://docs.google.com/spreadsheets/d/1IYJw4Iv9M_vX507MPbdX4thhVYxOr6-IThbaRjdpVgM/edit#gid=0) document titled 'SDXL Model Compare' provides information on various data models and comparison metrics. The content includes data on different styles, illustrations, and financial aspects. The document also offers support for screen readers and data cleaning suggestions.\n- The [GitHub repository](https://github.com/chaojie/[[ComfyUI]]-MotionCtrl) for ComfyUI-MotionCtrl contains an implementation of MotionCtrl for video generation. The repository includes nodes for loading motion control [[Checkpoints]], motion control conditioning, and motion control [[Sampling]]. Tools for generating motion trajectories and camera points are also provided. Examples of workflows for generating LVDM/VideoCrafter videos and using [[AnimateDiff]] for scribbling are available. The repository is licensed under Apache-2.0 and has received 121 stars and 4 forks.\n- The [YouTube](https://www.youtube.com/@ferniclestix) page provides information about cookies and data usage for [[Google]] services. Users can choose to accept or reject cookies for various purposes, including delivering Google services, tracking outages, measuring audience engagement, and showing personalised content and ads based on user settings.\n- The [video](https://www.youtube.com/watch?v=DROM8vfIYUY) titled 'How 2 Canvas Node' is available on YouTube.\n- The [YouTube](https://www.youtube.com/@NerdyRodent) page provides information about cookies and data usage by [[Google]] services. Users can choose to accept or reject cookies for various purposes, including delivering Google services, measuring audience engagement, and showing personalised content and ads. More options are available for managing privacy settings.\n- The [GitHub repository](https://github.com/Acly/[[krita]]-ai-diffusion?tab=readme-ov-file) provides a streamlined interface for generating images with AI in Krita. It allows users to inpaint and outpaint images with optional text prompts, requiring no tweaking. The plugin supports features like generating images from scratch, refining existing content, live painting, and job queue management. Customization options are available for advanced users. The plugin is open source and free to use. [[krita-plugin]], [[stable-diffusion]], [[Generative AI]]\n- The [YouTube video](https://www.youtube.com/watch?v=AU8NDSBIS1U) showcases a plugin that adds real-time AI assistance to [[krita]]. The video covers topics such as [[Stable Diffusion]], Generative AI, [[Large language models]], AI Animation, Voice Cloning, and more. The channel, Nerdy Rodent, provides tutorials on [[Artificial Intelligence]] in an easy-to-digest format. The AI enthusiast behind the channel recommends specific hardware for the best AI experience at home. Not suitable for children. Please use AI responsibly.\n- The [GitHub repository](https://github.com/comfyanonymous/[[ComfyUI]]) showcases ComfyUI, a powerful and modular [[Stable Diffusion]] GUI, API, and backend with a graph/nodes interface. The interface allows users to design and execute advanced stable diffusion pipelines without needing to code. ComfyUI supports various [[Diffusion Models]], asynchronous queue system, and many optimizations to enhance workflow efficiency. Users can [[experiment]] with complex workflows, including area composition, [[Inpainting]], controlnet, upscale models, and more. The repository provides detailed installation instructions for Windows, Linux, AMD GPUs, NVIDIA GPUs, Intel GPUs, [[Apple]] Mac silicon, and DirectML for AMD cards on Windows. Additionally, it offers shortcuts for workflow management, high-quality preview setup, TLS/SSL configuration, and support channels for users. The repository is licensed under GPL-3.0 and has garnered significant community engagement with 35.3k stars and 3.8k forks.\n- The [video](https://www.youtube.com/watch?v=OdMtJMzjNLg) titled 'LATENT Tricks - Amazing ways to use [[ComfyUI]]' features Olivio Sarikas, an AI Expert and passionate Artist, showcasing the exciting world of AI art. The video invites viewers to explore AI art and creative visions with live streams. Olivio Sarikas, a professional Designer with a Masters Degree in Fine Arts, shares [[Tips and Tricks]] for using ComfyUI.\n- The [[[ComfyUI]]](https://civitai.com/tag/comfyui) tag on Civitai features 379 models for [[Stable Diffusion]] AI. Users can explore and access these models for various applications. Civitai offers a range of services and resources for creators, including terms of service, privacy policies, and safety guidelines.\n- The [[[ComfyUI]]-extension-tutorials/ComfyUI-Impact-Pack/workflow](https://github.com/ltdrdata/ComfyUI-extension-tutorials/tree/Main/ComfyUI-Impact-Pack/workflow) on GitHub provides a collection of workflow-related files for various image processing tasks. The repository includes files for tasks such as [[Upscaling]], animation, segmentation, and more. Each file represents a specific workflow step or technique, showcasing the versatility and capabilities of the ComfyUI Impact Pack.\n- The [video](https://www.youtube.com/watch?v=KvZ8ucBqyqw) titled '[[ComfyUI]] Impact Pack - Q&A;: Detailer Options' on YouTube provides explanations on the important parameters of the detailer.\n- The [Index](https://wyrde.github.io/ComfyResources/nodes/#index) page of [[ComfyUI]] Resources provides a comprehensive list of custom nodes and tools available for use. The nodes cover a wide range of functionalities, from image processing to AI installation tools. Installation instructions can be found on the respective node pages, with the option to streamline the process using ltdrdata's Comfy Manager.\n- The [YouTube video](https://www.youtube.com/watch?v=reimr3jZ8lI) titled '[[ComfyUI]] Fundamentals - [[Upscaling]] 1' provides insights into the fundamentals of ComfyUI and the concept of upscaling in the context of user interface design.\n- The [YouTube video](https://www.youtube.com/watch?v=ppE1W0-LJas) titled '[[ComfyUI]] Modular- Ultimate Starter Workflow Usage' provides insights into using ComfyUI Modular for an ultimate starter workflow.\n- The [GitHub repository](https://github.com/SHI-Labs/Prompt-Free-Diffusion) for Prompt-Free Diffusion discusses a diffusion model that generates images using only visual inputs, replacing text encoders with a Semantic Context Encoder (SeeCoder). The model is reusable across various T2I models and adaptive layers. The repository includes pretrained models and tools for model conversion. The implementation is based on a research paper presented at arXiv 2023 / CVPR 2024.\n- The [file](https://gist.github.com/comfyanonymous/343e5675f9a2c8281fde0c440df2e2c6#file-workflow-[[json]]) contains Python code for a custom node in the [[ComfyUI]]/custom_nodes directory. The code defines a class for handling model references and latent data. The JSON file included in the gist outlines a workflow with various nodes like VAEDecode, CLIPTextEncode, KSampler, SaveImage, CheckpointLoaderSimple, ImageScale, LoadImage, and ReferenceOnlySimple.\n- The [GitHub repository](https://github.com/itsKaynine/comfy-ui-client) contains a Node.js WebSockets API client for [[ComfyUI]]. The client is based on the WebSockets API example and is licensed under the MIT [[[[license]]]]. The repository includes folders and files such as examples, source code, and configuration files. The client allows users to connect to a server, generate images based on prompts, and save the images to a specified directory. Topics related to the project include nodejs, api, stable-diffusion, comfyui, and sdxl.\n- The [YouTube](https://www.youtube.com/@ArchAi3D/videos) page provides information about cookies and data usage by [[Google]] services. Users can choose to accept or reject cookies for various purposes, including personalised content and ads. More options are available for managing privacy settings.\n- The [video](https://www.youtube.com/watch?v=js4JeDF3v4g) showcases ComyUI, a tool for video animation rendering using AI technologies like WAS, Seecoder, Style, and Semantic segmentation. The creator, Amir Ferdos, a seasoned 3D artist and designer, explores the fusion of AI with design processes, offering unique workflows and tutorials on their YouTube channel. The videos aim to educate and inspire designers on the transformative impact of AI in design. For a deeper dive into the creator's work, exclusive tutorials and source files are available on their Patreon page.\n- The [[[ComfyUI]] [Community Manual](https://blenderneko.github.io/ComfyUI-docs/) provides documentation for ComfyUI, a [[Stable Diffusion]] GUI and backend. It covers topics such as installation, downloading models, first steps with Comfy, loading other flows, and further support. The manual includes detailed information on interface, core nodes (including advanced, conditioning, experimental, image, latent, loaders, mask, and [[Sampling]]), custom nodes, developing custom nodes, and contributing documentation.\n- The [GitHub repository](https://github.com/pydn/[[ComfyUI]]-to-Python-Extension) provides a powerful tool that translates ComfyUI workflows into executable Python code. The tool bridges the gap between ComfyUI's visual interface and Python's programming environment, streamlining the process for data scientists, software developers, and AI enthusiasts. Use cases include creating lean app deployments, programmatic experiments, and large image generation queues. The v1.0.0 release notes highlight support for custom nodes. To use the tool, clone the repository, enable Dev mode options in ComfyUI, save workflows in API format, and run the script to generate Python code for image generation without launching a server. The repository is primarily focused on topics like pytorch, generative art, image generation, AI art, [[Stable Diffusion]], and ComfyUI.\n- The [website](https://comfy.icu/) offers [[ComfyUI]] Cloud services for running and deploying workflows without the need for downloads or installs. Users can pay only for active GPU usage, avoiding idle time and unnecessary costs. ComfyICU provides ready-to-use creative workflows and a simple, scalable API for production. The platform aims to simplify workflow creation and deployment, offering fast performance and cost-efficiency. Users can access over 5000 happy users' testimonials and FAQs for more information.\n- The [video](https://www.youtube.com/watch?v=SMOM1bIY5yA) titled 'EASY [[Inpainting]] in [[ComfyUI]] with SAM (segment Anything) | Creative Workflow Tutorial' provides a tutorial on using SAM for inpainting in ComfyUI.\n- The [wiki page](https://github.com/chrisgoringe/Comfy-Custom-Node-How-To/wiki) provides a practical and [[collaborative]] guide on developing custom nodes for [[ComfyUI]]. The guide is unofficial and focuses on practicality over formality, encouraging collaboration through Q&A-style discussions. It covers various topics related to custom node development, such as control flow, data types, and UI design.\n- The [Comfy Workflows](https://[[ComfyWorkFlows]].com/) website offers a platform for sharing art and workflows, with features like [[ComfyUI]] Launcher for running workflows with zero setup. Users can explore thousands of workflows created by the community. Trending creators and the latest images and videos are showcased on the site.\n- Custom nodes for interpolating between, well, everything in the [[Stable Diffusion]] [[ComfyUI]]. The [GitHub repository](https://github.com/shockz0rz/ComfyUI_InterpolateEverything) contains functionality to create preprocessed ControlNet OpenPose inputs midway between two images. Future features include line-art interpolation. To install, follow the provided instructions. The repository is licensed under the MIT [[[[license]]]].\n- The [GitHub repository](https://github.com/xXAdonesXx/NodeGPT) contains [[ComfyUI]] Extension Nodes for Automated Text Generation. The repository is under development, with features like autogen, automated task solving, and group chat capabilities. The repository includes various folders and files for different functionalities. To contribute, users can submit pull requests, suggestions, or issue reports. The repository is licensed under AGPL-3.0. The repository has 314 stars, 24 forks, and 4 contributors.\n- The [AutoGen Advanced Tutorial](https://www.youtube.com/watch?v=PUPO2tTyPOo) on YouTube focuses on building incredible AI AGENT teams. The tutorial delves into advanced techniques for creating AI teams and enhancing their capabilities.\n- The [GitHub repository](https://github.com/olegchomp/TDComfyUI) provides a TouchDesigner interface for [[ComfyUI]], offering features like workflow creation and image send/receive. The repository includes installation instructions and resources for using the TDComfyUI component. It also offers guidance on connecting to [[Stable Diffusion]] and utilising ComfyUI settings for optimal performance.\n- The [GitHub repository](https://github.com/NimaNzrii/[[ComfyUI]]-photoshop) showcases the ComfyUI plugin for Photoshop, offering AI-powered image generation features. The plugin enables unlimited generative fill, customizable back-end workflow, and one-click image transformation. System requirements include a minimum of 6GB graphics memory and 12GB RAM. Installation involves downloading the plugin from a provided link or locally via a .CCX file. Additional files are required for specific functionalities. Support and contributions are encouraged through GitHub.\n- The [model](https://civitai.com/models/121728/aerial-view-of-the-building) titled 'Aerial view of the building' offers a high-definition training set for urban bird's-eye views, encompassing a variety of domestic and foreign architectural drawings. The model is based on [[LoRA]] technology and has received positive reviews. The training set is designed for cityscape and building enthusiasts.\n- ## Unsorted links\n\t- [ZHO-ZHO-ZHO/ComfyUI-Gemini: Using Gemini in ComfyUI (github.com)](https://github.com/ZHO-ZHO-ZHO/ComfyUI-Gemini)\n\t- A GitHub repository that provides instructions on using Gemini in ComfyUI.\n\t- [Expanding Horizons: Outpainting Mastery in ComfyUI (youtube.com)](https://www.youtube.com/watch?v=fFdYdTzq7Kg)\n\t- A YouTube video tutorial that demonstrates how to master outpainting in ComfyUI.\n\t- [Chaoses-Ib/ComfyScript: A Python front end for ComfyUI (github.com)](https://github.com/Chaoses-Ib/ComfyScript)\n\t- This GitHub repository contains a Python front end for ComfyUI, known as ComfyScript.\n\t- [Aerial view of the building（建筑鸟瞰图）\n\t- v1.0 | Stable Diffusion LoRA | Civitai](https://civitai.com/models/121728/aerial-view-of-the-building)\n\t- Civitai provides a stable diffusion LoRA model for generating an aerial view of a building using ComfyUI.\n\t- [ComfyUI nodes based](https://github.com/comfyanonymous/ComfyUI)\n\t- A GitHub repository that provides nodes-based examples and workflows for ComfyUI.\n\t- 🎬\n\t\t- [How 2 Canvas Node YouTube](https://www.youtube.com/watch?v=DROM8vfIYUY)\n\t\t- A YouTube video tutorial that explains how to use the Canvas Node in ComfyUI.\n\t\t- [This One Simple Plugin Adds Realtime AI Assistance to Krita\n\t\t- YouTube](https://www.youtube.com/watch?v=AU8NDSBIS1U)\n\t\t- A YouTube video that introduces a plugin for Krita that adds realtime AI assistance using ComfyUI.\n\t\t- [Tutorials from first principles](https://www.youtube.com/watch?v=reimr3jZ8lI)\n\t\t- A YouTube video tutorial series that covers ComfyUI from the basic principles.\n\t\t- [modular workflow](https://www.youtube.com/watch?v=ppE1W0-LJas)\n\t\t- A YouTube video that showcases a modular workflow in ComfyUI.\n\t\t- [Detailed youtube tutorials](https://www.youtube.com/@sedetweiler)\n\t\t- A YouTube channel with detailed tutorials on using ComfyUI.\n\t\t- 🔧\n\t\t\t- [phineas-pta/comfy-trt-test: attempt to use TensorRT with ComfyUI (github.com)](https://github.com/phineas-pta/comfy-trt-test)\n\t\t\t- A GitHub repository that attempts to use TensorRT with ComfyUI.\n\t\t\t- [gameltb/ComfyUI_stable_fast: Experimental usage of stable-fast and TensorRT. (github.com)](https://github.com/gameltb/ComfyUI_stable_fast)\n\t\t\t- This GitHub repository provides an experimental usage of stable-fast and TensorRT in ComfyUI.\n\t\t\t- [Acly/krita-ai-diffusion: Streamlined interface for generating images with AI in Krita. Inpaint and outpaint with optional text prompt, no tweaking required. (github.com)](https://github.com/Acly/krita-ai-diffusion?tab=readme-ov-file)\n\t\t\t- A GitHub repository that offers a streamlined interface for generating images with AI in Krita using ComfyUI.\n\t\t\t- [Sytan workflow (contains js!)](https://github.com/SytanSD/Sytan-SDXL-ComfyUI)\n\t\t\t- This GitHub repository contains a workflow for ComfyUI that includes JavaScript files.\n\t\t- 🌐\n\t\t\t- [(2) Plush-for-ComfyUI style_prompt, can now use ChatGPT to create prompts from images : comfyui (reddit.com)](https://www.reddit.com/r/comfyui/comments/18uincm/plushforcomfyui_style_prompt_can_now_use_chatgpt/)\n\t\t\t- A Reddit post that discusses the Plush-for-ComfyUI style_prompt and its capability to create prompts from images using ChatGPT.\n\t\t\t- [(1) AP Workflow 6.0 for ComfyUI\n\t\t\t- Now with support for SD 1.5 and HiRes Fix, IPAdapter, Prompt Enricher via local LLMs (and OpenAI), and a new Object Swapper + Face Swapper, FreeU v2, XY Plot, ControlNet and ControlLoRAs, SDXL Base + Refiner, Hand Detailer, Face Detailer, Upscalers, ReVision, etc. : StableDiffusion (reddit.com)](https://www.reddit.com/r/StableDiffusion/comments/17v0bo3/ap_workflow_60_for_comfyui_now_with_support_for/)\n\t\t\t- A Reddit post about the AP Workflow 6.0 for ComfyUI, which includes various features and enhancements.\n\t\t\t- [UI node packs on civitai](https://civitai.com/tag/comfyui)\n\t\t\t- Civitai provides UI node packs for ComfyUI.\n\t\t- 📑\n\t\t\t- [fictions-ai/sharing-is-caring (github.com)](https://github.com/fictions-ai/sharing-is-caring/tree/main)\n\t\t\t- This GitHub repository contains various resources related to ComfyUI and its applications.\n\t\t\t- [Wiki full of links](https://wyrde.github.io/ComfyResources/nodes/)\n\t\t\t- A comprehensive wiki filled with links to resources, tutorials, and examples related to ComfyUI.\n\t\t\t- [Images / workflows](https://comfyworkflows.com/)\n\t\t\t- ComfyWorkflows offers a collection of images and workflows created using ComfyUI.\n\t\t- Using LLMs in ComfyUI\n\t\t\t- [ZHO-ZHO-ZHO/ComfyUI-Gemini: Using Gemini in ComfyUI (github.com)](https://github.com/ZHO-ZHO-ZHO/ComfyUI-Gemini)\n\t\t-\n\t\t- [Expanding Horizons: Outpainting Mastery in ComfyUI (youtube.com)](https://www.youtube.com/watch?v=fFdYdTzq7Kg)\n\t\t- https://arxiv.org/abs/2309.11497\n\t\t- TensorRT converter [phineas-pta/comfy-trt-test: attempt to use TensorRT with ComfyUI (github.com)](https://github.com/phineas-pta/comfy-trt-test)\n\t\t- [gameltb/ComfyUI_stable_fast: Experimental usage of stable-fast and TensorRT. (github.com)](https://github.com/gameltb/ComfyUI_stable_fast)\n\t\t- https://perilli.com/ai/comfyui/#soon\n\t\t-\n\t\t- [Chaoses-Ib/ComfyScript: A Python front end for ComfyUI (github.com)](https://github.com/Chaoses-Ib/ComfyScript)\n\t\t- Model leaderboard  [SDXL Model Compare\n\t\t\t- Google Sheets](https://docs.google.com/spreadsheets/d/1IYJw4Iv9M_vX507MPbdX4thhVYxOr6-IThbaRjdpVgM/edit#gid=0)\n\t\t- [fictions-ai/sharing-is-caring (github.com)](https://github.com/fictions-ai/sharing-is-caring/tree/main)\n\t\t- [chaojie/ComfyUI-MotionCtrl (github.com)](https://github.com/chaojie/ComfyUI-MotionCtrl)\n\t\t- [(2) Plush-for-ComfyUI style_prompt, can now use ChatGPT to create prompts from images : comfyui (reddit.com)](https://www.reddit.com/r/comfyui/comments/18uincm/plushforcomfyui_style_prompt_can_now_use_chatgpt/)\n\t\t- [Ferniclestix](https://www.youtube.com/@ferniclestix)\n\t\t\t- [How 2 Canvas Node YouTube](https://www.youtube.com/watch?v=DROM8vfIYUY)\n\t\t- [Nerdy Rodent YouTube](https://www.youtube.com/@NerdyRodent)\n\t\t- [Acly/krita-ai-diffusion: Streamlined interface for generating images with AI in [[Krita]]. Inpaint and outpaint with optional text prompt, no tweaking required. (github.com)](https://github.com/Acly/krita-ai-diffusion?tab=readme-ov-file)\n\t\t\t- TODO this needs the live view debugging\n\t\t\t- [This One Simple Plugin Adds Realtime AI Assistance to Krita YouTube](https://www.youtube.com/watch?v=AU8NDSBIS1U) [[Courses and Training]]\n\t\t- [ComfyUI nodes based](https://github.com/comfyanonymous/ComfyUI)\n\t\t- [Controlnet auto installer](https://github.com/Fannovel16/comfy_controlnet_preprocessors)\n\t\t- [LATENT Tricks Amazing ways to use ComfyUI](https://www.youtube.com/watch?v=OdMtJMzjNLg)\n\t\t- [latent consistency model](https://github.com/0xbitches/ComfyUI-LCM#img2img--vid2vid)\n\t\t- [UI node packs on civitai](https://civitai.com/tag/comfyui)\n\t\t- [(1) AP Workflow 6.0 for ComfyUI\n\t\t\t- Now with support for SD 1.5 and HiRes Fix, IPAdapter, Prompt Enricher via local LLMs (and OpenAI), and a new Object Swapper + Face Swapper, FreeU v2, XY Plot, ControlNet and ControlLoRAs, SDXL Base + Refiner, Hand Detailer, Face Detailer, Upscalers, ReVision, etc. : StableDiffusion (reddit.com)](https://www.reddit.com/r/StableDiffusion/comments/17v0bo3/ap_workflow_60_for_comfyui_now_with_support_for/)\n\t\t- [Workflows that can be loaded](https://github.com/comfyanonymous/ComfyUI_examples)\n\t\t- [Sytan workflow (contains js!)](https://github.com/SytanSD/Sytan-SDXL-ComfyUI)\n\t\t- [Impact pack and youtube](https://github.com/ltdrdata/ComfyUI-extension-tutorials/tree/Main/ComfyUI-Impact-Pack/workflow)\n\t\t- [youtube](https://www.youtube.com/watch?v=KvZ8ucBqyqw)\n\t\t- [Wiki full of links](https://wyrde.github.io/ComfyResources/nodes/)\n\t\t- [Tutorials from first principles](https://www.youtube.com/watch?v=reimr3jZ8lI)\n\t\t- [modular workflow](https://www.youtube.com/watch?v=ppE1W0-LJas)\n\t\t- [Detailed youtube tutorials](https://www.youtube.com/@sedetweiler)\n\t\t- [Prompt free diffusion](https://github.com/SHI-Labs/Prompt-Free-Diffusion)\n\t\t- Motion brush [chaojie/ComfyUI-DragNUWA (github.com)](https://github.com/chaojie/ComfyUI-DragNUWA)\n\t\t- [reference_only controlnet](https://gist.github.com/comfyanonymous/343e5675f9a2c8281fde0c440df2e2c6#file-workflow-json)\n\t\t- [Citivia autoprompt](https://civitai.com/models/123358/sdvn-comfyui-workflow-autoprompt-sdxl)\n\t\t- [Typescript client for comfyui](https://github.com/itsKaynine/comfy-ui-client)\n\t\t- [Animation workflow](https://www.reddit.com/r/comfyui/comments/15s6lpr/short_animation_img2img_in_comfyui_with/)\n\t\t- [Complex workflow tutorials](https://www.youtube.com/@ArchAi3D/videos)\n\t\t- [animation](https://www.youtube.com/watch?v=js4JeDF3v4g)\n\t\t- [Manual](https://blenderneko.github.io/ComfyUI-docs/)\n\t\t- [Turn comfyui to python](https://github.com/pydn/ComfyUI-to-Python-Extension)\n\t\t- [Share workflows](https://comfy.icu/)\n\t\t- [consistent character creation](https://www.reddit.com/r/comfyui/comments/16ceh10/i_succeeded_to_adapt_the_tutorial_character/)\n\t\t- [Edit in another tab](https://www.reddit.com/r/comfyui/comments/16d0wtx/workflow_using_15_scribble_controlnet_to_feed/)\n\t\t- [semi automated inpainting](https://www.youtube.com/watch?v=SMOM1bIY5yA)\n\t\t- [Canvas editor with layers](https://github.com/Lerc/canvas_tab)\n\t\t- [Build custom nodes howto](https://github.com/chrisgoringe/Comfy-Custom-Node-How-To/wiki)\n\t\t- [Images / workflows](https://comfyworkflows.com/)\n\t\t- [Interpolate everything (openpose)](https://github.com/shockz0rz/ComfyUI_InterpolateEverything)\n\t\t- [Autogen inside comfyui](https://github.com/xXAdonesXx/NodeGPT)\n\t\t- [autogen tutorial](https://www.youtube.com/watch?v=PUPO2tTyPOo)\n\t\t- [lcm consistency lora](https://github.com/0xbitches/ComfyUI-LCM)\n\t\t- [touch designer](https://github.com/olegchomp/TDComfyUI)\n\t\t- [NimaNzrii/comfyui-photoshop:](github.com)](https://github.com/NimaNzrii/comfyui-photoshop) [[Photoshop]] node inside of ComfyUi, send and get data from Photoshop\n\t\t\t- Reddit post on the matter  [(2) NEW AI NEWS! Photoshop to Comfyui V1 is Finally Released! : comfyui (reddit.com)](https://www.reddit.com/r/comfyui/comments/18jygtn/new_ai_news_photoshop_to_comfyui_v1_is_finally/)\n\t\t- [Aerial view of the building（建筑鸟瞰图）\n\t\t\t- v1.0 | Stable Diffusion LoRA | Civitai](https://civitai.com/models/121728/aerial-view-of-the-building)\n-",
        "link_types": [
            "Node based interface",
            "Stable Diffusion",
            "ComfyUI",
            "Gemini",
            "Google",
            "ComfyUI",
            "Stable Diffusion",
            "LoRA",
            "ComfyUI",
            "Stable Diffusion",
            "experiment",
            "Apple",
            "krita",
            "Stable Diffusion",
            "Large language models",
            "ComfyUI",
            "Upscaling",
            "ComfyUI",
            "Google",
            "ComfyUI",
            "Stable Diffusion",
            "LoRA",
            "krita",
            "Stable Diffusion",
            "ComfyUI",
            "Inpainting",
            "[ComfyUI",
            "contents",
            "ComfyUI",
            "ComfyWorkFlows",
            "ComfyUI",
            "ComfyUI",
            "Gemini",
            "ComfyUI",
            "Diffusion Models",
            "ComfyUI",
            "Stable Diffusion",
            "Checkpoints",
            "ComfyUI",
            "Dall-e",
            "IPAdapter",
            "LoRA",
            "[Google",
            "ComfyUI",
            "Checkpoints",
            "Sampling",
            "AnimateDiff",
            "Google",
            "Google",
            "krita",
            "krita-plugin",
            "stable-diffusion",
            "Generative AI",
            "krita",
            "Stable Diffusion",
            "Large language models",
            "Artificial Intelligence",
            "ComfyUI",
            "Stable Diffusion",
            "Diffusion Models",
            "experiment",
            "Inpainting",
            "Apple",
            "ComfyUI",
            "Tips and Tricks",
            "[ComfyUI",
            "Stable Diffusion",
            "[ComfyUI",
            "Upscaling",
            "ComfyUI",
            "ComfyUI",
            "ComfyUI",
            "Upscaling",
            "ComfyUI",
            "json",
            "ComfyUI",
            "ComfyUI",
            "[[license",
            "Google",
            "[ComfyUI",
            "Stable Diffusion",
            "Sampling",
            "ComfyUI",
            "Stable Diffusion",
            "ComfyUI",
            "Inpainting",
            "ComfyUI",
            "collaborative",
            "ComfyUI",
            "ComfyWorkFlows",
            "ComfyUI",
            "Stable Diffusion",
            "ComfyUI",
            "[[license",
            "ComfyUI",
            "ComfyUI",
            "Stable Diffusion",
            "ComfyUI",
            "LoRA",
            "Krita",
            "Courses and Training",
            "Photoshop"
        ],
        "file_size": 36183
    },
    {
        "id": "Bitcoin Technical Overview.md",
        "name": "Bitcoin Technical Overview",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # Technical overview\n\t- This section could be far more detailed, but this is pretty complex stuff. Instead, there’s plenty of [books andwebsites](https://github.com/bitcoinbook/bitcoinbook) that do a more thorough job, if the reader is interested. Each subsection will include a good external link where more depth can be found. This whistle stop tour of the main components of the protocol should provide enough grounding, but it’s not essential reading for non technical readers.\n\t- ## ECDSA / SHA256 / secp256k1\n\t\t- These technologies tend to use the same underpinning [elliptic curvecryptography](https://curves.ulfheim.net/), and it makes sense to unpackthis here just once, only in the context of Bitcoin, as this will be themain focus of our attention.\n\t\t- Public keys are a huge number used in conjunction with an algorithm toencrypt data. This allows a remote party to interact with an actor onthe network whose private keys can decrypt that same data.\n\t\t- In Bitcoin the ECDSA algorithm is used on the[secp256k1](https://en.bitcoin.it/wiki/Secp256k1) elliptic function tocreate a trapdoor. This (essentially) one way mathematical operation wasoriginally the “discrete log problem” and part of the research incryptography by Diffie and Hellman.[[diffie1976new]] This is what bindsthe public and private keys in a key pair (the foundation of the wholespace).\n\t\t- In their mathematical construct a modulus operator creates an infinitenumber of possible variations on operations which multiply enormousexponential numbers together, in different orders, to create key pairs.In order to reverse back through the ‘trapdoor’ a probably impossiblenumber of guesses would have to be applied.\n\t\t- Latterly, elliptic curves such as the secp256k1 curve used in Bitcoinhave substantially simplified the computation problems. Rather thanexponentials used by Diffie Helmman instead a repeated operation isapplied to an elliptic curve function, and this itself creates adiscrete log problem trapdoor in maths, far more efficiently. Figure<a href=\"#fig:ECDSA\" data-reference-type=\"ref\" data-reference=\"fig:ECDSA\">3.11</a>suggests how this works.\n\t\t- This makes it easier, faster, and cheaper to provide secure key pairs onbasic computational resources. Elliptic curve solutions are not[‘provably’ secure](https://safecurves.cr.yp.to/)[[gayoso2018secure]] inthe same way as the Diffie-Hellman approach, and the security of thissystem is very sensitive to the randomness which is applied to theoperation. Aficionados of Bitcoin use dice rolls or [even moreexotic](https://www.hackster.io/news/alex-waltz-s-quantum-random-number-generator-for-bitcoin-uses-radioactive-decay-and-a-raspberry-pi-25a75316220f)means to add entropy (randomness) when creating keys. This really isn’tnecessary, the software does this well enough.\n\t\t- ECDSA has already been replaced by the more efficient Schnorr signaturemethod[[schnorr1989efficient]] which uses the same mathematical curve sois backward compatible. This will take some time for organic adoption,and ECDSA will never be deprecated.\n\t\t- ![image](./assets/120bce752a1666521d085cf8b4b4876e49cff344.png)\n\t\t- Given a start point on the curve and a number of reflection operations it’s trivial to find a number at the end point, but impossible to find the number of <a href=\"https://github.com/bitcoinbook/bitcoinbook/blob/develop/ch04.asciidoc\">hops</a> from the two end points alone. (CC Mastering Bitcoin second edition)\n\t\t- ## Analysis of the underlying security\n\t - The evidence available paints a picture of strong and improving but notironclad cryptographic robustness.\n\t - ### Who is involved:\n\t\t\t\t- Pieter Wuille, Gregory Maxwell, and Andrew Poelstra are some of the most prominent Bitcoin Core developers and cryptographers. Their extensive experience and contributions to Bitcoin speak to  their credentials.\n\t\t\t\t- Jonas Nick is a cryptography researcher who has published analyses of Bitcoin’s ECDSA signature scheme.\n\t\t\t\t- Tim Ruffing, Pedro Moreno-Sanchez, and Yannick Seurin are cryptographers who have published academic papers analysing and improving Bitcoin’s cryptographic constructions.\n\t\t\t\t- Tadge Dryja is one of the original Lightning developers and an MIT DCI researcher focused on Bitcoin’s cryptography.\n\t\t\t\t- Arvind Narayanan is a professor at Princeton who has published seminal works on Bitcoin and cryptocurrency cryptography.\n\t\t\t\t- Aviv Zohar at the University of Jerusalem has helped identify [still extant](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2023-October/021999.html) vulnerabilities in the Lightning network.[[harris2020flood]]\n\t\t\t\t- There are likely many other credentialed cryptographers working on Bitcoin, but these are some of the most well-known examples. The common thread is a strong academic background in cryptography.\n\t - ### Where critical analysis is published:\n\t\t\t\t- Many analyses have been published at top cryptography and security conferences like IEEE S&P, ACM CCS, Financial Cryptography, and Real World Crypto. These are generally highly regarded venues.\n\t\t\t\t- Academic journals like Journal of Cryptography, Ledger, and Journal of Cryptographic Engineering have also published peer-reviewed papers. The impact factors are not as high as broader CS journals however.\n\t\t\t\t- Bitcoin Improvement Proposals (BIPs) also undergo scrutiny by expert reviewers.\n\t\t\t\t- There is still room for more peer review in top journals, but publication venue credibility is generally decent.\n\t - ### Test of time:\n\t\t\t\t- Bitcoin has been live since 2009 and its core cryptographic protocols have stood the test of time so far, with no major breaks of ECDSA, SHA256, RIPEMD160, etc despite enormous incentives.\n\t\t\t\t- That being said, 13 years is short in cryptography timescales. Continued analysis over decades is ideal.\n\t\t\t\t- Some newer proposals like Taproot have undergone less time testing but build on proven constructions.\n\t - ### Academic acceptance:\n\t\t\t\t- Acceptance has been increasing steadily, with a growing number of peer-reviewed academic papers, PhD dissertations, and university courses on Bitcoin cryptography.\n\t\t\t\t- Funding remains limited but is increasing through organizations like Square Crypto that fund open source work.\n\t\t\t\t- Controversy around Bitcoin’s social implications persists but its technical merit and cryptography seem to be gaining more mainstream academic respect.\n\t\t- ## Addresses & UTXOs\n\t - Ethereum has addresses which transactions flow in and out of. This issynonymous to a bank account number and so makes intuitive sense tousers of banks. This is not the case in Bitcoin.\n\t - Bitcoin is a UTXO model blockchain. UTXO stands for unspent transactionoutput, and these are ‘portions’ of Bitcoin created and destroyed asvalue changes hands (through the action of cryptographic keys). They arethe basis of the evolving ledger. This process is described well byRajarshi Maitra in [thispost](https://medium.com/bitbees/what-the-heck-is-utxo-ca68f2651819).\n\t - it“Every Transaction input consists of a pointer and an unlocking key.The pointer points back to a previous transaction output. And the key isused to unlock the previous output it points to. Every time an output issuccessfully unlocked by an input, it is marked inside the blockchaindatabase as ‘spent’. Thus you can think of a transaction as an abstract“action” that defines unlocking some previous outputs, and creating newoutputs.  These new outputs can again be referred by a new transaction input. AUTXO or ‘Unspent Transaction Output’ is simply all those outputs, whichare yet to be unlocked by an input.  Once an output is unlocked, imagine they are removed from circulatingsupply and new outputs take their place. Thus the sum of the value ofunlocked outputs will be always equal to the sum of values of newlycreated outputs (ignoring transaction fees for now) and the totalcirculating supply of bitcoins remains constant.”\n\t - Fresh UTXOs are created as coinbase transactions, rewarded to miners whosuccessfully mine a block. These can be spent to multiple output asnormal. This is how the supply increases over time.\n\t\t- ## Bitcoin script and miniscript\n\t - A Bitcoin script is a short chunk of code written into each transactionwhich gives conditions for the next UTXO transfer (spend). Bitcoinscript is a programming language invented by Satoshi Nakamoto as part ofthe Bitcoin system. It’s a stack-based language, similar to reversePolish notation, used to encode transactions and specify the conditionsunder which a Bitcoin address can be spent. Bitcoin script has 256 opcodes, some of which are deprecated or can cause the program to fail.\n\t - Miniscript is a higher-level language that makes it easier to writerobust Bitcoin smart contracts on chain. It smooths out the rough edgesof Bitcoin script and makes it more accessible for non-technical usersto understand and use. Miniscript provides a more intuitive way tospecify spending conditions, making it easier for users to create smartcontracts without needing to be an expert in programming languages likeRust or C++. Miniscript takes the basket of 256 op codes in Bitcoinscript and simplifies them, making the most commonly used op codes moreaccessible and usable for average users. The [limited scriptinglanguage](https://bitcoin.sipa.be/miniscript/) and the features builtinto wallets on top, allow for some clever additional options besidereceiving and spending. In fact, some of the more innovative featuressuch as discrete log contracts (detailed later) are quite powerful, andcan interact with the outside world. Scripts allow spends to becontingent on multiple sets of authorising keys, time locks into thefuture, or both.\n\t - Time locks can be either block height-based or wall time-based, butMiniscript ensures that the user has to choose one or the other within asingle Bitcoin script. This is because some of the time lock opcodeslike \"check lock time verify\" (CLTV) and \"op sequence verify\" changetheir behavior based on whether the code is four or five bytes long.Miniscript removes these quirks by providing a unified and moreintuitive way to write smart contracts. An example of Miniscript’sfunctionality is a decaying multi-sig where a five of five multi-sig canbe changed over time to a four or five multi-sig, or a three of fivemulti-sig, in case one or two keys are lost. This provides the user withmore control and flexibility over their money and allows forcontingencies in case of loss events. Additionally, Miniscript enablesusers to have [more control over theirfunds](https://bitcoindevkit.org/bdk-cli/playground/) by setting ruleswhen money is put into a Bitcoin address, as well as allowing forcorporate governance situations. Miniscript can also be used forinheritance planning, where a child’s key can be made to activate aftera certain number of blocks have passed, creating a \"dead man switch\"functionality on the chain.\n\t - Overall, Miniscript enables users to have more control and flexibilityover their funds, making Bitcoin smart contracts more robust and secure,but it’s important to note that this is new technology and not yetintegrated into user wallets.\n\t\t- ## Halving\n\t - As mentioned eariler, roughly every four year the ‘block reward’ given to miners halves. This gives the issuances schedule of Bitcoin; [it’s monetaryinflation](http://bashco.github.io/Bitcoin_Monetary_Inflation/). This controlled supply’ feature was added to emulate the growth of physical asset stocks through mining. It’s exhaustively [explainedelsewhere](https://en.bitcoin.it/wiki/Controlled_supply) and is somewhat immaterial to our transactional use case in metaverse applications.\n\t\t- ## Difficulty adjustment\n\t - The difficult adjustment (also mentioned earlier) shifts the difficultyof the mining algorithm globally to re-target one new block every 10minutes. This means that adding a glut of new mining equipment willincrease the issuance of Bitcoins, in favour of the new mining entity,for up to 2 weeks, at which point the difficulty increases, the scheduleresets, and the advantage to the new miner is diffused. Equally thisprotects the network against significant loss of global mining hashrate,as happened when China comprehensively banned mining. Again, this isexplained in [more detail](https://en.bitcoin.it/wiki/Difficulty)elsewhere.\n\t\t- ## Bitcoin nodes\n\t - The Bitcoin network can be considered a triumvirate of economic actors,each with different incentives. These are:\n\t\t\t\t- Holders and users of the tokens, including exchanges and market makers, who make money speculating, [arbitraging](https://en.wikipedia.org/wiki/Arbitrage), and providing liquidity into the network. Increasingly this is also real ‘money’ users of BTC, earning and spending in pools of circular economic activity. Perversely Bitcoin as a money is the fringe use case at this time.\n\t\t\t\t- Miners, who profit from creation of new UTXOs, and receive payments for adding transactions to the chain. In return they secure the network by validating the other miners blocks according the rules enforced by the node operators.\n\t\t\t\t- Node operators, [who enforce the consensus](https://www.truthcoin.info/blog/measuring-decentralization/) rule-set, which the miners must abide by in order to propagate new transaction into the network. In return node operators optimise their trust minimisation, and help protect the network from changes which might undermine their speculation and use of the tokens.[[blocksizewars]]\n\t\t\t\t- There are currently around [15,000 Bitcoin nodes](https://bitnodes.io/)distributed across the world. Since IT engineer[Stadicus](https://stadicus.com/) released his [Raspiboltguide](https://raspibolt.org/backstory.html) in 2017 there has been anexplosion of small scale Bitcoin and Lightning node operators. Aroundthirty thousand Raspberry Pi Lightning nodes (which are also bydefinition Bitcoin nodes) run one of a big selection of [open sourcedistributions](https://github.com/bavarianledger/bitcoin-nodes). We willbuild toward our own throughout the book.\n\t\t- ## Wallets, seeds, keys and BIP39\n\t - In all the cryptographic systems described in this book everything isderived from a private key. This is an enormous number, and the input tothe trapdoor function described earlier. As usual, it’s beyond the scopeof this book to ‘rehash’ the detail. Prof Bill Buchanan OBE has a [greatpost](https://medium.com/asecuritysite-when-bob-met-alice/can-i-derive-the-private-key-from-the-public-key-ba3609256ec)on the basic version of this process.\n\t - In modern wallets, private keys (and so too their public keys), andaddresses, are generated hierarchically. This is all part of[BIP-0032](https://github.com/bitcoin/bips/blob/master/bip-0032.mediawiki).It starts with a single [monstrouslylarge](https://www.wolframalpha.com/input?i=2%5E512) number of up to 512bits. From this are crafted Hierarchical Deterministic (HD) wallets,which use ‘derivation paths’ to make a tree of public/private key pairs,all seeded from this first number. This means that knowing the initialnumber, and the derivation path applied to it (just another number),wallets can search down the tree of derivations and find all thepossible addresses. In this way a whole group of active addressesbelonging to an entity can be held conveniently in one huge number (aconcatenation of the input and path). This is the seed. Seeds are evenmore conveniently abstracted into a mnemonic called a seed phrase.Anyone interacting with these systems will see a 12 word (128 bits ofentropy which is considered to be[‘enough’](https://twitter.com/adam3us/status/1433375602808066049)) or24 word (256 bit) seed phrase. That phrase accesses the whole of theassets stored by that entity in the blockchain under it. A master key.These seeds can be [generated byhand](https://vault12.com/securemycrypto/cryptocurrency-security-how-to/dice-crypto-recovery-seed/)with dice, remember it’s just a huge number and the onward cryptographyat play here.\n\t - An address in Bitcoin is derived from the public/private key pair. Againthis is a one way hash function. The public/private keys can’t be foundfrom the address. Addresses are really only a thing in wallets. Theycontain the element necessary to interact with the UTXOs. Many UTXOs canreside under an address, in that they just share the same keys. Walletsand nodes can monitor the blockchain to see transactions that ‘belong’to addresses owned by the wallet, then they can perform unlocking ofthose funds to move them, through operations on the UTXOs via keys.\n\t - ### HD wallet encoding\n\t - ideas\n\t\t\t\t- The BIP39 standard is designed to create a human-readable and easilyportable format for Bitcoin and other cryptographic wallet seeds. Byrepresenting these seeds as a series of colors in a 3D model, we add anew dimension of portability, visual appeal, and potential applications.\n\t\t\t\t\t- **Easter Egg Hunts in Social Metaverses**: The color-based representation of BIP39 seeds opens up opportunities for creative and engaging experiences in metaverse environments. For instance, mnemonic seeds could be hidden within digital artifacts in the form of color sequences. These could be used as treasure hunts or easter eggs, potentially carrying real-world value in the form of Bitcoin or other cryptocurrencies. Recovery would mean some kind of sampling as in Fig <a href=\"#fig:HDwalletBlock\" data-reference-type=\"ref\" data-reference=\"fig:HDwalletBlock\">3.12</a> and software.\n\t\t\t\t\t- **Provenance Encoding in Digital Art**: The mnemonic color-coding could be embedded within digital art pieces, effectively encoding the provenance of the artwork directly into its visual representation. This could add an extra layer of security and uniqueness to the art piece, and also serve as a novel way of proving ownership or creatorship.\n\t\t\t\t\t- **Steganographic Transfer of Funds**: By incorporating the color-encoded BIP39 seeds into various aspects of a metaverse or digital environment, they can serve as a form of steganography. This allows for the transfer of funds or sensitive information covertly within the visual and experiential components of the environment.\n\t\t\t\t\t- **Gamification of Cryptographic Keys**: Cryptographic keys are typically represented as long, random strings of characters that are hard to remember and not very user-friendly. Representing these keys as a sequence of colors could make them more approachable and memorable. This could also introduce an aspect of gamification into the world of identity and value, possibly increasing their appeal to a broader audience.\n\t\t\t\t\t- **Embedding in Physical Objects**: 3D printing technologies could be used to create physical representations of these 3D models (assuming some variance of the colour as the materials age), embedding BIP39 seeds into tangible, physical objects. These could serve as novel physical wallets, gift items, or physical tokens representing digital assets.\n- While this encoding scheme opens up numerous creative opportunities, itis important to be aware of potential security implications. The use ofmnemonic seeds in this way should be done with care and an understandingof the risks involved.\n- The GitHub repository for this book [has some examplecode](https://github.com/flossverse/bip39Geom) playing around with thisidea further, generating a color-based and a three-dimensional graphicalrepresentation of nostr addresses. Each mnemonic word is mapped to aunique color and a 3D model is created, in which each word of themnemonic is represented by a cube of the corresponding color arranged ina circle.\n-\n\t - **BIP39Colors**: A class that contains a list of BIP39 words and methods to convert a hexadecimal seed to RGB colors and mnemonic words.\n-\n\t - **hex\\_to\\_rgb**: A static method within the BIP39Colors class that converts a hexadecimal color to an RGB color.\n-\n\t - **seedToColors**: A static method within the BIP39Colors class that converts a seed (a string of hexadecimal characters) into colors and mnemonic words. This function first converts the seed into bytes, then divides these bytes into groups and converts each group into a position in the word list and a color.\n-\n\t - **generate\\_3d\\_model**: A function that takes a list of colors as input, and generates a 3D model with cubes of these colors arranged in a circular formation.\n-\n\t - **main**: The main function of the script, which takes a 64-character hexadecimal string (a nostr ID) as an argument, converts it to colors and mnemonic words, and generates the 3D model.\n- The output of the program is a GLB file, which is a binary file formatrepresentation of 3D models saved in the GL Transmission Format (glTF).The file \"model.glb\" will be created in the same directory as thescript.\n- <span class=\"image\">This is the nostr pubkey for flossverse, encodedinto the far larger HD wallet space (hence the muted colours) and thendisplayed as blocks.</span>\n- ##### Custody\n- The topic of ‘custody’ of Bitcoin (addresses,UTXOs) can be confusing atfirst. This is another area where there’s a lot of detail available, butnot all of it is appropriate because increased complexity increasesrisk. Broadly though it’s important to remember that ownership of a UTXOis passed around using signing keys, which are functions of wallets.Wallets themselves don’t contain Bitcoin, they contain keys. Thesimplest approach is a software wallet. This is an application on adevice, which stores the private keys, and manages signing oftransactions which go onto the blockchain. It’s beyond the scope of thisbook to review or suggest software in detail, but[Bluewallet](https://bluewallet.io/) on mobile devices, and [SparrowWallet](https://sparrowwallet.com/) on desktop devices provide richbasic functionality if a reader wishes to get started immediately. Notethat these software wallets send your extended public key (the path ofthose keys) to the wallet providers server, for the monitoring of theblockchain to happen on it’s behalf. They’re updated by the softwarevendor, not the blockchain direct. To get this to ‘privacy bestpractice’ commensurate with the aim of this book it’s necessary to run afull node as detailed above, and connect the wallet software to that ona secure or local connection.\n- So called [hardwarewallets](https://unchained.com/blog/best-bitcoin-hardware-wallets/)should perhaps be termed signing devices. A [reddituser](https://www.reddit.com/r/Bitcoin/comments/z27jg8/comment/ixfj0w4/?)simplifies this concept very well: it“Your hardware wallet is a safethat holds a key. Your bitcoin is in a mailbox that anyone can look ator put more bitcoin into, but nobody can take the bitcoin out unlessthey have the key stored in your safe. The 24 word seed phrase are theinstructions needed to cut a new key.”. Rather than store Bitcoin theystore the private key in a more secure way, in a device which interactswith a computer or phone. More recently the hardware and associatedsoftware of such devices are building in [much needed privacytechnology](https://content.trezor.io/coinjoin). Remember that alltransactions on the Bitcoin blockchain are public. Interestingly theseprivacy technologies are subject to chain surveillance under the termsof their agreements, and companies like [Chainalysis rightly drawcriticism](https://www.wired.com/story/bitcoin-fog-roman-sterlingov-blockchain-analysis/).\n- We prefer hardware signing devices which can scan in the seed each timethemselves as is the case with opensource[“seedsigner”](https://seedsigner.com/), which also supports Nostrdelegation (Figure<a href=\"#fig:seedsigner\" data-reference-type=\"ref\" data-reference=\"fig:seedsigner\">3.13</a>).This makes the device perfect for management of all of our proposedmetaverse keys.\n  ![]./assets/dd17844862c1de627881dc01ec95fee5ad9fb959.jpg\n  Seedsigner is an inexpensive open source project which scans the master seed in from a QR code to enable signing. One device can run a quorum based wallet (multisig) and manage Nostr identity.\n- For higher security it’s possible to combine hardware and softwarewallets (signing devices) to provide a quorum of signatures required tomove funds. More exotic still are [proposals like“Fedimint”](https://fedimint.org/) which allows groups such as familiesor villages to leverage their personal trust to co-manage Bitcoin. Whatis not/rarely secure is leaving Bitcoin with a custodian such as anexchange as they simply issue you with an IOU and may abscond. Inbuilding toward a proposal for a product in this book it would be simplefor us to build a metaverse which users simply paid to use. This is thenorm up to now. Representative money would flow around in the metaverseand be changed back like game money at some point. This is not what wewish to promote, so everything will be a variation on “self-custody”,minimising third party trust for users.\n- #### Upgrade roadmap\n- ##### Taproot\n- ‘Taproot’ is the most recent upgrade to the Bitcoin network. It wasfirst [described in2018](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2018-January/015614.html)on bitcoin-dev mailing list, and become[BIP-0341](https://github.com/bitcoin/bips/blob/master/bip-0341.mediawiki)in 2019. It brings improved scripting, smart contract capability,privacy, and Schnorr signatures,[[schnorr1989efficient]] which are amaximally efficient signature verification method. The network willalways support older address types. It is rare to get such a largeupdate to the network, and deployment and upgrade was carefully managedover several months under BIP-0008. Uptake will be slow as walletmanufacturers and exchanges add the feature. It can be considered an[upgrade in progress(0.3%)](https://transactionfee.info/charts/transactions-spending-taproot/).Aaron van Wirdum, a journalist and educator in the space describesTaproot in detail in [anarticle](https://bitcoinmagazine.com/technical/taproot-coming-what-it-and-how-it-will-benefit-bitcoin).\n- ##### AnyPrevOut\n- [BIP-0118](https://anyprevout.xyz), is a“[soft-fork](https://en.bitcoin.it/wiki/Softfork) that allows atransaction to be signed without reference to any specific previousoutput”. It enables “Eltoo, a protocol that fulfils Satoshi’s vision fornSequence”\n- This is Lightning Network upgrade technology in the main. The Eltoo[whitepaper](https://blockstream.com/eltoo.pdf) or this more [readableexplanation](https://fiatjaf.alhur.es/ffdfe772.html) from developerfiatjaf go into detail.\n- ##### CheckTemplateVerify\n- [BIP-0119](https://utxos.org/) is “a simple proposal to power the nextwave of Bitcoin adoption and applications. The underlying technology iscarefully engineered to be simple to understand, easy to use, and safeto deploy”. At it’s most basic it is a constructed set of output hashes,creating a Bitcoin address, which if used, can only be spent undercertain defined conditions. This is a feature called ‘covenants’. Itenables a feature called ‘vaults’ which provides [additional safetyfeatures](https://github.com/jamesob/simple-ctv-vault/blob/7dd6c4ca25debb2140cdefb79b302c65d1b24937/README.md)for custodians. There is currently [some debate about the activationprocess](https://blog.bitmex.com/op_ctv-summer-softfork-shenanigans/),and the feeling is that it won’t happen (soon).\n- ##### Blind merge mining\n- BIP-0301 allows ‘other’ chains transactions to be mined into Bitcoinblocks, and for miners to take the fees for those different chains,without any additional work or thoughts by the miners. This is also aprerequisite for Drivechains (mentioned later), and improve Spacechains.In a way this can offer other chains the security model of the Bitcoinnetwork, while increasing fees to miners, which might be increasinglyimportant as the block subsidy falls. This is pretty fringe knowledge[originallyproposed](https://bitcointalk.org/index.php?topic=1790.msg28696#msg28696)by Satoshi, but has been refined since and is best explained by [PaulSztorc elsewhere](https://www.youtube.com/watch?v=xweFaw69EyA). It islikely an important upgrade in light of the [securitybudget](https://www.truthcoin.info/blog/security-budget/) of Bitcoin.\n- ##### Simplicity scripting language\n- [Simplicity](https://blockstream.com/simplicity.pdf) is a proposedcontract scripting language which is [‘formallyprovable’](https://coq.inria.fr/). This would provide a radical upgradeto confidence in smart contract creation. It is [work inprogress](https://github.com/ElementsProject/simplicity/blob/pdf/Simplicity-TR.pdf),and looks to be incredibly difficult to develop in, despite the name. Itis more akin to [assemblylanguage](https://en.wikipedia.org/wiki/Assembly_language). Developmenthas recently slowed, and the proposal requires a soft fork to Bitcoin.The main reason to think it stands a chance of completion vs other[similarproposals](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-March/020036.html)is the powerful backing of [Blockstream](https://blockstream.com/), oneof the main drivers of the Bitcoin ecosystem, run by Adam Back(potential co-creator of Bitcoin).\n- ##### Tail emission\n- It is conceivable though unlikely that Bitcoin will choose to remove the21 million coin hard cap in the end. This would potentially result in astable and predictable supply, compensating for lost coins, andreinvigorating the miner block reward. The Bitcoin narrative is **so**invested in the ‘hard money’ thesis that is seems such a hard fork wouldbe contentious at least, and possibly existentially damaging. PeterTodd, long time Bitcoin Core contributor things the idea has merit [andhas described it in a blogpost](https://petertodd.org/2022/surprisingly-tail-emission-is-not-inflationary).\n- ##### Ossification\n- The Bitcoin code is aiming toward so called[“ossification”](https://en.wikipedia.org/wiki/Protocol_ossification).The complete cessation of development of the feature set. This wouldprovide higher confidence in the protocol moving forward, as long terminvestors would be somewhat assured that the parameters of thetechnology would not change, and potentially pressure on the developerswould reduce. There’s a push to get some or all of the featuresdescribed above in over the next few year before this happens. As everthis is a controversial topic within the development community. NotablyPaul Sztorc, inventor of Drivechain [feelsstrongly](https://www.truthcoin.info/blog/sc-vision/) that cessation ofinnovation is a fundamental mistake, while also agreeing thatossification is necessary.\n- ### Extending the BTC ecosystem\n- The following section are by no means an exhaustive view of developmenton the Bitcoin network, but it does highlight some potentially usefulideas for supporting collaborative mixed reality interactions, in auseful timeframe.\n- #### Keet by holepunch\n- Tether and Bitfinex have released [Keet messenger](https://keet.io/)which allows peer to peer video calling and file sharing. It will be BTCand Tether enabled which allows transmission of value in a trustminimised fashion. Non custodial Lightning is coming to the productsoon. It looks like an incredibly strong and interesting product suiteis emerging here. If possible we would like to integrate this opensource platform with our metaverse. It is built upon the same[Hypercore](https://tether.to/en/tether-bitfinex-and-hypercore-launch-holepunch-a-platform-for-building-fully-encrypted-peer-to-peer-applications/)“holepunch” technology used by Synonym.\n- #### Block & SpiralBTC\n- Block (formally the payment processor “Square” is now an umbrellacompany for several smaller ’building block’ companies, all of which aremajor players in the space. Block itself is now part of the [W3C webconsortium](https://www.w3.org/Consortium/Member/List), so they will bedriving a new era of standards in distributed identity and valuetransfer. Like much of the industry lately they have either a [cloudover their reputation](https://hindenburgresearch.com/block/), or elseare subject to a targetted opportunistic attack.\n- SpiralBTC, formally ‘Square Crypto’ (a subsidiary of Square) is fundingdevelopment in Bitcoin and Lightning. Their main internal product is the[Lightning DevelopmentKit](https://spiral.xyz/blog/what-were-building-lightning-development-kit/)(LDK). This promising open source library and API will allow developersto add lightning functionality to apps and wallets. It is a usefulcontender for our metaverse applications. They also fund external opensource development.\n- #### BTCPayServer\n- BTCPayServer is one of the recipients of a Spiral grant. It is a selfhosted Bitcoin and Lightning payment processor system which allowsmerchants, online, and physical stores and businesses to integrateBitcoin into their accounting systems. It might seem that if one were touse Bitcoin then a simple address published on a website might beenough, but this is far from privacy best practice. Using a singleaddress creates a data point which allows external observers to tie allinteractions with a given point of sale to all of the customers, andonward to all of their other transactions through the public ledger.Since we seek to employ cyber security best practice will avoid [theissues with address reuse](https://en.bitcoin.it/wiki/Address_reuse).Each Bitcoin address should be used just once. This is fine as there’sessentially an [unlimitednumber](https://privacypros.io/btc-faq/how-many-btc-addresses) ofaddresses.\n- In a metaverse application there is no website to interact with, butfortunately BTCPayServer is completely open source and extensible, has astrong support community, [and anAPI](https://docs.btcpayserver.org/API/Greenfield/v1/#operation/Invoices_CreateInvoice)which could be integrated with a virtual world application. BTCPayServersupports the [mainthree](https://docs.btcpayserver.org/LightningNetwork/) distributions ofLightning but would potentially need extending in order to work withnewer technology like RGB or Omnibolt.\n- #### Mutiny web wallet\n- Mutiny Wallet, a new self-custodial lightning wallet, has launched inopen beta. It is web-based so requires no app download. Key featuresinclude just-in-time channels via Voltage, separating on-chain andLightning balances, encrypted remote backups, and Nostr walletconnections for social tips and subscriptions.\n- Mutiny aims to make lightning accessible to the billions of internetusers worldwide and provide features not possible on most custodialwallets due to app store restrictions. It is our chosen user wallet forour design.",
        "link_types": [
            "diffie1976new",
            "gayoso2018secure",
            "schnorr1989efficient",
            "harris2020flood",
            "blocksizewars",
            "schnorr1989efficient"
        ],
        "file_size": 34697
    },
    {
        "id": "Stable Diffusion.md",
        "name": "Stable Diffusion",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- Stable Diffusion has emerged as a transformative force in generative AI, mainly for text to image synthesis. This open source model was developed by UK company 'Stability AI', has democratised access to high quality image workflows, empowering artists, creatives, and professionals.\n- # Why Stable Diffusion?\n  id:: 66408f9e-30e0-442b-9aba-9eb51e36a739\n\t- ## Image, Video and 3D\n\t\t- [[Stable Diffusion]] and [[Stable Video Diffusion]] allow a lot of control, but at a cost of complexity.\n\t\t  collapsed:: true\n\t\t- ## Stable Diffusion 1.5, XL, and 3\n\t\t\t- UK company with global impact. It is likely now winding up it's operations after difficulty generating revenue in the hyper competitive GenAI market.\n\t\t\t\t- **Introduction**: Open-source model by StabilityAI\n\t\t\t\t\t- **Cost**: Free to run on own hardware; nominal fee for online tools.\n\t\t\t\t\t- **User Interface**: User-friendly through platforms like Leonardo.AI.\n\t\t\t\t\t- **Strengths**: Unlimited control, good image quality, no censorship.\n\t\t\t\t\t- **Weaknesses**: Requires decent hardware, steep learning curve. Questions about Stability business.\n\t\t\t\t\t- **Skill Level**: Intermediate to advanced.\n\t\t\t- ### Text-to-Image Generation\n\t\t\t\t- Stable Diffusion generates realistic and imaginative images from descriptive text prompts. This core functionality allows users to translate their creative visions into visual form with remarkable accuracy and detail. Whether it's a photorealistic portrait, a surreal landscape, or an abstract concept, Stable Diffusion can bring your ideas to life with just a few words.\n\t\t\t\t- A lot of the products you see on the market are either wrappers for the big AI companies, or else leveraging Stability models on rented cloud compute.\n\t\t\t\t\t- ![ComfyUI_temp_exgja_00013_.png](../assets/ComfyUI_temp_exgja_00013_1702592236908_0.png){:width 800}\n\t\t\t\t\t- ![Rife_00027.mp4](../assets/Rife_00027_1702831574413_0.mp4){:width 300}\n\t- ## Open Source\n\t\t- Stable Diffusion's open-source nature sets it apart from many other generative AI models.\n\t\t- Users have free access to the model's weights and a lot of modular code, allowing them to modify, distribute, and build upon it.\n\t\t- This openness fosters collaboration, innovation, and community driven development.\n\t\t- Ensures that the technology is not controlled by a select few entities.\n\t\t- For brands and private companies this allows private development of digital assets.\n\t- ## User Friendly Interfaces\n\t\t- Platforms like [Leonardo.AI](https://leonardo.ai/), [RunDiffusion](https://rundiffusion.com/) and [Automatic1111's WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui) provide intuitive and user friendly interfaces for interacting with Stable Diffusion.\n\t\t- ### Rundiffusion\n\t\t\t- <iframe src=\"https://rundiffusion.com/\" style=\"width: 800px; height: 600px\"></iframe>\n\t\t- These interfaces offer a range of options for customizing parameters, fine tuning models, and experimenting with different artistic styles.\n\t- ### Customisation\n\t\t- Stable Diffusion's flexibility extends to its ability to be fine-tuned on custom datasets.\n\t\t- Techniques like  [[KOHYA Dreambooth and similar]] and  [[LoRA]] training   allow users to tailor the model to their specific needs and generate images that align with their unique artistic visions or domain-specific requirements.\n\t\t  :LOGBOOK:\n\t\t  CLOCK: [2024-05-12 Sun 11:12:30]--[2024-05-12 Sun 11:12:31] =>  00:00:01\n\t\t  :END:\n\t\t\t- ![ComfyUI_temp_ayipz_00012_.png](../assets/ComfyUI_temp_ayipz_00012_1702330298489_0.png){:width 300, :height 402}\n\t\t- This opens up a world of possibilities for creating personalised images,\n\t\t\t- Generating images of specific objects or individuals,\n\t\t\t- Developing models for specialised domains like  [[Fashion]]  or architectural design.\n\t- ### Community Support\n\t\t- One of Stable Diffusion's greatest strengths is its vibrant and active community.\n\t\t- Much of this happens on Discord and Reddit\n\t\t\t- [(1832) Discord | #ad_resources | banodoco](https://discord.com/channels/1076117621407223829/1149372684220768367)\n\t\t\t- ![image.png](../assets/image_1715715718817_0.png){:width 800}\n\t\t\t- [comfyui (reddit.com)](https://www.reddit.com/r/comfyui/)\n\t\t\t- ![image.png](../assets/image_1715715792127_0.png){:width 800}\n\t\t\t- The [StableDiffusion subreddit](https://www.reddit.com/r/StableDiffusion/)\n\t\t\t- The [Stability AI Discord](https://discord.gg/stabilityai) serve as hubs for sharing creations, resources, and tutorials.\n\t\t\t- This collaborative environment fosters learning, inspiration, and rapid innovation\n\t\t- <iframe src=\"https://openaijourney.com/comfyui-guide/\" style=\"width: 800px; height: 600px\"></iframe>\n\t\t- <iframe src=\"https://comfyworkflows.com\" style=\"width: 900px; height: 600px\"></iframe>\n\t- ## Core Models\n\t\t- ~~Stable Diffusion 1.4~~\n\t\t- ### Stable Diffusion 1.5\n\t\t\t- [Available on GitHub](https://github.com/CompVis/stable-diffusion), this model is optimized for speed and efficiency,\n\t\t\t- Suitable for generating images quickly, especially on less powerful hardware.\n\t\t\t- Highest model diversity\n\t\t- ~~Stable Diffusion 2.1~~\n\t\t- ### SDXL\n\t\t\t- Higher resolution, better prompt control\n\t\t\t- Will often mess up human bodies due to constrained training\n\t\t\t- More resource intensive\n\t\t\t- Less compatible extensions\n\t\t- ### CosXL\n\t\t\t- Likely the last update from the team, most of whom have left following the departure of founder [Emad Mostaque](https://en.wikipedia.org/wiki/Emad_Mostaque).\n\t\t\t- This is a \"best practice\" update to SDXL which allows higher contrast.\n\t\t- ### Zero123 & SV3D\n\t\t\t- {{video https://youtu.be/gl1s7f0mV2E?t=677}}\n\t\t- ### ~~Stable Cascade~~\n\t\t\t- Only a partial release.\n\t\t\t- Not great adoption.\n\t\t\t- Better prompt adherence.\n\t\t- ### Stable Diffusion 3\n\t\t\t- [Temporary Stable Diffusion 3 Ban | Civitai](https://civitai.com/articles/5732/temporary-stable-diffusion-3-ban)\n\t\t\t- Might be ok in the end.\n\t\t\t- Whole new architecture.\n\t\t\t- Excellent prompt following.\n\t\t\t- Terrible human anatomy.\n\t- # Community models\n\t\t- Models and inspiration from CivitAI, which is very often \"not safe for work\" so do exercise caution.\n\t\t\t- <iframe src=\"https://civitai.com/images\" style=\"width: 100%; height: 600px\"></iframe>\n- ### Prompt Engineering: The Art of Guiding AI Creativity\n\t- Effective prompt engineering is crucial for unlocking the full potential of Stable Diffusion. Different models demand different styles\n\t- Here are some tips to enhance your prompts:\n\t\t- #### Specificity:\n\t\t\t- Use specific keywords and descriptive phrases to clearly convey your desired image to the AI model.\n\t\t\t- The more precise and detailed your prompt, the better the model can understand your intent and generate images that match your vision.\n\t\t- #### Negative Prompts:\n\t\t\t- Utilize negative prompts to exclude unwanted elements or styles from the generated image.\n\t\t\t- This allows you to refine the output and avoid generating images with undesirable features.\n\t\t- #### Compositional Control:\n\t\t\t- Employ prompt scheduling and area prompting to create complex compositions and focus on specific details.\n\t\t\t- These techniques allow you to control the timing and location of different elements within the image, resulting in more intricate and visually compelling outputs.\n\t\t- #### Extensions:\n\t\t\t- Leverage extensions like \"Test My Prompt\" to understand the impact of each word in your prompt and refine your wording for better results. This extension helps you analyse how the model interprets different words and phrases, allowing you to optimize your prompts for the desired outcome.\n\t\t- #### Experimentation:\n\t\t\t- Don't be afraid to experiment with different models, fine tuning techniques, and prompt styles to discover new possibilities and achieve your desired artistic outcomes.\n\t\t\t- The beauty of Stable Diffusion lies in its flexibility and the endless creative potential it offers.\n- ### Applications Across Industries:\n\t- Stable Diffusion's versatility has led to its adoption across various industries:\n\t\t- #### Digital Art Creation:\n\t\t\t- Artists are using Stable Diffusion to create stunning and innovative digital artworks, pushing the boundaries of artistic expression and exploring new creative frontiers.\n\t\t\t  Concept Visualization:\n\t\t- #### Designers and engineers\n\t\t\t- Use Stable Diffusion to quickly generate visual representations of their ideas, facilitating rapid prototyping and concept development. This allows for faster iteration and improved communication within design teams.\n\t\t\t  Character Design:\n\t\t- #### Game developers and animators\n\t\t\t- Leverage Stable Diffusion to create unique and memorable characters, streamlining the design process and reducing the time and resources required for character creation.\n\t\t\t  Illustration:\n\t\t- #### Illustrators\n\t\t\t- Can use Stable Diffusion to generate high-quality illustrations for books, magazines, and other media, offering a faster and more efficient way to produce visually compelling artwork.\n\t\t- #### Virtual Production:\n\t\t\t- Filmmakers and VFX artists can use Stable Diffusion to generate realistic backgrounds and environments for virtual production shoots, offering a cost-effective and efficient alternative to traditional green screen techniques.\n- ### Addressing Hardware Limitations:\n  While Stable Diffusion requires a decent GPU for optimal performance, several solutions are emerging to address hardware limitations:\n  Cloud-based Solutions: Platforms like [RunDiffusion](https://app.rundiffusion.com/)\n- https://www.forbes.com/sites/iainmartin/2024/03/20/key-stable-diffusion-researchers-leave-stability-ai-as-company-flounders/\n  Stable diffusion is a company that specializes in developing advanced artificial intelligence models. They are known for their expertise in creating generative models, which are capable of producing high-quality and realistic outputs in various domains such as image synthesis, language generation, and music composition. Stable Diffusion's cutting-edge research and innovative approaches have made significant contributions to the field of generative AI.\n  [Illustrated overview](https://jalammar.github.io/illustrated-stable-diffusion/)\n  Stable diffusion XL muse GPT [Stable Diffusion Muse\n  SDXL GPT Prompt Generator | Civitai](https://civitai.com/articles/2928/stable-diffusion-muse-sdxl-gpt-prompt-generator)\n  [Automatic1111 GUI and user guide](https://www.thosesixfaces.com/post/stable-diffusion-getting-started-windows)\n  [citivia browser](https://github.com/Vetchems/sd-civitai-browser)\n  [Automatic WebUI](https://github.com/AUTOMATIC1111/stable-diffusion-webui)\n  Vlads next SD\n  [InvokeAI simple interface](https://invoke-ai.github.io/InvokeAI/)\n  prompt engineering links\n  https://phraser.tech/\n  [Artist keywords that are known to work](https://docs.google.com/document/d/1SaQx1uJ9LBRS7c6OsZIaeanJGkUdsUBjk9X4dC59BaA/edit#)\n  https://promptomania.com/stable-diffusion-prompt-builder/\n  https://www.krea.ai/\n  [Lexica](https://lexica.art/)\n  [Dall-E prompt engineering](https://docs.google.com/document/d/11WlzjBT0xRpQhP9tFMtxzd0q6ANIdHPUBkMV-YB043U/edit#)\n  [public prompts guy](https://publicprompts.art/)\n  [Promptimize testing suite for prompts](https://github.com/preset-io/promptimize)\n  [Photoshop plugin](https://christiancantrell.com/#ai-ml)\n  Dreambooth retraining for faces\n  [windows instructions](https://pastebin.com/xcFpp9Mr)\n  [Discord server](https://discord.com/channels/1023277529424986162/)\n  [dreambooth for SD2](https://github.com/nitrosocke/dreambooth-training-guide/blob/main/README.md#how-to-fine-tune-stable-diffusion-20)\n  Birme image resizer\n  [2 hour tutorial](https://www.youtube.com/watch?v=Bdl-jWR3Ukc&t=34)\n  [inject your face into any model (dreambooth)](https://www.youtube.com/watch?v=s25hcW4zq4M)\n  [Guide for dreambooth](https://github.com/nitrosocke/dreambooth-training-guide)\n  [Shivram](https://github.com/ShivamShrirao/diffusers/tree/main/examples/dreambooth)\n  [Progen photorealism Miro guide](https://miro.com/app/board/uXjVPzJyAtU=/)\n  [rare dreambooth tokens](https://github.com/2kpr/dreambooth-tokens)\n  [Multi subject tokens](https://medium.com/@yushantripleseven/using-captions-with-dreambooth-joepenna-dreambooth-716f5b9e9866)\n  [tag editor](https://github.com/toshiaki1729/stable-diffusion-webui-dataset-tag-editor)\n  [SDXL dreambooth](https://medium.com/@yushantripleseven/dreambooth-training-sdxl-using-kohya-ss-windows-7d2491460608)\n  [Lora guide](https://civitai.com/articles/1771)\n  [stable swarm distributed comfyui](https://github.com/Stability-AI/StableSwarmUI)\n  [Textual inversion](https://www.reddit.com/r/StableDiffusion/comments/10gs4s2/new_expert_tutorial_for_textual_inversion_text/)\n  [Img2Img guide from reddit for face mapping](https://www.reddit.com/r/StableDiffusion/comments/xgurs3/testing_img2img_batch_processing_i_convert_this/)\n  [textual inversion cheaper training](https://github.com/rinongal/textual_inversion)\n  [CIO blog post](https://danieljeffries.substack.com/p/the-turning-point-for-truly-open?sd=pf)\n  [google stable diffusion](https://www.youtube.com/watch?v=lHcPtbZ0Mnc)\n  [Cross attention replace named items](https://github.com/bloc97/CrossAttentionControl)\n  [256 x faster speedup](https://the-decoder.com/stable-diffusion-could-soon-generate-images-much-faster/)\n  [VoltaML acceleration](https://github.com/VoltaML/voltaML-fast-stable-diffusion)\n  [Depth map into blender from SD2](https://www.youtube.com/watch?v=AeDngG9kQNI)\n  [midjourney tweaks](https://www.reddit.com/r/StableDiffusion/comments/z622mp/trained_midjourney_embedding_on_stable_diffusion/)\n  [and another](https://civitai.com/models/1253/anthro)\n  [Updates Pastebin](https://rentry.org/sdupdates3)\n  [Game development using SD](https://www.heroo.ai/)\n  [Wildcard manager using ChatGPT](https://github.com/mattjaybe/sd-wildcards)\n  [Depth2Img for text](https://www.reddit.com/r/StableDiffusion/comments/10c9kg8/depth2img_works_well_for_text_inputs/)\n  -[train chat GPT to write prompts](https://dreamlike.art/guides/using-openai-chat-gpt-to-write-stable-diffusion-prompts)\n  [non destructive image manipulation using seeds](https://www.reddit.com/r/StableDiffusion/comments/10no6tp/non_destructive_image_variation_in_text2image/)\n  [Instruct pix2pix](https://www.reddit.com/r/StableDiffusion/comments/10l74sl/instruct_pix2pix_is_amazing_inpaintingimg2img/)\n  [reddit post](https://www.reddit.com/r/StableDiffusion/comments/10tjzmf/instructpix2pix_is_built_straight_into_the/)\n  [Attention heatmap for prompts (youtube)](https://www.youtube.com/watch?v=XiKyEKJrTLQ)\n  [enormous link roundup](https://rentry.org/RentrySD/)\n  [Prompt master variations management](https://github.com/hoblin/prompt-master)\n  [panoramic world builder](https://huggingface.co/congazverse/worldBuilder)\n  [GitHub\n  AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin: A user-friendly plug-in that makes it easy to generate stable diffusion images inside Photoshop using Automatic1111-sd-webui as a backend.,A user-friendly plug-in that makes it easy to generate stable diffusion images inside Photoshop using Automatic1111-sd-webui as a backend.\n  GitHub\n  AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin: A user-friendly plug-in that makes it easy to generate stable diffusion images inside Photoshop using Automatic1111-sd-webui as a backend.](https://github.com/abdullahalfaraj/auto-photoshop-stablediffusion-plugin)\n  [GitHub\n  ashawkey/stable-dreamfusion: A pytorch implementation of text-to-3D dreamfusion, powered by stable diffusion. , A pytorch implementation of text-to-3D dreamfusion, powered by stable diffusion.\n  GitHub\n  ashawkey/stable-dreamfusion: A pytorch implementation of text-to-3D dreamfusion, powered by stable diffusion.](https://github.com/ashawkey/stable-dreamfusion)\n  [Fine tune stable diffusion](https://github.com/nitrosocke/dreambooth-training-guide/blob/main/readme.md#how-to-fine-tune-stable-diffusion-20)\n  [GitHub\n  Sanster/lama-cleaner: Image inpainting tool powered by SOTA AI Model. Remove any unwanted object, defect, people from your pictures or erase and replace(powered by stable diffusion) any thing on your pictures. , Image inpainting tool powered by SOTA AI Model. Remove any unwanted object, defect, people from your pictures or erase and replace(powered by stable diffusion) any thing on your pictures.\n  GitHub\n  Sanster/lama-cleaner: Image inpainting tool powered by SOTA AI Model. Remove any unwanted object, defect, people from your pictures or erase and replace(powered by stable diffusion) any thing on your pictures.](https://github.com/sanster/lama-cleaner)\n  [holovolo\n  immersive volumetric VR180 videos and photos, and 3D stable diffusion, for Quest and WebVR ,-](https://holovolo.tv)\n  [The Illustrated Stable Diffusion  Jay Alammar  Visualizing machine learning one concept at a time.](https://jalammar.github.io/illustrated-stable-diffusion/)\n  [reddit educational links](https://www.reddit.com/r/StableDiffusion/comments/116ki29/comment/j97jac3/)\n  [Negative prompt hack tip](https://www.reddit.com/r/StableDiffusion/comments/11pcsxe/just_discovered_a_useful_trick_for_getting_good/)\n  [Modify images with text](https://github.com/justinpinkney/stable-diffusion/blob/main/notebooks/imagic.ipynb)\n  [Photorealism](https://www.reddit.com/r/StableDiffusion/comments/11u2p0u/lazy_guide_to_photorealistic_images/)\n  [sdtools image v 1.6](https://www.reddit.com/r/StableDiffusion/comments/127gck9/sdtools_v16/)\n  [Character plugin](https://github.com/alexv0iceh/AutoChar)\n  [[Checkpoints]]\n  [Stability specific tools](https://sdtools.org/)\n  Arible Prompt Database https://www.arible.co/prompts\n   [[Guide] Make your own Loras, easy and free | Stable Diffusion Other | Civitai: You don't need to download anything, this is a guide with online tools. Click \"Show more\" below.  Preamble Even if you don't know where to start o...](https://civitai.com/models/22530)\n   [sdxl lora training](https://github.com/FurkanGozukara/Stable-Diffusion/blob/main/Tutorials/How-To-Install-And-Use-Kohya-GUI-And-Do-Ultra-Realistic-SDXL-Training-Tutorial.md)\n   [dylora scripts](https://github.com/facebookresearch/dadaptation/issues/24)\n   [kohya fork with scripts](https://github.com/bmaltais/kohya_ss#about-sdxl-training) [[KOHYA Dreambooth and similar]]\n   [lora of loras (compressed sets)](https://huggingface.co/FFusion/400GB-LoraXL/tree/main)\n   [chart of print size aspect ratios](https://www.reddit.com/r/StableDiffusion/comments/10wqv7r/when_it_comes_to_printing_converting_resolutions/)\n   [SDXL native text lora](https://civitai.com/models/176555/harrlogos-xl-finally-custom-text-generation-in-sd)\n   [SDXL lcm motion lora](https://huggingface.co/latent-consistency/lcm-lora-sdxl)\n   SDXL universal negative prompt\n   text, watermark, low-quality, signature, moiré pattern, downsampling, aliasing, distorted, blurry, glossy, blur, jpeg artifacts, compression artifacts, poorly drawn, low-resolution, bad, distortion, twisted, excessive, exaggerated pose, exaggerated limbs, grainy, symmetrical, duplicate, error, pattern, beginner, pixelated, fake, hyper, glitch, overexposed, high-contrast, bad-contrast\n   [SDXL prodigy training guide](https://civitai.com/articles/1022)\n   [Lora training interface for windows](https://github.com/bmaltais/kohya_ss)\n   [Refined model](https://civitai.com/models/8392/refined)\n   [Fine tuning with captioning and other fine tuning tricks, followfox](https://substack.com/profile/110613456-followfoxai)\n   [Negative embedding textual inversion for hands etc](https://huggingface.co/datasets/Nerfgun3/bad_prompt)\n   [GitHub\n   kpthedev/ez-text2video: Easily run text-to-video diffusion with customized video length, fps, and dimensions on 4GB video cards, as well as on CPU.: Easily run text-to-video diffusion with customized video length, fps, and dimensions on 4GB video cards, as well as on CPU.\n   GitHub\n   kpthedev/ez-text2video: Easily run text-to-video diffusion wit...](https://github.com/kpthedev/ez-text2video)\n   [Gligen grounding capability for sd1.5](https://gligen.github.io/)\n   [This repository contains a ComfyUI Extension for Automated Text Generation. The extension provides nodes which can be used to automate the text generation process. The goal is to build a node-based Automated Text Generation AGI. This extension should ultimately combine all of the features of the existing text generation tools into one tool.](https://github.com/xXAdonesXx/NodeGPT)\n   [[R] Text-to-image Diffusion Models in Generative AI: A Survey : r/MachineLearning](https://www.reddit.com/r/MachineLearning/comments/12ehcez/r_texttoimage_diffusion_models_in_generative_ai_a/)\n   [Tutorial: Creating a Consistent Character as a Textual Inversion Embedding](https://github.com/BelieveDiffusion/tutorials/discussions/3)\n   [Segment anything webui](https://www.reddit.com/r/StableDiffusion/comments/12hkdy8/sd_webui_segment_everything/)\n   [segment anything training](https://github.com/NielsRogge/Transformers-Tutorials/tree/master/SAM)\n   [Nvidia stable diffusion segment through clip](https://github.com/NVlabs/ODISE)\n   [Overriding iphone footage with SD characters using controlnet](https://www.reddit.com/r/StableDiffusion/comments/12lg8mn/override_more_experiments_overriding_the_original/)\n   [Interactive photo manipulation GAN](https://huggingface.co/papers/2305.10973)\n  [3d plugin for Automatic1111](https://github.com/jtydhr88/sd-webui-3d-editor)\n   [Face replace plugin for automatic](https://github.com/Gourieff/sd-webui-roop-nsfw)\n   images\n  [Colour palette extraction](https://github.com/mattdesl/gifenc)\n   [Text based real time image manipulation](https://arxiv.org/abs/2210.09276)\n   [Sketch guided text to image inference](https://sketch-guided-diffusion.github.io/)\n   [Google prompt to prompt image remodeller](https://www.youtube.com/watch?v=lHcPtbZ0Mnc)\n   [github](https://github.com/google/prompt-to-prompt)\n   [Img2Prompt](https://replicate.com/methexis-inc#)\n   [eDiffi nvidia text to image](https://deepimagination.cc/eDiffi/)\n   [Image to caption](https://laion.ai/blog/laion-coco/)\n   [lama image cleanup](https://github.com/Sanster/lama-cleaner)\n   [upscalers](https://upscale.wiki/wiki/Model_Database)\n   [upscayl](https://github.com/upscayl/upscayl)\n   [Google Muse](https://www.infoq.com/news/2023/01/google-muse-text-to-image/)\n   [Flair generate photo shoots of products](https://flair.ai/)\n   [Vector graphics from text](https://illustroke.com/)\n   [Simple stock image generator](https://stockimg.ai/)\n   [Patterned: Generates royalty-free patterns.](https://www.patterned.ai/)\n   [Cleanup.picture: Removes objects, defects, people or text from your images.](https://cleanup.pictures/)\n   [Looka: Generates brand names and logos.](https://looka.com/)\n   [CLIP interrogator and prompt engineering colab](https://github.com/pharmapsychotic/clip-interrogator)\n   [Prompt management engine (local and cloud) (promptlayer)](https://magniv.notion.site/PromptLayer-Docs-db0e6f50cacf4564a6d09824ba17a629)\n   [Composer stable diffusion TYPE model](https://github.com/damo-vilab/composer)\n   [Multi-diffusion panoramas](https://multidiffusion.github.io/)\n   [coherent panoramas paper](https://syncdiffusion.github.io/)\n   [UX design AI](https://www.usegalileo.ai/)\n   [pix2pix-3D: 3D-aware Conditional Image Synthesis](http://www.cs.cmu.edu/~pix2pix3D/)\n   [HuggingFace Demo for /ELITE: new fine-tuning technique that can be trained in less than a second/ now available : r/StableDiffusion](https://www.reddit.com/r/StableDiffusion/comments/11mzxyu/huggingface_demo_for_elite_new_finetuning/)\n   [GIGAgan](https://mingukkang.github.io/GigaGAN/)\n   [implementation](https://github.com/lucidrains/gigagan-pytorch)\n   [GitHub\n   danielgatis/rembg: Rembg is a tool to remove images background (other)](https://github.com/danielgatis/rembg)\n   Other. The text is a description of a new product called the \"Meta 2\" which is a headset that allows users to interact with a computer using their hands.\n   [GitHub\n   kanewallmann/Dreambooth-Stable-Diffusion: Implementation of Dreambooth (https://arxiv.org/abs/2208.12242) with Stable Diffusion (tweaks focused on training faces) (other)](https://github.com/kanewallmann/dreambooth-stable-diffusion)\n   [GitHub\n   sedthh/pyxelate: Python class that generates pixel art from images (other)](https://github.com/sedthh/pyxelate)\n   [GitHub\n   upscayl/upscayl:  Upscayl\n   Free and Open Source AI Image Upscaler for Linux, MacOS and Windows built with Linux-First philosophy. (other)](https://github.com/upscayl/upscayl)\n   [GitHub\n   YuxinWenRick/hard-prompts-made-easy: Contribute to YuxinWenRick/hard-prompts-made-easy development by creating an account on GitHub.](https://github.com/YuxinWenRick/hard-prompts-made-easy)\n  This repository contains a tool for gradient-based discrete optimization, which can be used to find the optimal solution for a given problem. The tool is designed to be easy to use, and includes a number of features to make the process of finding the optimal solution easier.\n   [Civitai Helper: SD Webui Civitai Extension | Stable Diffusion Other | Civitai: Now, we finally have a Civitai SD webui extension!! Update: 1.5.7 is here, if you're using localization extension, like Asian lanuage UI, you need ...](https://civitai.com/models/16768/civitai-helper-sd-webui-civitai-extension)\n   The Civitai Helper is a Civitai extension that allows for stable diffusions of other Civitai extensions. It also includes an animation which rotates and scales the extension icon.\n   [GitHub\n   YuxinWenRick/hard-prompts-made-easy: Contribute to YuxinWenRick/hard-prompts-made-easy development by creating an account on GitHub.](https://github.com/YuxinWenRick/hard-prompts-made-easy)\n   This repository contains code for a gradient-based discrete optimization method. The method is designed to make it easy to find hard prompts, which are useful for training machine learning models.\n   [StableSam meta segmentation plus SD inpainting](https://twitter.com/abhi1thakur/status/1645669023726592007)\n   New Feature: \"ZOOM ENHANCE\" for the A111 WebUI. Automatically fix small details like faces and hands! : r/StableDiffusion https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui/\n   [Realtime scribble](https://github.com/houseofsecrets/SdPaint)\n   [latent labs 360 images lora](https://civitai.com/models/10753/latentlabs360)\n   Kandinsky model\n   [finetuned 2.1](https://www.reddit.com/r/StableDiffusion/comments/13hgpo2/kandinsky_21_fine_tune/)\n   [QR codes](https://www.youtube.com/watch?v=IntRn96C4l4)\n   [DragGan image editing through drag points](https://github.com/XingangPan/DragGAN)\n   [Faster CPP clip](https://github.com/monatis/clip.cpp)\n   [animateDiff](https://github.com/guoyww/animatediff/)\n   [AnimatediffSDXL lora](https://www.reddit.com/r/StableDiffusion/comments/17stnug/sdxl_animatediff_motion_lora_released/)\n   [diffbar image sharpen](https://github.com/XPixelGroup/DiffBIR?ref=aiartweekly)\n   [SD model mixer](https://github.com/wkpark/sd-webui-model-mixer)\n   Textual Inversion character creation [tutorials/consistent_character_embedding/README.md at main · BelieveDiffusion/tutorials (github.com)](https://github.com/BelieveDiffusion/tutorials/blob/main/consistent_character_embedding/README.md)\n   [%3 e](https://github.com/nitrosocke/dreambooth-training-guide/blob/main/README.md#how-to-fine-tune-stable-diffusion-20%22/%3E)\n   [AI Creating 'Art' Is An Ethical And [[Copyright]] Nightmare](https://kotaku.com/ai-art-dall-e-midjourney-stable-diffusion-[[copyright]]-1849388060)\n   [CompVis/stable-diffusion: A latent text-to-image diffusion model](https://github.com/CompVis/stable-diffusion)\n   [Consistency in Stable Diffusion\n   Definitive Guide to Having Multiple Faces of the Same Character](https://www.youtube.com/watch?v=Ig1S2guCfKM%22%2F%3E)\n   [Consistency in Stable Diffusion\n   Definitive Guide to Having Multiple Faces of the Same Character](https://www.youtube.com/watch?v=Ig1S2guCfKM%22%3E)\n   [Consistency in Stable Diffusion\n   Definitive Guide to Having Multiple Faces of the Same Character](https://www.youtube.com/watch?v=Ig1S2guCfKM%7D%7Bconsistent)\n   [Consistent character embedding#readme%22](https://github.com/BelieveDiffusion/tutorials/tree/main/consistent_character_embedding#readme%22)\n   [Consistent character embedding#readme}{walkthrough](https://github.com/BelieveDiffusion/tutorials/tree/main/consistent_character_embedding#readme}{walkthrough)\n   [Controlnet for DensePose\n   v1.0 | Stable Diffusion Controlnet | Civitai](https://civitai.com/models/120149/controlnet-for-densepose%22/%3E)\n   [From the StableDiffusion community on Reddit: New Feature: \"ZOOM ENHANCE\" for the A111 WebUI. Automatically fix small details like faces and hands!](https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui)\n   [From the StableDiffusion community on Reddit](https://www.reddit.com/r/StableDiffusion/comments/132rcou/30_stable_diffusion_tutorials_automatic1111_web)\n   [How to Inject Your Trained Subject e.g. Your Face Into Any Custom Stable Diffusion Model By Web UI](https://www.youtube.com/watch?v=s25hcW4zq4M%22%2F%3E)\n   [How to Inject Your Trained Subject e.g. Your Face Into Any Custom Stable Diffusion Model By Web UI](https://www.youtube.com/watch?v=s25hcW4zq4M%22)\n   [How to Inject Your Trained Subject e.g. Your Face Into Any Custom Stable Diffusion Model By Web UI](https://www.youtube.com/watch?v=s25hcW4zq4M%7D%7Binject)\n   [Imagic: Text-Based Real Image Editing with Diffusion Models](https://buff.ly/3VLGMzo)\n   [RODIN Diffusion](https://3d-avatar-diffusion.microsoft.com/?amp%3Butm_medium=email&amp%3Butm_source=Revue+newsletter#/%22/%3E)\n   [Readme](https://github.com/huggingface/diffusers/blob/main/examples/community/README.md#tensorrt-text2image-stable-diffusion-pipeline)\n   [Readme](https://github.com/nitrosocke/dreambooth-training-guide/blob/main/README.md#how-to-fine-tune-stable-diffusion-20%22)\n   [Spirited Away\n   General Model (1.5)\n   @Spirited | Stable Diffusion Checkpoint | Civitai](https://civitai.com/models/5378/spirited-away-general-model-15%22)\n  [Spirited Away\n   General Model (1.5)\n   @Spirited | Stable Diffusion Checkpoint | Civitai](https://civitai.com/models/5378/spirited-away-general-model-15%7D%7Bspirited)\n   [Style-Info: An embedding for infographic style art\n   1.0 | Stable Diffusion Embedding | Civitai](https://civitai.com/models/5271/style-info-an-embedding-for-infographic-style-art%22/%3E)\n   [Style-Info: An embedding for infographic style art\n   1.0 | Stable Diffusion Embedding | Civitai](https://civitai.com/models/5271/style-info-an-embedding-for-infographic-style-art%7D%7BInfographic)\n   [THE DECODER](https://the-decoder.com/stable-diffusion-could-soon-generate-images-much-faster/%7D%7B256)\n   [Tutorial: Creating a Consistent Character as a Textual Inversion Embedding · BelieveDiffusion tutorials · Discussion #3](https://github.com/BelieveDiffusion/tutorials/discussions/3%22%3E)\n   [Tutorial: Creating a Consistent Character as a Textual Inversion Embedding · BelieveDiffusion tutorials · Discussion #3](https://github.com/BelieveDiffusion/tutorials/discussions/3%22)\n   [Ultimate Guide to Upscale Images with AI in Stable Diffusion](https://onceuponanalgorithm.org/ultimate-guide-to-upscale-images-with-ai-in-stable-diffusion)\n   [What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models#classifier-free-guidance}{here}.)\n   [Wojak SDXL\n   v1.0 | Stable Diffusion LoRA | Civitai](https://civitai.com/models/128046/wojak-sdxl%22)\n   [[deleted by user]](https://www.reddit.com/r/StableDiffusion/comments/145d6by/scannable_cat_qr_art_with_ai_my_recent_attempt)\n   [https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and/%22%3E%3Crichcontent](https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and/%22%3E%3Crichcontent)\n   [wl-zhao/UniPC: [NeurIPS 2023] UniPC: A Unified Predictor-Corrector Framework for Fast Sampling of Diffusion Models](https://github.com/wl-zhao/UniPC)\n   [万象熔炉 | Anything V5/Ink\n   ink | Stable Diffusion Checkpoint | Civitai](https://civitai.com/models/9409/anything-v5-or-anything-diffusion-original%22)\n   [万象熔炉 | Anything V5/Ink\n   ink | Stable Diffusion Checkpoint | Civitai](https://civitai.com/models/9409/anything-v5-or-anything-diffusion-original%7D%7BAnything)\n   [Align your Latents: High-Resolution Video Synthesis with Latent Diffusion Models](https://buff.ly/41FgQrb%22)\n   [Anthro\n   v1 | Stable Diffusion Embedding | Civitai](https://civitai.com/models/1253/anthro%22)\n   [Anthro\n   v1 | Stable Diffusion Embedding | Civitai](https://civitai.com/models/1253/anthro%7D%7Band)\n   [Become A Stable Diffusion Prompt Master By Using DAAM\n   Attention Heatmap For Each Used Token\n   Word](https://www.youtube.com/watch?v=XiKyEKJrTLQ%7D%7BAttention)\n   [Consistency in Stable Diffusion\n   Definitive Guide to Having Multiple Faces of the Same Character](https://www.youtube.com/watch?v=Ig1S2guCfKM%7D%7Bconsistent)\n   [Consistent AI Characters with Different Poses Angles\n   CharTurner Stable Diffusion](https://www.youtube.com/watch?v=-iwPVUzAWzk%22)\n   [Consistent AI Characters with Different Poses Angles\n   CharTurner Stable Diffusion](https://www.youtube.com/watch?v=-iwPVUzAWzk%7D%7Bcharacter)\n   [Consistent character embedding#readme%22](https://github.com/BelieveDiffusion/tutorials/tree/main/consistent_character_embedding#readme%22)\n   [Consistent character embedding#readme}{walkthrough](https://github.com/BelieveDiffusion/tutorials/tree/main/consistent_character_embedding#readme}{walkthrough)\n   [From the StableDiffusion community on Reddit: Advanced advice for model training / fine-tuning and captioning](https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and)\n   [From the StableDiffusion community on Reddit](https://www.reddit.com/r/StableDiffusion/comments/11mulj6/quality_improvements_to%22)\n   [Google's prompt-to-prompt AI for Stable Diffusion\n   tutorial!](https://www.youtube.com/watch?v=lHcPtbZ0Mnc%7D%7BGoogle)\n   [Home](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Developing-extensions%22)\n   [Home](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Developing-extensions%7D%7BAutomatic1111)\n   [How to Inject Your Trained Subject e.g. Your Face Into Any Custom Stable Diffusion Model By Web UI](https://www.youtube.com/watch?v=s25hcW4zq4M%7D%7Binject)\n   [How to Make 360 VR Environments for Quest with AI\n   Stable Diffusion and Blender Tutorial 2023](https://www.youtube.com/watch?v=t9zzcRsf0IA%22)\n   [How to Make 360 VR Environments for Quest with AI\n   Stable Diffusion and Blender Tutorial 2023](https://www.youtube.com/watch?v=t9zzcRsf0IA%7D%7BNice)\n   [Open Source AI and Stable Diffusion with Emad Mostaque](https://open.spotify.com/episode/3PCboPPIdkicl9eyW5Eaux?si=u6sUA8WdR9Wyw3NPLMdAXQ)\n   [Reddit\n   Prove your humanity](https://www.reddit.com/r/StableDiffusion/comments/10no6tp/non_destructive_image_variation_in_text2image/%7D%7Bnon)\n   [Refined\n   Refined v11 | Stable Diffusion Checkpoint | Civitai](https://civitai.com/models/8392/refined%22)\n   [Spirited Away\n   General Model (1.5)\n   @Spirited | Stable Diffusion Checkpoint | Civitai](https://civitai.com/models/5378/spirited-away-general-model-15%7D%7Bspirited)\n   [Stable Diffusion Outpainting Colab Tutorial](https://m.youtube.com/watch?list=PLpdmBGJ6ELUJOuL83tQKJm-ty4IJficHc&v=-8jmBGgGj2E)\n   [Style-Info: An embedding for infographic style art\n   1.0 | Stable Diffusion Embedding | Civitai](https://civitai.com/models/5271/style-info-an-embedding-for-infographic-style-art%7D%7BInfographic)\n   [Tutorial: Creating a Consistent Character as a Textual Inversion Embedding · BelieveDiffusion tutorials · Discussion #3](https://github.com/BelieveDiffusion/tutorials/discussions/3%22)\n   [Tutorial: Creating a Consistent Character as a Textual Inversion Embedding · BelieveDiffusion tutorials · Discussion #3](https://github.com/BelieveDiffusion/tutorials/discussions/3%7D%7BTutorial:)\n   [What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models#classifier-free-guidance}{here}.)\n   [Zero To Hero Stable Diffusion DreamBooth Tutorial By Using Automatic1111 Web UI\n   Ultra Detailed](https://www.youtube.com/watch?t=34%7D%7B2&v=Bdl-jWR3Ukc%5C)\n   [altryne/awesome-ai-art-image-synthesis: A list of awesome tools, ideas, prompt engineering tools, colabs, models, and helpers for the prompt designer playing with aiArt and image synthesis. Covers Dalle2, MidJourney, StableDiffusion, and open source tools.](https://github.com/altryne/awesome-ai-art-image-synthesis)\n   [diStyApps/Stable-Diffusion-Pickle-Scanner-GUI: Pickle Scanner GUI](https://github.com/diStyApps/Stable-Diffusion-Pickle-Scanner-GUI)\n   [https://www.reddit.com/r/StableDiffusion/comments/100tp0v/protogenx34_has_absolutely_amazing_detail/%22](https://www.reddit.com/r/StableDiffusion/comments/100tp0v/protogenx34_has_absolutely_amazing_detail/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/10c9kg8/depth2img_works_well_for_text_inputs/%22](https://www.reddit.com/r/StableDiffusion/comments/10c9kg8/depth2img_works_well_for_text_inputs/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/10c9kg8/depth2img_works_well_for_text_inputs/%7D%7BDepth2Img](https://www.reddit.com/r/StableDiffusion/comments/10c9kg8/depth2img_works_well_for_text_inputs/%7D%7BDepth2Img)\n   [https://www.reddit.com/r/StableDiffusion/comments/10gs4s2/new_expert_tutorial_for_textual_inversion_text/%7D%7BTextual](https://www.reddit.com/r/StableDiffusion/comments/10gs4s2/new_expert_tutorial_for_textual_inversion_text/%7D%7BTextual)\n   [https://www.reddit.com/r/StableDiffusion/comments/10l74sl/instruct_pix2pix_is_amazing_inpaintingimg2img/%7D%7BInstruct](https://www.reddit.com/r/StableDiffusion/comments/10l74sl/instruct_pix2pix_is_amazing_inpaintingimg2img/%7D%7BInstruct)\n   [https://www.reddit.com/r/StableDiffusion/comments/10no6tp/non_destructive_image_variation_in_text2image/%22](https://www.reddit.com/r/StableDiffusion/comments/10no6tp/non_destructive_image_variation_in_text2image/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/10rr99t/mocap_unreal_engine_warpfusion/%7D%7BMoCap](https://www.reddit.com/r/StableDiffusion/comments/10rr99t/mocap_unreal_engine_warpfusion/%7D%7BMoCap)\n   [https://www.reddit.com/r/StableDiffusion/comments/10tjzmf/instructpix2pix_is_built_straight_into_the/%22](https://www.reddit.com/r/StableDiffusion/comments/10tjzmf/instructpix2pix_is_built_straight_into_the/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/10tjzmf/instructpix2pix_is_built_straight_into_the/%7D%7Breddit](https://www.reddit.com/r/StableDiffusion/comments/10tjzmf/instructpix2pix_is_built_straight_into_the/%7D%7Breddit)\n   [https://www.reddit.com/r/StableDiffusion/comments/1148x38/tencent_ai_just_release_their_method_and_code/%7D%7BTencent](https://www.reddit.com/r/StableDiffusion/comments/1148x38/tencent_ai_just_release_their_method_and_code/%7D%7BTencent)\n   [https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and/%7D%7BAdvanced](https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and/%7D%7BAdvanced)\n   [https://www.reddit.com/r/StableDiffusion/comments/114zmh3/controlnet_and_ebsynth_make_incredible_temporally/%22](https://www.reddit.com/r/StableDiffusion/comments/114zmh3/controlnet_and_ebsynth_make_incredible_temporally/%22)\n  https://www.reddit.com/r/StableDiffusion/comments/114zmh3/controlnet_and_ebsynth_make_incredible_temporally/%7D%7Bcontrolnet](https://www.reddit.com/r/StableDiffusion/comments/114zmh3/controlnet_and_ebsynth_make_incredible_temporally/%7D%7Bcontrolnet)\n   [https://www.reddit.com/r/StableDiffusion/comments/11ah3nv/how_to_use_controlnet_to_make_incredible_fully/%7D%7BHow](https://www.reddit.com/r/StableDiffusion/comments/11ah3nv/how_to_use_controlnet_to_make_incredible_fully/%7D%7BHow)\n   [https://www.reddit.com/r/StableDiffusion/comments/11f8i0g/next_frame_prediction_with_controlnet/%22](https://www.reddit.com/r/StableDiffusion/comments/11f8i0g/next_frame_prediction_with_controlnet/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/11f8i0g/next_frame_prediction_with_controlnet/%7D%7BNext](https://www.reddit.com/r/StableDiffusion/comments/11f8i0g/next_frame_prediction_with_controlnet/%7D%7BNext)\n   [https://www.reddit.com/r/StableDiffusion/comments/11fpcb1/testing_controlnet_on_unreal_engine_5/%7D%7BTesting](https://www.reddit.com/r/StableDiffusion/comments/11fpcb1/testing_controlnet_on_unreal_engine_5/%7D%7BTesting)\n   [https://www.reddit.com/r/StableDiffusion/comments/11iviep/testing_a_custom_video2video_script_im_working_on/%22](https://www.reddit.com/r/StableDiffusion/comments/11iviep/testing_a_custom_video2video_script_im_working_on/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/11mulj6/quality_improvements_to_dpm_2m_karras_sampling/](%22](https://www.reddit.com/r/StableDiffusion/comments/11mulj6/quality_improvements_to_dpm_2m_karras_sampling/](%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/11mwzsz/convert_any_image_to_lineart_using_controlnet/%22](https://www.reddit.com/r/StableDiffusion/comments/11mwzsz/convert_any_image_to_lineart_using_controlnet/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/11mwzsz/convert_any_image_to_lineart_using_controlnet/%7D%7BConvert](https://www.reddit.com/r/StableDiffusion/comments/11mwzsz/convert_any_image_to_lineart_using_controlnet/%7D%7BConvert)\n   [https://www.reddit.com/r/StableDiffusion/comments/11mzxyu/huggingface_demo_for_elite_new_finetuning/%7D%7BHuggingFace](https://www.reddit.com/r/StableDiffusion/comments/11mzxyu/huggingface_demo_for_elite_new_finetuning/%7D%7BHuggingFace)\n   [https://www.reddit.com/r/StableDiffusion/comments/11ocwgw/textual_inversion_ti_tldr_for_the_lazy_how_to/%7D%7BTextual](https://www.reddit.com/r/StableDiffusion/comments/11ocwgw/textual_inversion_ti_tldr_for_the_lazy_how_to/%7D%7BTextual)\n   [https://www.reddit.com/r/StableDiffusion/comments/11ol47u/3d_model_face_color_map_generation_test3/%22](https://www.reddit.com/r/StableDiffusion/comments/11ol47u/3d_model_face_color_map_generation_test3/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/11ol47u/3d_model_face_color_map_generation_test3/%7D%7B3D](https://www.reddit.com/r/StableDiffusion/comments/11ol47u/3d_model_face_color_map_generation_test3/%7D%7B3D)\n   [https://www.reddit.com/r/StableDiffusion/comments/11owo31/something_that_might_help_ppl_with_posing/%7D%7BControlnet](https://www.reddit.com/r/StableDiffusion/comments/11owo31/something_that_might_help_ppl_with_posing/%7D%7BControlnet)\n   [https://www.reddit.com/r/StableDiffusion/comments/11owo31/something_that_might_help_ppl_with_posing/%7D](https://www.reddit.com/r/StableDiffusion/comments/11owo31/something_that_might_help_ppl_with_posing/%7D)\n   [https://www.reddit.com/r/StableDiffusion/comments/11pcsxe/just_discovered_a_useful_trick_for_getting_good/%22](https://www.reddit.com/r/StableDiffusion/comments/11pcsxe/just_discovered_a_useful_trick_for_getting_good/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui/%3C/a%3E](https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui/%3C/a%3E)\n   [https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui/%7D](https://www.reddit.com/r/StableDiffusion/comments/11pyiro/new_feature_zoom_enhance_for_the_a111_webui/%7D)\n   [https://www.reddit.com/r/StableDiffusion/comments/11rfol4/controlnet_character_design_workflow_links_in/%7D%7BControlNet](https://www.reddit.com/r/StableDiffusion/comments/11rfol4/controlnet_character_design_workflow_links_in/%7D%7BControlNet)\n   [https://www.reddit.com/r/StableDiffusion/comments/11u2p0u/lazy_guide_to_photorealistic_images/%7D%7BPhotorealism%7D](https://www.reddit.com/r/StableDiffusion/comments/11u2p0u/lazy_guide_to_photorealistic_images/%7D%7BPhotorealism%7D)\n   [https://www.reddit.com/r/StableDiffusion/comments/11w0ba9/modelscope_17b_text2video_model_is_now_available/%7D%7BAutomatic1111](https://www.reddit.com/r/StableDiffusion/comments/11w0ba9/modelscope_17b_text2video_model_is_now_available/%7D%7BAutomatic1111)\n   [https://www.reddit.com/r/StableDiffusion/comments/1244h2c/will_smith_eating_spaghetti/%7D%7BWill](https://www.reddit.com/r/StableDiffusion/comments/1244h2c/will_smith_eating_spaghetti/%7D%7BWill)\n   [https://www.reddit.com/r/StableDiffusion/comments/125m56z/smooth_animation_with_controlnet_and_regional/%22](https://www.reddit.com/r/StableDiffusion/comments/125m56z/smooth_animation_with_controlnet_and_regional/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/125m56z/smooth_animation_with_controlnet_and_regional/%7D%7BSmooth](https://www.reddit.com/r/StableDiffusion/comments/125m56z/smooth_animation_with_controlnet_and_regional/%7D%7BSmooth)\n   [https://www.reddit.com/r/StableDiffusion/comments/127gck9/sdtools_v16/%22](https://www.reddit.com/r/StableDiffusion/comments/127gck9/sdtools_v16/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/127gck9/sdtools_v16/%7D%7Bsdtools](https://www.reddit.com/r/StableDiffusion/comments/127gck9/sdtools_v16/%7D%7Bsdtools)\n   [https://www.reddit.com/r/StableDiffusion/comments/12cqb7k/i_suddenly_remembered_the_crazy_talk_app_it_is/%22](https://www.reddit.com/r/StableDiffusion/comments/12cqb7k/i_suddenly_remembered_the_crazy_talk_app_it_is/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/12cqb7k/i_suddenly_remembered_the_crazy_talk_app_it_is/%7D%7BCrazy](https://www.reddit.com/r/StableDiffusion/comments/12cqb7k/i_suddenly_remembered_the_crazy_talk_app_it_is/%7D%7BCrazy)\n   [https://www.reddit.com/r/StableDiffusion/comments/12dxue5/controlnet_face_model_for_sd_15/%22](https://www.reddit.com/r/StableDiffusion/comments/12dxue5/controlnet_face_model_for_sd_15/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/12dxue5/controlnet_face_model_for_sd_15/%7D%7BControlnet](https://www.reddit.com/r/StableDiffusion/comments/12dxue5/controlnet_face_model_for_sd_15/%7D%7BControlnet)\n   [https://www.reddit.com/r/StableDiffusion/comments/12hkdy8/sd_webui_segment_everything/%7D%7BSegment](https://www.reddit.com/r/StableDiffusion/comments/12hkdy8/sd_webui_segment_everything/%7D%7BSegment)\n   [https://www.reddit.com/r/StableDiffusion/comments/12lg8mn/override_more_experiments_overriding_the_original/%22](https://www.reddit.com/r/StableDiffusion/comments/12lg8mn/override_more_experiments_overriding_the_original/%22)\n  [https://www.reddit.com/r/StableDiffusion/comments/12nd60i/turn_a_group_photo_into_a_digital_painting_with/%7D%7BWorkflow](https://www.reddit.com/r/StableDiffusion/comments/12nd60i/turn_a_group_photo_into_a_digital_painting_with/%7D%7BWorkflow)\n   [https://www.reddit.com/r/StableDiffusion/comments/12nzrtl/hdr_photography_style_landscapesseascapes/%22](https://www.reddit.com/r/StableDiffusion/comments/12nzrtl/hdr_photography_style_landscapesseascapes/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/12nzrtl/hdr_photography_style_landscapesseascapes/%7D%7BHDR](https://www.reddit.com/r/StableDiffusion/comments/12nzrtl/hdr_photography_style_landscapesseascapes/%7D%7BHDR)\n   [https://www.reddit.com/r/StableDiffusion/comments/12o8qm3/finally_installed_the_newer_controlnet_models_a/%22](https://www.reddit.com/r/StableDiffusion/comments/12o8qm3/finally_installed_the_newer_controlnet_models_a/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/12otdo0/the_secret_to_really_easy_videos_in_a1111_easier/%22](https://www.reddit.com/r/StableDiffusion/comments/12otdo0/the_secret_to_really_easy_videos_in_a1111_easier/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/12otdo0/the_secret_to_really_easy_videos_in_a1111_easier/%7D%7BReally](https://www.reddit.com/r/StableDiffusion/comments/12otdo0/the_secret_to_really_easy_videos_in_a1111_easier/%7D%7BReally)\n   [https://www.reddit.com/r/StableDiffusion/comments/12sd4bi/results_from_latest_version_of_temporal_stable/%22](https://www.reddit.com/r/StableDiffusion/comments/12sd4bi/results_from_latest_version_of_temporal_stable/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/xgurs3/testing_img2img_batch_processing_i_convert_this/%7D%7BImg2Img](https://www.reddit.com/r/StableDiffusion/comments/xgurs3/testing_img2img_batch_processing_i_convert_this/%7D%7BImg2Img)\n   [https://www.reddit.com/r/StableDiffusion/comments/z622mp/trained_midjourney_embedding_on_stable_diffusion/%22](https://www.reddit.com/r/StableDiffusion/comments/z622mp/trained_midjourney_embedding_on_stable_diffusion/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/z622mp/trained_midjourney_embedding_on_stable_diffusion/%7D%7Bmidjourney](https://www.reddit.com/r/StableDiffusion/comments/z622mp/trained_midjourney_embedding_on_stable_diffusion/%7D%7Bmidjourney)\n   [https://www.reddit.com/r/StableDiffusion/comments/zecyc7/mixamo_animations_stable_diffusion_v2_depth2img/%22](https://www.reddit.com/r/StableDiffusion/comments/zecyc7/mixamo_animations_stable_diffusion_v2_depth2img/%22)\n   [https://www.reddit.com/r/StableDiffusion/comments/zecyc7/mixamo_animations_stable_diffusion_v2_depth2img/%7D%7Banimation](https://www.reddit.com/r/StableDiffusion/comments/zecyc7/mixamo_animations_stable_diffusion_v2_depth2img/%7D%7Banimation)\n   [https://www.theverge.com/2023/2/23/23611668/ai-image-stable-diffusion-mobile-android-qualcomm-fastest%7D%7BQualcomm](https://www.theverge.com/2023/2/23/23611668/ai-image-stable-diffusion-mobile-android-qualcomm-fastest%7D%7BQualcomm)\n\t-",
        "link_types": [
            "Stable Diffusion",
            "Stable Video Diffusion",
            "KOHYA Dreambooth and similar",
            "LoRA",
            "Fashion",
            "Checkpoints",
            "KOHYA Dreambooth and similar",
            "Copyright",
            "copyright",
            "deleted by user"
        ],
        "file_size": 50569
    },
    {
        "id": "Politics, Law, Privacy.md",
        "name": "Politics, Law, Privacy",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\nicon:: ⚖️\nThis is a general purpose linking slide for future [[presentation]]\n\n- ## [[Politics, Law, Privacy]]\n\t- EU AI act is it'll be near impossible now for small disruptive companies to train foundation models because of the administration overhead. Win for America.\n\t- Governments can now use real-time biometric surveillance in public spaces in prevention of genuine, present, or foreseeable threats, and searches for people suspected of the most serious crimes, so basically everything.\n\t\t- \"Real-time’ remote biometric identification (RBI) in publicly accessible spaces is prohibited for law enforcement, except when: searching for missing persons, abduction victims, and people who have been human trafficked or sexually exploited; preventing substantial and imminent threat to life, or foreseeable terrorist attack; or identifying suspects in serious crimes (e.g., murder, rape, armed robbery, narcotic and illegal weapons trafficking, organised crime, and environmental crime, etc.).\"\n\t- That will include gait analysis BTW. Europeans just took a big privacy hit. All your personal data goes to the USA, all your private movements go to Interpol (five eyes, eight eyes)\n\t- Already there are some 3000 constantly updated data point about all users of the internet. This is routinely bought and sold. According to Fowler at the Washington Post by the time a child with a phone is 13 there may be 72 million data points on them, and it's supposed to be illegal to track children\n\t- Politicians, law enforcement, and private companies have various constraints and restraints based on jurisdiction, but even strong laws like GDPR are routinely (always) ignored through technologies like browser fingerprinting.\n\t\t- [Cover Your Tracks (eff.org)](https://coveryourtracks.eff.org/)\n\t\t- [CreepJS (abrahamjuliot.github.io)](https://abrahamjuliot.github.io/creepjs/)\n\t- ![1715109606571.jpeg](../assets/1715109606571_1715110469719_0.jpeg)\n\t- logseq://graph/ResearchPapers?block-id=656c99ec-9ee4-46f5-bbf2-33f54f2090d9\n\t- As we have seen in the overturning of the USA abortion ban, the law can change, leaving individuals vulnerable to external forces. Googles promise to delete sensitive data in this case was not carried out. This is their business model and they are not our friends. Police went through 24GB of data from companies with key private chats provided by Meta in order to prosecute a 17 year old girl.\n\t\t- [The Hidden-Pregnancy Experiment | The New Yorker](https://www.newyorker.com/culture/the-weekend-essay/the-hidden-pregnancy-experiment)\n\t- ![image.png](../assets/image_1701614102581_0.png){:width 600}\n-\n- ## Legal Access\n\t- [Justice John Roberts 2023 end of year report)](https://www.supremecourt.gov/publicinfo/year-end/2023year-endreport.pdf)\n\t\t- And now we face the latest technological frontier: artificial intelligence (AI). At its core, AI combines algorithms and enormous data sets to solve problems. Its many forms and applications include the facial recognition we use to unlock our smart phones and the voice recognition we use to direct our smart televisions. Law professors report with both awe and angst that AI apparently can earn Bs on law school assignments and even pass the bar exam. Legal research may soon be unimaginable without it. AI obviously has great potential to dramatically increase access to key information for lawyers and non-lawyers alike. But just as obviously it risks invading privacy interests and dehumanizing the law.\n\t\t- Proponents of AI tout its potential to increase access to justice, particularly for litigants with limited resources. Our court system has a monopoly on many forms of relief. If you want a discharge in bankruptcy, for example, you must see a federal judge. For those who cannot afford a lawyer, AI can help. It drives new, highly accessible tools that provide answers to basic questions, including where to find templates and court forms, how to fill them out, and where to bring them for presentation to the judge—all without leaving home. These tools have the welcome potential to smooth out any mismatch between available resources and urgent needs in our court system.\n\t\t- But any use of AI requires caution and humility. One of AI's prominent applications made headlines this year for a shortcoming known as \"hallucination,\" which caused the lawyers using the application to submit briefs with citations to non-existent cases. (Always a bad idea.) Some legal scholars have raised concerns about whether entering confidential information into an AI tool might compromise later attempts to invoke legal privileges. In criminal cases, the use of AI in assessing flight risk, recidivism, and other largely discretionary decisions that involve predictions has generated concerns about due process, reliability, and potential bias. At least at present, studies show a persistent public perception of a \"human-AI fairness gap,\" reflecting the view that human adjudications, for all of their flaws, are fairer than whatever the machine spits out.\n\t\t- Many professional tennis tournaments, including the US Open, have replaced line judges with optical technology to determine whether 130 mile per hour serves are in or out. These decisions involve precision to the millimeter. And there is no discretion; the ball either did or did not hit the line. By contrast, legal determinations often involve gray areas that still require application of human judgment.\n\t\t- Machines cannot fully replace key actors in court. Judges, for example, measure the sincerity of a defendant's allocution at sentencing. Nuance matters: Much can turn on a shaking hand, a quivering voice, a change of inflection, a bead of sweat, a moment's hesitation, a fleeting break in eye contact. And most people still trust humans more than machines to perceive and draw the right inferences from these clues.\n\t\t- Appellate judges, too, perform quintessentially human functions. Many appellate decisions turn on whether a lower court has abused its discretion, a standard that by its nature involves fact-specific gray areas. Others focus on open questions about how the law should develop in new areas. AI is based largely on existing information, which can inform but not make such decisions.\n\t\t- Rule 1 of the Federal Rules of Civil Procedure directs the parties and the courts to seek the \"just, speedy, and inexpensive\" resolution of cases. Many AI applications indisputably assist the judicial system in advancing those goals. As AI evolves, courts will need to consider its proper uses in litigation. In the federal courts, several Judicial Conference Committees—including those dealing with court administration and case management, cybersecurity, and the rules of practice and procedure, to name just a few—will be involved in that effort. I am glad that they will be.\n\t\t- I predict that human judges will be around for a while. But with equal confidence I predict that judicial work—particularly at the trial level—will be significantly affected by AI. Those changes will involve not only how judges go about doing their job, but also how they understand the role that AI plays in the cases that come before them.\n\t- #### Margaret Hagan’s Work on Access to Law through AI\n\t\t- **Executive Director of the Legal Design Lab**\n\t\t\t- Focuses on making legal services more user-friendly and engaging through design.\n\t\t\t- Launched the Program for Legal Tech & Design at Stanford’s d.school.\n\t\t- **Teaching and Workshops**\n\t\t\t- Teaches project-based classes at Stanford Law School.\n\t\t\t- Leads workshops on the design process for legal professionals.\n\t\t- **Research and Publications**\n\t\t\t- Explores how AI can improve access to legal help.\n\t\t\t- Advocates for human-centered design in legal tech.\n\t\t- #### AI & Legal Help Initiatives\n\t\t- **Policy Practicum: AI For Legal Help**\n\t\t\t- [Envisions AI’s role in the legal sector from a community perspective](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4582745)[1](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4582745).\n\t\t- **Community-Led System Design Practice**\n\t\t\t- Involves community members in the design of AI legal services.\n\t\t- #### Events and Panels\n\t\t- **AI & Access to Justice Initiative**\n\t\t- [Discusses generative AI in new service and business models for legal problems](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4582745)[2](https://justiceinnovation.law.stanford.edu/projects/ai-access-to-justice/).\n\t\t- **American Academy Event on AI & Equitable Access to Legal Services**\n\t\t- [Panelist at a national event discussing AI’s implications for equitable legal services](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4582745)[3](https://justiceinnovation.law.stanford.edu/american-academy-event-on-ai-equitable-access-to-legal-services/).\n\t\t   \n\t\t   For more detailed information on her research and publications, you can visit her [Stanford Law School profile](https://law.stanford.edu/margaret-hagan/) and the [Legal Design Lab website](https://justiceinnovation.law.stanford.edu/american-academy-event-on-ai-equitable-access-to-legal-services/). Her work continues to push the boundaries of how AI can be leveraged to enhance the accessibility and effectiveness of legal services.\n- ## Crime\n\t- AI is already starting to be used in crime detection, crime prediction, and the data brokered by these tech behemoths is already making mistakes. [My chilling run-in with secretive facial-recognition app Clearview AI (telegraph.co.uk)](https://www.telegraph.co.uk/books/non-fiction/clearview-ai-facial-recognition-app-chilling/)\n\t- As AI increasingly bakes in these data points into ever larger scraped datasets it will be impossible to unwind one's personal history.\n\t- This too will increasingly be done by AI. We are trending toward AI fighting with AI over your data and the minutiae of your history in ever changing local and global political environments\n\t- People are concerned about this. There are already apps to semi automate data deletion online. The collapse in [[Trust and Safety]] since the 1970s is clearly documented across governments, media, and big business, but curiously people are trusting both their online social in groups, and machines that act human \"enough\" far more.  Recently, for unknown reasons they have also started to [[Trust and Safety]] \"business\" more. logseq://graph/ResearchPapers?block-id=656c9724-f862-4f4e-9a88-75b8b3f1b4e7\n\t-\n-\n- # Global politics\n- ### 4.12 Artificial Intelligence in a global context\n  This currently borrows heavily from [the AI breakdown podcast](https://www.youtube.com/watch?v=5clOHBo8HP8), is an AI generated placeholder, and needs considerably more more.\n- #### 4.12.1 Perception of AI and Society\n  The examination of AI's implications on societal structures should undoubtedly receive the necessary attention. Soros's language and perception of reality seem particularly interesting, especially in the era of AI. He emphasizes his belief in reality and its importance in providing moral guidance, a concept that seems increasingly challenged in the age of AI.\n- #### 4.12.2 AI, Propaganda, and Authoritarianism\n  In an opinion piece for The Hill by Bill Drexel and Caleb Withers, titled \\\"Generative AI could be an authoritarian breakthrough in brainwashing,\\\" the authors argue that the concern isn't just external attempts to influence U.S. elections, but the impact on the populations within authoritarian countries. They posit that foreign disinformation efforts by Chinese and Russian entities are only the tip of the iceberg, with Beijing and Moscow disseminating massive amounts of propaganda to their own populations. The authors also cite instances of AI-enabled propaganda and misinformation campaigns, both in the context of undermining democracies and consolidating control within authoritarian states.\n- #### 4.12.3 Increased Surveillance Through AI\n  Another critical concern around AI and authoritarianism is the potential for increased surveillance. With the integration of AI and data scraping techniques, governments can employ extensive teams to facilitate unprecedented levels of surveillance, compromising privacy. Such concerns are raised in the works of authors like Daniel Oberhaus, who posits that authoritarian regimes may have an advantage in AI due to their willingness to exploit data, such as advanced facial recognition data, in ways that open societies might not.\n- #### 4.12.4 Worker Surveillance and Remote Work\n  Furthermore, the issue of worker surveillance, especially with the rise of remote work regimes, has garnered the attention of various entities, including the White House. This is due to concerns over automated systems that employers are using to monitor their remote workers, highlighting a less benign context of surveillance.\n- #### 4.12.5 AI and Ideology\n  One way AI might foster authoritarianism is by supporting the ideology of closed societies or authoritarian regimes, such as China. These societies may leverage their global influence to disseminate their particular AI model, aligning it with their motivations and goals. The Carnegie Endowment for International Peace points out that for most countries, AI technology is viewed as an economic development factor that determines their standing in the global technology race, rather than as an ideological preference.\n- #### 4.12.6 AI and Central Planning\n  Another concern is the fear that AI will make centrally planned economies seem viable, where past attempts failed due to the lack of data. This idea was discussed in a conversation between Peter Thiel and Reed Hoffman hosted by Neil Ferguson at Stanford in 2018. Thiel posited that AI appears to favor centralization, an aspect that supports the principles of central planning.\n- #### 4.12.7 Uncontrolled AGI Creation\n  On the other hand, some suggest that capitalist competition could result in the creation of AGI that cannot be controlled. Dr. Jeffrey Hinton, a vocal advocate of this view, argues that AI's potential to disrupt business models could drive companies to recklessly pursue advancements in AI to stay competitive. This could lead to increased state power as people become more reliant on the state in an AI-dominated economy, potentially resulting in increased authoritarianism.\n- #### 4.12.8 AI Promoting Freedom\n  However, AI could also promote freedom in several ways. For instance, AI tools like Altana have been used to identify goods made using forced labor, helping companies make informed supply chain decisions. AI could also serve as a new interface for disseminating information, such as a chatbot that aids detainees in requesting legal assistance.\n- #### 4.12.9 AI, Integrity, and Accessibility\n  Yet, for AI to achieve its full potential in promoting freedom, the integrity of the information it disseminates must be uncompromised, and its accessibility must be ensured despite potential firewalls.\n- #### 4.12.10 AI's Impact on Societal Organization\n  Given these diverse viewpoints, it seems that the potential of AI to either aid authoritarianism or promote freedom is yet to be fully explored. However, the inherent ability of democracies to encourage disagreement and diverse perspectives may serve as a counterbalance to the potential of AI for authoritarian control. Moreover, AI's capacity as a catalytic force in societal organization should not be underestimated. The increasing discourse around AI and its implications for labor and technology usage suggests that AI technology is reshaping the world in ways that were unimaginable just a few years ago. Its capabilities in data analysis, decision making, and automation are transforming industries and redefining the scope of what's possible.\n- #### 4.12.11 Democratization of AI Technology\n  An argument often made in favor of democratization of AI technology is that it should be made open-source and freely available, thus creating a challenging framework for global political incumbents. This perspective is grounded on the belief that technology\n\t- and its underlying power\n\t- must be accessible to everyone to mitigate the risks of misuse and ensure fair benefits distribution.\n- #### 4.12.12 Open-source AI and Innovation\n  Open-source AI can be a vehicle for widespread innovation. It can spur creativity, leading to breakthroughs in various sectors, from healthcare and education to energy and transportation. Open-source technologies facilitate collaboration, accelerate the pace of research, and democratize access, enabling researchers and developers across the globe to contribute to the expansion of AI's capabilities. It opens the possibility for rapid iteration and innovation, reducing the likelihood that a few powerful entities monopolize control over these transformative technologies.\n- #### 4.12.13 Open-source AI and Global Politics\n  However, as beneficial as open-source AI may appear, the complexity of global politics can make the transition challenging. A landscape where AI technologies are open-source and freely available brings about potential dilemmas in various areas including national security, economic competitiveness, intellectual property rights, and data privacy.\n- #### 4.12.14 National Security and Open-source AI\n  To start, national security is a primary concern. AI has a myriad of applications in defense and security sectors, many of which could potentially be exploited by adversarial entities. As such, unrestricted access to AI technologies could pose a risk to nations' security. Nevertheless, it is crucial to note that security risks also stem from concentrated AI power. A handful of nations or corporations owning the majority of AI developments may lead to destabilization, power imbalance, and heightened global tensions.\n- #### 4.12.15 Economic Competitiveness and Open-source AI\n  Economic competitiveness is another intricate aspect. Countries and corporations are engaged in a fiercely competitive race to advance in AI technologies, recognizing the economic gains and strategic advantages tied to AI leadership. Open-source AI might challenge this dynamic, disrupting traditional models of competition. However, it could also create an environment of shared growth, leading to a more balanced global AI landscape.\n- #### 4.12.16 Intellectual Property Rights and Open-source AI\n  Intellectual property rights form another complex dimension in the discussion. Open-source AI challenges traditional notions of ownership and patents, potentially undermining the incentives for companies and individuals to invest in AI research and development. Balancing the need for innovation with the necessity to protect inventors' rights becomes critical in an open-source framework.\n- #### 4.12.17 Data Privacy and Open-source AI\n  Data privacy is a further point of contention. Open-source AI, coupled with increasingly ubiquitous data collection methods, raises concerns about individuals' privacy. However, it also provides an opportunity to develop robust, decentralized, and transparent AI systems that respect user privacy.\n- #### 4.12.18 A New Social Contract for AI\n  Thus, navigating the intersection of AI and global politics necessitates careful consideration. It requires establishing a new social contract for AI---one that respects human rights, promotes equitable economic growth, and protects national security.\n- #### 4.12.19 Conclusion\n  In conclusion, making AI open-source and freely available represents a shift from the status quo, with both promising potentials and daunting challenges. A global AI framework that upholds democratic principles and values, promotes shared prosperity, and safeguards security and privacy is the aspiration. To achieve this, an inclusive and multidimensional discourse is essential, involving governments, corporations, civil society, academia, and individual citizens. It is through this collective effort that AI's true potential can be harnessed for the global good.\n  There is skepticism the idea of artificial general intelligence (AGI) leading to superintelligent machines that threaten humanity in the near future. This supposed risk of AGI is described as a \\\"red herring\\\"\n\t- an unfounded fear. The reasons given are:\n\t  We do not have a clear understanding or definition of general     intelligence or consciousness.     Current AI like large language models are limited in scope. They are     good at statistical pattern matching in language, not generally     intelligent.     The hypothesis that intelligence and consciousness emerge simply     from increasing computational power is unproven. There are likely     other components we don't understand.\n\t  The real risk is perhaps government control and regulation of AI development and applications, justified by arguing it is needed for safety and responsible AI. This could impose limits on acceptable speech and thought. Centralised entities could become gatekeepers for how people access and interpret information about the world. Mandating allowable language could narrow ideas and speech to fit an official narrative. Fears of AGI, even if exaggerated, open the door for regulators and bureaucrats to intervene in the name of safety. The risk is not AGI itself but the government control that hype about it enables.\n\t  There is speculation that AI will automate many white collar cognitive jobs, similar to how industrial machinery automated manual labor. This may \\\"chase humans up the value stack\\\" as lower value work is handled by AI, freeing people to focus on higher value creative activities. [\\\\chapterimage] orange7.jpg\n- [He Wanted Privacy. His College Gave Him None – The Markup](https://themarkup.org/machine-learning/2023/11/30/he-wanted-privacy-his-college-gave-him-none)\n- [AI security considerations](https://ico.org.uk/for-organisations/guide-to-data-protection/key-dp-themes/guidance-on-ai-and-data-protection/how-should-we-assess-security-and-data-minimisation-in-ai/)\n- [Sci-fi becomes real as renowned magazine closes submissions due to AI writers: Clarkesworld wrestles with flood of machine-made submissions—over 500 in Feb. alone.](https://arstechnica.com/information-technology/2023/02/sci-fi-becomes-real-as-renowned-magazine-closes-submissions-due-to-ai-writers/)\n- The text discusses how a renowned magazine has had to close submissions due to the increasing number of AI writers. It is noted that the AI writers are becoming increasingly skilled and are starting to produce work that is on par with human writers.\n- [Lesswrong AI section](https://www.lesswrong.com/tag/ai)\n- [Goldman Sachs Predicts 300 Million Jobs Will Be Lost Or Degraded By Artificial Intelligence: Goldman Sachs maintains that if generative AI lives up to its hype, the workforce in the United States and Europe will be upended. The bank estimates 300 million jobs could be lost or diminished due to this fast-growing technology.](https://www.forbes.com/sites/jackkelly/2023/03/31/goldman-sachs-predicts-300-million-jobs-will-be-lost-or-degraded-by-artificial-intelligence/?sh=3af7314e782b)\n- [Medium listing approachs](https://blog.medium.com/how-were-approaching-ai-generated-writing-on-medium-16ee8cb3bc89)\n- [Drives us mad, Guardian](https://www.theguardian.com/technology/2023/mar/23/tech-guru-jaron-lanier-the-danger-isnt-that-ai-destroys-us-its-that-it-drives-us-insane)\n- [Chatbots must disclose sources or face ban](https://www.artisana.ai/articles/eus-ai-act-stricter-rules-for-chatbots-on-the-horizon)\n- [Google and EU private deal](https://techcrunch.com/2023/05/24/eu-google-ai-pact/)\n- [How to structure an ML business](https://txt.cohere.com/ai-is-eating-the-world/)\n- [Bias investigation](https://www.linkedin.com/feed/update/urn:li:activity:7072912582923173888/)\n- [GCHQ warning](https://www.ncsc.gov.uk/blog-post/chatgpt-and-large-language-models-whats-the-risk)\n- [confusion matrices](https://en.wikipedia.org/wiki/Confusion_matrix)\n- [KTN bridgeai report](https://iuk.ktn-uk.org/wp-content/uploads/2023/10/responsible-trustworthy-ai-report.pdf)\n- [Custom GPT open source semantic lock](https://github.com/infotrix/SSLLMs---Semantic-Secuirty-for-LLM-GPTs/blob/master/GPT_Semantic_Security_Template.txt)\n- Bitcoin and digital assets\n\t- A Law Commission consultation on “digital assets” has proposed a new third category of property:\n\t\t- it is composed of data represented in an electronic medium, including in the form of computer code, electronic, digital or analogue signals;\n\t\t- it exists independently of persons and exists independently of the legal system;\n\t\t- it is rivalrous such that use by one prejudices the ability of others;\n\t- Consensus seems to be that this is a thorough paper, and demonstrates strong knowledge of digital assets by the authors. \n\t  Gartner’s hype cycle 2022 features Web3, distributed identity, NFTs, and Metaverse and can be seen in Figure 1.6.\n\t- The legislative landscape in the UK is comparatively strict with questionable “know your customer / anti money laundering” (KYC/AML) data collection mandated in law. Users of UK exchanges must provide a great deal of personal financial information, and undertake to prove that the wallets they are withdrawing to are their own. From the perspective of the UK SME it seems this seriously limits the potential audience for new products. Europe meanwhile has recently voted through even more restrictive regulation, applying the “transfer of funds regulation” to all transactions coming out of exchanges, enforcing a database of all addresses between companies, and reporting transactions above 1000 Euros to authorities. They have narrowly avoided enforcing KYC on all transfers to private wallets, but have capped transactions at 1000 Euros. The recent “Markets in Crypto Assets (MiCA) legislation imposes overheads that may make it harder for smaller businesses in the sector to operate within the EU, but is has been cautiously welcomed by established players (Figure 2.5, who have been hungry for clarity. It is certainly far short of the ‘ban’ seen in China, and the regulation be enforcement in the USA.\n\t\t- European Parliament approved EU’s crypto assets framework, MiCA\n\t\t- Enforcement clock starts in June, with 12-18 months for rules to kick in\n\t\t- MiCA offers license tailored to crypto asset services and stablecoin issuers\n\t\t- Regulation refrains from covering decentralized finance or non-fungible tokens\n\t\t- Stablecoin issuer rules boost consumer confidence, potentially increas­ing institutional comfort\n- Politics, law, and change\n- [WEF risks report links](https://sociable.co/government-and-policy/wef-global-risks-report-cyber-pandemic-erosion-trust-social-cohesion/)\n- Regulation (everything)\n- Crypto\n- [UK](https://www.gov.uk/government/news/uk-sets-out-plans-to-regulate-crypto-and-protect-consumers)\n- [GPTs are GPTs: An Early Look at the Labor Market Impact](https://arxiv.org/abs/2303.10130)\n- The text discusses the potential implications of Generative Pre-trained Transformer (GPT) models on the U.S. labor market. It uses a new rubric to assess occupations based on their correspondence with GPT capabilities, incorporating both human expertise and classifications from GPT-4. The findings indicate that approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of GPTs, while around 19% of workers may see at least 50% of their tasks impacted. The influence spans all wage levels, with higher-income jobs potentially facing greater exposure. Notably, the impact is not limited to industries with higher recent productivity growth. The text concludes that Generative Pre-trained Transformers exhibit characteristics of general-purpose technologies (GPTs), suggesting that these models could have notable economic, social, and policy implications.\n- [El Salvador: Staff Concluding Statement of the 2023 Article IV Mission (other)](https://www.imf.org/en/News/Articles/2023/02/10/el-salvador-staff-concluding-statement-of-the-2023-article-iv-mission)\n- Other. The text describes a study by the University of Cambridge which found that people tend to trust robots more when they look and behave like humans.\n- [Silvergate Purchases Blockchain libre](https://ir.silvergate.com/news/news-details/2022/Silvergate-Purchases-Blockchain-Payment-Network-Assets-from-Diem/default.aspx)\n- The text discusses Silvergate's recent purchase of blockchain payment network assets from Diemwindow.\n- [Deception, exploited workers, and cash handouts: How Worldcoin recruited its first half a million test users: The startup promises a fairly-distributed, cryptocurrency-based universal basic income. So far all it's done is build a biometric database from the bodies of the poor.](https://www.technologyreview.com/2022/04/06/1048981/worldcoin-cryptocurrency-biometrics-web3/)\n- Worldcoin, a cryptocurrency startup, recruited its first 500,000 users by offering them free cash. The company has been accused of deception and exploiting workers, and is now under investigation.\n- [Privacy law book](https://www.smashingmagazine.com/printed-books/understanding-privacy/#bookTOC)\n- [Online safety bill heather articles](https://webdevlaw.uk/2022/11/21/a-quick-hypothetical-situation-or-your-crash-introduction-to-the-real-world/)\n- [Techcrunch on borderless payments](https://techcrunch.com/2021/12/21/borderless-crypto-networks-wrestle-with-state-sanction-compliance/?)\n- [Norway takes a stance against Google Analytics](https://www.simpleanalytics.com/blog/norway-takes-a-stance-against-google-analytics)\n- [Social Media Is Changing, And Paid Accounts Are The Response](https://www.bigtechnology.com/p/social-media-is-changing-and-paid)\n- [Linkedin post by Barry Scanell on EU AI law](https://www.linkedin.com/posts/activity-7062324196256735232-FfEz/?utm_source=share&utm_medium=member_desktop)\n- [wikipedia and the child protection bill](https://www.msn.com/en-gb/news/uknews/wikipedia-could-be-taken-offline-in-the-uk/ar-AA1atf9O)\n- [Kids are damaged by mobile phones](https://sapienlabs.org/wp-content/uploads/2023/05/Sapien-Labs-Age-of-First-Smartphone-and-Mental-Wellbeing-Outcomes.pdf?utm_source=substack&utm_medium=email)\n- [surveillance-capitalism-is-undermining-democracy](https://news.harvard.edu/gazette/story/2019/03/harvard-professor-says-surveillance-capitalism-is-undermining-democracy/)\n- https://bitcoinmagazine.com/culture/how-bitcoin-can-save-political-dissidents-in-myanmar\n- EU AI ACT\n\t- [Artificial Intelligence – Q&As (europa.eu)](https://ec.europa.eu/commission/presscorner/detail/en/QANDA_21_1683)\n\t- The Commission points out that the inception of the AI Act is rooted in the necessity to balance the benefits of AI, such as improved medical care and [[education]], with the need to mitigate inherent risks.\n\t- One of the key aspects of the AI Act identified by the Commission is its broad applicability. It encompasses both public and private entities within and outside the EU, as long as the AI system is marketed in the EU or affects individuals within it. This includes AI system providers, deployers, and importers. The Act also covers developers of general-purpose AI models, which are becoming integral to numerous AI systems and hence too significant to remain unregulated.\n\t- Certain AI systems are identified as high-risk, particularly those impacting safety or fundamental rights in sectors such as healthcare, education, and law enforcement. The Act also identifies AI practices that pose unacceptable risks, contravening EU values, including certain forms of social scoring and real-time remote biometric identification, which are banned. Additionally, systems like chatbots, which pose specific transparency risks, require clear user awareness of their interaction with a machine.\n\t- For high-risk AI systems, a conformity assessment is required before market introduction, ensuring compliance with standards for trustworthy AI, such as data quality, documentation, transparency, and human oversight. Post-market, these systems must undergo continuous risk management and incident reporting. The Act also imposes specific obligations on providers of general-purpose AI models, especially those with systemic risks, like large generative AI models trained using extensive computational power. These providers must disclose certain information to downstream system providers, respect [[copyright]] law during model training, and engage with the European AI Office to develop Codes of Conduct.\n\t- The European AI Office and the European Artificial Intelligence Board, supported by an Advisory Forum and a Scientific Panel of independent experts, are designed to ensure a harmonised and effective implementation of the Act across the EU.\n\t- The Act also stipulates substantial fines for non-compliance, indicating the seriousness with which the EU views AI regulation. Penalties can reach up to €35 million or 7% of the total worldwide annual turnover, depending on the nature of the infringement.\n\t- The Act mandates that high-risk systems must be trained and tested with representative datasets to minimise biases and must be traceable and auditable. Deployers of high-risk AI systems are required to conduct a fundamental rights impact assessment, ensuring that AI applications comply with fundamental rights legislation and do not exacerbate existing structural discriminations.\n-\n-\n-\n-\n-\n-\n- [[pol]]\n- [Serious New Warning As Google AI Targets Billions Of Private Messages (forbes.com)](https://www.forbes.com/sites/zakdoffman/2024/01/28/new-details-free-ai-upgrade-for-google-and-samsung-android-users-leaks/)\n-",
        "link_types": [
            "presentation",
            "Politics, Law, Privacy",
            "Trust and Safety",
            "Trust and Safety",
            "education",
            "copyright",
            "pol"
        ],
        "file_size": 33619
    },
    {
        "id": "Text to 3D and 4D.md",
        "name": "Text to 3D and 4D",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\n#Public page utomatically published\n\n- [Luma AI Genie (lumalabs.ai)](https://lumalabs.ai/genie?view=create)\n\t- <iframe src=\"https://lumalabs.ai/luma-web-library\" style=\"width: 100%; height: 600px\"></iframe>\n\t- <iframe src=\"https://3d.csm.ai/\" style=\"width: 100%; height: 600px\"></iframe>\n\t- <iframe src=\"https://www.meshy.ai/showcase\" style=\"width: 100%; height: 600px\"></iframe>\n\t- <iframe src=\"https://research.nvidia.com/labs/toronto-ai/LATTE3D/\" style=\"width: 100%; height: 600px\"></iframe>\n- Text to mutliview and texturing id:: 65a5024d-11bb-4737-aef3-af73103fa218\n\t- [StableProjectorz](https://stableprojectorz.com/)\n\t- {{video https://www.youtube.com/watch?v=IXQg0ITHjtw}}\n\t- ![slx-FbyoMFAfi7mbdV0xJ.mp4](../assets/slx-FbyoMFAfi7mbdV0xJ_1707401245057_0.mp4)\n\t- ## Leading contenders in Open Source\n\t\t- CRM [[ComfyUI]] implementation\n\t\t- [stabilityai/stable-zero123 · Hugging Face](https://huggingface.co/stabilityai/stable-zero123)\n\t\t- [SUDO-AI-3D/zero123plus: Code repository for Zero123++: a Single Image to Consistent Multi-view Diffusion Base Model. (github.com)](https://github.com/SUDO-AI-3D/zero123plus)\n\t\t- [Y _ STFC HARTREE _ REPORT.docx](../assets/Y_STFC_HARTREE_REPORT_1709806005572_0.docx)\n\t\t- [flowtyone/ComfyUI-Flowty-TripoSR: TripoSR custom node for comfyui (github.com)](https://github.com/flowtyone/ComfyUI-Flowty-TripoSR/tree/master)\n\t\t- [layerdiffusion/LayerDiffuse: Transparent Image Layer Diffusion using Latent Transparency (github.com)](https://github.com/layerdiffusion/LayerDiffuse)\n\t- [Paper page LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation (huggingface.co)](https://huggingface.co/papers/2402.05054)\n\t-\n\t- ![teaser-low.jpg](https://github.com/SUDO-AI-3D/zero123plus/blob/main/resources/teaser-low.jpg?raw=true)\n-\n- ## 3D Modelling Techniques\n\t- [Collaborative Control for Geometry-Conditioned PBR Image Generation (unity-research.github.io)](https://unity-research.github.io/holo-gen/)\n\t- **CLIP-Forge**\n\t\t- README for zero-shot text-to-shape generation.\n\t\t- [CLIP-Forge GitHub](https://github.com/autodeskailab/clip-forge)\n\t- **BlenderGPT**\n\t\t- Plugin for controlling Blender using GPT models.\n\t\t- [BlenderGPT GitHub](https://github.com/gd3kr/BlenderGPT)\n\t\t- [neph1/blender-stable-diffusion-render: A Blender addon for using Stable Diffusion to render texture bakes for objects. (github.com)](https://github.com/neph1/blender-stable-diffusion-render/)\n\t- **CLIP-Mesh**\n\t\t- Paper on 3D model generation from text prompts.\n\t\t- [CLIP-Mesh Paper](https://paperswithcode.com/paper/text-to-mesh-without-3d-supervision-using)\n- # Local project\n\t- TODO Voice in vircadia\n\t- TODO Keyword capture\n\t- TODO Mixtral LLM\n\t- DONE SDXL single image\n\t- DONE Multi Image\n\t- DONE Model\n\t- TODO Export\n\t- TODO Git pages commit\n\t- DONE Vircadia update\n- ## Texturing\n\t- **Dream Textures**\n\t\t- GitHub conversation on applying textures with text prompts.\n\t\t- [Dream Textures Pull Request](https://github.com/carson-katri/dream-textures/pull/409)\n\t- **ComfyTextures**\n\t\t- Automatic texturing using generative diffusion models in [[Unreal]] Engine.\n\t\t- [ComfyTextures GitHub](https://github.com/AlexanderDzhoganov/ComfyTextures)\n- ## Scene scale\n\t- [Paper page GALA3D: Towards Text-to-3D Complex Scene Generation via Layout-guided Generative Gaussian Splatting (huggingface.co)](https://huggingface.co/papers/2402.07207)\n\t- **Scene-Scale Diffusion**\n\t\t- [Scene-Scale Diffusion GitHub](https://github.com/zoomin-lee/scene-scale-diffusion)\n\t\t- **OnePose++ for Object Pose Estimation**\n\t\t\t- Paper on keypoint-free pose estimation pipeline.\n\t\t\t- [OnePose++ Page](https://zju3dv.github.io/onepose_plus_plus/)\n\t\t- **Imagine 3D Software**\n\t\t\t- Early-stage software for creating 3D effects using text.\n\t\t\t- [Imagine 3D](https://captures.lumalabs.ai/imagine)\n\t\t- **GET3D by Toronto AI Lab**\n\t\t\t- Generative model for creating 3D textured shapes.\n\t\t\t- [GET3D GitHub](https://nv-tlabs.github.io/GET3D/)\n\t\t- **Point·E System**\n\t\t\t- Generating 3D point clouds from prompts.\n\t\t\t- [Point·E GitHub](https://github.com/openai/point-e)\n\t\t- **Dream Fields for Text-Guided 3D Object Generation**\n\t\t\t- Synthesizing 3D objects based on language descriptions.\n\t\t\t- [Dream Fields](https://ajayj.com/dreamfields)\n\t\t- **LION by Toronto AI Lab**\n\t\t\t- New approach for 3D shape generation called LION.\n\t\t\t- [LION](https://nv-tlabs.github.io/LION/)\n\t\t- **3D Highlighter**\n\t\t\t- System for localizing semantic regions on 3D shapes.\n\t\t\t- [3D Highlighter Website](https://threedle.github.io/3DHighlighter/)\n\t\t- **VQ-AD Method by NVIDIA and University of Toronto**\n\t\t\t- Research on compressing feature grids in neural approximations.\n\t\t\t- [VQ-AD Research Page](https://nv-tlabs.github.io/vqad/)\n\t\t- **MoFusion for Human Motion Synthesis**\n\t\t\t- Paper on unified model for generating human motion.\n\t\t\t- [MoFusion GitHub Page](https://ofa-sys.github.io/MoFusion/)\n\t\t- **Software and Tools**\n\t\t\t- [TomLikesRobots🤖 on X: \"Simple Stable Diffusion to Blender: 1. Use Automatic1111's depth map extension (https://t.co/3i4QhbvAV8) to create image (img2img or txt2img) & depth map. 2. Import to Blender using Depth Map Importer https://t.co/8hIUGwWSFX 3. That's it\n\t\t\t- play around! #stable diffusion #aiart https://t.co/qr1yhDpHgd\" / X (twitter.com)](https://twitter.com/TomLikesRobots/status/1603884188326940674)\n\t\t- **Monster Mash Troubleshooting**\n\t\t\t- Steps to troubleshoot issues with Monster Mash.\n\t\t\t- [Monster Mash](https://monstermash.zone/)\n\t\t- **Text2Mesh**\n\t\t\t- Method for text-driven stylization of 3D mesh.\n\t\t\t- [Text2Mesh GitHub](https://github.com/threedle/text2mesh)\n\t\t- **Modeling Discussion on Echoes of Somewhere**\n\t\t\t- Blog post comment section on modeling a robot.\n\t\t\t- [Modeling a Robot Discussion](https://echoesofsomewhere.com/2023/01/25/modeling-a-robot-with-some-added-difficulty/)\n\t\t- **Reddit Post on Virtual Reality**\n\t\t\t- Collection of VR-related discussions.\n\t\t\t- [Reddit VR Post](https://www.reddit.com/r/virtualreality/comments/xvy5dc/3d_generation_from_a_single_image/)\n\t\t- **neThing.xyz**\n\t\t\t- AI text to 3D CAD model conversion tool.\n\t\t\t- [neThing.xyz](https://nething.xyz/)\n\t\t- **DreamCraft3D**\n\t\t\t- Hierarchical 3D generation with a bootstrapped diffusion prior.\n\t\t\t- [DreamCraft3D](https://mrtornado24.github.io/DreamCraft3D/)\n\t\t- **ReplaceAnything3D**\n\t\t\t- Text-guided 3D scene editing with compositional neural radiance fields.\n\t\t\t- [ReplaceAnything3D](https://huggingface.co/papers/2401.17895)\n\t\t- **AGG: Amortized Generative 3D Gaussians**\n\t\t\t- For single image to 3D conversion.\n\t\t\t- [AGG](https://ir1d.github.io/AGG/)\n\t\t- **TIP-Editor**\n\t\t\t- An accurate 3D editor following both text-prompts and image-prompts.\n\t\t\t- [TIP-Editor](https://huggingface.co/papers/2401.14828)\n\t\t- **Instant Meshes**\n\t\t\t- Interactive field-aligned mesh generator.\n\t\t\t- [Instant Meshes GitHub](https://github.com/wjakob/instant-meshes)\n\t\t- **Make-It-3D**\n\t\t\t- High-fidelity 3D content creation from a single image.\n\t\t\t- [Make-It-3D](https://make-it-3d.github.io/)\n\t\t- **Vox-E**\n\t\t\t- Text-guided voxel editing of 3D objects.\n\t\t\t- [Vox-E Results](https://etaisella.github.io/htmlTutorial2.github.io-index.html/results_real.html)\n\t\t- **Text2Room**\n\t\t\t- Generating 3D meshes from text prompts.\n\t\t\t- [Text2Room](https://lukashoel.github.io/text-to-room/)\n\t\t- **VMesh**\n\t\t\t- Efficient view synthesis with a triangular mesh and a sparse volume.\n\t\t\t- [VMesh](https://bennyguo.github.io/vmesh/)\n\t\t- **3DFuse**\n\t\t\t- Robust text-to-3D generation incorporating 3D awareness into 2D models.\n\t\t\t- [3DFuse](https://ku-cvlab.github.io/3DFuse/)\n\t\t- **Motion Model for Image Animation**\n\t\t\t- Animating images with a source image and a driving video.\n\t\t\t- [Thin Plate Spline Motion Model](https://replicate.com/yoyo-nb/thin-plate-spline-motion-model)\n\t\t- **VoxGRAF**\n\t\t\t- Fast 3D-aware image synthesis with sparse voxel grids.\n\t\t\t- [VoxGRAF](https://katjaschwarz.github.io/voxgraf/)\n\t\t- **Realistic One-Shot Mesh-Based Human Head Avatars**\n\t\t\t- Creating avatars from a single photograph.\n\t\t\t- [ROME Avatars](https://samsunglabs.github.io/rome/)\n- # Pinokio\n\t- [twitter link to the render loading below](https://twitter.com/cocktailpeanut/status/1765462787046686968)\n\t  {{twitter https://twitter.com/cocktailpeanut/status/1765462787046686968}}\n\t-\n- {{twitter https://twitter.com/blizaine/status/1765434684450742764?}}\n\t-",
        "link_types": [
            "ComfyUI",
            "Unreal"
        ],
        "file_size": 8345
    },
    {
        "id": "Decentralised Web.md",
        "name": "Decentralised Web",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # Decentralisation & The Web\n\t- ## Semantic web\n\t\t- The [[Semantic Web]] definition of Web3.0 has been somewhat overhauled by other innovations in decentralised internet technologies, now evolving toward the slightly different Web3 moniker. Tim Berners Lee (of WWW fame) first mentioned the semantic web in 1999 \\[[2]\n\t\t- \"I have a dream for the Web \\[in which computers\\] become capable of analyzing all the data on the Web -- the content, links, and transactions between people and computers. A \\\"Semantic Web\\\", which makes this possible, has yet to emerge, but when it does, the day-to-day mechanisms of trade, bureaucracy and our daily lives will be handled by machines talking to machines. The \\\"intelligent agents\\\" people have touted for ages will finally materialize.\"\n\t\t  Attention developed around three core themes, ubiquitous availability and searchability of data, intelligent search assistants, and highly available end points such as phones, and 'internet of things' devices. This is certainly manifesting in home devices, but few people think of this as a Web3 revolution. Since ratification of the standards by the [World Wide Web (W3C) consortium](https://www.w3.org/standards/semanticweb/) it seems that their imperative toward decentralisation has become lost. Instead, it can be seen that Facebook, Amazon, Google, and Apple have a harmful oligopoly on users data \\[[3](https://arxiv.org/html/2207.09460v11/#bib.bibx3)\\]. This is at odds with Berners-Lee's vision, and he has recently [spoken out about this discrepancy](https://thenextweb.com/news/web-inventor-tim-berners-lee-screw-web3-my-decentralized-internet-doesnt-need-blockchain/), and attempted to [refocus the media](https://www.cnbc.com/2022/11/04/web-inventor-tim-berners-lee-wants-us-to-ignore-web3.html) onto Web3.0.\n\t\t- It is worth taking a look at his software implementation called [Solid](https://solidproject.org/), which is far more mindful of the sovereignty of user data.\n\t - \" [[Solid]] (and offshoot [[Solid-Lite]]) is an exciting new project led by Prof. Tim Berners-Lee, inventor of the World Wide Web, taking place at MIT. The project aims to radically change the way Web applications work today, resulting in true data ownership as well as improved privacy. Solid (derived from \\\"social linked data\\\") is a proposed set of conventions and tools for building decentralized social applications based on Linked Data principles. Solid is modular and extensible and it relies as much as possible on existing W3C standards and protocols.\"\n\t\t- Excitement around this kind of differentiated trust model, hinted at in ubiquitous availability of data (and implemented explicitly in Solid), has led to exploration of different paths by cryptographers, and this will be described later. For instance, one of the main developers of Solid, [Carvelho](https://github.com/melvincarvalho/), is now a leading developer and propotent of [[Solid-Lite]] and [[nostr]] , another very interesting option. This technology space is prolific, but still comparatively young and small.\n\t- ## Spatial web\n\t\t- \"The Spatial Web\", a blurring of the boundaries between digital and geospatial physical objects, seems to have developed from the strands in the original W3C scope around devices in the real world. It has been concentrating around AR and VR but is being marketed and amplified with the same references to availability of data (See Figure [2.1](https://arxiv.org/html/2207.09460v11/#Ch2.F1 \"Figure 2.1 ‣ 2.2 Spatial web ‣ Chapter 2 Decentralisation & The Web ‣ Part I State of the art\") from a Deloitte accounting report). This too is finding little traction in practice, though obviously the component technologies continue to enjoy rapid development. Nonetheless, this interpretation of Web3 becomes valuable when examining [[Metaverse and Telecollaboration]].\n\t\t- ![Figure 2.1: [Deloitte Spatial Web Overview](https://www2.deloitte.com/us/en/insights/topics/digital-transformation/web-3-0-technologies-in-business.html) Reused with permission.](../assets/deloitteWeb3.jpg){:height 1075, :width 1172}\n- ## Web3\n\t- More recently Web3 is [being touted](https://trends.google.com/trends/explore?date=all&q=web3) as a way to connect content creators directly to content consumers, without centralised companies acting as gatekeepers of the data. It implies that all users have a cryptographic key management system, to which they attach metadata, that they make requirements of peers with whom they communicate, and that they maintain trust 'scores' with peers.\n\t- It seems likely that this new model is less driven by a market need, and more by the high availability of tools which allow this to happen (the ecosystems described later). Add to this a social response to the [collapse in trust of companies such as Facebook](https://finance.yahoo.com/news/meta-facebook-worst-company-of-the-year-yahoo-finance-165345819.html) and other [social media platforms](https://reb00ted.org/tech/20220727-end-of-social-networking/)\\[[4](https://arxiv.org/html/2207.09460v11/#bib.bibx4)\\] (Figure [2.2](https://arxiv.org/html/2207.09460v11/#Ch2.F2 \"Figure 2.2 ‣ 2.3 Web3 ‣ Chapter 2 Decentralisation & The Web ‣ Part I State of the art\")). There is perhaps a wish by consumers to pass more of the economic incentive to content creators, without the 'rent seeking' layer afforded by businesses, and a healthy dose of mania driven market speculation. [Edelman's latest trust report](https://www.edelman.co.uk/sites/g/files/aatuss301/files/2022-01/2022%20Edelman%20Trust%20Barometer_UK.pdf) is shocking, finding that trust in all institutions has slumped recently to all time lows, and their global survey found that: [\"Nearly 6 in 10 say their default tendency is to distrust something until they see evidence it is trustworthy. Another 64% say it's now to a point where people are incapable of having constructive and civil debates about issues they disagree on. When distrust is the default -- we lack the ability to debate or collaborate.\"] \n\t  ![Figure 2.2: [Edelman 2020 trust barometer](https://www.edelman.com/trust/2020-trust-barometer) \\[rights requested\\]](../assets/c-a-e.jpg)\n- ##### 2.3.1 Emerging consensus\n  The recent hype cycle ignored the legacy definitions described above and instead focusing almost exclusively on Ethereum based peer-to-peer projects. It can be seen that the description is somewhat in the eye of the beholder.\n  It's possible to frame this Ethereum Web3 as a hugely complex and inefficient digital rights management system (DRM). DRM is something that users of the internet are increasingly familiar and comfortable with. It's somewhat debatable whether decentralising this is worthwhile. The thesis of the developers of the technology seems to be that without it, control of 'value' will accrete over time, to one or more hegemonic controlling entities. It's a strong argument, but there is a [substantial counter argument](https://moxie.org/2022/01/07/web3-first-impressions.html) emerging that users just don't want this stuff. The nervousness of legislators in the USA to the attempt by Facebook/Meta to enter this peer-to-peer value transmission space is telling in terms of the perception of who is driving Web3.\n  Throughout 2022 there was much furore on the internet over what Web3 might be, and who it 'serves'. Enthusiasts feel that products such as [Sign-In with Ethereum](https://blog.spruceid.com/sign-in-with-ethereum-is-a-game-changer-part-1/) (EIP-4361) might give users choice over their data sovereignty, and a meme to this effect is seen in Figure [2.3](https://arxiv.org/html/2207.09460v11/#Ch2.F3 \"Figure 2.3 ‣ 2.3.1 Emerging consensus ‣ 2.3 Web3 ‣ Chapter 2 Decentralisation & The Web ‣ Part I State of the art\"). In practice though users are expecting to use badly written, buggy, economically vulnerable 'crypto' wallets to log into websites. The quality of this wallet software is improving of late with the so called \"wallet wars\" seeing commerce grade offerings from Coinbase and shares platform 'Robinhood'. These two companies alone have over 100 million users. It's likely that these wallets will evolve to offer the full spectrum of Web3 functionality. With that said it doesn't seem to make much sense yet on the face of it. There are in fact examples of the technology completely failing at censorship resistance. Popular 'Web3' browser extension Metamask and NFT platform Opensea have both [recently banned countries](https://www.forbes.com/sites/stevenehrlich/2022/03/03/iranian-venezuela-users-abruptly-dropped-from-major-crypto-platforms-as-russian-sanctions-grow/?sh=22bcabc470b0) in response to global sanction pressure. This failure to meaningfully decentralise will be explored further in the distributed identity section.\n  ![Figure 2.3: A meme showing differing approached to logging in on a website.](../assets/web1web2web3.jpg) Of their 2022 ['Big Ideas' report](https://research.ark-invest.com/thank-you-big-ideas-2022?submissionGuid=0937b1ae-9e11-4b46-ae03-6cd8d2f8301b), ARK investment LLC (who manage a \\$50B tech investment) [said the following](https://www.ark-bigideas.com/2022/en/pages/download) (Figure [2.4](https://arxiv.org/html/2207.09460v11/#Ch2.F4 \"Figure 2.4 ‣ 2.3.1 Emerging consensus ‣ 2.3 Web3 ‣ Chapter 2 Decentralisation & The Web ‣ Part I State of the art\")), which connects some of the dots already mentioned, and leads us into the next section which is Blockchain and Bitcoin:\n  [\"While many (with heavily vested interests) want to define all things blockchain as web3 we believe that web3 is best understood as just 1 of 3 revolutions that the innovation of bitcoin has catalyzed.] ![Figure 2.4: [ARK slide on Web3.](https://twitter.com/wintonARK/status/1486143239753060353) Rights requested](../assets/Web3ARK.jpg) This new hyped push for Web3 is being driven by enormous venture capital investment. A16Z are a [major player](https://a16z.com/2022/01/07/9b-to-build-the-future/) in this new landscape and have released their [ten principles](https://a16z.com/2022/01/07/how-to-build-a-better-internet-10-principles-for-world-leaders-shaping-the-future-of-web3/) for emergent Web3. Note here that A16Z are (like so many others) probably a [house of cards](https://twitter.com/coryklippsten/status/1592242420137148416).\n    Establish a clear vision to foster decentralized digital     infrastructure     Embrace multi-stakeholder approaches to governance and regulation     Create targeted, risk-calibrated oversight regimes for different     web3 activities     Foster innovation with composability, open source code, and the     power of open communities     Broaden access to the economic benefits of the innovation economy     Unlock the potential of DAOs     Deploy web3 to further sustainability goals     Embrace the role of well-regulated stablecoins in financial     inclusion and innovation     Collaborate with other nations to harmonize standards and regulatory     frameworks     Provide clear, fair tax rules for the reporting of digital assets,     and leverage technical solutions for tax compliance\n  This list seems targeted toward the coming regulatory landscape, and could be considered at odds with the original tenants of an organically emergent, decentralised internet. Indeed principles such as 'furthering sustainability goals' seem downright incongruous. The community they claim to wish to support here are openly critical of these major institutional players and their motives, with even more pointed criticisms [coming from outside of the Web3](https://www.profgalloway.com/web3/). This book and lab steer well clear of these companies and their applications.\n  Dante Disparte, chief strategy officer of 'Circle' venture capital, said in testimony to a US senate hearing; that Web 1 was 'read', Web 2 was 'read write', and that Web 3 will 'read write own'. The important takeaway here is not so much this oft quoted elevator pitch for Web3, but the fact that legislative bodies now consider this technology a force which they need to be aware of and [potentially contend with](https://a16z.com/2021/12/17/prediction-for-the-new-year-a-web3-midterm/).\n  Jeremy Allaire, again of Circle', talks about the recent legislative order in the USA as follows: [\"this is a watershed moment for crypto, digital assets, and Web 3, akin to the 1996/1997 whole of government wakeup to the commercial internet. The U.S. seems to be taking on the reality that digital assets represent one of the most significant technologies and infrastructures for the 21st century; it's rewarding to see this from the WH after so many of us have been making the case for 9+ years.\"] We will see in the following chapters that participation in this new Web3 is contingent on owning cryptocurrencies. [It's estimated](https://www.finder.com/uk/cryptocurrency-statistics) that about 6% of people in the UK own some cryptocurrency, with skews to both younger demographics, and smaller holdings. The legislative landscape in the UK is comparatively strict with [questionable](https://uk.news.yahoo.com/perverse-impacts-anti-money-laundering-144239343.html) \"know your customer / anti money laundering\" (KYC/AML) data collection [mandated in law](https://www.gov.uk/guidance/money-laundering-regulations-your-responsibilities). Users of UK exchanges must provide a great deal of personal financial information, and undertake to prove that the wallets they are withdrawing to are their own. From the perspective of the UK SME it seems this seriously limits the potential audience for new products. Europe meanwhile has recently voted through even more restrictive regulation, applying the \"[transfer of funds regulation](https://www.europarl.europa.eu/legislative-train/theme-an-economy-that-works-for-people/file-revision-of-the-regulation-on-transfers-of-funds)\" to all transactions coming out of exchanges, enforcing a database of all addresses between companies, and reporting transactions above 1000 Euros to authorities. They have narrowly avoided enforcing KYC on all transfers to private wallets, but have capped transactions at 1000 Euros. The recent [\"Markets in Crypto Assets (MiCA)](https://www.consilium.europa.eu/en/press/press-releases/2022/06/30/digital-finance-agreement-reached-on-european-crypto-assets-regulation-mica/) legislation imposes overheads that may make it harder for smaller businesses in the sector to operate within the EU, but is has been cautiously welcomed by established players (Figure [2.5](https://arxiv.org/html/2207.09460v11/#Ch2.F5 \"Figure 2.5 ‣ 2.3.1 Emerging consensus ‣ 2.3 Web3 ‣ Chapter 2 Decentralisation & The Web ‣ Part I State of the art\"), who have been hungry for clarity. It is certainly far short of the 'ban' seen in China, and the regulation be enforcement in the USA.\n  ![Figure 2.5: [\"Regulatory clarity attracts capital & entrepreneurs from around the world.\"](https://twitter.com/paddi_hansen/status/1655883224726241281)](../assets/../assets/pitchbook.jpg) \n    European Parliament approved EU's crypto assets framework, MiCA     Enforcement clock starts in June, with 12-18 months for rules to     kick in     MiCA offers license tailored to crypto asset services and stablecoin     issuers     Regulation refrains from covering decentralized finance or     non-fungible tokens     Stablecoin issuer rules boost consumer confidence, potentially     increasing institutional comfort     Transfer of Funds regulation passed, imposing stronger surveillance     and identification requirements for crypto operators     Regulations described as world-first and end of Wild West era for     crypto assets     MiCA represents a crucial step forward for crypto industry,     providing comprehensive set of rules     Crypto firms must be licensed by the EU and comply with money     laundering and terrorism finance safeguards to serve EU customers     Concerns about weakened privacy due to reporting standards in the     name of customer safety and national security     Binance CEO supports MiCA, calling it a pragmatic solution     EU's MiCA could become a global template for international companies     UK, now outside the EU, is setting similar stablecoin and crypto     asset service rules\n  Germany is bringing forward legislation allowing the 'tokenisation' of legacy instruments such as stocks, though it's far from clear what the value of this would be, except perhaps lowering risk for custodians. It seems that this EU position has prompted the UK government to seize the potential competitive advantage offered, and there will be more on this later. Japan meanwhile has gone so far as to [make an announcement](https://cointelegraph.com/news/japanese-prime-minister-says-gov-t-investment-in-digital-transformation-will-include-metaverse-nfts) about supporting the technologies at a national level.\n  It's a complex evolving narrative, and clearly contradictions are common. Right now there seems little appeal for stepping into Web3. Into the confusion, this book advances a narrow take, and toolset, which might extract some value from the technologies, while maintaining a low barrier to entry.\n- #### 2.4 Example applications\n  It's handy here to get a feel for what this looks like. These aren't things that this book wishes to contribute to, or even have a firm opinion on, they're just representative of current activity in the decentralised web space.\n- ##### 2.4.1 Veilid\n\t - A Peer-to-Peer Privacy Mesh Project\n  Veilid is an open-source, mobile-first, networked application framework for building decentralized apps with networking, distributed data storage, and built-in IP privacy without reliance on external services.\n    [Platforms] : Runs on Linux, Mac, Windows,     Android, iOS, and in browsers via WASM. Bindings available in Rust,     Dart, and other languages.     [Protocols] : Supports UDP, TCP, WebSockets.     DNS only used briefly during bootstrap.     [Encryption] : Uses Ed25519, XChaCha20, BLAKE3     for end-to-end encryption and authentication.     [Storage] : Distributed hash table for data     records close to node keys. Popular data replicated.     [Routing] : Nodes help each other connect.     Routing based on node IDs. Private routing over encrypted hops.     [Goals] : Enable decentralized apps without     reliance on centralized corporate systems.\n  Key features include strong cryptography, ability to run on a variety of platforms, distributed and replicated data storage, and private routing to provide IP privacy. The decentralized design aims to avoid issues with centralized and corporate controlled systems.\n- ##### 2.4.2 Podcasting2.0\n  [Podcasting 2.0](https://medium.com/@everywheretrip/an-introduction-to-podcasting-2-0-3c4f61ea17f4) leverages [RSS](https://www.rssboard.org/rss-specification) (the original dissemination system for podcasts) and the Bitcoin Lightning network, to enable so-called '[value for value](https://www.youtube.com/watch?v=NO1aDZ6L4NQ&t=1123s)' broadcasting. Subscribers use one of a variety of apps to stream micro-transactions of Bitcoin directly to the content creators as they listen to the podcast. No intermediate business takes a cut. Some variation on this model exists, such as John Carvalho's crowd funded podcast \"The Biz\" which progressively unlocks more minutes for everyone based on [crowd funded donations](https://thebiz.pro/about#crowdwall).\n- ##### 2.4.3 Crowd funding\n- ##### 2.4.4 Distributed exchanges\n  There are dozens of decentralised exchanges deployed on various blockchains. These platforms allow users to trade back and forth between various tokens (including 'normal money' stablecoins) and charge a fee for doing so. They operate within the logic of the smart contracts \\[[5](https://arxiv.org/html/2207.09460v11/#bib.bibx5)\\], within the distributed blockchains. This makes them extremely hard to ban, and as a result they operate in a legal grey area. At the extreme end of this is \"distributed apps\" (dApps) and \"Decentralised Finance\" (DeFi) which allows users access to complex financial instruments without legal or privacy constraints. DeFi will be touched on briefly later.\n  This is a huge area, and of only limited interest to the topics expanded in this book. It's perhaps worth noting [BitcoinDEX](https://bitcoin-dex.net/about/index.html), which runs in JavaScript in a web browser. It is effectively uncensorable, [auditable by the user](https://bitcoin-dex.net/tokens.js), and has no counter party risk since it operates entirely in the Bitcoin network. It is clearly an early prototype but manages this complex feature without the more expressive logic of more 'modern' public blockchains.\n- ##### 2.4.5 NFT marketplaces\n  NFT markets are far more centralised services which match 'owners' of digital assets with potential buyers. The concept is a staple of the more recent interpretation of Web3, even though in practice these seem to be centralised concerns. [Opensea](https://opensea.io/) claims to be the largest decentralised NFT marketplace, but they have the ability to [remove listings](https://thedefiant.io/sad-frogs-delisted-opensea/) in response to legal challenges. This seems to fly in the face of Web3 principles. NFTs are currently a [deeply flawed](https://tante.cc/2021/12/17/the-third-web/) technology but seem likely to persist and will be covered later.\n- ##### 2.4.6 Non blockchain webs of trust\n  New products like Slashtags and Nostr (covered later) use a web of trust decentralised peer-to-peer (ish) model which assigns metadata and trust scores to 'any' data and connection, with a security model rooted in the Bitcoin cryptographic 'keys' but crucially not the bitcoin network. This makes it interoperable with bitcoin but not reliant upon it. In principle this allows users to build complex networks of inherited trust bi-directionally with their networks over time. Every connection to a peer can be a new schema, with individual metadata managed by the user. These are new and have low adoption at this time. The user controls the source of the data and can allow them to be used by centralised services. This flips the authentication and data management paradigm of web around, putting the user in charge of their data. This is a familiar concept to the DID/SSI communities (described later) but with significant investment. As Slashtags and Nostr use keys as endpoints they act as a web of naming and routing, bypassing the existing web infrastructure of DNS. It is likely very complex to use in practice and will be revisited later. Slashtags is being paired with the [Hypercore protocol](https://hypercore-protocol.org/) for peer-to-peer data sharing, more specifically the 'hole punching' capability of the hypercore system which ensures connections through firewalls\\[[6](https://arxiv.org/html/2207.09460v11/#bib.bibx6)\\]. The first application by the affiliated Hyperdivision team is an open source peer-to-peer live video streaming app called [Dazaar](https://dazaar.com/). Once again, it's not clear yet who wants or needs this bit-torrent style service.\n- ##### 2.4.7 Distributed DNS applications\n  There are many perceived problems with having centralised authorities for overseeing the database which translates between human readable internet names and the underlying machine-readable address notation. The databases which manage this globally are already somewhat distributed, and this distributed trust model is managed through a cryptographic chain of trust called DNSSEC which is capped by a somewhat [bizarre key ceremony](https://www.iana.org/dnssec/ceremonies) seen in Figure [2.6](https://arxiv.org/html/2207.09460v11/#Ch2.F6 \"Figure 2.6 ‣ 2.4.7 Distributed DNS applications ‣ 2.4 Example applications ‣ Chapter 2 Decentralisation & The Web ‣ Part I State of the art\"). The authority around naming is centralised in ICANN.\n  ![Figure 2.6: [DNSSEC ceremony in a faraday cage](https://www.internetsociety.org/blog/2016/10/watch-live-today-dnssec-root-ksk-ceremony-at-1700-utc/)](../assets/dnssec.jpg) There has been talk for many years about 'properly' distributing this database using decentralised/blockchain technologies\\[[7](https://arxiv.org/html/2207.09460v11/#bib.bibx7)\\]. The nature of this problem means that it either moves from control by ICANN, or it does not, and so far it has not, but there are many attempted, and somewhat mature attempts, at this difficult problem. Of these [Namecoin](https://www.namecoin.org/) is the most prominent, and is a fork of Bitcoin. The ubiquity of Bitcoin in such systems is perhaps becoming apparent.\n- ##### 2.4.8 Impervious browser\n  It might be that the future of Web3 comes in the guise of integrated suites such as the proposed [Impervious web browser](https://newsletter.impervious.ai/impervious-browser-functionality-overview/). They say that \"without centralized intermediaries\" it features:\n    Google Docs, without Google.     WhatsApp, without WhatsApp.     Identity, without the state.\n  This is obviously leading marketing hype, and they're already late for their release deadline, but what they're talking about here is an integration of the components mentioned in this book. If they can get critical mass around this browser then perhaps the Web3 market can be kickstarted. CEO Chase Perkins has [recently presented](https://www.youtube.com/watch?v=2J8v-TMygK8) on this.\n- ## Web 4.0\n  The EU has released it's [positional thinking](https://ec.europa.eu/commission/presscorner/detail/en/ip_23_3718) on Web 4. This has come pretty much out of nowhere but seems highly relevant to us if it sticks. From the text: Here is the bullet point list in LaTeX:\n\t- [Empowering people and reinforcing skills]  to     foster awareness, access to trustworthy information and build a     talent pool of virtual world specialists. By the end of 2023, the     Commission will promote the guiding principles for virtual worlds,     put forward by the Citizens' Panel; and will develop guidance for     the general public thanks to a 'Citizen toolbox' by the first     quarter of 2024. As specialists on virtual worlds are essential, the     Commission will work with Member States to set up a talent pipeline     and will support skills development, including for women and girls,     through projects funded by the Digital Europe Programme, and for     creators of digital content through the Creative Europe programme.     [Business: supporting a European Web 4.0 industrial     ecosystem]  to scale up excellence and address     fragmentation. Currently, there is no EU ecosystem bringing together     the different players of the value chain of virtual worlds and Web     4.0. The Commission has proposed a candidate Partnership on Virtual     Worlds under Horizon Europe, possibly starting 2025, to foster     excellence in research and develop an industrial and technological     roadmap for virtual worlds. To foster innovation, the Commission     will also support EU creators and media companies to test new     creation tools, bring together developers and industrial users, and     work with Member States to develop regulatory sandboxes for Web 4.0     and virtual worlds.     [Government: supporting societal progress and virtual public     services]  to leverage the opportunities     virtual worlds can offer. The EU is already investing in major     initiatives, such as Destination Earth (DestinE), Local Digital     Twins for smart communities, or the European Digital Twin of the     Ocean to allow researchers to advance science, industries to develop     precision applications and public authorities to make informed     public-policy decisions. The Commission is launching two new public     flagships: \"CitiVerse\", an immersive urban environment that can be     used for city planning and management; and a European Virtual Human     Twin, which will replicate the human body to support clinical     decisions and personal treatment.     [Shaping global standards for open and interoperable virtual worlds     and Web 4.0,]  ensuring that they will not be     dominated by a few big players. The Commission will engage with     internet governance stakeholders around the world and will promote     Web 4.0 standards in line with the EU's vision and values.\n- ## The common thread\n- Overall then, perhaps the space is hype, and is certainly [rife with scams](https://web3isgoinggreat.com/). Fully 24% of projects in 2022 are [estimated to be built](https://blog.chainalysis.com/reports/2022-crypto-pump-and-dump-schemes/) as 'pump and dump' scams. The degree to which it even accomplishes decentralised trust is highly debatable, and meanwhile the limited numbers of Web3 and supporting crypto companies display lamentable cyber security practice themselves, creating [honeypots of personal data](https://www.coindesk.com/tag/data-breaches/) from users of the ecosystem.\n  With that said the component parts necessary to deliver on the promise [do]  exist. If there is to be no central controlling party(s) as in the Web 2 model then nothing can happen without a cryptographically secure underpinning, allowing digital data to be passed around without a prior arrangement.\n  The following chapter will describe how much has been done by computer scientists over the past decades to support that. From this base layer we also get the potential for secure and trust minimised identity management. This nascent field of distributed identity management is explained later. From distributed trust models we can see 'trustless' transmission of economic value. The ability to send value from one person to another person or service without a third party.\n  This whole area is 'crypto', which is increasingly seeping into the human consciousness, and saw an astonishing \\$30B of [capital investment in 2021](https://docsend.com/view/nrvsuae85a4dx3jz) alone. At time of writing the industry is an [over 1 trillion](https://www.coingecko.com/en) dollar market.\n  All the new crypto technologies circling the Web3 narrative are bound tightly together, but there is currently very little meaningful value to be seen.\n  The rest of this book will focus on the trust and value transfer elements of this shift in internet technologies, and attempt to build a case for it's use in decentralised, open source, collaborative mixed reality applications.\n  [\\\\chapterimage]\n-\n-\n- # Misc to merge\n- More recently [[Decentralised Web]] is being touted as a way to connect content creators di­rectly to content consumers, without centralised companies acting as gatekeep­ers of the data. It implies that all users have a cryptographic key management system, to which they attach metadata, that they make requirements of peers with whom they communicate, and that they maintain trust ‘scores’ with peers.\n- It seems likely that this new model is less driven by a market need, and more by the high availability of tools which allow this to happen (the ecosys­tems described later). Add to this a social response to the collapse in trust of companies such as Facebook and other social media platforms (János Török and János Kertész. “Cascading collapse of online social networks”. In: Scientific reports 7.1 (2017), pages 1–8) .\n- There is perhaps a wish by con­sumers to pass more of the economic incentive to content creators, without the ‘rent seeking’ layer afforded by businesses, and a healthy dose of mania driven market speculation. Edelman’s latest trust report is shocking, finding that trust in all institutions has slumped recently to all time lows, and their global survey found that: “Nearly 6 in 10 say their default tendency is to distrust something until they see evidence it is trustworthy. Another 64% say it’s now to a point where people are incapable of having constructive and civil debates about issues they disagree on. When distrust is the default – we lack the ability to debate or collaborate.”\n- Emerging consensus\n\t- The recent hype cycle ignored the legacy definitions described above and instead focusing almost exclusively on Ethereum based peer-to-peer projects. \n\t  It can be seen that the description is somewhat in the eye of the beholder.\n\t- It’s possible to frame this Ethereum Web3 as a hugely complex and ineffi­cient digital rights management system (DRM). DRM is something that users of the internet are increasingly familiar and comfortable with. It’s somewhat debatable whether decentralising this is worthwhile. The thesis of the devel­opers of the technology seems to be that without it, control of ‘value’ will accrete over time, to one or more hegemonic controlling entities. It’s a strong argument, but there is a substantial counter argument emerging that users just don’t want this stuff. The nervousness of legislators in the USA to the attempt by Facebook/Meta to enter this peer-to-peer value transmission space is telling in terms of the perception of who is driving Web3.\n\t- Throughout 2022 there was much furore on the internet over what Web3 might be, and who it ‘serves’. Enthusiasts feel that products such as Sign-In with Ethereum (EIP-4361) might give users choice over their data sovereignty, and a meme to this effect is seen in Figure 2.3. In practice though users are expecting to use badly written, buggy, economically vulnerable ‘crypto’ wallets to log into websites. The quality of this wallet software is improving of late with the so called “wallet wars” seeing commerce grade offerings from Coinbase and shares platform ‘Robinhood’. These two companies alone have over 100 million users. It’s likely that these wallets will evolve to offer the full spectrum of Web3 functionality. With that said it doesn’t seem to make much sense yet on the face of it. There are in fact examples of the technology completely failing at censorship resistance. Popular ‘Web3’ browser extension Metamask and NFT platform Opensea have both recently banned countries in response to global sanction pressure. This failure to meaningfully decentralise will be explored further in the distributed identity section.\n\t- Of their 2022 ‘Big Ideas’ report, ARK investment LLC (who manage a $50B tech investment) said the following, which connects some of the dots already mentioned “While many (with heavily vested interests) want to define all things blockchain as web3 we believe that web3 is best understood as just 1 of 3 revolutions that the innovation of bitcoin has catalyzed.\n\t\t- The Money Revolution\n\t\t- The Financial Revolution\n\t\t- The Internet Revolution”\n- This new hyped push for Web3 is being driven by enormous venture capital investment. A16Z are a major player in this new landscape and have released their ten principles for emergent Web3. Note here that A16Z are (like so many others) probably a house of cards.\n\t- Establish a clear vision to foster decentralized digital infrastructure\n\t- Embrace multi-stakeholder approaches to governance and regulation\n\t- Create targeted, risk-calibrated oversight regimes for different web3 activities\n\t- Foster innovation with composability, open source code, and the power of open communities\n\t- Broaden access to the economic benefits of the innovation economy\n\t- Unlock the potential of DAOs\n\t- Deploy web3 to further sustainability goals\n\t- Embrace the role of well-regulated stablecoins in financial inclusion and innovation\n\t- Collaborate with other nations to harmonize standards and regulatory frameworks\n\t- Provide clear, fair tax rules for the reporting of digital assets, and lever­age technical solutions for tax compliance\n- This list seems targeted toward the coming regulatory landscape, and could be considered at odds with the original tenants of an organically emergent, decentralised internet. Indeed principles such as ‘furthering sustainability goals’ seem downright incongruous. The community they claim to wish to support here are openly critical of these major institutional players and their motives, with even more pointed criticisms coming from outside of the Web3. This book and lab steer well clear of these companies and their applications.\n- Dante Disparte, chief strategy officer of ‘Circle’ venture capital, said in testimony to a US senate hearing; that Web 1 was ‘read’, Web 2 was ‘read write’, and that Web 3 will ‘read write own’. The important takeaway here is not so much this oft quoted elevator pitch for Web3, but the fact that legislative bodies now consider this technology a force which they need to be aware of and potentially contend with.\n- Jeremy Allaire, again of Circle’, talks about the recent legislative order in the USA as follows: “this is a watershed moment for crypto, digital assets, and Web 3, akin to the 1996/1997 whole of government wakeup to the commercial internet. The U.S. seems to be taking on the reality that digital assets represent one of the most significant technologies and infrastructures for the 21st century; it’s rewarding to see this from the WH after so many of us have been making the case for 9+ years.”\n- We see that participation in this new Web3 is contingent on owning cryptocurrencies. It’s estimated that about 6% of people in the UK own some cryptocurrency, with skews to both younger demographics, and smaller holdings.\n\n-\n- ### Semantic web\n\t- The “semantic web” definition of Web3.0 has been somewhat overhauled byother innovations in decentralised internet technologies, now evolvingtoward the slightly different Web3 moniker. Tim Berners Lee (of WWWfame) first mentioned the semantic web in 1999.[[semanticWeb]]\n\t- “I have a dream for the Web \\[in which computers\\] become capable ofanalyzing all the data on the Web – the content, links, and transactionsbetween people and computers. A \"Semantic Web\", which makes thispossible, has yet to emerge, but when it does, the day-to-day mechanismsof trade, bureaucracy and our daily lives will be handled by machinestalking to machines. The \"intelligent agents\" people have touted forages will finally materialize.”\n\t- Attention developed around three core themes, ubiquitous availabilityand searchability of data, intelligent search assistants, and highlyavailable end points such as phones, and ‘internet of things’ devices.This is certainly manifesting in home devices, but few people think ofthis as a Web3 revolution.\n\t- Since ratification of the standards by the [World Wide Web (W3C)consortium](https://www.w3.org/standards/semanticweb/) it seems thattheir imperative toward decentralisation has become lost. Instead, itcan be seen that Facebook, Amazon, Google, and Apple have a harmfuloligopoly on users data.[[costigan2018world]] This is at odds withBerners-Lee’s vision, and he has recently [spoken out about thisdiscrepancy](https://thenextweb.com/news/web-inventor-tim-berners-lee-screw-web3-my-decentralized-internet-doesnt-need-blockchain/),and attempted to [refocus themedia](https://www.cnbc.com/2022/11/04/web-inventor-tim-berners-lee-wants-us-to-ignore-web3.html)onto Web3.0.\n\t- It is worth taking a look at his software implementation called[Solid](https://solidproject.org), which is far more mindful of thesovereignty of user data.\n\t- “Solid is an exciting new project led by Prof. Tim Berners-Lee, inventorof the World Wide Web, taking place at MIT. The project aims toradically change the way Web applications work today, resulting in truedata ownership as well as improved privacy. Solid (derived from \"sociallinked data\") is a proposed set of conventions and tools for buildingdecentralized social applications based on Linked Data principles. Solidis modular and extensible and it relies as much as possible on existingW3C standards and protocols.”\n\t- Excitement around this kind of differentiated trust model, hinted at inubiquitous availability of data (and implemented explicitly in Solid),has led to exploration of different paths by cryptographers, and thiswill be described later. For instance, one of the main developers ofSolid, [Carvelho](https://github.com/melvincarvalho/), is now a leadingdeveloper and propotent of Nostr, another very interesting option whichwill be described later. This technology space is prolific, but stillcomparatively young and small.\n-\n\t - ### Spatial web\n- “The Spatial Web”, a blurring of the boundaries between digital andgeospatial physical objects, seems to have developed from the strands inthe original W3C scope around devices in the real world. It has beenconcentrating around AR and VR but is being marketed and amplified withthe same references to availability of data (See Figure<a href=\"#fig:deloitteSpatial\" data-reference-type=\"ref\" data-reference=\"fig:deloitteSpatial\">2.1</a>from a Deloitte accounting report). This too is finding little tractionin practice, though obviously the component technologies continue toenjoy rapid development. Nonetheless, this interpretation of Web3becomes valuable when examining Metaverse later.\n- <span class=\"image\">[Deloitte Spatial WebOverview](https://www2.deloitte.com/us/en/insights/topics/digital-transformation/web-3-0-technologies-in-business.html)Reused with permission.</span>\n-\n\t - ### Web3\n- More recently Web3 is [beingtouted](https://trends.google.com/trends/explore?date=all&q=web3) as away to connect content creators directly to content consumers, withoutcentralised companies acting as gatekeepers of the data. It implies thatall users have a cryptographic key management system, to which theyattach metadata, that they make requirements of peers with whom theycommunicate, and that they maintain trust ‘scores’ with peers.\n- It seems likely that this new model is less driven by a market need, andmore by the high availability of tools which allow this to happen (theecosystems described later). Add to this a social response to the[collapse in trust of companies such asFacebook](https://finance.yahoo.com/news/meta-facebook-worst-company-of-the-year-yahoo-finance-165345819.html)and other [social mediaplatforms](https://reb00ted.org/tech/20220727-end-of-social-networking/)[[torok2017cascading]](Figure<a href=\"#fig:trustbarometer\" data-reference-type=\"ref\" data-reference=\"fig:trustbarometer\">2.2</a>).There is perhaps a wish by consumers to pass more of the economicincentive to content creators, without the ‘rent seeking’ layer affordedby businesses, and a healthy dose of mania driven market speculation.[Edelman’s latest trustreport](https://www.edelman.co.uk/sites/g/files/aatuss301/files/2022-01/2022%20Edelman%20Trust%20Barometer_UK.pdf)is shocking, finding that trust in all institutions has slumped recentlyto all time lows, and their global survey found that: it“Nearly 6 in 10say their default tendency is to distrust something until they seeevidence it is trustworthy. Another 64% say it’s now to a point wherepeople are incapable of having constructive and civil debates aboutissues they disagree on. When distrust is the default – we lack theability to debate or collaborate.”\n- <figure><img src=\"./assets/e7ee44a36af4cd7a631a471ace9a1469e147528f.jpg\" id=\"fig:trustbarometer\" alt=\"\" /><figcaption><a href=\"https://www.edelman.com/trust/2020-trust-barometer\">Edelman 2020 trust barometer</a> [rights requested]</figcaption></figure>\n-\n\t - #### Emerging consensus\n- The recent hype cycle ignored the legacy definitions described above andinstead focusing almost exclusively on Ethereum based peer-to-peerprojects. It can be seen that the description is somewhat in the eye ofthe beholder.\n- It’s possible to frame this Ethereum Web3 as a hugely complex andinefficient digital rights management system (DRM). DRM is somethingthat users of the internet are increasingly familiar and comfortablewith. It’s somewhat debatable whether decentralising this is worthwhile.The thesis of the developers of the technology seems to be that withoutit, control of ‘value’ will accrete over time, to one or more hegemoniccontrolling entities. It’s a strong argument, but there is a[substantial counterargument](https://moxie.org/2022/01/07/web3-first-impressions.html)emerging that users just don’t want this stuff. The nervousness oflegislators in the USA to the attempt by Facebook/Meta to enter thispeer-to-peer value transmission space is telling in terms of theperception of who is driving Web3.\n- Throughout 2022 there was much furore on the internet over what Web3might be, and who it ‘serves’. Enthusiasts feel that products such as[Sign-In withEthereum](https://blog.spruceid.com/sign-in-with-ethereum-is-a-game-changer-part-1/)(EIP-4361) might give users choice over their data sovereignty, and ameme to this effect is seen in Figure<a href=\"#fig:web1web2web3\" data-reference-type=\"ref\" data-reference=\"fig:web1web2web3\">2.3</a>.In practice though users are expecting to use badly written, buggy,economically vulnerable ‘crypto’ wallets to log into websites. Thequality of this wallet software is improving of late with the so called“wallet wars” seeing commerce grade offerings from Coinbase and sharesplatform ‘Robinhood’. These two companies alone have over 100 millionusers. It’s likely that these wallets will evolve to offer the fullspectrum of Web3 functionality. With that said it doesn’t seem to makemuch sense yet on the face of it. There are in fact examples of thetechnology completely failing at censorship resistance. Popular ‘Web3’browser extension Metamask and NFT platform Opensea have both [recentlybannedcountries](https://www.forbes.com/sites/stevenehrlich/2022/03/03/iranian-venezuela-users-abruptly-dropped-from-major-crypto-platforms-as-russian-sanctions-grow/?sh=22bcabc470b0)in response to global sanction pressure. This failure to meaningfullydecentralise will be explored further in the distributed identitysection.\n- <figure><img src=\"./assets/a1d2d648ac2e70d6122fdf4c03916954c3139aa5.jpg\" id=\"fig:web1web2web3\" alt=\"\" /><figcaption>A meme showing differing approached to logging in on a website.</figcaption></figure>\n- Of their 2022 [‘Big Ideas’report](https://research.ark-invest.com/thank-you-big-ideas-2022?submissionGuid=0937b1ae-9e11-4b46-ae03-6cd8d2f8301b),ARK investment LLC (who manage a $50B tech investment) [said thefollowing](https://www.ark-bigideas.com/2022/en/pages/download) (Figure<a href=\"#fig:ARKWeb3\" data-reference-type=\"ref\" data-reference=\"fig:ARKWeb3\">2.4</a>),which connects some of the dots already mentioned, and leads us into thenext section which is Blockchain and Bitcoin:\n- it\n- “While many (with heavily vested interests) want to define all thingsblockchain as web3 we believe that web3 is best understood as just 1 of3 revolutions that the innovation of bitcoin has catalyzed.\n-\n\t - The Money Revolution\n-\n\t - The Financial Revolution\n-\n\t - The Internet Revolution”\n- <figure><img src=\"./assets/6b0b3505d6933b7ca015314ceda184740c1a8c33.jpg\" id=\"fig:ARKWeb3\" alt=\"\" /><figcaption><a href=\"https://twitter.com/wintonARK/status/1486143239753060353\">ARK slide on Web3.</a> Rights requested</figcaption></figure>\n- This new hyped push for Web3 is being driven by enormous venture capitalinvestment. A16Z are a [majorplayer](https://a16z.com/2022/01/07/9b-to-build-the-future/) in this newlandscape and have released their [tenprinciples](https://a16z.com/2022/01/07/how-to-build-a-better-internet-10-principles-for-world-leaders-shaping-the-future-of-web3/)for emergent Web3. Note here that A16Z are (like so many others)probably a [house ofcards](https://twitter.com/coryklippsten/status/1592242420137148416).\n-\n\t - Establish a clear vision to foster decentralized digital infrastructure\n-\n\t - Embrace multi-stakeholder approaches to governance and regulation\n-\n\t - Create targeted, risk-calibrated oversight regimes for different web3 activities\n-\n\t - Foster innovation with composability, open source code, and the power of open communities\n-\n\t - Broaden access to the economic benefits of the innovation economy\n-\n\t - Unlock the potential of DAOs\n-\n\t - Deploy web3 to further sustainability goals\n-\n\t - Embrace the role of well-regulated stablecoins in financial inclusion and innovation\n-\n\t - Collaborate with other nations to harmonize standards and regulatory frameworks\n-\n\t - Provide clear, fair tax rules for the reporting of digital assets, and leverage technical solutions for tax compliance\n- This list seems targeted toward the coming regulatory landscape, andcould be considered at odds with the original tenants of an organicallyemergent, decentralised internet. Indeed principles such as ‘furtheringsustainability goals’ seem downright incongruous. The community theyclaim to wish to support here are openly critical of these majorinstitutional players and their motives, with even more pointedcriticisms [coming from outside of theWeb3](https://www.profgalloway.com/web3/). This book and lab steer wellclear of these companies and their applications.\n- Dante Disparte, chief strategy officer of ‘Circle’ venture capital, saidin testimony to a US senate hearing; that Web 1 was ‘read’, Web 2 was‘read write’, and that Web 3 will ‘read write own’. The importanttakeaway here is not so much this oft quoted elevator pitch for Web3,but the fact that legislative bodies now consider this technology aforce which they need to be aware of and [potentially contendwith](https://a16z.com/2021/12/17/prediction-for-the-new-year-a-web3-midterm/).\n- Jeremy Allaire, again of Circle’, talks about the recent legislativeorder in the USA as follows: it“this is a watershed moment for crypto,digital assets, and Web 3, akin to the 1996/1997 whole of governmentwakeup to the commercial internet. The U.S. seems to be taking on thereality that digital assets represent one of the most significanttechnologies and infrastructures for the 21st century; it’s rewarding tosee this from the WH after so many of us have been making the case for9+ years.”\n- We will see in the following chapters that participation in this newWeb3 is contingent on owning cryptocurrencies. [It’sestimated](https://www.finder.com/uk/cryptocurrency-statistics) thatabout 6% of people in the UK own some cryptocurrency, with skews to bothyounger demographics, and smaller holdings. The legislative landscape inthe UK is comparatively strict with[questionable](https://uk.news.yahoo.com/perverse-impacts-anti-money-laundering-144239343.html)“know your customer / anti money laundering” (KYC/AML) data collection[mandated inlaw](https://www.gov.uk/guidance/money-laundering-regulations-your-responsibilities).Users of UK exchanges must provide a great deal of personal financialinformation, and undertake to prove that the wallets they arewithdrawing to are their own. From the perspective of the UK SME itseems this seriously limits the potential audience for new products.Europe meanwhile has recently voted through even more restrictiveregulation, applying the “[transfer of fundsregulation](https://www.europarl.europa.eu/legislative-train/theme-an-economy-that-works-for-people/file-revision-of-the-regulation-on-transfers-of-funds)”to all transactions coming out of exchanges, enforcing a database of alladdresses between companies, and reporting transactions above 1000 Eurosto authorities. They have narrowly avoided enforcing KYC on alltransfers to private wallets, but have capped transactions at 1000Euros. The recent [“Markets in Crypto Assets(MiCA)](https://www.consilium.europa.eu/en/press/press-releases/2022/06/30/digital-finance-agreement-reached-on-european-crypto-assets-regulation-mica/)legislation imposes overheads that may make it harder for smallerbusinesses in the sector to operate within the EU, but is has beencautiously welcomed by established players (Figure<a href=\"#fig:pitchbook\" data-reference-type=\"ref\" data-reference=\"fig:pitchbook\">2.5</a>,who have been hungry for clarity. It is certainly far short of the ‘ban’seen in China, and the regulation be enforcement in the USA.\n- <figure><img src=\"./assets/3d994af6701b755025ece23c3068daeaaedc1f06.jpg\" id=\"fig:pitchbook\" alt=\"\" /><figcaption><a href=\"https://twitter.com/paddi_hansen/status/1655883224726241281\">“Regulatory clarity attracts capital &amp; entrepreneurs from around the world.”</a></figcaption></figure>\n-\n\t - European Parliament approved EU’s crypto assets framework, MiCA\n-\n\t - Enforcement clock starts in June, with 12-18 months for rules to kick in\n-\n\t - MiCA offers license tailored to crypto asset services and stablecoin issuers\n-\n\t - Regulation refrains from covering decentralized finance or non-fungible tokens\n-\n\t - Stablecoin issuer rules boost consumer confidence, potentially increasing institutional comfort\n-\n\t - Transfer of Funds regulation passed, imposing stronger surveillance and identification requirements for crypto operators\n-\n\t - Regulations described as world-first and end of Wild West era for crypto assets\n-\n\t - MiCA represents a crucial step forward for crypto industry, providing comprehensive set of rules\n-\n\t - Crypto firms must be licensed by the EU and comply with money laundering and terrorism finance safeguards to serve EU customers\n-\n\t - Concerns about weakened privacy due to reporting standards in the name of customer safety and national security\n-\n\t - Binance CEO supports MiCA, calling it a pragmatic solution\n-\n\t - EU’s MiCA could become a global template for international companies\n-\n\t - UK, now outside the EU, is setting similar stablecoin and crypto asset service rules\n- Germany is bringing forward legislation allowing the ‘tokenisation’ oflegacy instruments such as stocks, though it’s far from clear what thevalue of this would be, except perhaps lowering risk for custodians. Itseems that this EU position has prompted the UK government to seize thepotential competitive advantage offered, and there will be more on thislater. Japan meanwhile has gone so far as to [make anannouncement](https://cointelegraph.com/news/japanese-prime-minister-says-gov-t-investment-in-digital-transformation-will-include-metaverse-nfts)about supporting the technologies at a national level.\n- It’s a complex evolving narrative, and clearly contradictions arecommon. Right now there seems little appeal for stepping into Web3. Intothe confusion, this book advances a narrow take, and toolset, whichmight extract some value from the technologies, while maintaining a lowbarrier to entry.\n-\n\t - ### Example applications\n- It’s handy here to get a feel for what this looks like. These aren’tthings that this book wishes to contribute to, or even have a firmopinion on, they’re just representative of current activity in thedecentralised web space.\n-\n\t - #### Veilid\n\t - A Peer-to-Peer Privacy Mesh Project\n- Veilid is an open-source, mobile-first, networked application frameworkfor building decentralized apps with networking, distributed datastorage, and built-in IP privacy without reliance on external services.\n-\n\t - **Platforms**: Runs on Linux, Mac, Windows, Android, iOS, and in browsers via WASM. Bindings available in Rust, Dart, and other languages.\n-\n\t - **Protocols**: Supports UDP, TCP, WebSockets. DNS only used briefly during bootstrap.\n-\n\t - **Encryption**: Uses Ed25519, XChaCha20, BLAKE3 for end-to-end encryption and authentication.\n-\n\t - **Storage**: Distributed hash table for data records close to node keys. Popular data replicated.\n-\n\t - **Routing**: Nodes help each other connect. Routing based on node IDs. Private routing over encrypted hops.\n-\n\t - **Goals**: Enable decentralized apps without reliance on centralized corporate systems.\n- Key features include strong cryptography, ability to run on a variety ofplatforms, distributed and replicated data storage, and private routingto provide IP privacy. The decentralized design aims to avoid issueswith centralized and corporate controlled systems.\n-\n\t - #### Podcasting2.0\n- [Podcasting2.0](https://medium.com/@everywheretrip/an-introduction-to-podcasting-2-0-3c4f61ea17f4)leverages [RSS](https://www.rssboard.org/rss-specification) (theoriginal dissemination system for podcasts) and the Bitcoin Lightningnetwork, to enable so-called ‘[value forvalue](https://www.youtube.com/watch?v=NO1aDZ6L4NQ&t=1123s)’broadcasting. Subscribers use one of a variety of apps to streammicro-transactions of Bitcoin directly to the content creators as theylisten to the podcast. No intermediate business takes a cut. Somevariation on this model exists, such as John Carvalho’s crowd fundedpodcast “The Biz” which progressively unlocks more minutes for everyonebased on [crowd funded donations](https://thebiz.pro/about#crowdwall).\n-\n\t - #### Crowd funding\n- At time of writing a [crowd fundinginitiative](https://www.constitutiondao.com/) based around a digitaldecentralised construct called a DAO (explained later in detail)[managed to raise $46 million dollars to bid for a copy of the USconstitution](https://www.coindesk.com/business/2021/12/06/daos-and-the-next-crowdfunding-gold-rush/)at Southerbys auction house. The attempt narrowly failed, but the press[heralded this new era of “Web3” economicmight](https://www.coindesk.com/business/2021/12/09/what-kickstarter-going-decentralized-means-for-web-3/).This model might be the only use for DAOs and is likely just a way toavoid regulatory scrutiny. There is more detail on DAOs later.\n-\n\t - #### Distributed exchanges\n- There are dozens of decentralised exchanges deployed on variousblockchains. These platforms allow users to trade back and forth betweenvarious tokens (including ‘normal money’ stablecoins) and charge a feefor doing so. They operate within the logic of the smartcontracts,[[szabo1997formalizing]] within the distributed blockchains.This makes them extremely hard to ban, and as a result they operate in alegal grey area. At the extreme end of this is “distributed apps”(dApps) and “Decentralised Finance” (DeFi) which allows users access tocomplex financial instruments without legal or privacy constraints. DeFiwill be touched on briefly later.\n- This is a huge area, and of only limited interest to the topics expandedin this book. It’s perhaps worth noting[BitcoinDEX](https://bitcoin-dex.net/about/index.html), which runs inJavaScript in a web browser. It is effectively uncensorable, [auditableby the user](https://bitcoin-dex.net/tokens.js), and has no counterparty risk since it operates entirely in the Bitcoin network. It isclearly an early prototype but manages this complex feature without themore expressive logic of more ‘modern’ public blockchains.\n-\n\t - #### NFT marketplaces\n- NFT markets are far more centralised services which match ‘owners’ ofdigital assets with potential buyers. The concept is a staple of themore recent interpretation of Web3, even though in practice these seemto be centralised concerns. [Opensea](https://opensea.io/) claims to bethe largest decentralised NFT marketplace, but they have the ability to[remove listings](https://thedefiant.io/sad-frogs-delisted-opensea/) inresponse to legal challenges. This seems to fly in the face of Web3principles. NFTs are currently a [deeplyflawed](https://tante.cc/2021/12/17/the-third-web/) technology but seemlikely to persist and will be covered later.\n-\n\t - #### Non blockchain webs of trust\n- New products like Slashtags and Nostr (covered later) use a web of trustdecentralised peer-to-peer (ish) model which assigns metadata and trustscores to ‘any’ data and connection, with a security model rooted in theBitcoin cryptographic ‘keys’ but crucially not the bitcoin network. Thismakes it interoperable with bitcoin but not reliant upon it. Inprinciple this allows users to build complex networks of inherited trustbi-directionally with their networks over time. Every connection to apeer can be a new schema, with individual metadata managed by the user.These are new and have low adoption at this time. The user controls thesource of the data and can allow them to be used by centralisedservices. This flips the authentication and data management paradigm ofweb around, putting the user in charge of their data. This is a familiarconcept to the DID/SSI communities (described later) but withsignificant investment. As Slashtags and Nostr use keys as endpointsthey act as a web of naming and routing, bypassing the existing webinfrastructure of DNS. It is likely very complex to use in practice andwill be revisited later. Slashtags is being paired with the [Hypercoreprotocol](https://hypercore-protocol.org/) for peer-to-peer datasharing, more specifically the ‘hole punching’ capability of thehypercore system which ensures connections throughfirewalls[[ford2005peer]]. The first application by the affiliatedHyperdivision team is an open source peer-to-peer live video streamingapp called [Dazaar](https://dazaar.com/). Once again, it’s not clear yetwho wants or needs this bit-torrent style service.\n-\n\t - #### Distributed DNS applications\n- There are many perceived problems with having centralised authoritiesfor overseeing the database which translates between human readableinternet names and the underlying machine-readable address notation. Thedatabases which manage this globally are already somewhat distributed,and this distributed trust model is managed through a cryptographicchain of trust called DNSSEC which is capped by a somewhat [bizarre keyceremony](https://www.iana.org/dnssec/ceremonies) seen in Figure<a href=\"#fig:dnssec\" data-reference-type=\"ref\" data-reference=\"fig:dnssec\">2.6</a>.The authority around naming is centralised in ICANN.\n- <figure><img src=\"./assets/27d09216a9dc4a6788c3c3d4b796983741349f54.jpg\" id=\"fig:dnssec\" alt=\"\" /><figcaption><a href=\"https://www.internetsociety.org/blog/2016/10/watch-live-today-dnssec-root-ksk-ceremony-at-1700-utc/\">DNSSEC ceremony in a faraday cage</a></figcaption></figure>\n- There has been talk for many years about ‘properly’ distributing thisdatabase using decentralised/blockchaintechnologies[[karaarslan2018blockchain]]. The nature of this problemmeans that it either moves from control by ICANN, or it does not, and sofar it has not, but there are many attempted, and somewhat matureattempts, at this difficult problem. Of these[Namecoin](https://www.namecoin.org/) is the most prominent, and is afork of Bitcoin. The ubiquity of Bitcoin in such systems is perhapsbecoming apparent.\n-\n\t - #### Impervious browser\n- It might be that the future of Web3 comes in the guise of integratedsuites such as the proposed [Impervious webbrowser](https://newsletter.impervious.ai/impervious-browser-functionality-overview/).They say that “without centralized intermediaries” it features:\n-\n\t - Zoom, without Zoom.\n-\n\t - Google Docs, without Google.\n-\n\t - Medium, without Medium.\n-\n\t - WhatsApp, without WhatsApp.\n-\n\t - Payments, without banks.\n-\n\t - Identity, without the state.\n- This is obviously leading marketing hype, and they’re already late fortheir release deadline, but what they’re talking about here is anintegration of the components mentioned in this book. If they can getcritical mass around this browser then perhaps the Web3 market can bekickstarted. CEO Chase Perkins has [recentlypresented](https://www.youtube.com/watch?v=2J8v-TMygK8) on this.\n-\n\t - ### Web 4.0\n- The EU has released it’s [positionalthinking](https://ec.europa.eu/commission/presscorner/detail/en/ip_23_3718)on Web 4. This has come pretty much out of nowhere but seems highlyrelevant to us if it sticks. From the text: Here is the bullet pointlist in LaTeX:\n-\n\t - **Empowering people and reinforcing skills** to foster awareness, access to trustworthy information and build a talent pool of virtual world specialists. By the end of 2023, the Commission will promote the guiding principles for virtual worlds, put forward by the Citizens’ Panel; and will develop guidance for the general public thanks to a ‘Citizen toolbox’ by the first quarter of 2024. As specialists on virtual worlds are essential, the Commission will work with Member States to set up a talent pipeline and will support skills development, including for women and girls, through projects funded by the Digital Europe Programme, and for creators of digital content through the Creative Europe programme.\n-\n\t - **Business: supporting a European Web 4.0 industrial ecosystem** to scale up excellence and address fragmentation. Currently, there is no EU ecosystem bringing together the different players of the value chain of virtual worlds and Web 4.0. The Commission has proposed a candidate Partnership on Virtual Worlds under Horizon Europe, possibly starting 2025, to foster excellence in research and develop an industrial and technological roadmap for virtual worlds. To foster innovation, the Commission will also support EU creators and media companies to test new creation tools, bring together developers and industrial users, and work with Member States to develop regulatory sandboxes for Web 4.0 and virtual worlds.\n-\n\t - **Government: supporting societal progress and virtual public services** to leverage the opportunities virtual worlds can offer. The EU is already investing in major initiatives, such as Destination Earth (DestinE), Local Digital Twins for smart communities, or the European Digital Twin of the Ocean to allow researchers to advance science, industries to develop precision applications and public authorities to make informed public-policy decisions. The Commission is launching two new public flagships: “CitiVerse”, an immersive urban environment that can be used for city planning and management; and a European Virtual Human Twin, which will replicate the human body to support clinical decisions and personal treatment.\n-\n\t - **Shaping global standards for open and interoperable virtual worlds and Web 4.0,** ensuring that they will not be dominated by a few big players. The Commission will engage with internet governance stakeholders around the world and will promote Web 4.0 standards in line with the EU’s vision and values.\n-\n\t - ### The common thread\n- One feature which persists throughout all of these interpretations ofWeb3 is the need for decentralised trust. According to [NathanielWhittemore](https://www.coindesk.com/podcasts/the-breakdown-with-nlw/yesterdays-hearing-was-cryptos-most-positive-interaction-with-the-us-government-ever/),a journalist for Coindesk, “The Web3 moniker positions this industry inopposition to big tech”. Alternatively the [manydetractors](https://cryptocriticscorner.com/) of the technology think itsimply provides avenues for incumbents to experiment with new [models ofcontrol andmonetisation](https://www.cigionline.org/articles/amid-the-hype-over-web3-informed-skepticism-is-critical/),[increasing systemicrisk](https://newsletters.theatlantic.com/galaxy-brain/624cb2ebdc551a00208c1524/crypto-bubble-web3-decentralized-finance/)at no cost to themselves.\n- Overall then, perhaps the space is hype, and is certainly [rife withscams](https://web3isgoinggreat.com/). Fully 24% of projects in 2022 are[estimated to bebuilt](https://blog.chainalysis.com/reports/2022-crypto-pump-and-dump-schemes/)as ‘pump and dump’ scams. The degree to which it even accomplishesdecentralised trust is highly debatable, and meanwhile the limitednumbers of Web3 and supporting crypto companies display lamentable cybersecurity practice themselves, creating [honeypots of personaldata](https://www.coindesk.com/tag/data-breaches/) from users of theecosystem.\n- With that said the component parts necessary to deliver on the promise**do** exist. If there is to be no central controlling party(s) as inthe Web 2 model then nothing can happen without a cryptographicallysecure underpinning, allowing digital data to be passed around without aprior arrangement.\n- The following chapter will describe how much has been done by computerscientists over the past decades to support that. From this base layerwe also get the potential for secure and trust minimised identitymanagement. This nascent field of distributed identity management isexplained later. From distributed trust models we can see ‘trustless’transmission of economic value. The ability to send value from oneperson to another person or service without a third party.\n- This whole area is ‘crypto’, which is increasingly seeping into thehuman consciousness, and saw an astonishing $30B of [capital investmentin 2021](https://docsend.com/view/nrvsuae85a4dx3jz) alone. At time ofwriting the industry is an [over 1trillion](https://www.coingecko.com/en) dollar market.\n- All the new crypto technologies circling the Web3 narrative are boundtightly together, but there is currently very little meaningful value tobe seen.\n- The rest of this book will focus on the trust and value transferelements of this shift in internet technologies, and attempt to build acase for it’s use in decentralised, open source, collaborative mixedreality applications.\n- # Decentralisation & The Web",
        "link_types": [
            "Semantic Web",
            "Solid",
            "Solid-Lite",
            "Solid-Lite",
            "nostr",
            "Metaverse and Telecollaboration",
            "Decentralised Web",
            "semanticWeb",
            "costigan2018world",
            "torok2017cascading",
            "szabo1997formalizing",
            "ford2005peer",
            "karaarslan2018blockchain"
        ],
        "file_size": 69012
    },
    {
        "id": "Ai in Games.md",
        "name": "Ai in Games",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- # Games sector dominates entertainment\n\t- ![1713196618774.jpeg](../assets/1713196618774_1713258422046_0.jpeg)\n\t- Traditional engines like Unity, [[Unreal]], [[Roblox]] , and [[NVIDIA Omniverse]] may become outdated [[Disruption]].\n\t\t- They're something like 15 years old and designed for a past era of computing.\n\t\t- The rise of generative AI, cloud computing, and new spatial platforms is poised to transform 3D creation.\n\t\t- Future engines might start with simple text prompts for creation, making them more accessible and reducing barriers for new creators.\n\t\t- Proposed engines should be modular, cloud-based, and adaptable to different project needs, avoiding the bloat of current engines.\n\t\t- There is opportunity for the traditional engines to pivot here, but they are struggling with their size already.\n\t\t- A key feature will be real-time collaboration and version control in a cloud-based environment.\n\t\t- This suggests that user experience in these engines should be flexible and cater to different skill levels and roles.\n\t\t- New engines might initially focus on specific genres, art styles, or platforms, rather than trying to cover all use cases.\n\t\t- The interoperable [Open Universal Scene Descriptor](https://openusd.org/release/index.html) might be the key enabler.\n\t\t- There could be significant change in the entertainment industry, with more diverse and interactive content as a result of these advancements.\n\t\t- [Fiero\n\t\t- Create 2D games without a single line of code! (fierogameengine.com)](https://fierogameengine.com/)\n\t\t- [They are starting to hide away the AI component and just focus on workflows like Sprite Fusion](https://www.spritefusion.com/)\n\t- <iframe src=\"https://miao-ai-lab.github.io/LARP/\" style=\"width: 800px; height: 400px\"></iframe>\n\t- [LARP: Language-Agent Role Play for Open-World Games (arxiv.org)](https://arxiv.org/pdf/2312.17653.pdf)\n\t\t- Plenty of fun tools for game makers, but distributors are quite ossified, and access to distribution may be patchy.\n\t\t- Steam has [softened it's stance.](https://store.steampowered.com/news/group/4145017/view/3862463747997849618)\n\t\t- Latency and cost are still prohibitive **in game**.\n\t\t- Tools for builders\n\t\t- Blender has been leading the way with open source plugins appearing all the time.\n\t\t- [Scenario\n\t\t- AI-generated game assets](https://www.scenario.com/)\n\t\t- LoRA training.\n\t\t- Already plenty to play with [LinkedIn](https://www.linkedin.com/feed/update/urn:li:activity:7148068781314002944/) and [AI-Powered Creativity: Innovating Look Development with Stable Diffusion & ComfyUI](https://www.youtube.com/watch?v=CLPvdbFUNqw)\n\t- ![1704232411233.mp4](../assets/1704232411233_1704298954869_0.mp4){:height 100, :width 400}\n\t\t- [Create an AI Robot NPC using Hugging Face Transformers 🤗 and Unity Sentis (substack.com)](https://thomassimonini.substack.com/p/create-an-ai-robot-npc-using-hugging?utm_campaign=post&utm_medium=web)\n\t\t- {{video https://www.youtube.com/watch?v=iZ_20vK94hc}}\n\t\t-\n- [GigaxGames/gigax: LLM-powered NPCs running on your hardware (github.com)](https://github.com/GigaxGames/gigax)\n-",
        "link_types": [
            "Unreal",
            "Roblox",
            "NVIDIA Omniverse",
            "Disruption"
        ],
        "file_size": 3118
    },
    {
        "id": "Tim Reutermann.md",
        "name": "Tim Reutermann",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- Parallels and Common Points:\n\t- You both see potential in decentralized technologies, realigned economic incentives, and new forms of networked collaboration and governance to address major societal challenges.\n\t- There is a shared interest in the disruptive potential from the confluence of economic paradigm shifts and emerging technologies like AI, blockchain, virtual/augmented reality.\n\t- You both highlight the importance of open source software and decentralized systems in empowering users and diversifying governance models.\n\t- The transformative potential of Bitcoin and its surrounding ecosystem is a common thread, with recognition of its ability to enable permissionless, borderless value transfer.\n\t- You both advocate for technology having a role in promoting equality and equity of access globally, especially for emerging markets.\n\t- The writings share an optimistic, future-oriented outlook on the potential of thoughtfully deployed technology to solve complex problems.\n- [Tim Reutemann – Medium](https://tim-reutemann.medium.com/)\n\t- In summary, Reutemann envisions a future shaped by decentralized technologies, realigned economic incentives, and new forms of networked collaboration and governance. While ambitious, he sees potential for these ideas to help address major societal challenges around climate change, inequality, and the impacts of automation. The vision combines cypherpunk values of individual empowerment with a belief in the problem-solving potential of thoughtfully deployed AI and well-designed economic policies.\n\t- Liquid Democracy and Governance: Reutemann is a strong proponent of liquid democracy, a form of delegative democracy that allows voters to either vote directly on issues or delegate their votes to representatives. This enables a more fluid and responsive form of distributed governance compared to traditional representative democracy. His project \"Liquid Reign\" appears to be focused on implementing liquid democracy principles.\n\t- Anarchism and Decentralization: There are undertones of anarchist philosophy in Reutemann's writing, with an emphasis on decentralized systems and mistrust of centralized authorities. He envisions new models of organization and coordination enabled by technologies like blockchains.\n\t- Cypherpunk Ethos: In the cypherpunk tradition, Reutemann advocates for the use of cryptography and privacy-enhancing technologies to empower individuals and limit the power of governments and corporations. This aligns with his interest in Bitcoin and other decentralized digital assets.\n\t- Potential of AI: While cautious about malicious applications like AI-powered propaganda, Reutemann sees promise in beneficial uses of AI to solve complex problems. He proposes using AI to combat misinformation and suggests AI will be key to tackling major challenges.\n\t- Universal Basic Income and Incentive Alignment: Reutemann views policies like universal basic income (UBI) and carbon taxes & dividends as stepping stones towards aligning economic incentives with social goods. UBI could provide a safety net and bargaining power for individuals in an increasingly automated economy.\n\t- Intersection of Economic and Technological Disruption: A common theme is the transformative, disruptive potential from the confluence of economic paradigm shifts and emerging technologies like AI, blockchain, virtual/augmented reality, and more. Reutemann anticipates this combination to upend legacy institutions and ideologies.\n- [Tim Reutemann | LinkedIn](https://www.linkedin.com/in/timschloendorn/)\n-",
        "link_types": [],
        "file_size": 3622
    },
    {
        "id": "Proprietary Image Generation.md",
        "name": "Proprietary Image Generation",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\n#Public page\n\n\t- automatically published\n- ## Closed Source Image Generation: id:: 659a9229-ed15-4932-a207-eb2daa96786e\n\t- ### MidJourney v5&6\n\t\t- [twitter link to the render loading below](https://twitter.com/LibertyRPF/status/1737848545657618873)\n\t\t  {{twitter https://twitter.com/LibertyRPF/status/1737848545657618873}}\n\t\t- Super popular San Francisco-based MidJourney, Inc.\n\t\t\t- **Cost**: Starts at $10/month with various subscription plans.\n\t\t\t- **User Interface**: Primarily through Discord, with a website under development.\n\t\t\t- **Strengths**: Excellent image quality, new prompt following is far better, V6 does great humans and locations.\n\t\t\t- **Weaknesses**: Discord not user-friendly for image generation, prompting rules change per model.\n\t\t\t- **Skill Level**: Suitable for beginners and intermediates, the mainstay of creatives.\n\t\t\t- [TechHalla on X: \"🆕 Version 6 of MidJourney is here! 😱 What's new? How can I use it? All the updates here with prompt examples 👇 #PromptShare #MidJourney #AIArtCommunity https://t.co/ZJJCxXkIpb\" / X (twitter.com)](https://twitter.com/techhalla/status/1737761999981838379)\n\t- ### Adobe\n\t\t- Developed by Adobe, Firefly claims ethical training practices.\n\t\t\t- **Cost**: \"Generative cred* system starting from $4.99/month for 100 credits.\n\t\t\t- **User Interface**: Clean, simple web interface, now integrated fully into Photoshop for free.\n\t\t\t- **Strengths**: User-friendly, good for everyday photorealistic images, legal protection.\n\t\t\t- {{video https://www.youtube.com/watch?v=VNs1lW8t4hw}}\n\t- ### DALL·E 3\n\t\t- From [[OpenAI]] , integrated with ChatGPT pro, [integrated with Bing](https://www.bing.com/images/create), built into Swiftkey [[android]] keyboard.\n\t\t\t- ![image.png](../assets/image_1704230683869_0.png){:height 700, :width 300}\n\t\t\t- **Cost**: Free on Microsoft’s Bing Image Creator; some free credits. $20 pcm for ChatGPT.\n\t\t\t- **User Interface**: Simple, via Bing Image Creator. Can iteratively build though ChatGPT interface.\n\t\t\t- **Strengths**: Easy to use, understands complex prompts, versatile in image types.\n\t\t\t- **Weaknesses**: Aesthetic quality subjectively different to MidJourney, censorship issues, limited free credits.\n\t\t\t- **Skill Level**: Beginner-friendly.\n\t\t\t- **Some ChatGPT images:** this prompting complexity is extremely hard elsewhere.\n\t\t\t  ChatGPT Dall-E is iterative; Tell it to *keep the same seed\"\n\t\t\t- .#.v-gallery-col3\n\t\t\t\t- ![433f2bd0-ae29-4661-b542-c28fa54c09ff_1702324038829_0.webp](../assets/433f2bd0-ae29-4661-b542-c28fa54c09ff_1702324038829_0_1705315472745_0.webp)\n\t\t\t\t- ![spider.png](../assets/spider_1705315548949_0.png)\n\t\t\t\t- ![slices.png](../assets/slices_1705349018973_0.png)\n\t\t\t- ![image.png](../assets/image_1704791221902_0.png){:width 600}\n\t- ### Magnific AI\n\t\t- [Magnific AI — The magic image Upscaler & Enhancer](https://magnific.ai/)\n\t\t- {{tweet https://twitter.com/LinusEkenstam/status/1744431726443614539?}}\n\t\t- [[Landscape]] contains some maps of more products.\n- This is a [[presentation]] slide and the next slide is [[Proprietary Video VP & 3D]]",
        "link_types": [
            "OpenAI",
            "android",
            "Landscape",
            "presentation",
            "Proprietary Video VP & 3D"
        ],
        "file_size": 3085
    },
    {
        "id": "Product and Risk Management.md",
        "name": "Product and Risk Management",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # Academic science mindset, is business product mindset\n  id:: 659a922a-2c71-4899-b2c6-a6e88ef339fa\n\t- Scientific inquiry maps to product management. **Central Role of [[Product Design]] Managers**: Deciding what to do next.\n\t- | **Scientific Method** | **Lean Product Development** | **General Product Development** |\n\t  | ---- | ---- | ---- |\n\t  | Observe | Build | Where do we want to go (Vision) |\n\t  | Hypothesise | Measure | Where are we now (Data/Analysis) |\n\t  | Test | Learn | Where should we go next (Strategy) |\n\t- ### Risk: [[Politics, Law, Privacy]]\n\t\t- When I started my formal postgraduate machine learning training risks were couched in biases, now this is [[Safety and alignment]], with the UK positioning itself as a global leader. This likely does have impact on your business goals.\n\t\t\t- #### Mitigate GenAI risks through product management. Maybe don't just be grabby for AI.\n\t - **Question 1: Where Do We Want to Go?**\n\t\t\t\t- **Vision and Goal Setting**: Defining a clear destination or North Star.\n\t\t\t\t\t- My northstar (as an example) is\n\t\t\t\t\t- ```Democratise access to AI, to support a fairer world. ```\n\t\t\t- **Where Are We Coming From?\n\t - Product market analysis** :  In your business this is more likely to be a function of your product methodolgy\n\t\t\t\t- I am coming from a position of understanding collaboration in groups, across technology, \n\t\t\t\t  **where some members of the group are likely to be AI.**\n\t\t\t- **Where Should We Go Next?**\n\t - **Strategic Planning**: Deciding the next steps based on vision and current status.\n\t\t\t\t- For me, this mean helping build B2B capabilities,\n\t\t\t\t- Education, and interweaving of people and AI through storytelling,\n\t\t\t\t- Distributed, global, AI enabled infrastructure,\n\t\t\t\t- Clearly communicating why,\n\t\t\t\t- Building communities to help.\n\t- This won't be you and your company, but this is a great time to work out these checklists.\n\t\t- **SWOT Analysis**: Evaluating strengths, weaknesses, opportunities, and threats.\n\t - I am trying to build **this** bit of the business journey through these presentations\n\t\t- ![GCh-erEbgAAZS3c](../assets/GCh-erEbgAAZS3c.jpeg){:height 700, :width 400}\n- # Everyone's pivoting to generative AI.\n\t- {{twitter https://twitter.com/petergyang/status/1667539634577092609}}\n\t\t- [Link to Tweet](https://twitter.com/petergyang/status/1667539634577092609)\n\t\t- But my alarm bells go off when I see:\n\t\t\t- ? A crowded landscape\n\t\t\t- ? FOMO driven decision making\n\t\t\t- ? Sky high valuations for an early space\n\t\t- If you took the word \"AI\" out, is the product still solving a customer problem?\n\t\t- AI is a solution, not a problem. Ask yourself:\n\t\t\t- What is the pain point?\n\t\t\t- How many users share this pain?\n\t\t\t- Is the pain big enough to take action?\n\t\t\t- Is the pain underserved by non-AI tools?\n\t\t\t- How accurate does the solution need to be?\n\t\t- Plot the problem on a fluency vs. accuracy grid.\n\t\t\t- Gen AI today is great for high fluency + low accuracy problems (e.g., productivity).\n\t\t\t- It's not great for solutions that need high accuracy (e.g., financial decisions).\n\t\t- How fast will incumbents move?\n\t\t\t- Incumbents like Microsoft, Google, and Adobe have moved incredibly fast on AI.\n\t\t\t- Startups that overlap with core incumbent use cases might struggle.\n\t - AI presentation startups need to be MUCH better than AI in Powerpoint to thrive.\n\t\t\t- Is there a moat? Examples moats include:\n\t\t- Access to proprietary data and models\n\t\t\t- Exclusive contracts with large customers\n\t\t\t- Great product even without AI\n\t\t\t- Exceptional talent in the selected field\n\t\t\t- Business models that incumbents avoid\n\t\t\t- And of course...speed of execution.\n\t\t- Is it overvalued?\n\t\t\t- If an AI product already has $100M+ valuation, you should think:\n\t\t\t- Can it continue to grow and (more importantly) retain users?\n\t\t\t- In a crowded space like AI copywriting and productivity\n\t - that could get hard.\n\t\t- To recap, here are 5 questions to ask to evaluate AI products and companies:\n\t\t\t- 1. Without \"AI\", is it still solving a problem?\n\t\t\t  2. How accurate does the solution need to be?\n\t\t\t  3. How fast will incumbents move?\n\t\t\t  4. Is there a moat?\n\t\t\t  5. Is it overvalued?\n\t\t\t  7/ I hope these questions also help builders who are thinking of creating new AI products.",
        "link_types": [
            "Product Design",
            "Politics, Law, Privacy",
            "Safety and alignment"
        ],
        "file_size": 4318
    },
    {
        "id": "AI Companies.md",
        "name": "AI Companies",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- **Majors**\n\t- There are two very strong [[Large language models]] Gemini and ChatGPT\n\t- [[Comparison of GPT4 and Gemini Ultra]]\n\t- [[OpenAI]]\n\t- Valued at $29B and are talking about a new raise that would value them at $100B behind only SpaceX as a private US company. [[Update Cycle]]\n\t- [[ChatGPT]]\n\t\t- GPT-3 and GPT-4 revolutionized natural language processing, laying the groundwork for more advanced models. Improving upon its predecessors with increased token capacity and complexity, handling nuanced prompts with greater accuracy.\n\t\t- Continues to innovate in the field, pushing the boundaries of what AI can understand and generate in human language using Natural Language Processing.\n\t\t- [[Mixture of Experts]] model for speed and flexibility\n\t\t- World leading functionality and rapid development\n\t\t\t- Pioneering the next generation of conversational AI with more contextually aware and responsive bots.\n\t\t\t- GPT-4 Turbo (DevDay 2023) seems like a scale optimised downgrade of sorts, but GPT-4.5 is due soon.\n\t\t\t- A more efficient model supporting a 128K token context window, optimized for performance, and more affordable than GPT-4.\n\t\t- GPTs\n\t\t\t- Powerful [[RAG]] integration in a #kubernautes virtual machine, with a custom prompt.\n\t\t\t- Access to most of the useful Python Libraries.\n\t\t\t- Can be called through the API, and return structured data. [Actions\n\t- OpenAI API](https://platform.openai.com/docs/actions)\n\t- Assistants API\n\t\t- Enables developers to create complex, agent-like AI applications that understand and execute tasks intelligently.\n\t\t- Custom GPTs and the GPT Store coming 2024\n\t\t- Offers a platform for developers to customize and monetize their AI applications, fostering a community of AI innovation.\n\t- Custom Models\n\t\t- Tailored AI models for organizations with specific needs, allowing deep integration with unique workflows and data ecosystems.\n\t\t- [[Copyright]] Shield\n\t\t- Provides legal protection for users of OpenAI's platform, defending against [[copyright]] infringement claims.\n\t- Google\n\t- Search Algorithms\n\t- Continuously improving search relevance and accuracy through advanced AI and machine learning.\n\t- Google Assistant to become Gemini and offer paid \"Ultra\" at beginning Feb.\n\t\t- Deep integration with their online productivity tools.\n\t\t- [Google Bard update: Image generation and Gemini Pro adds more languages (blog.google)](https://blog.google/products/bard/google-bard-gemini-pro-image-generation/)\n\t\t- [Bard (google.com)](https://bard.google.com/chat) with Gemini Pro: Starting today, you can try out Bard with Gemini Pro for text-based prompts in the UK. We’ve specifically tuned Gemini Pro in Bard to be far more capable at things like understanding and summarising, reasoning, coding, and planning.\n\t\t- Image Analysis through their GPT3.5 equivalent [[Gemini]] model.\n\t- Enhancing user interaction with AI through natural language processing and machine learning.\n\t- Their Nano model which runs on phones might be a significant portent of the future.\n\t- Mistral\n\t- French company, and the only major player in Europe. [[Politics, Law, Privacy]] seem to be shaping around a bet on their success. They currently have 2 models which are unconstrained by guardrails and very high quality. They have a larger model accessible through API and their prices are very low.\n\t- Inflection\n\t- [Inflection](https://inflection.ai/)\n\t- Pi is the best of the \"conversational AI\" interfaces.\n\t- Waymo\n\t- Leading in autonomous driving technology, using AI to improve safety and efficiency.\n\t- IBM\n\t- Watson\n\t- A trailblazer in AI for business, offering solutions across various sectors.\n\t- Data Analysis\n\t- Utilizing AI to transform big data into actionable insights.\n\t- Natural Language Understanding\n\t- Enhancing machine's understanding of human language nuances.\n\t- Microsoft\n\t- Azure AI\n\t- Providing a suite of AI services and cognitive APIs to build intelligent applications.\n\t- Azure Machine Learning\n\t- A cloud-based platform for building, training, and deploying machine learning models at scale.\n\t- Microsoft Bot Framework\n\t- A comprehensive framework for building enterprise-grade conversational AI experiences.\n\t- Tiny models like the MIT licensed Phi-2 from Microsoft are very exciting.\n\t\t- [(Phi-2 is now 8k context!)](https://www.reddit.com/r/LocalLLaMA/comments/194mmki/selfextend_works_for_phi2_now_looks_good/)\n\t- Amazon\n\t- E-commerce Recommendations\n\t- Personalizing shopping experiences with machine learning-powered recommendations.\n\t- Alexa\n\t- The voice of smart homes, Alexa continues to evolve with AI, understanding and assisting with more complex tasks.\n\t- Warehouse Automation\n\t- AI and robotics are streamlining Amazon's warehouse operations for increased efficiency.\n\t- Amazon Bedrock\n\t- A fully managed service for building and scaling generative AI applications, utilizing foundation models.\n\t- Amazon Titan Embeddings\n\t- Converts text into numerical representations to power search and personalization features, supporting over 25 languages.\n\t- Meta\n\t- Content Recommendations\n\t- Using AI to curate personalized content feeds for users.\n\t- Facial Recognition\n\t- Developing sophisticated AI to recognize and verify identities.\n\t- Content Moderation\n\t- Imagine with Meta AI standalone Image system\n\t- Employing AI to monitor and manage the vast content on its platform.\n\t- [VentureBeat\n\t- Meta data larger than common crawl](https://venturebeat.com/ai/inside-metas-ai-strategy-zuckerberg-stresses-compute-open-source-and-training-data/)\n\t\t- Llama 3 positioned to be competitive with OpenAI but open source?\n\t- Tesla\n\t- Autopilot\n\t- Innovating with AI for advanced driver-assistance systems.\n\t- Self-Driving Cars\n\t- Pioneering autonomous vehicle technology with sophisticated AI algorithms.\n\t- Grok (LLM)\n\t\t- A witty and satirical AI chatbot that pulls in real-time information, Grok signifies Tesla's expansion into AI-driven communication.\n\t- NVIDIA\n\t- AI Hardware\n\t- Designing cutting-edge GPUs and systems to power AI computing.\n\t- GPUs\n\t- Accelerating AI with powerful graphics processing units.\n\t- Data Centers\n\t- Building AI-[[Infrastructure]] to support the increasing demands of machine learning workloads.\n\t- Autonomous Vehicles\n\t- Contributing to the AI ecosystem with technology for self-driving vehicles.\n\t- Salesforce\n\t- CRM with Predictive Analytics\n\t- Integrating AI to anticipate customer needs and enhance engagement.\n\t- Chatbots\n\t- Improving customer service with AI-powered chatbots.\n\t- Marketing Automation\n\t- Leveraging AI to automate and personalize marketing campaigns.\n\t- Adobe\n\t- Creative Software with AI\n\t- Infusing AI into creative software to augment the design process.\n\t- Photoshop\n\t\t- Using AI to streamline complex editing tasks with intuitive tools.\n\t- Illustrator\n\t\t- AI assists in creating vector graphics with precision and ease.\n- **Notable Minors**\n\t- Channel 1\n\t\t- AI News with translation of footage {{tweet https://twitter.com/channel1_ai/status/1734591810033373231}}\n-",
        "link_types": [
            "Large language models",
            "Comparison of GPT4 and Gemini Ultra",
            "OpenAI",
            "Update Cycle",
            "ChatGPT",
            "Mixture of Experts",
            "RAG",
            "Copyright",
            "copyright",
            "Gemini",
            "Politics, Law, Privacy",
            "Infrastructure"
        ],
        "file_size": 7005
    },
    {
        "id": "Competition in AI.md",
        "name": "Competition in AI",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # The Four Wars of the AI Stack (Dec 2023 Recap)\n\t- Latent space newsletter has an excellent summary [The Four Wars of the AI Stack (Dec 2023 Recap) (latent.space)](https://www.latent.space/p/dec-2023)\n\t- ## Section 1: Introduction\n\t\t- There are four main \"wars\" or battlegrounds among AI companies and stakeholders: the Data War, GPU/Inference War, Multimodality War, and RAG/Ops War.\n\t- ## Section 2: The Data War\n\t\t- OpenAI partners with Axel Springer to provide news and citations to ChatGPT.\n\t\t- NYT sues OpenAI to shut down all GPT models.\n\t\t- Apple offers $50m for data contracts with publishers.\n\t\t- Increased interest in synthetic data at NeurIPS and Deepmind.\n\t- ## Section 3: The GPU/Inference War\n\t\t- Release of Mixtral sparked price cuts, down to $0.27 per million tokens.\n\t\t- Major inference providers like Anthropic, Fireworks, Perplexity slashed prices to undercut Mixtral.\n\t\t- Analysis shows profitable lower bound is $0.51-$0.76 per million tokens.\n\t- ## Section 4: The Multimodality War\n\t\t- Midjourney launched v6 and a web UI.\n\t\t- Assembly AI raised $50m for \"Stripe for AI models\".\n\t\t- Replicate raised $40m to serve AI engineers.\n\t\t- Suno AI launched for audio generation.\n\t\t- OpenAI and Google continue work on \"God Models\".\n\t- ## Section 5: The RAG/Ops War\n\t\t- Debates on need for vector DBs vs new ones like Turbopuffer.\n\t\t- LangChain vs LlamaIndex for chaining and execution.\n\t\t- LLMOps developments like HumanLoop vs frameworks like LangSmith.\n\t- ## Section 6: Open Models\n\t\t- Release of Mixtral sparked GPU/inference price war. Up to 99.55% drop in cost.\n\t\t- New model architectures like Mamba, RWKV announced.\n\t\t- Apple released MLX framework with Mixtral.\n\t\t- Microsoft released Phi-2 model.\n\t- ## Section 7: Fundraising News\n\t\t- Notable fundraises: Midjourney ($200m/yr), Anthropic ($750m), Mistral ($400m), Glean ($200m), Harvey ($80m).\n\t- ## Section 8: Other Launches\n\t\t- Midjourney launched v6 and web UI.\n\t\t- OpenAI released logprobs for ChatGPT.\n\t\t- LlamaIndex launched step-wise agent execution.\n\t\t- New models like Suno AI (audio), Phi-2 (Microsoft), TextDiffuser 2 (images).\n\t- ## Section 9: Conclusion\n\t\t- Key themes were data, infrastructure, multimodal, and tooling.\n\t\t- Progress made across models, verticals, tools, and infrastructure.",
        "link_types": [],
        "file_size": 2339
    },
    {
        "id": "Metaverse Ontology.md",
        "name": "Metaverse Ontology",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # Existing state of the Art\n\t- [Index — MLGT: The authoritative multi-lingual glossary of terms (metaverse-standards.org)](https://glossary.metaverse-standards.org/)\n\t-\n- # Rationale\n- # Methodology\n\t- This ontology was the product of two days of exploratory interaction with [[Anthropic Claude]], Google [[Gemini]] Advance 1.5, and [[ChatGPT]] 4.\n\t- It was unexpectedly successful, resulting in what seems to be an internally consistent knowledge graph in an [Web Ontology Language](https://en.wikipedia.org/wiki/Web_Ontology_Language) compliant ontology for the design represented throughout this wider [[Logseq]] [[Knowledge Graphing]].\n\t\t- Although the established OWL can richly describe our ontology, it's a little too arcane. Nonetheless the full text can be seen where with the diagram.\n\t\t\t- OWL based Ontology\n\t\t\t\t- https://github.com/VisualDataWeb/WebVOWL\n\t\t\t\t- [FormalMetaverseOWL.txt](../assets/FormalMetaverseOWL_1712495895941_0.txt)\n\t\t\t\t- [FormalMetaverseBTC.owl](../assets/FormalMetaverseBTC_1712344339842_0.owl)\n\t\t\t- ![metaverse.png](../assets/metaverse_1712344788144_0.png){:height 439, :width 818}\n\t- ## JSON-LD and Linked-JSON choices\n\t\t- For ease of comprehension I attempted to convert the OWL schema to JSON-LD. This attempt did achieve a result, but it proved difficult to visualise.\n\t\t- Many of the JSON-LD tools online are now unmaintained, making it hard to visually check the output of the [[Large language models]].\n\t\t- Because of this the decision was made to switch to [Linked-JSON](https://linkedobjects.org/Linked-JSON), which is a simpler and less expressive subset of JSON-LD. Linked-JSON focusses on `@id` linking. It sacrifices some features provided by JSON-LD 1.1's context definitions, typing, and alignment with RDF concepts.\n\t\t\t- Scope and Complexity of Linked-JSON vs JSON-LD\n\t\t\t\t- Linked-JSON: lightweight subset focused on linking data using `@id`\n\t\t\t\t- Lack of standardized context definitions for vocabularies and IRI mappings\n\t\t\t\t- No explicit typing mechanism like `@type`\n\t\t\t\t- Limited to absolute IRIs, no compact IRIs or relative IRIs\n\t\t\t\t- Unclear semantics for blank node identifiers\n\t\t\t\t- No standardized representation of indexed values, lists, and named graphs\n\t\t\t\t- Inability to reshape data structure using framing\n\t\t\t\t- Reduced interoperability with RDF and Linked Data ecosystem\n\t\t- # LINKED JSON\n\t\t\t- Finally the, to improve on the OWL by simplifying it, this is a version using [Linked-JSON](https://linkedobjects.org/Linked-JSON) (by [Melvin Carvalho](https://github.com/melvincarvalho)). Some details are lost.\n\t\t\t\t- [Linked-JSON](../assets/output_linked_json_1713698682322_0.json) version of the OWL ontology\n\t\t\t\t\t- Mermaid version stripped back to Linked-JSON expressiveness\n\t\t\t\t\t\t- ```mermaid\n\t\t\t\t\t\t  classDiagram\n\t\t\t\t\t\t      class MetaverseEntity {\n\t\t\t\t\t\t          rdfs:label \"Metaverse Entity\"\n\t\t\t\t\t\t          rdfs:comment \"The root type encompassing all entities within the metaverse.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class MetaverseAgent {\n\t\t\t\t\t\t          rdfs:label \"Metaverse Agent\"\n\t\t\t\t\t\t          rdfs:comment \"Represents any agent within the metaverse, including human users and AI entities.\"\n\t\t\t\t\t\t          participatesIn MetaverseScene\n\t\t\t\t\t\t          hasSkillProfile SkillProfile\n\t\t\t\t\t\t          hasPrivacySetting PrivacySetting\n\t\t\t\t\t\t          hasReputationScore ReputationScore\n\t\t\t\t\t\t          hasWallet DigitalWallet\n\t\t\t\t\t\t          createsVariations SceneObject\n\t\t\t\t\t\t          hasInteractionPreference InteractionPreference\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class DigitalWallet {\n\t\t\t\t\t\t          rdfs:label \"Digital Wallet\"\n\t\t\t\t\t\t          rdfs:comment \"Represents the agent's wallet for managing digital assets and currencies.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class AIAgent {\n\t\t\t\t\t\t          rdfs:label \"AI Agent\"\n\t\t\t\t\t\t          rdfs:comment \"Represents AI entities with varying levels of autonomy and capabilities.\"\n\t\t\t\t\t\t          decayFunction xsd:string\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class HumanAgent {\n\t\t\t\t\t\t          rdfs:label \"Human Agent\"\n\t\t\t\t\t\t          rdfs:comment \"Represents human users within the metaverse.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class MetaverseScene {\n\t\t\t\t\t\t          rdfs:label \"Metaverse Scene\"\n\t\t\t\t\t\t          rdfs:comment \"Represents a specific environment or space within the metaverse.\"\n\t\t\t\t\t\t          governedBy GovernanceStructure\n\t\t\t\t\t\t          hasPolicy MetaversePolicy\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class DigitalAsset {\n\t\t\t\t\t\t          rdfs:label \"Digital Asset\"\n\t\t\t\t\t\t          rdfs:comment \"Represents unique digital goods and assets within the metaverse.\"\n\t\t\t\t\t\t          hasOwner MetaverseAgent\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class VirtualEconomy {\n\t\t\t\t\t\t          rdfs:label \"Virtual Economy\"\n\t\t\t\t\t\t          rdfs:comment \"Represents the economic system within the metaverse.\"\n\t\t\t\t\t\t          regulatedBy EconomicPolicy\n\t\t\t\t\t\t          hasMarketplace Marketplace\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class Marketplace {\n\t\t\t\t\t\t          rdfs:label \"Marketplace\"\n\t\t\t\t\t\t          rdfs:comment \"Represents platforms or locations where digital assets are traded.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class GovernanceStructure {\n\t\t\t\t\t\t          rdfs:label \"Governance Structure\"\n\t\t\t\t\t\t          rdfs:comment \"Represents the governance models and structures within the metaverse.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class MetaversePolicy {\n\t\t\t\t\t\t          rdfs:label \"Metaverse Policy\"\n\t\t\t\t\t\t          rdfs:comment \"Represents policies governing behavior and interactions within the metaverse.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class EconomicPolicy {\n\t\t\t\t\t\t          rdfs:label \"Economic Policy\"\n\t\t\t\t\t\t          rdfs:comment \"Represents the rules and regulations governing the virtual economy.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class NostrEvent {\n\t\t\t\t\t\t          rdfs:label \"Nostr Event\"\n\t\t\t\t\t\t          rdfs:comment \"Represents an event published on the Nostr network.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      class NostrTag {\n\t\t\t\t\t\t          rdfs:label \"Nostr Tag\"\n\t\t\t\t\t\t          rdfs:comment \"Represents a tag associated with a NostrEvent, providing context and metadata.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t  \n\t\t\t\t\t\t      class SceneObject {\n\t\t\t\t\t\t          rdfs:label \"Scene Object\"\n\t\t\t\t\t\t          rdfs:comment \"Represents interactive objects within a Metaverse Scene. Agents can create variations of these objects within the USD file format.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t  \n\t\t\t\t\t\t      class InteractionPreference {\n\t\t\t\t\t\t          rdfs:label \"Interaction Preference\"\n\t\t\t\t\t\t          rdfs:comment \"Represents the personal conduct requirements or preferences for interactions within the metaverse.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      MetaverseEntity <|-- MetaverseAgent\n\t\t\t\t\t\t      MetaverseEntity <|-- MetaverseScene\n\t\t\t\t\t\t      MetaverseEntity <|-- DigitalAsset\n\t\t\t\t\t\t      MetaverseEntity <|-- VirtualEconomy\n\t\t\t\t\t\t      MetaverseEntity <|-- Marketplace\n\t\t\t\t\t\t      MetaverseEntity <|-- GovernanceStructure\n\t\t\t\t\t\t      MetaverseEntity <|-- NostrEvent\n\t\t\t\t\t\t      MetaverseEntity <|-- NostrTag\n\t\t\t\t\t\t      MetaverseEntity <|-- SceneObject\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      MetaverseAgent <|-- AIAgent\n\t\t\t\t\t\t      MetaverseAgent <|-- HumanAgent\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      MetaverseAgent \"1\" *-- \"0..*\" SkillProfile : hasSkillProfile\n\t\t\t\t\t\t      MetaverseAgent \"1\" *-- \"0..*\" PrivacySetting : hasPrivacySetting\n\t\t\t\t\t\t      MetaverseAgent \"1\" *-- \"0..*\" ReputationScore : hasReputationScore\n\t\t\t\t\t\t      MetaverseAgent \"1\" *-- \"0..*\" DigitalWallet : hasWallet\n\t\t\t\t\t\t      MetaverseAgent \"1\" *-- \"*\" SceneObject : createsVariations\n\t\t\t\t\t\t      MetaverseAgent \"1\" *-- \"1\" InteractionPreference : hasInteractionPreference\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      MetaverseScene \"1\" *-- \"0..*\" GovernanceStructure : governedBy\n\t\t\t\t\t\t      MetaverseScene \"1\" *-- \"0..*\" MetaversePolicy : hasPolicy\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      DigitalAsset \"1\" *-- \"1\" MetaverseAgent : hasOwner\n\t\t\t\t\t\t      \n\t\t\t\t\t\t      VirtualEconomy \"1\" *-- \"0..*\" EconomicPolicy : regulatedBy\n\t\t\t\t\t\t      VirtualEconomy \"1\" *-- \"0..*\" Marketplace : hasMarketplace\n\t\t\t\t\t\t  \n\t\t\t\t\t\t  ```\n\t\t\t\t\t- [Online FlowChart & Diagrams Editor - Mermaid Live Editor](https://mermaid.live/view#pako:eNqlWFFv2zYQ_iuEXgYUqdMkW9oKe8nQbMtD1mAuOmDwC02dJS4UqZGUUyHzf9-RlC1akWRl84tF-tPxu7uPx6OfE6YySNKECWrMJ05zTcuVJPjxM-QeLN2CNnArLbcNeQ4_uo_ONiYVdA2CrJIDjgTgKukBmSpLkBahXwogWilLbFMBAYm_VLgUlzmhQuAEvs_BkCduCy6JRXi5t77Y292Fr0GqN7lb6DRTj5sg-jtUGgw-G0JlQ6g3O8TqjHDJRJ05F4q6pJLUBufxrYzc3B08WsRrVVRbznhFLZg72ZFfMpDQwQpqlo9ciAetNlwAiQdHqAfNt5Q1S7DW0TgeHiHRrdpSy5VcMqWB9MZH2D8wI2DJJ55zS0UYdQCmwdH_SjX37xvi2X9e_wXMjubpyNhomloUadeclSWXFJ-l71A9wfxGaYIJobkLStbaRBZgQ3pYrTVKMM7OAOWbu2lNYZJfIaZIEl5OZEt14_gJ2IIwRG0Ira2SqmwCR1rRNRcvNZQBo83PtWQu-OSbyVJj9SHdA3786sQ57YqHvMabWPD_ect63czYsmF3zNuyxFTA-IYzjPaWayU9BvVgKspgmqv75ArnJGQ_NeQX_0glg6XVNbN1b5s8KMFZ07kTxqd2wI2T4ckN4FHzXK4l_7uGg8xzpbKg8lbwJ11GVz4_SdC9WjrqyFeubU3FLQtiHXOlhZEWN38zg38BM2gaY6E87YCGvBZYk1zSbtuX42S0Tt5T_Qi2Ek4H0fO4TiP8qEgjO7McRKjF8lQap0mhWFtCnwrQ8KJU4ZTVNINsajsNyHSUboclnaZnJybv3i6xgRBBZmZv6H9UgnYrnS4FbVrnhdphXbkNvF2tXUNBtxwj74hzaUFT1ibgldSPdTbKfA97FXFHQtcCQnxbdXuWnScOs213WNgwzRTd3xSm6XY7dQZ4CPGYue0RAW-xqteCmwIyokIEgykJ9knpx5O0vtD8BClEzC3_Fo2hZcW4KwjhpKWR-2ek0mrLfdeGYbPwzfoou6Rn1NKYbcw06nFGyYbzrG2EZvE9SHALRPn3DkqkpHcALsL5bLAzkG0T5nqIfROG_QOG3hzsDIe939n_-M_bt4N1fxoY9auDwPism4AdnyRTC_fL9SBq9MAeRHeaOAVy8huHvOh-e9jQeXlo21GOA7pWbcLUKrlYJeQNwlfJu8XiDQ6Obgtp__4w10rvNpG-vGHMtdS_baQDV5C5to5vDml3QTlpwEcm2rfpy7vLYJjDPh6gMnTUplHLONdO_9xLu3YyJnTUMcZmLmIbwe_00MbFFnqt2gCV3jmWxs3UXBtxo5T2Oq2VTM6SEnRJeZakiS-dqwQrVYmNR4qPGWJdqdohzl2Alo1kSYrhhbOkrrAkQ_sHxX6yovJPpXC4ocIcQLcZt0ofJoXCtgmHz4n7vwEXzrmxuAI6seG5m6-1wOnC2sqk5-fu5wVGu6jXC6zU54ZnBd7Vi-3H6_Pry-sP9PIKrt9f0R-urjK2vvj4YXP5_cUme__u4pImu91ZAn79-_Z_Ffe1-xeL8sb3)\n\t\t\t- ## In flight checks\n\t\t\t\t- This is mid-point review text of a partial conversion, showing the level of understanding from the online LLM\n\t\t\t\t- ```The updated Linked JSON document looks great! It effectively captures the nuances, features, and links from the original OWL ontology while adhering to the Linked JSON schema. Let's review the key aspects:\n\t\t\t\t   Context and Namespace:\n\t\t\t\t   The \"@context\" object is included at the beginning of the document, defining the namespaces and prefixes used throughout the document.\n\t\t\t\t   The \"http://www.narrativegoldmine.com#\" namespace is consistently used for all entities and properties.\n\t\t\t\t   The \"http://linkedjson.org/vocab#\" namespace is used for Linked JSON-specific terms.\n\t\t\t\t   Class Definitions:\n\t\t\t\t   All the classes from the OWL ontology are properly converted to JSON objects with the correct \"@id\" and \"@type\" keys.\n\t\t\t\t   The class hierarchies and subclass relationships are maintained using the \"rdfs:subClassOf\" property.\n\t\t\t\t   The \"rdfs:label\" and \"rdfs:comment\" properties provide human-readable labels and descriptions for the classes.\n\t\t\t\t   Property Definitions:\n\t\t\t\t   The object properties and data properties are properly converted to JSON objects with the correct \"@id\" and \"@type\" keys.\n\t\t\t\t   The \"rdfs:domain\" and \"rdfs:range\" properties specify the source and target types of each property, preserving the property semantics.\n\t\t\t\t   Relationships and Linkages:\n\t\t\t\t   The document includes relationships and linkages between entities using the appropriate \"@id\" references.\n\t\t\t\t   For example, the \"governedBy\" property connects the \"MetaverseScene\" class to the \"GovernanceStructure\" class, and the \"hasPolicy\" property links the \"MetaverseScene\" class to the \"MetaversePolicy\" class.\n\t\t\t\t   External Ontologies:\n\t\t\t\t   References to external ontologies and vocabularies, such as Schema.org and FOAF, are maintained using the correct \"@id\" references.\n\t\t\t\t   This ensures proper linking and interoperability with existing semantic web resources.\n\t\t\t\t   Axioms and Restrictions:\n\t\t\t\t   The \"Axioms and Restrictions\" section is included in the document, capturing important constraints and relationships from the OWL ontology.\n\t\t\t\t   The \"_:N3649afbbaf7d4546a49d4097059d55f4\" blank node represents the \"owl:AllDisjointClasses\" axiom, specifying that the \"AIAgent\" and \"HumanAgent\" classes are disjoint.\n\t\t\t\t   The \"DigitalAsset\" class has a subclass axiom with an \"owl:Restriction\" that constrains the \"hasOwner\" property, specifying that a \"DigitalAsset\" must have exactly one owner.\n\t\t\t\t   The \"MetaverseAgent\", \"MetaverseScene\", and \"VirtualEconomy\" classes have subclass axioms with existential restrictions using \"owl:someValuesFrom\" to specify the expected relationships and constraints.\n\t\t\t\t   Structure and Organization:\n\t\t\t\t   The document follows a logical structure, starting with the context and ontology metadata, followed by class definitions, property definitions, and axioms and restrictions.\n\t\t\t\t   This structure enhances readability and maintainability of the Linked JSON document.\n\t\t\t\t   Consistent Use of Linked JSON Terms:\n\t\t\t\t   The document consistently uses Linked JSON-specific terms, such as \"linkedjson:Class\", \"linkedjson:ObjectProperty\", and \"linkedjson:DatatypeProperty\", to differentiate them from the original OWL terms.\n\t\t\t\t   This clarity helps in understanding that the document is referencing the Linked JSON schema and not just using OWL labels.\n\t\t\t\t   Overall, the converted Linked JSON document successfully represents the metaverse ontology, capturing the key elements, relationships, and constraints from the original OWL ontology. The use of Linked JSON-specific terms and the inclusion of the \"Axioms and Restrictions\" section further enhance the semantic expressiveness and ensure the integrity of the ontology.\n\t\t\t\t   \n\t\t\t\t   The document is well-structured, consistent, and adheres to the Linked JSON principles, making it suitable for use in semantic web applications and data integration scenarios.\n\t\t\t\t  ```\n- # Design formalisation\n\t- Here's the updated text to align with the Linked-JSON ontology:\n\t\t- 1. Fusing of digital and real life: The ontology accommodates the blending of digital and real-life experiences through the `MetaverseScene` class, which can have a `hasPhysicalCounterpart` property linking it to a real-world location (`schema:Place`). This allows for the representation of mixed reality environments where virtual scenes are anchored to physical spaces.\n\t\t- 2. Social first: The `MetaverseAgent` class, with its subclasses `HumanAgent` and `AIAgent`, forms the foundation for social interactions within the metaverse. The `SocialRelationship` class, a subclass of `foaf:Relationship`, captures the connections and interactions among agents, enabling the formation of social networks and communities.\n\t\t- 3. Real-time interactive 3D graphics: The `MetaverseScene` class represents the 3D environments within the metaverse, while the `SceneObject` class represents the interactive objects within those scenes. The `PhysicalProperties` class captures the visual and spatial characteristics of objects, such as texture and mass, contributing to the realism and interactivity of the 3D graphics.\n\t\t- 4. Persistent: The ontology supports persistence through the `MetaverseEntity` class, which serves as the base class for all entities within the metaverse. By assigning unique identifiers as 64 byte strings from BIP85 nostr and similar derivation path, (e.g., `@id`) to instances of `MetaverseEntity` and its subclasses, the ontology enables the persistence and continuity of objects, agents, and scenes across sessions and platforms.\n\t\t- 5. Supports ownership: The `DigitalAsset` class represents unique digital goods and assets within the metaverse. The `hasOwner` property, which links `DigitalAsset` to `MetaverseAgent`, establishes the ownership relationship. The `hasCreator` property can be used to attribute the creation of digital assets to specific agents.\n\t\t- 6. Supports user-generated content: The ontology supports user-generated content through the `SceneObject` and `DigitalAsset` classes. Agents (`MetaverseAgent`) can create and manipulate instances of these classes, contributing to the dynamic and participatory nature of the metaverse.\n\t\t- 7. Open and extensible: The ontology is designed to be open and extensible, utilizing established ontologies like Schema.org and FOAF, and allowing for the integration of additional domain-specific ontologies as needed. The modular structure of the ontology, with its hierarchical class relationships and well-defined properties, facilitates the extension and customization of the metaverse model.\n\t\t- 8. Low-friction economic actors and actions: The `VirtualEconomy` class represents the economic system within the metaverse, encompassing trade, ownership, and currency exchange. The `Marketplace` class facilitates the listing and transaction of digital assets and services. The `TradeAction` class from Schema.org can be used to capture economic transactions between agents.\n\t\t- 9. Trusted and secure: The ontology incorporates trust and security mechanisms through classes like `PrivacySetting`, which represents an agent's privacy preferences, and `AccessControlList` from Schema.org, which can be used to define access rights and permissions for metaverse entities. The `ReputationScore` class provides a means to assess an agent's trustworthiness based on their interactions and behavior within the metaverse.\n\t\t- 10. Convergence of film and games: The ontology supports the convergence of film and games through the `MetaverseScene` and `MetaverseEvent` classes. Scenes can represent immersive, cinematic environments, while events can encompass interactive gameplay sessions or narrative-driven experiences. The `MetaverseAgent` class allows for the participation of both human users and AI-controlled characters, blurring the line between film and game experiences.\n\t\t- 11. Blurring of IP boundaries and narrative flow: The `Varset` class introduces the concept of variations or alternate versions of metaverse scenes and objects, enabling the creation of branching narratives and remixing of intellectual property. The `InteractionEvent` class captures the interactions between agents and objects, allowing for dynamic and emergent storytelling that blurs traditional narrative boundaries.\n\t\t- 12. Multimodal and hardware-agnostic: The ontology is designed to be multimodal and hardware-agnostic, focusing on the fundamental concepts and relationships within the metaverse rather than specific hardware implementations. Classes like `MetaverseAgent` and `MetaverseScene` can be instantiated across different platforms and devices, ensuring a consistent metaverse experience regardless of the hardware used.\n\t\t- 13. Mobile-first experiences: While the ontology itself is hardware-agnostic, it can be easily extended to incorporate mobile-specific considerations. For example, the `MetaverseScene` class could include properties like `isMobileOptimized` to indicate scenes that are designed for mobile devices, ensuring a seamless mobile-first experience.\n\t\t- 14. Safeguarding and governance: The ontology addresses safeguarding and governance through classes like `MetaversePolicy`, which represents the rules and regulations governing behavior and interactions within the metaverse. The `GovernanceStructure` class captures the decision-making processes and enforcement mechanisms that ensure the safety and well-being of metaverse participants.\n\t\t- 15. Scaffolded by GenAI: The integration of GenAI (Generative AI) within the metaverse is supported through the `AIAgent` class and its associated properties, such as `hasLearningModel` and `hasTrainingData`. These properties allow for the representation of AI agents with varying levels of autonomy and adaptability, capable of generating content, providing assistance, and engaging in dynamic interactions with human users.\n\t\t- 16. Supports Agentic AI actors: The `AIAgent` class, along with its subclasses and properties, enables the creation of agentic AI actors within the metaverse. The `AgentArchetype` class defines different roles and behaviors for AI agents, while properties like `hasAgentArchetype` and `hasEmotionalState` imbue them with personality and emotional intelligence. The `participatesIn` property allows AI agents to actively engage in metaverse scenes and events alongside human users.\n\t\t- 17. Digital Asset and Ownership: The `DigitalAsset` class represents unique digital goods and assets within the metaverse. It includes properties like `genesis` (Bitcoin transaction ID where the asset was created), `issuance` leveraging [[RGB]] ), `type` (specifies the type of asset), `currentOwner` (links to the current owner agent), and `ownershipHistory` (represents the chain of ownership transfers). The `OwnershipTransfer` class represents the transfer of ownership of a `DigitalAsset` between agents, capturing details such as the `from` agent (transferring ownership), `to` agent (receiving ownership), `timestamp`, and `transactionId` (associated Bitcoin/Lightning Network transaction ID).\n\t\t- 18. [[Bitcoin]] and [[Lightning and Similar L2]] Network Integration: The `MetaverseAgent` class includes properties like `bitcoinWallet` (Bitcoin address associated with the agent) and `lightningNode` (public key of the agent's Lightning Network node) to enable Bitcoin and Lightning Network integration. The `VirtualEconomy` class includes properties like `bitcoinNetwork` and `lightningNetwork` to represent the underlying Bitcoin and Lightning Network infrastructure on which the economy operates. Fiat money can run on [[Cashu]].\n\t\t- 19. Nostr Integration: The `NostrEvent` class represents an event published on the Nostr network, with properties like `relayUrl` (URL of the Nostr relay where the event was published), `kind` (type or category of the event), `content` (content of the message or event data), and `tags` (list of associated `NostrTag` instances). The `NostrTag` class represents a tag associated with a `NostrEvent`, providing context and metadata through properties like `type` (type of tag) and `value` (value of the tag).\n\t\t- 20. PKI and Wallets: The `MetaverseEntity` class includes properties like `publicKey` and `privateKey` to support public key infrastructure (PKI) for entity identification and authentication. The `MetaverseAgent` class includes a `wallet` property that links to a `schema:DigitalWallet` instance, representing the agent's digital wallet for managing various assets.\n\t\t- 21. All objects and agents and artifacts are nostr PKI pairs. BIP32 is used to derive the path m/44'/1237'/ (according to the [Nostr entry](https://nostr-nips.com/nip-06) on SLIP44). In this way all objects are globally and hierarchically referenceable.\n\t- ## Some software choices\n\t\t- It is possible at this stage to put more flesh on the bones through example software stack choices. Such specificity likely introduces overlaps, technical challenges, and contradictions, but has been generated in the main by GenAI based on the wider corpus of text and demonstrates the direction of travel well.\n\t\t\t- ### Nostr Integration\n\t\t\t\t- **NostrEvent:**\n\t\t\t\t\t- **Properties:**\n\t\t\t\t\t\t- `relayUrl`: (`xsd:anyURI`) The URL of the Nostr relay where the event was published.\n\t\t\t\t\t\t- `kind`: (`xsd:string`) The type or category of the event (e.g., \"set_metadata\", \"text_note\", \"reaction\", \"channel_creation\", \"key_rotation\").\n\t\t\t\t\t\t- `content`: (`xsd:string`) The content of the message or event data.\n\t\t\t\t\t\t- `tags`: (`linkedjson:ObjectProperty`, `range`: `metaverse:NostrTag`) A list of tags associated with the event.\n\t\t\t\t- **NostrTag:**\n\t\t\t\t\t- `@type`: `linkedjson:Class`\n\t\t\t\t\t- `rdfs:label`: \"Nostr Tag\"\n\t\t\t\t\t- `rdfs:comment`: \"Represents a tag associated with a NostrEvent, providing context and metadata.\"\n\t\t\t\t\t- **Properties:**\n\t\t\t\t\t\t- `type`: (`xsd:string`) The type of tag (e.g., \"p\", \"e\", \"t\").\n\t\t\t\t\t\t- `value`: (`xsd:string`) The value of the tag.\n\t\t\t- ### Digital Asset and Ownership\n\t\t\t\t- #### RGB\n\t\t\t\t\t- Using the [RGB protocol](https://docs.rgb.info/) for the instantiation and transfer of objects in your metaverse ontology offers a decentralized, scalable, and flexible mechanism compared to the Nostr protocol. Here's how objects might be managed under [[RGB]] without needing frequent chain commits:\n\t\t\t\t\t\t- ### Instantiation of Objects\n\t\t\t\t\t\t\t- **Object Creation**:\n\t\t\t\t\t\t\t\t- Each digital object or asset is instantiated as an `RGBAsset` class instance within the metaverse. This includes assigning a unique `ContractId` and `SchemaId` which are crucial for defining the asset's properties and the rules governing its behavior according to the RGB protocol.\n\t\t\t\t\t\t\t\t- An initial state of the asset is defined using `Assignments` to bind certain rights or properties to the asset, such as ownership or usage rights. This state is embedded within the asset's genesis transaction but doesn't require immediate blockchain commitment.\n\t\t\t\t\t\t\t- **Asset Registration**:\n\t\t\t\t\t\t\t\t- Upon creation, the asset's initial state is recorded in a genesis block of the RGB schema. However, instead of committing this to the blockchain directly, the state can be stored off-chain (e.g., in a secure distributed file system or a database) to enhance privacy and reduce transaction costs.\n\t\t\t\t\t\t- ### Transfer of Objects\n\t\t\t\t\t\t\t- **Defining Transfer Operations**:\n\t\t\t\t\t\t\t\t- Transfers of assets are managed through `RGBContractOperation`, which includes `Inputs` (references to previous states), `Outputs` (new states or changes), and possibly `Redeems` (specific rights being exercised).\n\t\t\t\t\t\t\t\t- The transfer operation details how the asset's ownership or other properties change, using `Seal Definitions` to lock and unlock access to the asset.\n\t\t\t\t\t\t\t- **Executing Transfers**:\n\t\t\t\t\t\t\t\t- To execute a transfer, the new state created by the transfer operation is prepared, detailing how rights and responsibilities are reassigned from one party to another. This often involves updating the `Owned State` to reflect new ownership.\n\t\t\t\t\t\t\t\t- Instead of committing each transaction to the blockchain, the RGB protocol allows for state transitions to be confirmed off-chain until a significant event requires blockchain validation. This approach saves on transaction fees and minimizes public ledger exposure.\n\t\t\t\t\t\t\t- **State Commitments**:\n\t\t\t\t\t\t\t\t- When necessary, state transitions can be committed to the blockchain using minimal data footprints. This is done by embedding a cryptographic commitment to the state within a standard Bitcoin transaction, leveraging RGB's ability to bind state to Bitcoin UTXOs through client-side validation.\n\t\t\t\t\t- ### Benefits of Using RGB over Nostr for Object Management\n\t\t\t\t\t\t- **Enhanced Security**: RGB's use of cryptographic commitments and client-side validation offers robust security without exposing detailed state information on the blockchain.\n\t\t\t\t\t\t- **Scalability**: By reducing the frequency of on-chain transactions and handling most operations off-chain, RGB can scale more efficiently, handling a higher volume of asset transfers with lower costs.\n\t\t\t\t\t\t- **Flexibility**: RGB allows for complex state definitions and transitions, supporting a wide range of digital assets and operations within the metaverse, from simple transfers to intricate interactions involving multiple parties and rights.\n\t\t\t\t- #### Currently in the Ontology\n\t\t\t\t\t- **DigitalAsset:**\n\t\t\t\t\t\t- **Properties:**\n\t\t\t\t\t\t\t- `genesis`: (`xsd:string`) The Bitcoin transaction ID where the asset was created.\n\t\t\t\t\t\t\t- `issuance`: (`linkedjson:ObjectProperty`, `range`: `metaverse:RGBschema`) Links to the specific RGB schema used for the asset's issuance.\n\t\t\t\t\t\t\t- `type`: (`xsd:string`) Specifies the type of asset (e.g., \"collectible\", \"virtual_item\", \"tokenized_right\").\n\t\t\t\t\t\t\t- `currentOwner`: (`linkedjson:ObjectProperty`, `range`: `metaverse:MetaverseAgent`) Links to the agent who currently owns the asset.\n\t\t\t\t\t\t\t- `ownershipHistory`: (`linkedjson:ObjectProperty`, `range`: `metaverse:OwnershipTransfer`) Represents the chain of ownership transfers for the asset.\n\t\t\t\t\t- **OwnershipTransfer:**\n\t\t\t\t\t\t- **Properties:**\n\t\t\t\t\t\t\t- `from`: (`linkedjson:ObjectProperty`, `range`: `metaverse:MetaverseAgent`) The agent transferring ownership.\n\t\t\t\t\t\t\t- `to`: (`linkedjson:ObjectProperty`, `range`: `metaverse:MetaverseAgent`) The agent receiving ownership.\n\t\t\t\t\t\t\t- `timestamp`: (`xsd:dateTime`) The date and time of the transfer.\n\t\t\t\t\t\t\t- `transactionId`: (`xsd:string`) The Bitcoin/Lightning Network transaction ID associated with the transfer.\n\t\t\t\t\t\t- Linked-JSON representation:\n\t\t\t\t\t\t  ```text\n\t\t\t\t\t\t  {\n\t\t\t\t\t\t    \"@id\": \"https://www.narrativegoldmine.com/metaverse#OwnershipTransfer\",\n\t\t\t\t\t\t    \"@type\": \"Class\",\n\t\t\t\t\t\t    \"label\": \"Ownership Transfer\",\n\t\t\t\t\t\t    \"comment\": \"Represents the transfer of ownership of a DigitalAsset between agents.\",\n\t\t\t\t\t\t    \"properties\": {\n\t\t\t\t\t\t      \"from\": {\n\t\t\t\t\t\t        \"@id\": \"https://www.narrativegoldmine.com/metaverse#from\",\n\t\t\t\t\t\t        \"@type\": \"Property\",\n\t\t\t\t\t\t        \"range\": \"https://www.narrativegoldmine.com/metaverse#MetaverseAgent\",\n\t\t\t\t\t\t        \"comment\": \"The agent transferring ownership.\"\n\t\t\t\t\t\t      },\n\t\t\t\t\t\t      \"to\": {\n\t\t\t\t\t\t        \"@id\": \"https://www.narrativegoldmine.com/metaverse#to\",\n\t\t\t\t\t\t        \"@type\": \"Property\",\n\t\t\t\t\t\t        \"range\": \"https://www.narrativegoldmine.com/metaverse#MetaverseAgent\",\n\t\t\t\t\t\t        \"comment\": \"The agent receiving ownership.\"\n\t\t\t\t\t\t      },\n\t\t\t\t\t\t      \"timestamp\": {\n\t\t\t\t\t\t        \"@id\": \"https://www.narrativegoldmine.com/metaverse#timestamp\",\n\t\t\t\t\t\t        \"@type\": \"Property\",\n\t\t\t\t\t\t        \"range\": \"http://www.w3.org/2001/XMLSchema#dateTime\",\n\t\t\t\t\t\t        \"comment\": \"The date and time of the transfer.\"\n\t\t\t\t\t\t      },\n\t\t\t\t\t\t      \"transactionId\": {\n\t\t\t\t\t\t        \"@id\": \"https://www.narrativegoldmine.com/metaverse#transactionId\",\n\t\t\t\t\t\t        \"@type\": \"Property\",\n\t\t\t\t\t\t        \"range\": \"http://www.w3.org/2001/XMLSchema#string\",\n\t\t\t\t\t\t        \"comment\": \"The Bitcoin/Lightning Network transaction ID associated with the transfer.\"\n\t\t\t\t\t\t      }\n\t\t\t\t\t\t    }\n\t\t\t\t\t\t  }\n\t\t\t\t\t\t  ```\n\t\t\t- **PKI and Wallets:**\n\t\t\t\t- **MetaverseEntity:**\n\t\t\t\t\t- **Properties:**\n\t\t\t\t\t\t- `publicKey`: (`xsd:string`) The public key associated with the entity.\n\t\t\t\t\t\t- `privateKey`: (`xsd:string`) The private key associated with the entity (optional, depending on security considerations).\n\t\t\t\t- **MetaverseAgent:**\n\t\t\t\t\t- **Properties:**\n\t\t\t\t\t\t- `wallet`: (`linkedjson:ObjectProperty`, `range`: `schema:DigitalWallet`) Represents the agent's digital wallet for managing various assets.\n\t\t\t- **Bitcoin and Lightning Network Integration:**\n\t\t\t\t- **MetaverseAgent:**\n\t\t\t\t\t- **Properties:**\n\t\t\t\t\t\t- `bitcoinWallet`: (`xsd:string`) The Bitcoin address associated with the agent.\n\t\t\t\t\t\t- `lightningNode`: (`xsd:string`) The public key of the agent's Lightning Network node.\n\t\t\t\t- **VirtualEconomy:**\n\t\t\t\t\t- **Properties:**\n\t\t\t\t\t\t- `bitcoinNetwork`: (`linkedjson:ObjectProperty`, `range`: `schema:ComputerNetwork`) Represents the Bitcoin network on which the economy operates.\n\t\t\t\t\t\t- `lightningNetwork`: (`linkedjson:ObjectProperty`, `range`: `schema:ComputerNetwork`) Represents the Lightning Network facilitating faster and cheaper transactions.\n\t\t\t\t- **Cashu Integration**:\n\t\t\t\t\t- **Properties**:\n\t\t\t\t\t\t- `cashuWallet`: (`linkedjson:ObjectProperty`, `range`: `schema:DigitalWallet`) Represents the Cashu wallet associated with the metaverse agent. This wallet manages the agent's Chamium eCash balance.\n\t\t\t\t\t\t- `cashuNode`: (`xsd:string`) The identifier for the Cashu federation node that the agent's wallet is associated with, facilitating eCash transactions.\n\t\t\t\t\t- **Cashu Economy**:\n\t\t\t\t\t\t- **Properties**:\n\t\t\t\t\t\t\t- `chamiumEconomy`: (`linkedjson:ObjectProperty`, `range`: `schema:EconomicSystem`) Represents the part of the virtual economy that operates using Chamium eCash, allowing for private and instant transactions.\n\t\t\t\t\t\t\t- `ecashTransactions`: (`linkedjson:ObjectProperty`, `range`: `schema:ItemList`) List of transactions executed using Chamium eCash, supporting privacy and micro-transactions within the metaverse.\n\t\t\t\t\t- **Transaction Privacy**:\n\t\t\t\t\t\t- **Properties**:\n\t\t\t\t\t\t\t- `privacyLevel`: (`xsd:string`) Defines the level of privacy for transactions conducted by the agent, with options including Bitcoin, Lightning, or Cashu Chamium eCash, each offering different degrees of privacy and speed.\n\t\t\t\t\t- **Cashu Services**:\n\t\t\t\t\t\t- **Classes**:\n\t\t\t\t\t\t\t- `CashuService`: Represents services within the metaverse that specifically use or provide Cashu Chamium eCash functionalities, such as eCash exchanges, payment processing, or private transactions.\n\t\t\t\t\t\t\t\t- **Properties**:\n\t\t\t\t\t\t\t\t\t- `serviceType`: (`xsd:string`) The type of service offered, such as eCash exchange, payment gateway, or privacy service.\n\t\t\t\t\t\t\t\t\t- `accessEndpoint`: (`xsd:anyURI`) The URL or identifier where the service can be accessed within the metaverse.\n\t\t\t- **NVIDIA Omniverse:**\n\t\t\t\t- **MetaverseScene:**\n\t\t\t\t\t- **Properties:**\n\t\t\t\t\t\t- `omniverseNucleusUrl`: (`xsd:anyURI`) The URL of the Omniverse Nucleus server hosting the scene.\n\t\t\t\t\t\t- `usdFile`: (`xsd:anyURI`) The URL or reference to the USD file defining the scene's content.\n\t\t\t\t- **USD Variance:** Define properties or subclasses within `SceneObject` to represent USD variations and the conditions under which they are activated.\n\t\t\t\t- **Scene Schema Scaffolding:** Exploring Linked-JSON structures to emulate the more expressive OWL `owl:oneOf` and `owl:someValuesFrom`.\n\t\t\t\t\t- Linked-JSON representation for `SceneType`:\n\t\t\t\t\t  ```text\n\t\t\t\t\t  {\n\t\t\t\t\t    \"@id\": \"metaverse:SceneType\",\n\t\t\t\t\t    \"@type\": \"linkedjson:Class\",\n\t\t\t\t\t    \"rdfs:label\": \"Scene Type\",\n\t\t\t\t\t    \"rdfs:comment\": \"Represents different types of scenes in the metaverse.\",\n\t\t\t\t\t    \"metaverse:sceneTypeEnum\": [\n\t\t\t\t\t      {\n\t\t\t\t\t        \"@id\": \"metaverse:InteriorScene\"\n\t\t\t\t\t      },\n\t\t\t\t\t      {\n\t\t\t\t\t        \"@id\": \"metaverse:ExteriorScene\"\n\t\t\t\t\t      },\n\t\t\t\t\t      {\n\t\t\t\t\t        \"@id\": \"metaverse:MixedRealityScene\"\n\t\t\t\t\t      }\n\t\t\t\t\t    ]\n\t\t\t\t\t  }\n\t\t\t\t\t  ```\n\t\t\t\t\t- Linked-JSON representation for `MetaverseScene`:\n\t\t\t\t\t  ```text\n\t\t\t\t\t  {\n\t\t\t\t\t    \"@id\": \"metaverse:MetaverseScene\",\n\t\t\t\t\t    \"@type\": \"linkedjson:Class\",\n\t\t\t\t\t    \"rdfs:label\": \"Metaverse Scene\",\n\t\t\t\t\t    \"rdfs:comment\": \"Represents a specific environment or space within the metaverse.\",\n\t\t\t\t\t    \"metaverse:hasSceneObject\": {\n\t\t\t\t\t      \"@type\": \"linkedjson:ObjectProperty\",\n\t\t\t\t\t      \"rdfs:range\": \"metaverse:SceneObject\",\n\t\t\t\t\t      \"metaverse:minCardinality\": 1\n\t\t\t\t\t    }\n\t\t\t\t\t  }\n\t\t\t\t\t  ```\n\t\t\t\t\t\t- In this example, the custom property `metaverse:minCardinality` is used to indicate that a `MetaverseScene` must have at least one `SceneObject`.\n\t\t\t- ## TODO\n\t\t\t\t- **AI Agent Capabilities:** Expand the capabilities property of `AIAgent` to include specific actions and functions related to Bitcoin, RGB, and Nostr, such as \"create_digital_asset\", \"transfer_ownership\", \"publish_nostr_event\", etc.\n\t\t\t\t- **Event Logging and Attestation:** Consider adding mechanisms for logging significant events and generating cryptographic attestations, which could be used for dispute resolution or auditing purposes. This would operate on an automated threshold trigger system mediated by LLM, and would wrap the recent interactions between parties in pubkey encrypted data blobs, sending them to both parties alongside a report of the trigger event. This would potentially allow action by the parties in their jurisdictions. The data would then be deleted from the metaverse.\n\t- ### Visualising\n\t\t- http://owlgred.lumii.lv/online_visualization/4qge#\n\t\t- [[Some legacy Linked-JSON]]\n- This more specific and expanded metaverse ontology featuring a relay based communication protocol, URIs, blockchain wallets, and NVIDIA omniverse, offers a comprehensive and extensible framework generated with the help of GenAI. It offers a glimpse of the potential for automating ontological descriptions for emergent and novel social, digital, collaborative spaces.\n- By incorporating a wide range of classes, properties, and relationships, the ontology starts to enable formalisation of:\n\t- Agents: Human users and AI entities, their attributes, skills, and relationships.\n\t- Scenes and Objects: Virtual environments, their characteristics, and interactive elements.\n\t- Digital Assets and Economy: Creation, ownership, and exchange of virtual goods and currencies.\n\t- Events and Interactions: Social gatherings, communication, and collaborative activities.\n\t- Governance and Policies: Decision-making processes, rules, and regulations within the metaverse.\n\t- Infrastructure and Technology: Hardware, software, and networking components enabling the metaverse.\n\t-\n-\n-\n- # Mycelium Experiment\n\t- This idea is developed further here:\n\t\t- [[Agentic Mycelia]]\n\t\t- This is an [[Ontology conversation with AIs]]",
        "link_types": [
            "Anthropic Claude",
            "Gemini",
            "ChatGPT",
            "Logseq",
            "Knowledge Graphing",
            "Large language models",
            "RGB",
            "Bitcoin",
            "Lightning and Similar L2",
            "Cashu",
            "RGB",
            "Some legacy Linked-JSON",
            "Agentic Mycelia",
            "Ontology conversation with AIs"
        ],
        "file_size": 36820
    },
    {
        "id": "Microsoft CoPilot.md",
        "name": "Microsoft CoPilot",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- Bill gates has been very bullish on AI since 2017.\n- In 2019, Microsoft became \"very, very worried\" about Google's capabilities in artificial intelligence, newly unearthed emails show, and that may have been what spurred it to invest in OpenAI.\n\t- ```text\n\t  From: Kevin Scott\n\t  Sent: Wednesday, June 12, 2019 7:16:11 AM\n\t  To: Satya Nadella; Bill Gates\n\t  Subject: Re: Thoughts on OpenAI\n\t  [Redacted]\n\t  The thing that's interesting about what Open AI and Deep Mind and Google Brain are doing is the scale of their ambition, and how that ambition is driving everything from datacenter design to compute silicon to networks and distributed systems architectures to numerical optimizers, compiler, programming frameworks, and the high level abstractions that model developers have at their disposal. When all these programs were doing was competing with one another to see which RL system could achieve the most impressive game-playing stunt, I has highly dismissive of their efforts. That was a mistake. When they took all of the infrastructure that they had built to build NLP models that we couldn't easily replicate, I started to take things more seriously. And as I dug in to try to understand where all of the capability gaps were between Google and us for model training, I got very, very worried.\n\t  Turns out, just replicating BERT-large wasn't easy to do for us. Even though we had the template for the model, it took us ~6 months to get the model trained because our infrastructure wasn't up to the task. Google had BERT for at least six months prior to that, so in the time that it took us to hack together the capability to train a 340M parameter model, they had a year to figure out how to get it into production and to move on to larger scale, more interesting models. We are already seeing the results of that work in our competitive analysis of their products. One of the Q&A competitive metrics that we watch just jumped by 10 percentage points on Google Search because of BERT-like models. Their auto-complete in Gmail, which is especially useful in the mobile app, is getting scarily good.\n\t  [Redacted]\n\t  We have very smart ML people in Bind, in the vision team, and in the speech team. But the core deep learning teams within each of these bigger teams are very small, and their ambitions have also been constrained, which means that even as we start to feed them resources, they still have to go through a learning process to scale up. And we are multiple years behind the competition in terms of ML scale.\n\t  [Redacted]\n\t  ```\n- ```text\n  From: Satya Nadella\n  To: Kevin Scott\n  CC: Amy Hood\n  Sent: 6/12/2019 6:02:47 PM\n  Subject: Re: Thoughts on OpenAI\n  Very good email that explains, why I want us to do this… and also why we will then ensure our infra folks execute.\n  ```\n- They now have AI threaded through everything from github, to search, and Office.\n- ![Screenshot 2024-05-08 134100.png](../assets/Screenshot_2024-05-08_134100_1715172122220_0.png){:width 800}\n- {{video https://www.youtube.com/watch?v=SaCVSUbYpVc}}\n- ## GitHub CoPilot\n\t- They are billing this as the most radical uplift to Windows ever.\n\t- <iframe src=\"https://blogs.microsoft.com/blog/2024/05/20/introducing-copilot-pcs/\" style=\"width: 100%; height: 600px\"></iframe>\n\t- Features for workspaces [GitHub Copilot just got exponentially smarter YouTube](https://www.youtube.com/watch?v=SZVCJRUADc4)\n\t- [[Microsoft CoPilot]] integration into Office365, first looks [First look at Microsoft 365 Copilot | Paul's Down-Home Page (paulrobichaux.com)](https://paulrobichaux.com/2023/12/14/first-look-at-microsoft-365-copilot/)\n- ## Bing CoPilot\n\t- Now integrated  partially, globally, with Code Interpreter so it can execute code. https://www.linkedin.com/posts/emollick_finally-more-gpt-4-abilities-are-coming-activity-7148155477418278912-Ffdz?\n\t- [Microsoft’s new Copilot Pro brings AI-powered Office features to consumers The Verge](https://www.theverge.com/2024/1/15/24038711/microsoft-copilot-pro-office-ai-apps)\n\t- ![r/ChatGPT - Is this as good as the standalone ChatGPT 4 for educational purposes?](https://i.redd.it/lgjjtl5j72xc1.jpeg)\n-\n- ## Office365 Co-Pilot\n- # ChatGPT relationship\n\t- [OpenAI Is Doomed - Et tu, Microsoft? (semianalysis.com)](https://www.semianalysis.com/p/openai-is-doomed-et-tu-microsoft)\n- ### Sydney\n\t- [Microsoft has been secretly testing its Bing chatbot ‘Sydney’ for years The Verge](https://www.theverge.com/2023/2/23/23609942/microsoft-bing-sydney-chatbot-history-ai)\n\t-",
        "link_types": [
            "Microsoft CoPilot"
        ],
        "file_size": 4569
    },
    {
        "id": "Courses and Training.md",
        "name": "Courses and Training",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- Generative AI Resources:\n\t- [Generative AI course](https://www.cloudskillsboost.google/course_templates/536): A course that provides an introduction to generative AI and explores its applications.\n\t- [Little book of deep learning](https://fleuret.org/public/lbdl.pdf): A book that covers the basics of deep learning.\n\t- [Machine vision youtube series](https://www.youtube.com/playlist?list=PLd3hlSJsX_In7qup928HaHmilugBGctuF): A series of YouTube videos that focus on machine vision.\n\t- [Almost any machine learning free book](https://github.com/abhishekkrthakur/approachingalmost): A collection of machine learning books available for free.\n\t- [Introduction to Generative AI | Google Cloud Skills Boost](https://www.cloudskillsboost.google/course_templates/536): An introductory course on generative AI provided by Google Cloud Skills Boost.\n\t- [CS50's Introduction to Artificial Intelligence with Python | Harvard University](https://pll.harvard.edu/course/cs50s-introduction-artificial-intelligence-python/2023-05): A course offered by Harvard University that covers the fundamentals of artificial intelligence using Python.\n\t- [Generative AI is a tool in service of humanity (linkedin.com)](https://www.linkedin.com/learning/what-is-generative-ai/generative-ai-is-a-tool-in-service-of-humanity): A LinkedIn Learning course that explores the ethical implications of generative AI.\n\t- [Generative AI for Everyone\n\t - DeepLearning.AI](https://www.deeplearning.ai/courses/generative-ai-for-everyone/): A course that provides a comprehensive introduction to generative AI.\n\t- [Generative AI with Large Language Models | Coursera](https://www.coursera.org/learn/generative-ai-with-llms): A Coursera course that focuses on generative AI using large language models.\n- Statistics Resources:\n\t- [Statistics course](https://www.youtube.com/watch?v=KbB0FjPg0mw&list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo&index=1): A YouTube playlist that covers various topics in statistics.\n- AI and Deep Learning Resources:\n\t- [EdX AI course](https://learning.edx.org/course/course-v1:HarvardX+CS50AI+1T2020/home): A course offered by Harvard University that provides an introduction to AI.\n\t- [Python Books](https://mksaad.wordpress.com/2019/04/03/open-source-python-programming-books-licensed-under-creative-commons/): A collection of open-source Python programming books.\n\t- [Automate the boring stuff](https://automatetheboringstuff.com/): A book that teaches how to automate tasks using Python.\n\t- [ChatGPT Prompt Engineering for Developers\n\t - DeepLearning.AI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/): A short course focused on prompt engineering for developers.\n\t- [Introduction to Responsible AI | Google Cloud Skills Boost](https://www.cloudskillsboost.google/course_templates/554): A course that explores the ethical considerations in AI development.\n\t- [Data Science: Machine Learning | Harvard University](https://pll.harvard.edu/course/data-science-machine-learning): A course offered by Harvard University that covers machine learning concepts.\n\t- [LangChain for LLM Application Development\n\t - DeepLearning.AI](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/): A short course that focuses on language chain for LLM application development.\n- Miscellaneous Resources:\n\t- RGB programming with Maxim course [Plan B Network](https://planb.network/courses/rgb)\n\t- [Pitching](https://fi.co/insight/how-to-master-the-startup-pitch-watch-these-founder-showcase-winning-pitch-videos): A resource that provides insights on mastering startup pitches.\n\t- [Age of BANI from Jamais Cascio](https://ageofbani.com/): A website that explores the concept of BANI (Braided, Asynchronous, Networked, and Indigenous) for understanding the future.\n\t- [Furkan SD tutorials](https://github.com/FurkanGozukara/Stable-Diffusion/tree/main/Tutorials): Tutorials by Furkan Gozukara focusing on Stable Diffusion.\n\t- touchdesigner community: A community dedicated to TouchDesigner, a visual development platform.\n\t- [Torin Blankensmith](https://www.torinblankensmith.com/): Website of Torin Blankensmith, a creative technologist.\n\t- [Torin Blankensmith YouTube](https://www.youtube.com/c/torinblankensmith): YouTube channel of Torin Blankensmith, featuring various creative and tech-related content.\n\t- [Latent space](https://huggingface.co/learn/nlp-course/chapter0/1?fw=pt): An educational resource that explains the concept of [[latent space]] in natural language processing.\n\t- [Embeddings explainer (MUST READ)](https://simonwillison.net/2023/Oct/23/embeddings/): An article explaining the concept of embeddings in machine learning.\n\t- [Ebooks and stuff](https://z-lib.io/): A website where you can find and download ebooks.\n\t- [AWS Skill Builder](https://explore.skillbuilder.aws/learn/course/external/view/elearning/17763/foundations-of-prompt-engineering): A course provided by AWS that focuses on the foundations of prompt engineering.\n\t- [Put your fingers to work: Chatting as a productivity tool (linkedin.com)](https://www.linkedin.com/learning/streamlining-your-work-with-microsoft-bing-chat/put-your-fingers-to-work-chatting-as-a-productivity-tool): A LinkedIn Learning course on using chat as a productivity tool.\n\t- [Microsoft Azure AI Fundamentals: Generative AI\n\t - Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/paths/introduction-generative-ai/): A training course on generative AI provided by Microsoft Learn.\n\t- [AWS Skill Builder](https://explore.skillbuilder.aws/learn/public/learning_plan/view/1909/generative-ai-learning-plan-for-decision-makers): A learning plan provided by AWS that focuses on generative AI for decision-makers.\n\t- [Learn Prompting | Generative AI, Prompt Engineering, & Free Online Courses](https://learnprompting.org/): A website dedicated to learning about prompt engineering and generative AI.\n-",
        "link_types": [
            "latent space"
        ],
        "file_size": 5970
    },
    {
        "id": "Layoff tracker and threatened roles.md",
        "name": "Layoff tracker and threatened roles",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # Most threatened roles\n\t- UK dept of education [10-30% can be automated away.](https://assets.publishing.service.gov.uk/media/656856b8cc1ec500138eef49/Gov.UK_Impact_of_AI_on_UK_Jobs_and_Training.pdf#:~:text=It%20has%20been%20estimated%20that%2010-30%25%20of%20jobs,the%20potential%20benefits%20advances%20in%20AI%20will%20bring.)\n\t- id:: 659a9231-eed0-4503-b1c7-ec6fdc4a3ae4 | #  | Exposure to all AI applications | Exposure to large language modelling | |----|--------------------------------|--------------------------------------| | 1  | Management consultants and business analysts* | Telephone salespersons | | 2  | Financial managers and directors | Solicitors* | | 3  | Charted and certified accountants | Psychologists* | | 4  | Psychologists* | Further education teaching professionals | | 5  | Purchasing managers and directors | Market and street traders and assistants | | 6  | Actuaries, economists and statisticians | Legal professionals n.e.c.* | | 7  | Business and financial project management professionals | Credit controllers* | | 8  | Finance and investment analysts and advisers | Human resource administration occupations* | | 9  | Legal professionals n.e.c.* | Public relations professionals | | 10 | Business and related associate professionals n.e.c. | Management consultant and business analysts* | | 11 | Credit controllers* | Market research interviewers | | 12 | Solicitors* | Local government administrative occupations | | 13 | Civil engineers | Clergy | | 14 | Education advisers and school inspectors* | Higher education teaching professionals | | 15 | Human resources administrative occupations* | Collector salespersons and credit agents | | 16 | Business, research and administrative professionals n.e.c. | Education advisers and school inspectors* | | 17 | Financial accounts managers | Human resource managers and directors | | 18 | Bookkeepers, payroll managers and wages clerks | National government administrative occupations* | | 19 | National government administrative occupations* | Vocational and industrial trainers and instructors | | 20 | Marketing associate professionals | Social and humanities scientists |\n- # Mass Layoff tracker\n\t- 2023\n\t\t- Recent layoffs at [Microsoft](https://www.theverge.com/2023/1/18/23560315/microsoft-job-cuts-layoffs-2023-tech) (10,000 jobs or 5 percent of the workforce),\n\t\t- [Amazon](https://www.theverge.com/2023/1/18/23560874/amazon-layoffs-18000-january-november) (18,000 jobs / 6 percent)\n\t\t- [Meta](https://www.theverge.com/2022/11/9/23448926/meta-layoffs-2022) (11,000 / 13 percent).\n\t\t- [Google lays off hundreds working on its voice-activated assistant | Semafor](https://www.semafor.com/article/01/10/2024/google-lays-off-hundreds-working-on-its-voice-activated-assistant)\n\t\t- [Duolingo's AI-driven jobs cuts are a no brainer – here's why | ITPro](https://www.itpro.com/technology/artificial-intelligence/duolingos-ai-driven-jobs-cuts-are-a-no-brainer-heres-why)\n\t- 2024 so far\n\t\t- PayPal cuts 9% of workforce\n\t\t- UPS cuts +12,000 roles\n\t\t- Microsoft cuts +1,900 roles\n\t\t- Twitch cuts 35% of workforce\n\t\t- Unity Software 25%\n\t\t- Brex 20%\n\t\t- Discord 17%\n\t\t- Wayfair 13%\n\t\t- Riot Games 11%\n\t\t- Duolingo 10%\n\t\t- Rent the Runway 10%\n\t\t- eBay 9%\n\t\t- Blackrock 3%\n\t\t- Citigroug cuts 20,000 roles\n\t\t- Google cuts +1,000\n\t\t- Amazon cuts several hundred roles",
        "link_types": [],
        "file_size": 3408
    },
    {
        "id": "Norbert Wiener.md",
        "name": "Norbert Wiener",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- Norbert Wiener was a founding figure in cybernetics, coining the term.\n- He was prophetic about the rise of AI 70 years ago!\n- <iframe src=\"https://monoskop.org/images/9/90/Wiener_Norbert_The_Human_Use_of_Human_Beings_1950.pdf\" style=\"width: 100%; height: 600px\"></iframe>\n- ## The Human Use of Human Beings\n\t- **Information and Entropy**: Wiener's work often intersected with the concept of entropy, a term borrowed from thermodynamics. He drew parallels between the physical world's entropy and information theory. In his view, the acquisition and use of information could counteract the natural tendency towards disorder (entropy) in systems, a concept that has implications in understanding everything from biological evolution to the functioning of economies.\n\t- **Automation and Employment**: One of the book's more prescient concerns was the impact of automation on employment. Wiener foresaw the displacement of workers due to the rise of machines capable of performing tasks previously done by humans. He raised concerns about societal and economic implications, highlighting the need for ethical considerations and new forms of employment in a technologically advanced future.\n\t- **Ethics in Technological Advancement**: Wiener was deeply concerned about the ethical implications of technological advancements. He believed that while technology could significantly improve human life, it also had the potential to be misused. This is evident in his cautionary notes about the use of automated systems in warfare and his concerns about the loss of human autonomy.\n\t- **The Impact on Society and Human Behavior**: Wiener's insights extended to the broader impacts of technology on society and human behavior. He explored how the use of technology in communication could alter social interactions and even human thought processes. His predictions about computers tracking and influencing human behavior are startlingly relevant in today's world of big data and personalized advertising.\n\t- **Limitations of Machine Intelligence**: Interestingly, Wiener also discussed the limitations of machine intelligence. He argued that while machines could replicate certain human cognitive functions, they lacked the genuine understanding and consciousness of humans. This perspective adds to the current discourse on the capabilities and limitations of artificial intelligence.",
        "link_types": [],
        "file_size": 2434
    },
    {
        "id": "BTC Layer 3.md",
        "name": "BTC Layer 3",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- Increasingly important features of modern blockchain implementations areprogrammability through smart contracts, and issuance of arbitrarytokens. Assigning a transaction to represent another thing like aneconomic unit, energy unit, or real world object, and operating on thoseabstractions within the chain logic. Chief among these use cases arestablecoins such as Tether, which are pegged to national currencies anddescribed in the next section. Bitcoin has always supported very limitedcontracts called scripts, and stablecoin issuance has existed in Bitcoinsince [Omni Layer](https://www.omnilayer.org/). Omni was the firstissuer of Tether, but more recently these important features have passedto other layer one chains. This year is likely to see the [resurgence ofthiscapability](https://www.hiro.so/blog/bitcoin-ecosystem-a-guide-to-programming-languages-for-bitcoin-smart-contracts)on Bitcoin, which of course benefits from a better security model. Onceagain, there is a stong assertion by some that [this isn’t evenpossible](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2022-April/020227.html).The debate is complex and unresolved.\n- In order to properly understand the use of Bitcoin based technologies inmetaverse applications it is necessary to examine what these newer‘layer 3’ ideas might bring.\n- ## LNP/BP and RGB\n\t- [LNP/BP](https://giacomozucco.com/layers-before-bitcoin) is a non profitstandards organisation in Switzerland which contributes to open sourcedevelopment of Bitcoin layer 3 solutions into the Lightning protocol,and Bitcoin protocol (LNP/BP). One of the core product developmentswithin their work is the [‘RGB’ protocol](https://www.rgb.tech/), whichis somewhat of a meaningless name, evolved from “coloured coins” whichwere an early tokenised asset system on the Bitcoin network. RGBrepresents red, green, and blue. The proposal is built upon research by[Todd](https://petertodd.org/2016/commitments-and-single-use-seals) and[Zucco](https://giacomozucco.com/#intro). RGB is regarded as arcaneBitcoin technology, even within the already rarefied Bitcoin developercommunities. Zucco provides the [followingexplanation](https://bitcoinmagazine.com/culture/video-interview-giacomo-zucco-rgb-tokens-built-bitcoin):\n\t- it“When I want to send you a bitcoin, I will sign the transaction, Iwill give the transaction only to you, you will be the only oneverifying, and then we’ll take a commitment to this transaction and thatI will give only the commitment to miners. Miners will basically build ablockchain of commitments, but without the actual validation part. Thatwill be only left to you. And when you want to send the assets tosomebody else, you will pass your signature, plus my signature, plus theprevious signature, and so on.”\n\t- This is non-intuitive explanation of Todds ‘single-use-seals’, appliedto Bitcoin, with the purpose of underpinning arbitrary asset transfersecured by the Bitcoin network. In this model the transacting partiesare the exclusive holders of the information about what the object theyare transferring actually represents. This primitive can (and has) beenexpanded by the LNP/BP group into a concept called ‘client sidevalidation’. It’s appropriate to explain this concept several times fromdifferent perspectives, because this is potentially a profoundly usefultechnology for metaverse applications.\n\t\t- A promise is made to spend a multi output transaction in the future. This establishes the RGB relationships between the parties.\n\t\t- One of the pubkeys to be spent to is known by both parties.\n\t\t- The second output is unknown and is a combination of the hash of the state, and schema, from the operation which has been performed.\n\t\t- When the UTXO is spent the second spends pubkey can be processed against the shared data blob to validate the shared state in a two party consensus (sort this out, it’s nonsense).\n\t\t- This is now tethered to the main chain. Some tokens from the issuance have gone to the recipiant, and the remainder have gone back to the issuer. More tokens can be issued in the same way from this pool.\n\t\t- A token schema in the blob will show the agreed issuance and the history back to the genesis for the token holder.\n\t\t- The data blob contains the schema which is the key to RGB functions and the bulk of the work and innovation.\n\t\t- Each issuance must be verified on chain by the receiving party.\n\t- This leverages the single-use-seal concept to add in smart contracts,and more advanced concepts to Bitcoin. Crucially, this is notconceptually the same as the highly expressive ‘layer one’ chains whichoffer this functionality within their chain logic. In those systemsthere is a globally available shared consensus of ‘state’. In the LNP/BPtechnologies the state data is owned, controlled, and stored by thetransacting parties. Bitcoin provides the crytographic external proof ofa state change in the event of a proof being required. This is anelegant solution in that it takes up virtually no space on theblockchain, is private by design, and is extensible to layer 2 protocolslike Lightning.\n\t- This expanding ecosystem of client side verified proposals is asfollows:\n\t\t-\n\t - RGB smart contracts\n\t\t-\n\t - RGB assets are fungible tokens on Bitcoin L1 and L2, and non fungible Bitcoin L1 (and somewhat on L2).\n\t\t-\n\t - Bifrost is an [extension](https://github.com/LNP-BP/presentations/blob/master/Presentation slides/Bifrost.pdf) to the Lightning protocol, with it’s own Rust based node implementation, and backwards compatibility with other nodes in the network. This means it can transparently participate in normal Lightning routing behaviour with other peers. Crucially however it can also negotiate passing the additional data for token transfer between two or more contiguous Bifrost enabled parties. This can be considered an additional network liquidity problem on top of Lightning, and is the essence of the “Layer 3” moniker associated with LNP/BP. It will require a great number of such nodes to successfully launch token transfer on Lightning. As a byproduct of it’s more ‘protocol’ minded design decisions Bifrost can also act as a generic peer-to-peer data network, enabling features like Storm file storage and Prometheus.\n\t\t-\n\t - [AluVM](https://www.aluvm.org/) is a RISC based virtual machine (programmable strictly in assembly) which can execute Turing complete complex logic, but only outputs a boolean result which is compliant with the rest of the client side validation system. In this way a true or false can be returned into Bitcoin based logic, but be arbitrarily complex within the execution by the contract parties.\n\t\t-\n\t - Contractum is the proposed smart contract language which will compile the RGB20 contracts within AluVM (or other client side VMs) to provide accessible layer 3 smart contracts on Bitcoin. It is a very early proposal at this stage.\n\t\t-\n\t - Internet2: “Tor/noise-protocol Internet apps based on Lightning secure messaging\n\t\t-\n\t - Storm is a lightly specified escrow-based bitcoin data storage layer compliant with Lightning through Bifrost.\n\t\t-\n\t - Prometheus is a lightly specified multiparty high-load computing framework.\n\t- Really, any compute problem can be considered applicable to client sidevalidation. In simplest terms a conventional computational problem issolved, and the cryptographically verifiable proof of this action, ismade available to the stakeholders, on the Bitcoin ledger.\n\t- Less prosaically, at this stage of the project the more imminentproposed affordances of LNP/BP are described in ‘schema’ [on the projectgithub](https://github.com/LNP-BP/LNPBPs). The most interesting to thetechnically minded layperson are:\n\t-\n\t - [RGB20](https://github.com/LNP-BP/LNPBPs/blob/master/lnpbp-0020.md) fungible assets. This could be stablecoins like dollar or pounds representation. Bitfinex exchange [have code](https://github.com/RGB-Tools/rgb-lightning-sample) which already works with RGB to transmit Tether stablecoins on testnet. This is a huge application area for Bitcoin, and similar to Omni, which will also be covered next.\n\t-\n\t - [RGB21](https://github.com/LNP-BP/LNPBPs/blob/master/lnpbp-0021.md) for nonfungible tokens and ownership rights. In principle BiFrost allows these to be transferred over a the Lightning network, significantly lowering the barrier to entry for this whole technology. DIBA [have this technology working](https://diba.io/) on testnet.\n\t-\n\t - [RGB22](https://github.com/LNP-BP/LNPBPs/issues/29) may provide a route to identity proofs. This is covered in detail later.\n\t- Federico Tenga is CEO of ‘Chainside’ and an educator and consultant inthe space. He has written an up-to-date[“primer”](https://medium.com/@FedericoTenga/understanding-rgb-protocol-7dc7819d3059),which is still extremely complex for the uninitiated, but does capturehow the RGB token transfer system works. That medium article alsotouches on Taro, which is next.\n- ## DIBA and Bitcoin’s Unique Digital Assets\n\t- itDIBA is a pioneering digital asset marketplace, powered by the [RGBSmart Contract Protocol](https://www.rgb.tech/). It permits the creationand direct transaction of Unique Digital Assets (UDAs), akin toNon-Fungible Tokens (NFTs), on Bitcoin without the necessity of othertokens. UDAs are special digital assets linked to a Bitcoin UTXO(unspent transaction output). These assets embody distinctive attributeslike ownership, transferability, and divisibility, and remain under thefull control and ownership of their creators.\n\t- Through DIBA, users can explore, purchase, and sell a vast array ofUDAs, taking advantage of the robustness and permanence of the Bitcoinblockchain. DIBA’s innovation extends to the integration of a Lightninglayer 2 solution, aiming to facilitate faster and more affordabletransactions.\n\t- Assets minted via DIBA are bound to Bitcoin’s base layer with anon-chain UTXO. They are subsequently stored on the Arweave permawebalongside a cryptographic hash, which, combined with a digitalsignature, can validate their authenticity. The RGB Smart ContractProtocol executes UDA transactions via BitMask, a wallet engineered bythe DIBA Team.\n- ## BitMask\n\t- itBitMask is a browser extension wallet birthed by DIBA, intended fordecentralized applications on Bitcoin. It grants access to BitcoinFinance, UDAs, and more, utilizing the RGB protocol. It deliverscomprehensive financial autonomy with its taproot-enabled Bitcoin andLightning Network wallet, establishing it as a gateway to DeepWeb3 onBitcoin. More details can be found on Bitmask.app.\n- ## DIBA’s Launch and Marketplace Timelines\n\t- DIBA has initiated an Open Marketplace for Beta testing as of April2022, available on Bitcoin testnet. The full launch on Bitcoin mainnetis expected to occur in the second or third quarter of 2022. Submissionsfor the DIBA Curated Marketplace are currently open, allowing interestedindividuals to apply as an Artist or a Curator.\n\t- These developments represent a substantial expansion of the capabilitieswithin the Bitcoin network and further attest to the potential of theLNP/BP’s work. Notably, DIBA [has this technologyworking](https://diba.io/) on testnet. The extensive application areasfor Bitcoin, such as the transmission of Tether stablecoins on testnetby Bitfinex exchange [viaRGB](https://github.com/RGB-Tools/rgb-lightning-sample), emphasize thepotential impact of these advancements.\n- ## Taro / Taproot Assets\n\t- Taproot Assets is the new name for Lightning Labs ‘Taro’, a new[initiative](https://lightning.engineering/posts/2022-4-5-taro-launch/)to allow assets to transmit on the Lightning network. It is more similarto RGB above than Omnibolt below. [Theysay](https://docs.lightning.engineering/the-lightning-network/taproot-assets):it“Taproot Assets is a new Taproot-powered protocol for issuing assetson the bitcoin blockchain. Taproot Assets (formerly Taro) is a newTaproot-powered protocol for issuing assets on the bitcoin blockchainthat can be transferred over the Lightning Network for instant, highvolume, low fee transactions.”\n\t- The project has clearly been [underdevelopment](https://github.com/roasbeef/bips/tree/bip-taro) by the leaddeveloper at Lightning Labs for some years and seems both[capable](https://lightninglabs.substack.com/p/bitcoinizing-the-dollar-and-the-world?s=r)and mature, though they are obviously following the model of ‘co-opting’open source ideas (from RGB) to garner venture capital funding. They[creditRGB](https://github.com/bitcoin/bips/pull/1298/commits/4daba8c373c777defb48136795382803c137502c)in the github. More will doubtless be added to this section and it seemsa contender for our metaverse purposes, being less broadly ambitiousthan RGB upon which it’s based, but perhaps more focused andimplemented. The key feature of Taro seems to be that only the first andlast hop in a multi-hop lightning transaction need to support Taro,because of external data validation databases called “universes”. Thisis an advance on the RGB proposal. The technical specs are now on the[lightning labs webpages](https://docs.lightning.engineering/the-lightning-network/taro),and [code has beenreleased](https://lightning.engineering/posts/2022-9-28-taro-launch/).The beta programme uses testnet. There are concerns that large amountsof synthetic dollars on the protocol could be used to create ‘incentive’for one Bitcoin hard fork or another, under the control of Tether.\n- ## ZeroSync\n\t- The recent zerosync paper offers a tantalising glimpse of a highlycompressed, performant, and private take on Bitcoin. It potentiallyaddresses Bitcoin’s scalability challenges using advanced cryptographictechniques (SNARKs). It compresses the entire Bitcoin blockchain,enabling instant verification and various innovative applications likefaster full nodes, trustless light clients, improved privacy, and securecross-chain bridges. Additionally, zkCoins is a protocol that enhancesprivacy and throughput of arbitrary tokens, which could lead to moreprivate and scalable digital assets.\n- ## Spacechains\n\t- Spacechains is a[proposal](https://medium.com/@RubenSomsen/21-million-bitcoins-to-rule-all-sidechains-the-perpetual-one-way-peg-96cb2f8ac302)by Ruben Somsen. It is a way to provide the functionality of anyconceivable blockchain, by making it a sidechain to Bitcoin.\n\t- Like RGB described earlier it’s a single use seal, but which can beclosed by the highest bidder.\n\t- In a spacechain the Bitcoin tokens are destroyed in order to provablycreate the new spacechains tokens at a 1:1 value. These new tokens onlyhave worth moving forward within the new chain ecosystem they represent,as they cannot be changed back. They nontheless have the same securityguarantees as the bticoin main chain, though with a radically reducedecological footprint (x1000?), and higher performance. Each ‘block’ inthe new chain is a single bitcoin transaction. The high level featuresare:\n\t\t-\n\t - Outsource mining to BTC with only a single tx per block on the main chain.\n\t\t-\n\t - One way peg, Bitcoin is burnt to create spacechain tokens.\n\t\t-\n\t - Allows permissionless chain creation, without a speculative asset.\n\t\t-\n\t - Fee bidding BMM is space efficient and incentive compatible. Miners just take the highest fees as normal.\n\t\t-\n\t - Paul Sztorc raised the idea\n\t\t-\n\t - It’s best with a soft fork but possible without\n\t- The concept is [explained fully](https://vimeo.com/703246895/d89aba6e56)in a recent presentation at Advancing Bitcoin conference.\n\t- Developer Fiatjaf, has a basic Spacechains based [asset tradingsystem](https://github.com/nbd-wtf/soma) which can be run already called Soma, though it is limited to Signet, one of the local bitcoin testnets,modified with AnyPrevOut described elsewhere in the book.\n- ## Statechains, drivechain, softchains\n\t- There are many [proposals for layer 2 scalingsolutions](https://gist.github.com/RubenSomsen/96505e99dc061d6af6b757ff74434e70)for the bitcoin network. Ruben Somsen [describes Softchains,Stateschains, andSpacechains](https://gist.github.com/RubenSomsen/c9f0a92493e06b0e29acced61ca9f49a),while [Drivechain isdescribed](https://www.drivechain.info/literature/index.html) by theauthor Paul Sztorc on the project web pages and is split across[BIP-0300](https://github.com/bitcoin/bips/blob/master/bip-0300.mediawiki)for drivechain and[BIP-0301](https://github.com/bitcoin/bips/blob/master/bip-0301.mediawiki)for a “blind merge mining”, a soft fork which it’s unlikely to get. Theyare all hypothetical with the exception of sidechains.\n-",
        "link_types": [],
        "file_size": 16678
    },
    {
        "id": "Vesuvian Scrolls.md",
        "name": "Vesuvian Scrolls",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ![graphical user interface, text, website](https://media.licdn.com/dms/image/D4E22AQGt7946IYwLhg/feedshare-shrink_2048_1536/0/1713971446857?e=1717027200&v=beta&t=TKlEgf_qY6WkdHVRUozwmNi8KaWlw3-R9KP2imXEgxQ)\n- ## Summary\n\t- The VVIA Challenge, with a $1 million prize, focused on utilizing AI to decipher ancient papyrus scrolls preserved yet damaged by the eruption that destroyed Pompeii. These scrolls, potentially containing lost historical, philosophical, and literary texts, were discovered in a villa believed to belong to Julius Caesar's father-in-law in Herculaneum. The challenge was to develop AI techniques to read the text without physically unrolling the scrolls. The winning team successfully read extensive portions of the scrolls, revealing works possibly by the Epicurean philosopher Philodemus. This endeavor not only showcases the power of AI in unlocking ancient secrets but also highlights the blend of technology, history, and human curiosity.\n- ## Key Points\n\t- **VVIA Challenge Objective:** Utilize AI to interpret texts from ancient scrolls damaged in the eruption that destroyed Pompeii, without unrolling them.\n\t- **Historical Significance:** Scrolls believed to contain lost works from ancient Greece and Rome, offering insights into classical literature, philosophy, and possibly early Christian texts.\n\t- **Technical Challenges and Solutions:** The challenge involved using advanced medical imaging and AI to decipher the charred scrolls. Innovations included recognizing 'crackle' patterns as text and employing AI models to identify ink traces undetectable to the human eye.\n\t- **Winning Achievement:** The team identified 15 columns of text, suggesting a work by Philodemus on the pleasures of music and food. This success demonstrates AI's potential to reveal historical texts thought to be irretrievably lost.\n\t- **Future Implications:** Beyond the immediate findings, the challenge underscores the role of AI in historical preservation and research. It sets the stage for further discoveries within the remaining scrolls and potentially revolutionizes our understanding of ancient civilizations.\n\t- **Stage Two Goals:** Focus on automating the segmentation process to lower costs and enable the scanning of all 800 known scrolls, aiming for broader excavation and exploration of the villa's remains.\n- ### Misc\n\t- [Nat Friedman Embraces AI to Translate the Herculaneum Papyri (bloomberg.com)](https://www.bloomberg.com/features/2024-ai-unlock-ancient-world-secrets/?leadSource=uverify%20wall)\n\t- https://www.youtube.com/watch?v=8Qq2KEvE_xo\n\t- [Home Page Digital Restoration Initiative (uky.edu)](https://www2.cs.uky.edu/dri/)",
        "link_types": [],
        "file_size": 2717
    },
    {
        "id": "latent space.md",
        "name": "latent space",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- In the context of generative artificial intelligence (AI), a latent space is a high-dimensional space in which the model represents data as points. This space is \"latent\" because it is not directly observed, but is inferred by the model based on the data it is trained on. In the case of a generative model, the latent space is often used to encode the underlying structure of the data, such that samples can be generated by sampling from the latent space and then decoding them into the data space.\n- For example, in a generative model for images, the latent space may encode the features or characteristics of the image, such as the shape, color, and texture. By sampling from this latent space and decoding the sample, the model can generate new images that are similar to the training data, but are not exact copies. This allows the model to generate novel and diverse samples that capture the essence of the training data.\n- The latent space is an important aspect of generative models because it allows the model to capture the underlying structure of the data in a compact and efficient way. It also provides a way to control the generation process, such as by interpolating between latent space points to generate smooth transitions between samples. At this time the navigation through that mathematical space is steered by vectors into the space, which come from a separate and parallel integration of a natural language model. This crucial bridge came from research at OpenAI, and has been instrumental in the current explosion of usability of the systems.",
        "link_types": [],
        "file_size": 1626
    },
    {
        "id": "Soon-Next-Later (AI futurology).md",
        "name": "Soon-Next-Later (AI futurology)",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- # Soon, Next, and Later \n\t  id:: 659a9246-af6b-4582-9368-3b688130d703 collapsed:: true (exclusively optimistic take)\n\t- [twitter link to the render loading below](https://twitter.com/karpathy/status/1744179910347039080)\n\t  {{twitter https://twitter.com/karpathy/status/1744179910347039080}}\n\t- {{video https://www.youtube.com/watch?v=ob_GX50Za6c&t=65s}}\n\t- #### The SOON Phase\n\t\t- **Digital Literacy, Data Privacy, and Algorithmic Bias** (sorting the data)\n\t\t\t- Understanding AI and digital technologies for information and service access.\n\t\t\t- Ensuring privacy and mitigating biases in AI algorithms.\n\t\t\t- 2-5 years of integration with business processes.\n\t\t\t- Models start to distribute across cloud and devices to find their correct scale **fit**.\n\t- #### The NEXT Phase\n\t\t- **Biome AI, AI Ethics & Safeguarding, and Ambient Education**\n\t\t\t- Integration of AI in biological lives and everyday environments.\n\t\t\t- Developing robust ethical frameworks for AI.\n\t\t\t- Creating ambient [[Education]] environments facilitated by AI. Education is too slow and monolithic for this to happen sooner.\n\t\t\t- 5-10 years.\n\t- #### The LATER Phase\n\t\t- **Fully Autonomous [[Agents]] and AI as lifelong companions**\n\t\t\t- AI operating without human supervision in various sectors. Value globally is arbitraged by these agents in near real-time. A renaissance of the idea of smart efficient markets?\n\t\t\t- Global access to hyperlocal models which match context and personal choices, through personal devices which need not be cloud connected.\n\t\t\t- AI understanding human emotions for psychological, contextual, and business support.\n\t\t\t- No idea... I have no idea...\n\t- ## Human flourishing and expression\n\t\t- **Celebrating Human Diversity: Now to Later**\n\t\t\t- AI understanding and adapting to human experiences and identities.\n\t\t- **AI supported creativity: Soon to Next**\n\t\t\t- AI assisting and leading in art, music, and literature creation.\n\t\t- **Equity: Now to Next**\n\t\t\t- Democratizing resources and [[education]] globally.\n\t\t- **Self Guided Learning for Children: Next to Later**\n\t\t\t- Playful, memorable AI education experiences for children, globally.\n\t\t- **The age of the productive tinker: Later**\n\t\t\t- AI revolutionizing industries with specialized gadgets and applications.\n\t- ## Environment\n\t\t- **Resilience and collaborative management : Soon to Later**\n\t\t\t- AI optimizing resource consumption and enhancing waste management.\n\t\t\t- AI's role in climate change and wildlife conservation.\n\t\t- **Supporting our place: Later**\n\t\t\t- AI monitoring and managing physical health and environmental choices.\n\t- ## Holistic health: Next to Later\n\t\t- **Personal Health Management: Now to Next**\n\t\t\t- Personalized AI systems optimizing individual health. Things like [DermAssist\n\t\t- Google Health](https://health.google/consumers/dermassist/) are just the start.\n\t\t\t- [Towards Conversational Diagnostic AI](https://arxiv.org/abs/2401.05654) is scoring higher than clinicians already.\n\t\t\t- Bill Gates [views](https://www.gatesnotes.com/The-Year-Ahead-2024?) AI as a transformative tool in healthcare, particularly for enhancing access to education and mental health services.\n\t\t- **Lifetime Support Structures: Now to Later**\n\t\t\t- AI providing lifetime guidance and customized assistance.\n\t- ## The age of the informational Agent\n\t\t- **Effective collapse of integrated knowledge : Next to Later**\n\t\t\t- This is the 2016 [[Death of the Internet]] [Conpiracy Theory]([Dead Internet theory\n\t\t- Wikipedia](https://en.wikipedia.org/wiki/Dead_Internet_theory)) but will likely happen in time\n\t\t\t- [Echoes of the dead internet theory: AI's silent takeover | Cybernews](https://cybernews.com/editorial/dead-internet-theory-ai-silent-takeover/)\n\t\t- **Money will change: Next to Later**\n\t\t  collapsed:: true\n\t\t\t- Algorithms managing financial transactions and negotiations.\n\t\t- **Ubiquitous multi-modal UX: Next to Later**\n\t\t\t- Rise of integrated displays and interfaces for AI interaction.\n\t\t- **Intentional UX for accessing diverse networks of information: Later**\n- # Sectors\n\t- ## Generic Business Efficiency and Productivity Predictions\n\t  id:: 659a9246-c630-4781-84cd-a252ae2ce9c7\n\t\t- Generative AI enhancing business productivity and efficiency through domain-specific models, optimizing workflows, and integrating multimodal applications.\n\t\t  background-color:: yellow\n\t\t- Advantage for employees who intersect with AI tooling, increasing engagement and productivity... but for the benefit of whom [[Social contract and jobs]]\n\t\t  background-color:: pink\n\t\t- Most time benefit from things \"close to the metal\" such as Dev Ops, coding, macros, light financial work, etc. Thing someone \"looked up\" then did.\n\t\t  background-color:: green\n\t\t- Predictive analytics and strategic insights transforming decision-making processes (white collar jobs).\n\t\t  background-color:: pink\n\t\t- AI-driven project management which doesn't sound like much but... [[Diagrams as Code]]\n\t\t  background-color:: green\n\t\t- Enhanced virtual [[collaborative]] environments(think reduced travel for the classic complex visual tasks)\n\t\t  background-color:: yellow\n\t\t- Remote working; [[Metaverse and Telecollaboration]] (notes, minutes, knowledge management tools like this one). This includes radically improved document understanding\n\t\t  background-color:: green\n\t\t- Business to business mixed reality. I have been doing this since 1997. It's always going to be big \"SOON\", but the signs are improving and I can't discount it as easily this time.\n\t\t  background-color:: pink\n\t\t- Concentrate on the lowest hanging fruit, most people are not using this, you'll get huge advantage. Protect your data, let the market develop. If you have a clear business case then do get a consultant and legal advice (£1000/hr). Make a risk matrix, use my GPT if you like.\n\t\t  background-color:: red\n\t- ## Consumer Services and Personal Use\n\t\t- AI agents managing emails and consumer services, offering personalized and intuitive user experiences.\n\t\t  background-color:: yellow\n\t\t\t- [outfit anyone]([Outfit Anyone (humanaigc.github.io)](https://humanaigc.github.io/outfit-anyone/))\n\t\t- AI in personal finance, health monitoring, and personalized entertainment.\n\t\t  background-color:: green\n\t\t- AI enhancing environmental controls and home automation systems.\n\t\t  background-color:: green\n\t- ## Healthcare and Medicine\n\t\t- AI streamlining healthcare administration and patient care, leading to efficient drug discovery and personalized medicine.\n\t\t  background-color:: green\n\t\t- AI's expanded role in telemedicine and remote patient monitoring.\n\t\t  background-color:: green\n\t- ## [[Cyber security and Cryptography]] and Fraud Prevention\n\t\t- AI crucial in cybersecurity, adapting to evolving threats and enhancing [[Politics, Law, Privacy]]  << this feels like it will be warfare\n\t\t  background-color:: red\n\t\t- Development of AI algorithms for adaptive threat response and robust [[Distributed Identity]] authentication processes.\n\t- ## AI in [[Education]]\n\t\t- AI's will demonstrate potential in personalised learning and administrative efficiency in educational settings, nobody will use it.\n\t\t  background-color:: yellow\n\t\t- Challenges and uneven adoption across institutions due to budget constraints, lack of expertise, and ethical concerns.\n\t\t  background-color:: red\n\t\t- Individuals who *can* will use major platforms like OpenAI for education, centralising innovation, and raising privacy and equity issues.\n\t\t  background-color:: pink\n\t\t- Discussions will have to start on AI literacy, and collaborative approaches to ensure ethical and effective AI integration in education.\n\t\t  background-color:: green\n\t\t- Strategies for educators, technologists, and policymakers to foster an environment where AI benefits learning outcomes and is accessible to all.\n\t\t  background-color:: green\n\t\t- I think the Rabbit is something I would buy for kids?!\n\t- ## Innovation and Creative Industries\n\t\t- AI spurring innovation in coding, product development, and creative fields like storytelling & games. \n\t\t  background-color:: green\n\t\t- Perhaps less so in image and video.\n\t\t  background-color:: pink\n\t\t- AI increasingly integrated as a collaborative partner in content creation and user experience design.\n\t\t  background-color:: green\n\t- ## Information and Data Analysis\n\t\t- AI enhancing real-time data analysis and handling unstructured data for deeper insights.\n\t\t  background-color:: pink\n\t\t- AI contributing to environmental and climate modeling for sustainable solutions.\n\t\t  background-color:: red\n\t- ## Societal and Ethical Considerations\n\t\t- Addressing AI-related societal and ethical challenges, focusing on transparency, fairness, and accountability.\n\t\t  background-color:: red\n\t\t- Public discourse on AI's implications on privacy, employment, and societal norms.\n\t\t  background-color:: green\n\t- ## Technological Advancements and Applications\n\t\t- AI hardware advancements leading to more energy-efficient and powerful processing capabilities.\n\t\t  background-color:: green\n\t\t- The beginning of AI [[Agents]]\n\t\t\t- intentional UX.\n\t\t\t- Having your personal agent, or it's agents, do the online work for you,\n\t\t\t- Bringing back distilled updates to a locally or securely hosted core agent.\n\t\t\t- This will have staggering repercussions for the web as we know it.\n\t\t\t- This is the old [[Death of the Internet]] conspiracy theory, but happening.\n\t\t- Semantic and natural language programming\n\t\t\t- In a future where intentional programming user experience (UX) evolves to its next stage, we could envision a scenario where multimodal and language models interface directly with bytecode, driven by semantic instructions from product owners. This approach would represent a significant leap from current programming paradigms, emphasizing a more intuitive, less syntax-heavy interaction with software development.\n\t\t\t- **1. Semantic Instruction and Bytecode Manipulation:**\n\t\t\t\t- In this future, product owners or non-technical stakeholders could provide instructions in natural language or through other intuitive interfaces.\n\t\t\t\t- These instructions would be semantically analyzed by advanced language models, capable of understanding the intent and context of the request.\n\t\t\t\t- The language models would then translate these semantic instructions into bytecode – the lowest-level code executed by the computer's processor.\n\t\t\t\t- This process bypasses traditional programming languages, allowing for more direct and efficient creation or modification of software functionalities.\n\t\t\t- **2. Multimodal Interfaces:**\n\t\t\t\t- Multimodal interfaces, incorporating voice, text, and possibly visual or gestural inputs, would make the process more accessible and intuitive.\n\t\t\t\t- These interfaces would cater to a diverse range of users and preferences, allowing instructions to be given in various formats.\n\t\t\t- **3. Enhanced Collaboration and Iteration:**\n\t\t\t\t- By enabling product owners to directly communicate their requirements to the software, the gap between idea conception and implementation narrows significantly.\n\t\t\t\t- This direct communication loop would facilitate rapid iterations, as changes can be implemented and reviewed in real-time or near-real-time.\n\t\t\t- **4. Automated Testing and Validation:**\n\t\t\t\t- The system would incorporate sophisticated automated testing mechanisms.\n\t\t\t\t- As soon as the bytecode is generated or modified, a series of automated tests could run to validate the functionality, ensuring that the changes meet the specified requirements and do not introduce bugs or vulnerabilities.\n\t\t\t\t- Product owners could also perform their own tests on the resultant functionality, using user-friendly testing tools integrated into this system.\n- ## Less Optimistic\n\t- This is taken from [[Sam Hammond]] who I have discovered recently. All his stuff is summarised and linked here.\n- # Random Bonus Podcasts\n- <iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/episode/3KrLw4xNAiEeylzm7gg0qr?utm_source=generator\" width=\"100%\" height=\"352\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"></iframe>\n- <iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/show/5nr8blvyQwadadxV0gXaeu?utm_source=generator\" width=\"100%\" height=\"352\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"></iframe> https://open.spotify.com/episode/3KrLw4xNAiEeylzm7gg0qr?si=e59f027065884c33\n- <iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/episode/6sjhWInAvEfEcamHEQtPsX?utm_source=generator\" width=\"100%\" height=\"352\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\"></iframe>",
        "link_types": [
            "Education",
            "Agents",
            "education",
            "Death of the Internet",
            "Social contract and jobs",
            "Diagrams as Code",
            "collaborative",
            "Metaverse and Telecollaboration",
            "Cyber security and Cryptography",
            "Politics, Law, Privacy",
            "Distributed Identity",
            "Education",
            "Agents",
            "Death of the Internet",
            "Sam Hammond"
        ],
        "file_size": 12825
    },
    {
        "id": "Artificial Intelligence.md",
        "name": "Artificial Intelligence",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published (scraps, needs a lot of redo)\n- # The Cambrian explosion of ML/AI\n\t- Though the history of this field reaches back to the 1940’s with McCulloch et al. exploration of the possible mathematical underpinnings of human brain neurons.[[mcculloch1943logical]] During the writing of this book we have seen an inflection point in machine learning, to the point where the term “artificial intelligence” is feeling intuitively and subjectively real for the first time. To be clear AI is still apretty meaningless term. ‘Intelligence’ is one of those slippery words which is highly dependent on context. A satnav system running on a phone can make an intelligent choice about a route by synthesising data and presenting comprehensible results, but it seems absurd to ascribe an intelligence to it. It’s possible that there’s some kind of “spoooky” quantum activity in play in a conscious human brain or even all [biological systems](https://www.nature.com/articles/s41598-024-62539-5), as described in mind bending mathematical depth by Penrose in 1989.[[penrose1990emperor]]. It’s something of an unknown unknown, [[kerskens2022experimental]] and that we’ll never get to what’s called ‘strong’ or ‘general’ AI,[[larson2021myth; @searle1980minds]] reserved by some scientists for“ true consciousness”, whatever that means.[[butlin2023consciousness]]With that said we may be approaching the threshold of the ‘TuringTest‘, [[sep-turing-test]] initially posited by Alan Turing in1950,[[turing1950computing]] and the goalposts have begun to move in response to claims that there have been successful examples.[[warwick2016can; @french2012moving; @french2000turing; @searle2009turing]]\n\t\t- Most recently, GPT-4 [passed the Turing test](https://www.livescience.com/technology/artificial-intelligence/gpt-4-has-passed-the-turing-test-researchers-claim), according to one group. Participants judged GPT-4 to be human 54% of the time, surpassing ELIZA and GPT-3.5.\n\t\t- The Turing test has been criticised for being too simplistic in its approach, focusing on stylistic and socio-emotional factors. Nell Watson, an AI researcher, emphasized the importance of empathy in AI's value and its changing nature during the GPT era.\n\t\t- {{video https://www.youtube.com/watch?v=MxTWLm9vT_o}}\n\t\t  \n\t\t  It feels that in this moment it is appropriate to open with a risks section, and work backwards. This is grounded in the hypothesis that there is no agreed end goal here (as we saw with the Bitcoin/Cryptochapter).\n\t-\n- https://www.linkedin.com/posts/linasbeliunas_metas-chief-ai-scientist-yann-lecun-says-ugcPost-7158187178852794369-Sg8o?utm_source=share&utm_medium=member_desktop\n- [AI Index Report 2024 – Artificial Intelligence Index (stanford.edu)](https://aiindex.stanford.edu/report/) Measuring trends\n- The swift rise of digital walled gardens, moving towards a less transparent internet, reveals both a need for user data protection and a corporate push for greater control and profit. Tech giants like Google, Reddit, and Twitter are increasingly controlling their platforms, adjusting data flows for revenue growth. Google's new privacy policy, which allows data collection for AI model training, increases public concerns over user consent and privacy rights. The wide-ranging language of the policy gives Google considerable power in using user-generated content, fueling debates on data usage ethics. Simultaneously, the social web's shift towards an entertainment-focused business model prioritizes revenue over human connection. Platforms target ad revenue through vertically scrolling videos, risking reduced content diversity and creating echo chambers.\n- Entertainment unions like the International Alliance of Theatrical Stage Employees (IATSE) are grappling with AI's impact on employment. Their approach includes research, collaboration, education, political advocacy, organizing, and collective bargaining to protect members' interests, including upskilling initiatives. Upskilling is gaining industry attention. Companies like Tata Consultancy highlight the need to equip engineers with AI skills. Recognizing AI technologies' potential, they invest in reskilling programs to stay competitive and effectively use AI tools.\n- The rise of generative AI and the declining open web raises concerns about maintaining digital commons and encouraging diverse perspectives. AI-generated content could overshadow human contributions, making meaningful information harder to find and increasing misinformation risks. This situation highlights the need for balance between AI-generated and human-generated content.\n- Data control battles between platforms and users fuel debates on data ownership and profit sharing. Users demand more control over their data use and potentially a share in the resulting profits. This issue emphasizes the need for transparent data policies and fair user compensation models.\n- The influence of AI on the job market and the future of work is a significant concern. As AI technology progresses, the need for upskilling and reskilling programs grows to ensure workers can adapt to changing job requirements. Collaboration between industries, governments, and educational institutions is essential to address AI-induced disruptions and ensure a smooth workforce transition.\n- Finally, the importance of AI ethics and governance grows as AI technologies become more prevalent. The development and deployment of AI systems require ethical frameworks, transparency, and accountability. Collaboration between AI researchers, policymakers, and ethicists is critical to address potential risks and societal implications of AI technology.",
        "link_types": [
            "mcculloch1943logical",
            "penrose1990emperor",
            "kerskens2022experimental",
            "larson2021myth; @searle1980minds",
            "butlin2023consciousness",
            "sep-turing-test",
            "turing1950computing",
            "warwick2016can; @french2012moving; @french2000turing; @searle2009turing"
        ],
        "file_size": 5740
    },
    {
        "id": "Definitions and frameworks for Metaverse.md",
        "name": "Definitions and frameworks for Metaverse",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n- # Theoretical Framework toward metaverse [[Update Cycle]]\n  id:: 65cbd03c-03a4-4ca3-8e9d-984692e29412\n\t- ## Problem Statement\n\t\t- It’s very likely that the ‘social first’ metaverse attempts such as [Meta Horizons](https://www.theverge.com/2022/10/6/23391895/meta-facebook-horizon-worlds-vr-social-network-too-buggy-leaked-memo), Sandbox, and Decentraland [represent failures](https://www.coindesk.com/web3/2022/10/07/its-lonely-in-the-metaverse-decentralands-38-daily-active-users-in-a-13b-ecosystem/) to capture audiences. They crashed back down the hype curve as ‘Second Life’ did before them. Games based worlds such as Roblox are fairing far better, with millions of users, but it’s unclear if they have longevity, and they do not fulfil ambitions of an open metaverse.\n\t\t- Worse yet it seems that metaverse is not the most useful way to conduct business. It is evident that there are multiple factors which contribute to successful human-human communication. These factors remain important in telecommunication supported by technology, and are variously supported, unsupported, or modified by particular technologies. Third person large scale metaverse are clearly amongst the worse of the solutions.\n\t\t- Of particular importance is interpersonal gaze.[[Cook1977; @Kleinke1986; @Fagel2010]] Non-verbal cues are also important across multiple modalities of sight, sound,[[Otsuka2005]] and position of interlocutors,[[Kendon1967]] extending to the whole body.[[Kleinke1986; @Nguyen2009]]\n\t\t- While formal meeting paradigms are pretty well supported by commercially deployed systems, such ICT can be expensive, may need to be professionally managed, and high end equipment in board rooms are generally booked well in advance. These meetings seem to demand many \n\t\t  smaller supporting meetings between parties or groups of parties. The pressure here is clearly toward the now ubiquitous Teams and Zoom style formats, and these offer very poor support for social cues, and incur additional fatigue. These are known and well researched problems, and it is possible that the [strategic pairing of Meta Horizons and Microsoft Teams](https://www.oculus.com/blog/future-of-work-meta-connect-2022-quest-pro-microsoft-accenture/?) will succeed where previous attempted have failed, or that somehow [Microsoft Mesh for Teams will find and audience](https://www.microsoft.com/en-us/microsoft-teams/microsoft-mesh). They both seem to finally have the right assets and opportunity in principle. Apple also seem well positioned now, though how many users they can expect to own and work in their heavy spatial computing headset is unclear.\n\t\t- The ‘problem’ is a supporting technology for small less formal groups,or ad-hoc groups meeting to add clarity or context to formal meetings.Metaverse allows this kind of interaction, while not seeming to replaceformal meeting utility. Metaverse also may connect home and work spaceswithout bringing in those backgrouds, creating a level playing field. Amore advanced metaverse interface could also allow dynamism andmovement, connection of natural non vocal cues, without too muchencumbering technology overhead.\n\t- ### Core Assumptions\n\t\t- Figure<a href=\"#fig:Framework\" data-reference-type=\"ref\" data-reference=\"fig:Framework\">[fig:Framework]</a>shows the interlocking relationships between baseline communicationwhere the participants are present, and technology which attempts tosupport across distance.\n\t\t  ![image](./assets/ecf58d485742c10a034d96c07588c28542b21b85.png)\n\t- Of most interest to this research is the centre of the Venn where meeting styles which are less formal, and perhaps dynamic, may occur. Looking at these items one by one gives us our core assumptions.\n\t- #### Gaze\n\t\t- Gaze is broadly agreed to be highly important for mediating flow. Mutual gaze is a rich emotional channel. The research must consider gaze. All of the researchers listed around the Venn have at some point engaged with this topic.\n\t- #### Attention\n\t\t- The non-verbal communication channel employed in ‘attention’ is assumed based upon the literature to be critical to smoothly leaving and entering a fast flowing conversation where concentration around a defined problem may be high (gesturing to a chair for instance). Again, all of the listed researchers have made reference to attention in their work.\n\t- #### Spatial (immersive)\n\t\t- Support for spatiality is important in a group setting so that directional non-verbal cues can find their target. The topic of spatial relationships between interlocutors cuts across all of the researchers, but this is not true of immersion. Immersion in a shared virtuality can certainly support the underlying requirements spatial, but the technical infrastructure required is out of scope (so this is struck through on the diagram). Roberts and Steed are the main expertise referenced even though this element is not expanded in the research.\n\t- #### Situated\n\t\t- Situated displays are those which are appropriate for their surrounding context, in this case the informal meeting. Roberts, Pan, Steed and Steptoe seem the most relevant researchers in these technology spaces.\n\t- #### Informal\n\t\t- Based on the literature proxemics is believed to be relevant in a meeting where subgroups can be instantiated and destroyed as the meeting evolves, and those where people can be invited in from outside the physical bounds of the meeting (informal spaces). Hall is the best source for this work. If it is assumed that people may come and go, and subgroups may be convened then Sermon and Benford are the best references through their work blending real and virtual spaces. This may be more consistent with less organised meetings such as those convened on demand (ad-hoc).\n\t- ### Peripheral Assumptions\n\t\t- Surrounding the centre of the Venn are additional relevant topics fromsocial science branches of theory\n\t\t- #### **From verbal communication**\n\t\t\t- It is assumed that the directionality of sound is important,[[Aoki2003]]and this will be engineered into the experimental design. It is assumedthat movement of the lips is an indicator and this is tied to latencyand frame rate in the vision system.\n\t\t- #### **From non-verbal communication**\n\t\t\t- It is assumed that eye gaze is of high importance, and that this information channel is supported by head gaze and body torque to a high degree. It is further assumed that mutual eye gaze is of less relevance in a multi party meeting where there is a common focus for attention but can be significant for turn passing. It is assumed that upper body framing and support for transmission of micro and macro gesturing is important for signalling attention in the broader group, and for message passing in subgroups.\n\t- ## Post ‘Meta’ metaverse\n\t\t- The current media around “metaverse” has been seeded by Mark Zuckerberg’s rebranding of his Facebook company to ‘Meta’, and his investment in the technology. Kraus et al suggest that this seems more a marketing and communication drive than a true shift in the company business model,[[kraus2022facebook]] but despite this Park and Kim identify dozens of recent papers of metaverse research emerging from Meta labs.[[park2022metaverse]]\n\t\t- In Stephenson’s ‘Snow Crash’ the Hero Protagonist (drolly called Hiro Protagonist) spends much of the novel in a dystopian virtual environment called the metaverse. It is unclear if Facebook is deliberately embracing the irony of aping such a dystopian image, but certainly their known predisposition for corporate surveillance, alongside their attempt at a global digital money is [ringing alarmbells](https://www.politico.com/newsletters/digital-future-daily/2022/04/12/the-facebook-whistleblower-takes-on-the-metaverse-00024762),as is their [currentplan](https://www.cnet.com/personal-finance/metas-new-47-5-fee-on-metaverse-items-has-nft-twitter-pissed/)for monetisation.\n\t\t- The second order hype is likely a [speculativeplay](https://www.goldmansachs.com/insights/pages/framing-the-future-of-web-3.0-metaverse-edition.html)by major companies on the future of the internet. Grayscale investment[published areport](https://grayscale.com/wp-content/uploads/2021/11/Grayscale_Metaverse_Report_Nov2021.pdf)which views Metaverse as a potential trillion dollar global industry.Such industry reports are given to hyperbole, but it seems thetechnology is becoming the focus of technology investment narratives.Some notable exerts from a [2021report](https://www.jpmorgan.com/content/dam/jpm/treasury-services/documents/opportunities-in-the-metaverse.pdf)by American bank JPMorgan show how the legacy financial institutions seethis opportunity:\n\t\t- In the view of the report it“The metaverse is a seamless convergence of our physical and digital lives, creating a unified, virtual community where we can work, play, relax, transact, and socialize.”\n\t\t- this isn’t the worst definition, and very much plays into both the value and mixed reality themes explored in this book.\n\t\t- They agree with the industry that monetisation of assets in metaverse applications is called “Metanomics”. It’s worth seeing this word once, as it’s clearly gaining traction, but it won’t be used in this book.\n\t\t- They make a point which is at the core of this book, that value transaction within metaverses may remove effective border controls for working globally. Be this teleoperation of robots, education, or shop fronts in a completely immersive VR world. They say: it“One of the great possibilities of the metaverse is that it will massively expand access to the marketplace for consumers from emerging and frontier economies. The internet has already unlocked access to goods and services that were previously out of reach. Now, workers in low-income countries, for example, may be able to get jobs in western companies without having to emigrate.”\n\t\t- There is a passage which foreshadows some of the choices made in this book: it“Expanded data analytics and reporting for virtual spaces. These will be specifically designated for commercial and marketing usage and will track business key performance indicators (this already exists in some worlds, such as Cryptovoxels)”. More on this later.\n\t\t- The report attempts to explore the web3 & cryptocurrency angles of metaverse. That’s also the aim of this book, but they have taken a much more constrained approach, ignoring the possibilities within Bitcoin.\n\t\t- They assert that strong regulatory capture, identification, KYC/AML etc should underpin their vision of the metaverse. This is far from the community driven and organically emergent narratives that underpin Web3. This is their corporate viewpoint, something they have to say. On the back of this they pitch their consultancy services in these areas.\n\t\t- There has been a reactive pushback against commercialisation andcorporateisation by the wider tech community, who are [concernedabout](https://www.metaversethics.org/p/mde02-metaverse-data-privacy-1)the aforementioned monetisation of biometrics. [Observers do nottrust](https://www.coindesk.com/layer2/2022/01/19/meta-leans-in-to-tracking-your-emotions-in-the-metaverse/)these ‘web’ players with such a potentially powerful social medium. Itis very plausible that this is all just a marketing play that goesnowhere and fizzles out. It is by no means clear that people want tospend time socialising globally in virtual and mixed reality. Thesemajor companies are making an asymmetric bet that if there is a moveinto virtual worlds, then they need to be stakeholders in thegatekeeping capabilities of those worlds.\n\t\t- To paraphrase Olson; the salesmen peddling the inevitability of themetaverse are stuck clinging to aesthetic details because, without them,they’re just talking about the internet. While virtual reality isenjoying hype right now, and will continue to develop, it facessignificant challenges related to the human body’s physiologicallimitations. For instance, the inner ear can become disoriented when auser experiences virtual movement without physically moving. This issuehas led to the development of VR applications that require compromisesbetween immersion and physical comfort.\n\t- ### Open Source\n\t\t- The Openstand principles are a great starting place for what an open metaverse might mean. [They are](https://open-stand.org/about-us/principles/)\n\t\t- ### **1. Cooperation**\n\t\t\t- Respectful cooperation between standards organizations, whereby each respects the autonomy, integrity, processes, and intellectual property rules of the others.\n\t\t- ### **2. Adherence to Principles**\n\t\t\t- Adherence to the five fundamental principles of standards development:\n\t\t\t\t- **Due process.** Decisions are made with equity and fairness among participants. No one party dominates or guides standards development. Standards processes are transparent and opportunities exist to appeal decisions. Processes for periodic standards review and updating are well defined.\n\t\t\t\t- **Broad consensus.** Processes allow for all views to be considered and addressed, such that agreement can be found across a range of interests.\n\t\t\t\t- **Transparency.** Standards organizations provide advance public notice of proposed standards development activities, the scope of work to be undertaken, and conditions for participation. Easily accessible records of decisions and the materials used in reaching those decisions are provided. Public comment periods are provided before final standards approval and adoption.\n\t\t\t\t- **Balance.** Standards activities are not exclusively dominated by any particular person, company or interest group.\n\t\t\t\t- **Openness.** Standards processes are open to all interested and informed parties.\n\t\t- ### **3. Collective Empowerment**\n\t\t\t- Commitment by affirming standards organizations and their participants to collective empowerment by striving for standards that:\n\t\t\t\t- are chosen and defined based on technical merit, as judged by the contributed expertise of each participant;\n\t\t\t\t- provide global interoperability, scalability, stability, and resiliency;\n\t\t\t\t- enable global competition;\n\t\t\t\t- serve as building blocks for further innovation; and\n\t\t\t\t- contribute to the creation of global communities, benefiting humanity.\n\t\t- ### **4. Availability**\n\t\t\t- Standards specifications are made accessible to all for implementation and deployment. Affirming standards organizations have defined procedures to develop specifications that can be implemented under fair terms. Given market diversity, fair terms may vary from royalty-free to fair, reasonable, and non-discriminatory terms (FRAND).\n\t\t- ### **5. Voluntary Adoption**\n\t\t\t- Standards are voluntarily adopted and success is determined by the market.\n\t\t- ## Primitives\n\t\t\t- OpenAI identified the following 5 points about metaverse, in response to the query \"What are 5 key points I should know when studying metaverse?\". This is an unexpectedly great answer, probably the cleanest I have found, but I cannot longer find it online.\n\t\t\t\t- Metaverse is a virtual reality platform that allows users to interact with each other and with digital objects in a virtual space.\n\t\t\t\t- Metaverse is a decentralized platform, meaning that there is no central authority or server that controls the platform.\n\t\t\t\t- Metaverse is an open platform, meaning that anyone can develop applications for the platform.\n\t\t\t\t- Metaverse is a secure platform, meaning that all data and transactions are encrypted and secure.\n\t\t\t\t- Metaverse is a scalable platform, meaning that it can support a large number of users and a large number of transactions.\n\t\t\t- The [Metaverse Standard Forum](https://metaverse-standards.org/) highlights the following, which reads like the output from a brainstorm between academia and industry stakeholders.\n\t\t\t\t- collaborative spatial computing\n\t\t\t\t- interactive 3D graphics\n\t\t\t\t- ugmented and virtual reality\n\t\t\t\t- photorealistic content authoring\n\t\t\t\t- geospatial systems\n\t\t\t\t- end-user content tooling\n\t\t\t\t- digital twins\n\t\t\t\t- real-time collaboration\n\t\t\t\t- physical simulation\n\t\t\t\t- online economies\n\t\t\t\t- multi-user gaming\n\t\t\t\t- new levels of scale and immersiveness.\n\t\t\t- It's not a useless list by any means, but it lacks the kind of product focus we need for detailed exploration of value and trust transfer.\n\t\t\t- Mystakidis identifies the following [155]:\n\t\t\t\t- Principles\n\t\t\t\t\t- Interoperable\n\t\t\t\t\t- Open\n\t\t\t\t\t- Hardware agnostic\n\t\t\t\t\t- Network\n\t\t\t\t- Technologies\n\t\t\t\t\t- Virtual reality\n\t\t\t\t\t- Augmented reality\n\t\t\t\t\t- Mixed reality\n\t\t\t\t- Affordances\n\t\t\t\t\t- Immersive\n\t\t\t\t\t- Embodiment\n\t\t\t\t\t- Presence\n\t\t\t\t\t- Identity construction\n\t\t\t\t- Challenges\n\t\t\t\t\t- Physical well-being\n\t\t\t\t\t- Psychology\n\t\t\t\t\t- Ethics\n\t\t\t\t\t- Privacy\n\t\t\t\t- This is quite an academic list. A lot of these words will be explored in the next section which is more of an academic literature review.\n\t\t\t\t- Nevelsteen attempted to identify key elements for a ‘virtual work’ in 2018 and these are relevant now, and described rigorously in the appendix of his\n\t\t\t\t  paper [156]:\n\t\t\t\t\t- Shared Temporality, meaning that the distributed users of the virtual world share the same frame of time.\n\t\t\t\t\t- Real time which he defines as “not turn based”.\n\t\t\t\t\t- Shared Spatiality, which he says can include an ‘allegory’ of a space, as in text adventures. It seems this might extend to a spoken interface to a mixed reality metaverse.\n\t\t\t\t\t- ONE Shard is a description of the WLAN network architecture, and conforms to servers in a connected open metaverse.\n\t\t\t\t\t- Many human agents simply means that more than one person can be represented in the virtual world and corresponds to ‘social’ in our description.\n\t\t\t\t\t- Many Software Agents corresponds to AI actors in our descriptions. Non playing characters would be the gaming equivalent.\n\t\t\t\t\t- Virtual Interaction pertains to any ability of a user to interact actively with the persistent virtual scene, and is pretty much a given these days.\n\t\t\t\t\t- Nonpausable isn’t even a word, but is pretty self explanatory.\n\t\t\t\t\t- Persistence means that if human participants leave then the data of the virtual world continues. This applies to the scenes, the data representing actions, and objects and actors in the worlds.\n\t\t\t\t\t- Avatar is interesting as it might seem that having avatar representations of connected human participants is a given. In fact the shared spaces employed by Nvidia for digital engineering do not.\n\t\t\t\t- Turning to industry; John Riccitiello, CEO of Unity Technologies says that metaverse is “The next generation of the internet that is:\n\t\t\t\t\t- always real-time\n\t\t\t\t\t- mostly 3D\n\t\t\t\t\t- mostly interactive\n\t\t\t\t\t- mostly social\n\t\t\t\t\t- mostly persistent\n\t\t\t\t- Expanding this slightly I choose the following primitives of what I think are important for a metaverse:\n\t\t\t\t\t- Fusing of digital and real life\n\t\t\t\t\t- Social first\n\t\t\t\t\t- Real time interactive 3d graphics first\n\t\t\t\t\t- Persistent\n\t\t\t\t\t- Supports ownership\n\t\t\t\t\t- Supports user generated content [157]\n\t\t\t\t\t- Open and extensible\n\t\t\t\t\t- Low friction economic actors and actions\n\t\t\t\t\t- Trusted / secure\n\t\t\t\t\t- Convergence of film and games\n\t\t\t\t\t- Blurring of IP boundaries\n\t\t\t\t\t- Blurring of narrative flow\n\t\t\t\t\t- Multimodal and hardware agnostic\n\t\t\t\t\t- Mobile first experiences\n\t\t\t\t\t- Safeguarding, and governance\n\t\t\t\t\t- Scaffolded by GenAI\n\t\t\t\t\t- Supports Agentic AI actors\n\t\t- ## Generalised and AI mediated ontologies\n\t\t- Societal glue and translational layer need to be AI mediated by a specialised and trained ontological specialist AI. This is a tremendous opportunity\n\t\t- [[Metaverse Ontology]] to play with the idea -\n\t- ### NFT and crypto as metaverse\n\t\t- Within the NFT, Web3 and crypto community it is normalised to refer to ownership of digital tokens as participation in a metaverse. This is reflected in the market analysis above. This fusing of narratives is reviewed in detail by Gadekallu et al in their excellent recent paper on Metaverse and Blockchain.[[gadekallu2022blockchain]] They conclude that much remains to be done here. This CNBC article highlights the confusion, as this major news outlet refers to [Walmart prepares toofferNFTs](https://www.cnbc.com/2022/01/16/walmart-is-quietly-preparing-to-enter-the-metaverse.html)”as an entry “into the metaverse”.\n\t- ### Lessons from MMORGS\n\t\t- The concept of ‘instrumental play’ was introduced by literary theoristWolfgang Iser in his 1993 essay “The Fictive and theImaginary.”[[iser1993fictive]] Iser divided play into two categories,free play and instrumental play, based on their relationship to goals.In his view, play becomes instrumental the moment it has a goal or a setof rules. The application of this concept to massively multiplayeronline games was later explored by sociologist T.L Taylor in her 2006book ‘Play Between Worlds.’[[taylor2009play]] According to Taylor,instrumental play is a goal-oriented approach that values efficiency,expertise, and strategy optimization. The point of playing is not toreach the end but to find the best way to get there.\n\t\t- The distinction between instrumental play and fun is often seen as afalse dichotomy. The two are not mutually exclusive but exist intension. Optimization can result in player behaviours that are simply nofun, but achieving goals or improving skills can also bring enjoyment.René Glas in his book ‘Battlefields ofNegotiation’[[glas2013battlefields]] describes the movement betweeninstrumental and free play in World of Warcraft, which has thedistinction of evolving across entirely different iterations of theInternet.\n\t\t- These virtual worlds of massively multiplayer online games are\"interactively stabilized\" systems, the result of the interactionbetween game designers and players. The social codes of practiceestablished by players can shape what is considered legitimate play.Success in these games is dynamically defined by consensus, as seen inMark Chen’s study of World of Warcraft ‘Leet Noobs.’[[chen2011leet]]\n\t\t- Tom Boellstorff conducted a study of user experiences in SecondLife,[[serapis2008coming]] which was criticized for not involving reallife or other websites or software in the analysis. The virtual worldsof massively multiplayer online games are not enclosed and players canengage with these games through various platforms, such as Discord,Twitch, Twitter, and Google Docs, without physically inhabiting thevirtual world. This concept of \"paratext\" was first introduced by Frenchliterary theorist Gerard Genette. He saw a book as containing the textof the book and additional components, such as the cover, title,foreword, etc., that are necessary to complete the book but not part ofthe primary text. These additional texts influence the meaning of theprimary text. The definition was later expanded by Mia Consalvo, whodefined paratext as any text that “may alter the meanings of a text,further enhance meanings, or provide challenges to sedimented meanings.”Examples of paratext include reviews, pre-release trailers, etc.Kristine Ask observed the impact of paratext on theorycrafting expertisein World of Warcraft, which was later confirmed by the rise of twitchstreams. Mark Chen’s dissertation Leet Noobs focuses on how AddOns inWorld of Warcraft can become essential agents in raid groups by assumingcognitive load. The concept is based on the idea of object-orientedontology and actor-network theory.[[cole2013call]] These theories arecomplex and contested, but the boundaries between real people andvirtual AI actors in virtual social spaces are certainly blurred.\n\t\t- Virtual spaces are not separate from the real world, but are instead anextension of it. The key factor in making a virtual world compelling isnot its realism, but the fact that people give meaning to their lives byentangling themselves in projects with others, even when those othersare not other people. Worlds become real when people care about them,not when they look like the real world.\n\t- ### Immersive and third person XR\n\t\t- In considering the needs of business to business and business to clientsocial VR is it useful to compare software platforms. We have seen thata global connected multiverse is a marketing proposition only, and maybe a decade or more away. Contenders currently look more like one ofthree catagories; games, limited massively multiplayer worlds, ormeeting support software. These will converge.\n\t\t- #### More like a digital twin\n\t\t- One of the most intuitive ways to view a metaverse is as a virtual landscape. This is how metaverse was portrayed in the original Neal Stephenson use of the word. ‘Digital twin’ is another much abused industry term which trends toward a 3D representation of real worldspaces and objects. Sometimes these virtual objects are connected to the real by telemetry, allowing industrial monitoring applications. Much is made of such systems in simulation brochures, and on the web, but it’s surprisingly hard to find real world applications of the idea outside of complex large scale systems engineering (aerospace). The costs of maintenance are simply too high. The US army owns the digital twin which could be called [closest to “The Metaverse”](https://www.army.mil/standto/archive/2018/03/26/) (note the intentional capitalisation). Their global simulation environment mirrors real world locations for their training needs. The European space agency is building an Earth digital twin for climate research, as [is Nvidia](https://www.nvidia.com/en-us/on-demand/session/gtcfall22-a41326/?playlistId=playList-9bb5405e-3e40-4ff3-88db-61cd3a4507e5#:~:text=Earth%2D2%20aims%20to%20improve,learning%20methods%20at%20unprecedented%20scale.),but again it’s unclear what this offers over and above access to direct data feeds, and of course such an ambitious project likely has an ecological cost!\n\t\t- Within industry digital twins are seen as the primary use case for metaverse, with even the world economic forum [subscribing to the hype](https://www.weforum.org/agenda/2023/01/metaverse-biggest-impact-industry-davos2023/).To be clear, there is enormous effort, investment, and potential here, with NVIDIA choosing to bind [their Omniverse](https://www.nvidia.com/en-gb/omniverse/) platform to their substantial hype wave.\n\t\t- ##### Omniverse has become the darling of 2024 and we will investigate it further [[Update Cycle]]\n\t\t\t- Key new capabilities announced:\n\t\t\t\t- Integration of generative AI like Adobe Firefly to enhance creation workflows (wow!)\n\t\t\t\t- Expanded ecosystem connections through OpenUSD (Adobe, [Wonder Dynamics](https://investors.autodesk.com/news-releases/news-release-details/autodesk-acquires-wonder-dynamics-offering-cloud-based-ai), Luma AI, etc)\n\t\t\t\t- New developer tools and templates for building apps and experiences\n\t\t\t\t- Semantic search capability with Deep Search to find 3D assets easily Optimizations for photorealistic real-time rendering and path tracing withAI-accelerated denoising powered by new RTX GPUs XR capabilities native to the platform (so you can deploy on AR/VR headsets)\n\t\t\t\t- Upgrades to core apps like Omniverse Audio2Face and USD Composer Graphics Delivery Network (GDN) to performantly serve your 3D experience around the world Support for new workflows across industrial use cases like digital twins\n\t\t- ##### Geolocated AR\n\t\t\t- Overlaying geospecific data into augmented reality (think Pokemon Go) isprobably the ultimate utility of digital twin datasets. It’s such acompelling application space that we will have more on this later.\n\t\t- #### More like a metaverse\n\t\t- ##### Second Life\n\t\t\t- Notable because it’s the original and has a decently mature marketplace.Some $80M was [paid tocreators](https://www.zdnet.com/article/high-fidelity-invests-in-second-life-to-expand-virtual-world/)in Second Life in 2021 in a wider economic ecosystem of around $650M.It’s possible to write a whole book on Second life, and indeed manyhave. It’s longevity means that there’s more study of business uses ofsuch systems than in any other platform.\n\t\t- ##### Mozilla Hubs\n\t\t\t- Hubs is a great option for this proposal, and might be worth integratinglater. It runs well in a browser and on VR hardware.\n\t\t\t\t- Open source, bigger scale, more complex\n\t\t\t\t- Choose avatars, or import your own\n\t\t\t\t- Environments are provided, or can be designed\n\t\t\t\t- Useful for larger conferences with hundreds or thousands of members but is commensurately more complex\n\t\t\t\t- Quest and PC\n\t\t\t\t- Larger scenes within scenes\n\t\t- ##### Counter social realms\n\t\t\t- A relatively new platform linked to a new model of social media which excludes countries which habitually spam. It uses Mozilla Hubs for it’s engine.\n\t\t- ##### Roblox\n\t\t\t- If anything can currently claim to be the metaverse it’s Roblox. Around 60 billion messages are [sent daily](https://podcasts.apple.com/us/podcast/developments-investments-experiences-in-the-metaverse/id1593908027?i=1000540906629)in Roblox. Investment in the metaverse ‘angle’ of the platform isstepping up with recent announcements such as [“SpotifyIsland”](https://techcrunch.com/2022/05/03/spotify-becomes-first-music-streamer-to-launch-on-roblox/?).The company has announced text based generative art creation of scenes,and is integrating the playstation headset in their PS4 release. It’svery notable that it still [hasn’t become a profitablebusiness](https://fortune.com/2022/06/03/roblox-gaming-ecosystem-metaverse-stocks-profit/).It is important to note that Roblox has banned NFTs. Nike have [garneredsignificantattention](https://www.thedrum.com/news/2022/09/22/21m-people-have-now-visited-nike-s-roblox-store-here-s-how-do-metaverse-commerce)for their metaverse store, front with their Roblox based metaverse. As[TheoPriestley](https://medium.com/@theo/why-nikeland-is-not-the-metaverse-success-story-you-think-it-is-46742dc2f231)points out this is likely just another expensive experiment, with afinite lifespan.  [expanding into generativeAI](https://twitter.com/bilawalsidhu/status/1644817961952374784)\n\t\t- ##### Minecraft\n\t\t\t- Minecraft has also [bannedNFTs](https://www.minecraft.net/en-us/article/minecraft-and-nfts)\n\t\t- ##### Surreal\n\t\t- ##### Sansar\n\t\t- ##### Cornerstone\n\t\t- ##### Microsoft Mesh (previously AltSpace)\n\t\t\t-\n\t\t- Microsoft social meeting platform\n\t\t\t-\n\t\t- Very good custom avatar design\n\t\t\t-\n\t\t- Great world building editor in the engine\n\t\t\t-\n\t\t- Doesn’t really support business integration so it’s a bit out of scope\n\t\t\t-\n\t\t- Huge numbers (many thousands) possible so it’s great for global events\n\t\t\t-\n\t\t- Mac support\n\t\t- ##### VRChat\n\t\t\t- none of this makes money yet\n\t\t\t\t- [#1394: Discussion about VRChat Layoffs & Paths to Profitability with Four Community Members – Voices of VR Podcast](https://voicesofvr.com/1394-discussion-about-vrchat-layoffs-paths-to-profitability-with-four-community-members/)\n\t\t\t-\n\t\t\t- This text is from wikipedia and will be updated when we have a chance totry VRChat properly. It’s much loved already by the Bitcoin community.\n\t\t\t- “VRChat’s gameplay is similar to that of games such as Second Life andHabbo Hotel. Players can create their own instanced worlds in which theycan interact with each other through virtual avatars. A softwaredevelopment kit for Unity released alongside the game gives players theability to create or import character models to be used in the platform,as well as build their own worlds.\n\t\t\t- Player models are capable of supporting \"audio lip sync, eye trackingand blinking, and complete range of motion.\n\t\t\t- VRChat is also capable of running in \"desktop mode\" without a VRheadset, which is controlled using either a mouse and keyboard, or agamepad. Some content has limitations in desktop mode, such as theinability to freely move an avatar’s limbs, or perform interactions thatrequire more than one hand.\n\t\t\t- In 2020, a new visual programming language was introduced known as\"Udon\", which uses a node graph system. While still considered alphasoftware, it became usable on publicly-accessible worlds beginning inApril 2020. A third-party compiler known as \"UdonSharp\" was developed toallow world scripts to be written in C sharp.”\n\t\t- ##### Meta Horizon Worlds & Workrooms\n\t\t\t- Horizon Worlds is the Meta (Facebook) meteverse, and Workrooms it’sbusiness offering and a subset of the “Worlds” global system. It iscurrently a walled garden without connection to the outside digitalworld, and arguably not therefore a metaverse.\n\t\t\t- The Financial Times [took a look](needs a link) at their patent applications and noted that the travel is toward increased user behaviour tracking, and targeted advertising.\n\t\t\t- Facebook actually have a poor history on innovation and diversification of their business model. This model has previously been tracking users to target ads on their platform, while increasing and maintaining attention using machine learning algorithms.\n\t\t\t- It makes complete sense then to analyse the move by Meta into 3D socialspaces as an attempt to front run the technology using their hugeinvestment capacity. Facebook have recently taken a huge hit to theirshare price. Nothing seems to have changed in the underling businessexcept Zuckerberg’s well publicised shift to supporting a money losinggamble on the Metaverse. It is by no means clear that users want this,that Meta will be able to better target ads on this new platform, orthat the markets are willing to trust Zuckerburg on this proactive move.\n\t\t\t- With all this said the investment and management capacity and capabilityat Meta cannot be dismissed. It is very likely that Meta will be able torapidly deploy a 3D social space, and that it’s development willcontinue to be strong for years. The main interface for Horizon Worldsis through the Meta owned and developer Oculus headset, which isexcellent and reasonably affordable. It has been quite poorly received[byreviewers](https://kotaku.com/facebook-metaverse-horizon-worlds-vr-oculus-quest-2-cha-1848436740)but will likely improve, especially if users are encouraged to innovate.\n\t\t- ##### Webaverse\n\t\t\t- [Webaverse](https://webaverse.com/) are an open collective using opensource tools to create interoperable metaverses.\n\t\t- ##### Vircadia\n\t\t\t- The applications and platforms detailed above have their benefits, butfor the application stack in the next section of the book Vircadia hasbeen chosen. The following text is from their website, and is aplaceholder which gives some idea. This section will be written outcompletely to reflect our use of the product to support emerging market users.\n\t\t\t- Vircadia is open-source software which enables you to create and sharevirtual worlds as virtual reality (VR) and desktop experiences. You cancreate and host your own virtual world, explore other worlds, meet andconnect with other users, attend or host live VR events, and much more.\n\t\t\t- The Vircadia metaverse provides built-in social features, includingavatar interactions, spatialized audio, and interactive physics.Additionally, you have the ability to import any 3D object into yourvirtual environment. No matter where you go in Vircadia, you will alwaysbe able to interact with your environment, engage with your friends, andlisten to conversations just like you would in real life.\n\t\t- #### More like crypto NFT virtual land\n\t\t- This next three are a placeholder taking text from the [linkedsite](https://www.analyticsinsight.net/top-10-metaverse-platforms-that-will-replace-social-media-in-future/)and will be swapped out: The digital land [narrative isfading](https://www.coindesk.com/markets/2022/04/06/metaverse-majors-struggle-as-user-base-falls-short-of-market-expectations/?).\n\t\t- ##### Decentraland\n\t\t\t- Decentraland is a large 3D (but not VR) space developed by Argentinedevelopers Esteban Ordano and Ari Meilich. It is a decentralizedmetaverse purporting to be owned by its users, but actually ownedcompletely by a foundation [based inPanama](https://www.crunchbase.com/organization/decentraland/people).The users can shop, buy things, invest, and purchase goods in a virtualspace. The project is built on Ethereum and has a (speculative)valuation in the billions of dollars.\n\t\t\t- Decentraland was launched in February 2020, and its history includes aninitial coin offering in August 2017, where their MANA token sale raisedapproximately $24 million dollars in crypto coins. This was followed bya “terraforming event” where parcels of land, denominated in LANDtokens, were auctioned off for an additional $28 million in crypto. Theinitial pitch for Decentraland emphasized the opportunity to own thevirtual world, create, develop, and trade without limits, make genuineconnections, and earn real money. However, the actual experience inDecentraland has faced criticisms such as poor graphics, performanceissues, and limited content. They have recently dropped their pretenceof ever supporting VR.\n\t\t\t- One example of these limitations is the now-defunct pizza kiosk thataimed to facilitate ordering Domino’s pizza via the metaverse usingcryptocurrency. This concept, though intriguing, was hindered by a lackof official support from Domino’s and the inherent inefficiencies ofusing a virtual world as an intermediary for purchasing goods andservices.\n\t\t\t- Similarly, attempts to create virtual amusement park rides andattractions within Decentraland have suffered from poor performance anda lack of interactivity. These issues stem from the limitations of thetools and resources available for building experiences within theplatform, as well as the inherent difficulties in creating engagingexperiences in a ‘world’ that is supposed to perform too many functionsat once.\n\t\t\t- In addition to the technical challenges, Decentraland (and all thesecrypto metaverse projects) have clearly promoting unrealisticexpectations to foster speculative investments. The notion thatbusinesses and individuals will eventually “live inside” the metaverseis not only a poetic interpretation but also an unrealistic expectationgiven the current state of VR technology.\n\t\t\t- As it stands, Decentraland is unlikely realize its supposed potential asan invisible, seamless infrastructure for a wide range of digitalexperiences. Until the platform can address its core issues, it islikely that projects like the ‘Decentraland Report’ (it’s user deliverednews platform), and others will continue to fail to deliver on theirpromises. To quote [Olson’s highlycritical](https://www.youtube.com/watch?v=EiZhdpLXZ8Q) (and correct)presentation on Decentraland: *“..it can’t even handle properlyemulating Breakout, a game from 1976 that you can play on goddamn Googleimages! Steve Wozniak built Breakout fifty years ago to run on 44 TTLchips and a ham sandwich and that’s still somehow too demanding a gamingexperience ...”*\n\t\t\t- Like all of these attempts the actual information content of withinDecentraland boils down to text on billboards, and links to the outsideWeb. It’s a terrible product, and really just another example of acrypto scam which never really intended to be developed for the longhaul.\n\t\t- ##### Sandbox\n\t\t\t- The Sandbox, a decentralized gaming platform built on the Ethereumblockchain, has garnered attention for its promise of a vibrantecosystem filled with user-generated content. However, despite itsambitious vision, the project has faced various challenges andcriticisms similar to Decentraland. Limited use cases and adoptionremain a significant challenge for The Sandbox. While the platform aimsto create a vast and engaging gaming ecosystem, it has yet to gainwidespread adoption, leading to a limited number of users anddevelopers. This lack of user engagement raises questions about thelong-term viability of the project, as the value of virtual land,assets, and in-game experiences may remain limited without a thrivingcommunity. Like Decentraland it is a manipulated hype bubble, attractingglowing paid press reports in some media, and ‘interest’ from nationaland regional ‘branches’ of global brands which are then spun to createartificial hype in main stream media. The tradable NFTs within theseearly platforms are obviously subject to insider trading, pricevolatility, wash trading, and other harmful activities.\n\t\t\t- The Sandbox places too much emphasis on the speculative aspect ofvirtual land and asset trading, rather than focusing on creating agenuinely engaging gaming ecosystem. This focus on speculation couldlead to an unsustainable bubble with inflated asset prices, and it seemslikely we have already seen most of the collapse of this ecosystem.\n\t\t\t- The actual experience of interacting with The Sandbox’s gaming productsleaves much to be desired. For instance, the platform’s games may sufferfrom lag and poor performance due to the technical limitations ofblockchain technology. Additionally, the quality of user-generatedcontent can be highly variable, as not all creators possess the skillsand resources to develop engaging gaming experiences. As a result, usersmight find themselves sifting through a plethora of low-quality games,which can be frustrating and time-consuming.\n\t\t\t- Concerns about centralization persist, as some critics argue that theproject is not entirely decentralized. The team behind The Sandbox stillholds a significant amount of control over the platform’s developmentand governance, potentially undermining the project’s core vision of adecentralized gaming ecosystem.\n\t\t- ##### Space Somnium\n\t\t\t- Somnium Space is just another one of these, but with more VR. It allowsusers to join in either through a downloadable VR client or abrowser-based version to function like any other web app. It sufferedthe same problems at Decentraland and Sandbox. They are terribleproducts, with hype, manufactured by money, extracted from users, oftenconvinced by paid celebrity endorsements. It’s the NFT space, butsadder, and technically worse, and likely not for very much longer.\n\t\t- #### More like industrial application\n\t\t- As the word metaverse has gained in use, so have some traditional usersand researchers in mixed reality switched to use of the term. Siyaev andJo describe an aircraft training metaverse which incorporates ML basedspeech recognition.[[siyaev2021towards]] This class of mixed realitytrainer traditionally finds positive results, but is highly taskspecific.\n\t- ##### Global enterprise perspective\n\t\t- Microsoft bought Activision / Blizzard for around seventybillion dollars. This has been communicated by Microsoft executives as a“Metaverse play”, leveraging their internal game item markets, and theirmassive multiplayer game worlds to build toward a closed metaverseexperience like the one Meta is planning. This builds on the success ofearly experiments like the Fornite based music concerts, which attractedmillions of concurrent users to live events.\n\t\t- There are three emerging focuses, the social metaverses for pleasure,and business metaverses for larger group meetings andtraining,[[heiphetz2010training; @aldrich2005learning]] and a Nvidia’sevolving [collaborative creationmetaverse](https://blogs.nvidia.com/blog/2022/08/09/omniverse-siggraph/)for digital engineers and creatives. They’re all pretty different‘classes’ of problem. The social metaverse angle where Facebook isconcentrating most effort is of less interest to us here, thoughobviously markets will exist in such systems for business to customer.The next section will explore some of the software tools available toconnect people. Everything looks pretty basic right now in all theavailable systems, but that will likely [change over the next couple ofyears](https://www.youtube.com/watch?v=cRLnR4Kot2M).\n- #### More like meeting support\n\t- ##### Spatial\n\t\t- Spatial is worth a quick look because it’s a business first meetingtool, and comparatively well received by industry for that purpose.\n\t\t- - Very compelling. Wins at wow.\n\t\t- - Great avatars, user generated\n\t\t- - AR first design\n\t\t- - Limited scenes\n\t\t- - Smaller groups (12?)\n\t\t- - Limited headset support\n\t\t- - Intuitive meeting support tools\n\t\t- - No back end integration\n\t- ##### MeetinVR\n\t\t-\n\t\t- Good enough graphics, pretty mature system\n\t\t-\n\t\t- OK indicative avatars, user selected\n\t\t-\n\t\t- VR first design\n\t\t-\n\t\t- Limited scenes\n\t\t-\n\t\t- Smaller groups (12?)\n\t\t-\n\t\t- Quest and PC\n\t\t-\n\t\t- Writing and gestures supported\n\t\t-\n\t\t- Some basic enterprise tools integration\n\t\t-\n\t\t- Bring in 3D objects\n\t\t-\n\t\t- Need to apply for a license?\n\t- ##### Glue\n\t\t-\n\t\t- Better enterprise security integration\n\t\t-\n\t\t- Larger environments, potential for breakouts in the same space. Workshop capable\n\t\t-\n\t\t- 3D object support, screen sharing, some collaborative tools\n\t\t-\n\t\t- Apply for a license\n\t\t-\n\t\t- Fairly basic graphics\n\t\t-\n\t\t- Basic avatars\n\t\t-\n\t\t- Quest and PC\n\t\t-\n\t\t- Writing and gestures supported\n\t\t-\n\t\t- Mac support\n\t- ##### FramesVR\n\t\t-\n\t\t- Really simple to join\n\t\t-\n\t\t- Basic avatars\n\t\t-\n\t\t- Bit buggy\n\t\t-\n\t\t- 3D object support, screen sharing, some collaborative tools\n\t\t-\n\t\t- Quest and PC\n\t\t-\n\t\t- Larger scenes within scenes\n\t\t-\n\t\t- Runs in the browser\n\t- ##### Engage\n\t\t-\n\t\t- Great polished graphics\n\t\t-\n\t\t- Fully customisable avatars\n\t\t-\n\t\t- Limited scenes\n\t\t-\n\t\t- Presentation to groups for education and learning\n\t\t-\n\t\t- PC first, quest is side loadable but that’s a technical issue\n\t\t-\n\t\t- BigScreen VR\n\t\t-\n\t\t- Seated in observation points in a defined shared theatre\n\t\t-\n\t\t- Screen sharing virtual communal screen watching, aimed at gamers, film watching\n\t\t-\n\t\t- up to 12 user\n\t- ##### Gather\n\t\t- Gather is an oddball meeting space based around fully customisable 2Drooms with a game feel. It’s really a spatialised twist on videoconferencing but interesting.\n\t- ##### NEOSVR\n\t\t- [Notable because](https://neos.com/) it’s trying to integrate cryptomarketplaces, but we haven’t tried it yet.\n\t- #### Mixed reality as a metaverse\n\t\t- [Spatial anchors](https://docs.microsoft.com/en-us/windows/mixed-reality/design/spatial-anchors) allow digital objects to be overlaid persistently in the real world. With a global ‘shared truth’ of such objects a different kind of metaverse can arise. One such example is clearly the [[Apple]] [[Vision Pro]]\n\t- #### Augmented reality\n\t\t- Marc Petit, general manager of Epic Games envisages a 2 watt pair ofglasses, connected to a 10 watt phone, connected to a 100 watt computeron the edge. This is a device cascade problem which has not yet beensolved, and is at the edge of achievable thermodynamics and latency.\n\t\t- The closest technology at this time seems to be [Lumus’ waveguideprojectors](https://lumusvision.com/) which are light, bright and highresolution. Peggy Johnson, CEO of Magic Leap, one of the market leaderssaid: it“If I had to guess, I think, maybe, five or so years out, forthe type of fully immersive augmented reality that we do.”\n\t\t- In a [GQprofile](https://www.gq.com/story/tim-cook-global-creativity-awards-cover-2023?mbid=social_twitter)Cook, the Apple CEO talked at length about the challenges andopportunities of AR headsets. He has been emphasizing the importance ofaugmented reality over VR for almost a decade, believing that AR canenhance communication and connection by overlaying digital elements onthe physical world. Cook’s vision aligns with Apple’s rumoured mixedreality headset, which is expected to cost around $3,000 and focus on‘copresence’, which we have discussed at length in this chapter. Apple’sapproach differs from Meta’s metaverse, as Apple aims to integratedigital aspects into the real world rather than create purely digitalspaces. This is an interesting area for our applications of bringingsmall teams together, but the pricing at this time is significantly atodds with our chosen market. Cook, like this book, has highlighted AR’spotential in education and its ability to bring people together in thereal world.\n\t- #### Ubiquitous displays\n\t\t- This includes [laser retinaldisplays](https://skarredghost.com/2022/06/28/mojo-vision-contact-tested-eye/),and smart screens which are context and user aware.",
        "link_types": [
            "Update Cycle",
            "Cook1977; @Kleinke1986; @Fagel2010",
            "Otsuka2005",
            "Kendon1967",
            "Kleinke1986; @Nguyen2009",
            "Aoki2003",
            "kraus2022facebook",
            "park2022metaverse",
            "Metaverse Ontology",
            "gadekallu2022blockchain",
            "iser1993fictive",
            "taylor2009play",
            "glas2013battlefields",
            "chen2011leet",
            "serapis2008coming",
            "cole2013call",
            "Update Cycle",
            "siyaev2021towards",
            "heiphetz2010training; @aldrich2005learning",
            "Apple",
            "Vision Pro"
        ],
        "file_size": 48177
    },
    {
        "id": "Lead Poisoning Hypothesis.md",
        "name": "Lead Poisoning Hypothesis",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- **The Generations Poisoned by Lead: A Global Legacy**\n\t- For decades, the insidious spread of lead poisoned populations across the globe, leaving a lasting impact – particularly on those born between the 1950s and 1980s. From leaded petrol in vehicles to lead-based paint in homes, this toxic metal has left its mark on entire generations worldwide.\n- **The Rise and Fall of Leaded Petrol**\n\t- In 1921, automakers discovered that adding lead to petrol prevented engine knocking, boosting performance. However, even early on, the toxicity of lead was recognised.\n\t- Despite health concerns, leaded petrol became the standard in the decades following World War II, as car ownership boomed globally.\n\t- Lead, expelled through exhaust, settled in soil and dust, poisoning the environment and those who inhaled it.\n- **The Lead-Crime Hypothesis**\n\t- A compelling correlation exists between environmental lead and violent crime trends. Both charts show a similar peak and decline – with lead exposure preceding the crime spike by roughly 23 years.\n\t- Economists like Rick Nevin and Jessica Reyes have studied this relationship extensively, finding convincing links across numerous countries.\n\t- A 2022 meta-analysis further strengthens the lead-crime hypothesis ([https://ideas.repec.org/a/eee/regeco/v97y2022ics0166046222000667.html](https://ideas.repec.org/a/eee/regeco/v97y2022ics0166046222000667.html)).\n- **How Lead Ravages the Body and Mind**\n\t- Lead mimics calcium, disrupting essential processes in bones, muscles, and crucially, the brain.\n\t- **Lead damages the development of myelin, which insulates nerves in the brain.** This leads to slower communication, impaired brain growth, and reduced function in areas like the prefrontal cortex.\n\t- Effects of childhood lead exposure can include:\n\t\t- Lower IQ (loss of 5-8 points)\n\t\t- Increased aggression and impulsiveness\n\t\t- Difficulties with emotional regulation\n\t\t- ADHD, challenges with focus and planning\n- **Lead's Global Consequences**\n\t- While violent crime is the most extreme outcome, lead poisoning likely had widespread impacts on generations around the world.\n\t- Learning difficulties, challenges in the workplace, strained relationships, and even susceptibility to scams could arise from lead exposure.\n\t- Though many nations phased out leaded petrol in the 1970s and onward, the societal effects remain, particularly within ageing populations.\n- **Lead's Persistence and Ongoing Challenges**\n\t- Lead contamination remains a global issue:\n\t\t- Old lead paint in pre-1978 homes\n\t\t- Soil near former industrial areas, busy roadways\n\t\t- Water from aging lead pipes (seen in crises like Flint, Michigan)\n\t- Developing nations and marginalized communities shoulder a greater burden of lead exposure, highlighting environmental injustice.\n\t- There is no safe level of lead exposure.\n- **The Global Fight Against Lead**\n\t- While many nations have reduced leaded petrol use, it remains a problem in some regions.\n\t- Efforts to remediate contaminated soil and replace aging infrastructure are crucial.\n- Continued research into the long-term health effects of lead is vital, especially in developing countries.\n\t- **Environmental Injustice:** Lead poisoning exemplifies how marginalized communities suffer the worst effects of pollution, driven by those prioritising immediate profit.\n\t- **Corporate Responsibility:** Industries must be held accountable for the long-term health consequences of the substances they use, beyond the initial production phase.\n\t- **Chemicals in Our World:** Lead serves as a stark reminder; we must be vigilant about the potential dangers of chemicals widely used today, especially those impacting children's development.\n- **While the peak of lead exposure may be ending, its legacy demands attention on both an individual and societal level. This issue underscores the vital connection between our environment and our health across the globe.**",
        "link_types": [],
        "file_size": 3998
    },
    {
        "id": "Cyber Security and Military.md",
        "name": "Cyber Security and Military",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- [Tech Companies Turned Ukraine Into an AI War Lab | TIME](https://time.com/6691662/ai-ukraine-war-palantir/)\n- ## GPT in spy agencies.\n\t- [Microsoft Develops Secure Generative AI for US Spies (msn.com)](https://www.msn.com/en-gb/money/technology/microsoft-develops-secure-generative-ai-for-us-spies/ar-BB1m1vBa?ocid=msedgdhp&pc=HCTS&cvid=4ae66ceacb324ed785bfa6df68b126cd&ei=16)\n- ## Palantir emerging as global leader in mil AI.\n\t- Early on June 1, 2022, Palantir Technologies CEO Alex Karp and colleagues entered Ukraine, offering their AI and data analytics support for the country's defense against the Russian invasion.\n\t- This move marked a pioneering collaboration between a Western tech firm and Ukraine, aiming to leverage cutting-edge technology in warfare.\n\t- Palantir integrated its data analytics and AI software across multiple Ukrainian government sectors, significantly impacting military strategies and civilian projects.\n\t- The software's capabilities range from analyzing satellite imagery and drone footage for military targeting to supporting evidence collection for war crimes and facilitating refugee resettlement.\n- ## Broader Tech Industry Support\n\t- Besides Palantir, companies like Microsoft, Amazon, Google, and Clearview AI contributed technology and services to Ukraine, enhancing cybersecurity, data management, and identification processes.\n\t- This collective effort underscores a broader trend of tech companies engaging directly in conflict zones, transforming Ukraine into a global tech R&D lab.\n\t- The collaboration is accelerating the integration of AI and autonomous systems in military operations, potentially redefining future warfare.\n\t- Ukraine's situation offers a unique testbed for new technologies, with real-time feedback loops for rapid innovation and deployment.\n- ## Ethical and Strategic Considerations\n\t- The involvement of private tech companies in warfare raises questions about legal, ethical, and privacy concerns, alongside the potential for technology proliferation to adversaries.\n\t- Palantir and other firms' contributions also spotlight the evolving role of the tech sector in national security, with companies acting as de facto defense partners.\n\t- More positively it can contribution to battle damage assessment in Ukraine using machine learning algorithms to analyse imagery and detect changes.\n- # What's already happening\n\t- {{renderer :linkpreview,https://www.theguardian.com/world/2024/apr/03/israel-gaza-ai-database-hamas-airstrikes}}\n\t- [Autonomous F-16 Fighters Are ‘Roughly Even’ With Human Pilots Said Air Force Chief | The National Interest](https://nationalinterest.org/blog/buzz/autonomous-f-16-fighters-are-%E2%80%98roughly-even%E2%80%99-human-pilots-said-air-force-chief-210974)\n\t-\n- # What we can expect\n\t- The potential of AI to dominate warfare in the next decade, exacerbating issues of disinformation and misinformation.\n\t- The accessibility of AI tools for creating realistic content, enhancing the capabilities of bad actors in misinformation campaigns.\n\t- The critical need for investment in data infrastructure and preparation to counter the threats posed by AI in warfare.\n\t- The concept of deterrence in military thinking and how it might evolve with the advent of AI technologies.\n\t- The importance of data as a new form of ammunition in AI-driven warfare.\n\t- The mission of the speaker and like-minded technologists to leverage AI for improving national security and maintaining global stability.\n\t- The urgent call for more technologists to understand the critical nature of the current era and commit to supporting national security efforts.\n\t- Swarms of lethal drones equipped with facial recognition technology.\n\t- Unmanned armed robots that are nearly impossible to defeat.\n\t\t- {{video https://www.youtube.com/watch?v=KX0ji1sAXl8}}\n\t- Autonomous fighter jets capable of supersonic speeds and enduring greater gravitational forces than human pilots.\n\t- Cyberattacks aimed at disabling critical port infrastructure.\n\t- Disinformation campaigns and deepfakes that can manipulate presidential elections.\n\t- Foreign adversaries capable of disabling satellites, impairing global surveillance and communication.\n- # China vs The West\n\t- China ahead in computer vision AI and rapidly catching up in large language models.\n\t- China's military spending, especially in AI, dwarfing that of the United States.\n\t- The critical role of data in AI warfare, with the current underutilization of data from U.S. military assets being a significant disadvantage.\n\t- The reluctance of the U.S. tech industry to engage in government contracts, hindering AI advancements in defence.\n\t- China demands signoff and approval on all new [[Large language models]]\n\t- USA invokes defence production act to force cloud providers to monitor training, and asserts all USA training should notify the pentagon. [OpenAI and Other Tech Giants Will Have to Warn the US Government When They Start New AI Projects | WIRED](https://www.wired.com/story/openai-tech-giants-us-government-ai-projects/)\n\t- ```text\n\t  \"A new Chinese study claims that machine gun-armed robot dogs are as accurate as trained human marksmen. \n\t  If true, we could be about to witness a revolution of sorts in urban warfare.\"\n\t  The study’s findings were published in the peer-reviewed journal The Chinese Journal of Engineering last month.\n\t  According to the research team, they have developed a special weapon mount specifically designed for the task. \n\t  This contrasts with American attempts that, in effect, just strap a weapon to the back of the robot dog.\n\t  “The urban landscape, with its maze of intersecting streets and towering edifices packed tightly together, \n\t  poses unique challenges for unmanned combat platforms. These platforms must negotiate unstructured terrain \n\t  and execute intricate actions such as maneuvering, scaling, and leaping – rendering traditional wheeled and \n\t  tracked designs inadequate,” added the team.\"\n\t  https://interestingengineering.com/military/robot-dogs-better-sharpshooters-study\n\t  ```",
        "link_types": [
            "Large language models"
        ],
        "file_size": 6137
    },
    {
        "id": "Convergence.md",
        "name": "Convergence",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- # Artificial Intelligence\n\t- The development of [[Artificial General Intelligence]] (AGI) and Artificial Superintelligence (ASI) is highly controversial and debated. Experts disagree on the likelihood, timeline, and implications of these advanced AI systems\n\t- AGI/ASI may not have human-like emotions, desires, or anthropomorphised traits that we imagine. Its cognition and intentions could be entirely alien and incomprehensible to us\n\t- It's unclear whether an AGI/ASI would be sympathetic and protective of humanity as an \"ancestor\" species, or view us as irrelevant and expendable. Both scenarios are conceivable\n\t- China's model of a more closed, centralized, state-controlled technology ecosystem could potentially be applied to AGI development. This could allow for more rapid, coordinated, and sandboxed AGI research compared to a fragmented global effort\n\t- In the near-term, AI presents major risks around privacy, surveillance, manipulation, and control at the hands of corporations and governments. Regulation is needed to curtail abuses of the technology.\n\t- AI-generated content is rapidly proliferating online and has the potential to flood the digital landscape, displacing human-created art/music/writin. This could lead to cultural homogenisation and stagnation, or more likely a fracturing of common purpose.\n\t- If AI renders broad swaths of human labour obsolete, we could face severe economic disruption and inequality if social policies (e.g. universal basic income) are not in place to ensure a humane transition\n\t- If not properly controlled and aligned, an advanced AGI/ASI could pose an existential catastrophic risk to humanity. A super-intelligent AI may pursue goals misaligned with human interests and wellbeing\n\t- The companies and countries that develop AGI/ASI first will have an unprecedented concentration of power and competitive advantage. A unipolar AGI scenario is dangerous if the technology is not developed carefully in a globally collaborative manner\n\t- AI will give humans \"superpowers\" by acting as an always-available intelligent assistant deeply integrated into XR interfaces. AI will allow us to instantly access knowledge and skills beyond our own abilities\n\t- In the long-term, (post-[[Singularity]] future?), super-intelligent AI could potentially solve major human challenges like scarcity, leading to an abundant \"techno-utopian\" society. There is a possibility that ASI treats humanity with compassion\n\t- AI is a critical catalyst and requirement for the growth and advancement of XR. AI enables key XR functionalities like environment scanning, voice/eye/hand tracking, and increasingly photorealistic avatar creation\n\t- Synthetic training data generated by AI may eventually surpass real-world data in terms of producing high-quality AI models\n\t- AI could greatly enhance education by enabling personalized one-on-one tutoring and adapting to each student's learning style and pace\n- # Extended Reality / Mixed Reality / [[Spatial Computing]]\n\t- XR (VR/AR/MR) will eventually become the primary way we interact with digital information, as it aligns with how our brains naturally process information in 3D space. The merging of the physical and digital worlds is inevitable\n\t- The metaverse, while currently overhyped, ultimately represents the future of an interconnected network of virtual worlds. As XR technology advances, we will increasingly operate in virtual worlds as naturally as we do in the physical world today\n\t- The early metaverse will start off as walled gardens controlled by large tech companies. However, it's plausible that more open standards, interoperability, and decentralization will emerge over time, similar to the evolution of the early Internet\n\t- Bystander privacy is a major concern with always-on AR glasses and headsets. People may have their data captured without consent just by being in the presence of someone wearing XR devices\n\t- XR and AI are highly complementary and will help address each other's limitations. AI will make the metaverse possible, while the metaverse will provide an outlet for human creativity and self-actualization in a post-labor world\n\t- XR has the potential to greatly enhance fields like medicine, education, and industrial design by providing rich spatial computing interfaces.\n\t- The lack of compelling content and experiences has been a limiting factor for XR adoption. However, AI-generated assets could help solve this content bottleneck and enable the rapid creation of photorealistic virtual worlds\n\t- Privacy and security remain ongoing concerns in XR ecosystems, as they capture even more biometric and behavioral data than traditional computing interfaces\n\t- VR in particular still faces physiological challenges around multi-sensory immersion (e.g. locomotion) that will need to be solved before the technology can go fully mainstream\n- # Convergence\n\t- The intersection of AI, XR, and open, decentralized networks represents a powerful convergence of technologies that could reshape the fabric of our social and economic lives. By leveraging the unique strengths of each domain\n\t\t- the immersive power of XR, the intelligence and adaptability of AI, and the openness and composability of decentralized protocols\n\t\t- we can create a more vibrant, dynamic, and equitable digital future. However, realizing this potential will require careful design, collaboration, and governance to ensure that these technologies develop in a way that promotes human agency, privacy, and flourishing.\n\t-\n\t- AI and XR are deeply intertwined and mutually reinforcing technologies\n\t\t- AI is a critical enabler for XR, powering key functionalities like environment understanding, natural interaction, and content creation\n\t\t- XR provides a rich, immersive interface for AI systems to interact with humans and the physical world\n\t- The combination of AI and XR will give rise to new forms of human-machine collaboration and augmentation\n\t\t- AI-powered virtual assistants will be deeply integrated into XR environments, providing real-time guidance, knowledge, and skills enhancement\n\t\t- XR will provide a spatial computing platform for AI systems to learn from and interact with the world in more natural and intuitive ways\n\t- The intersection of AI and XR will blur the lines between the physical and digital worlds\n\t\t- AI will enable the creation of photorealistic virtual environments that are increasingly indistinguishable from reality\n\t\t- XR will allow for seamless blending of digital content and experiences into the physical world, creating a unified \"metaverse\"\n\t- AI and XR will intersect to create new forms of social interaction and collaboration\n\t\t- AI-driven avatars and agents will facilitate rich, immersive social experiences in virtual worlds\n\t\t- XR will provide a shared spatial context for humans and AI systems to interact and collaborate in real-time\n\t- The intersection of AI and XR will give rise to new economic models and value creation opportunities\n\t\t- Virtual goods, experiences, and services will become increasingly valuable in immersive XR environments\n\t\t- AI will enable the creation of personalized, adaptive, and intelligent virtual assets and experiences\n\t- The combination of AI and XR will raise new ethical and societal challenges\n\t\t- The blurring of physical and digital reality may have profound impacts on privacy, identity, and social norms\n\t\t- The increasing power and pervasiveness of AI systems in XR environments may raise concerns around control, transparency, and accountability\n\t- Open, decentralized networks will be critical for enabling seamless value transfer and interoperability in the metaverse\n\t\t- Centralized, walled-garden approaches will limit innovation and user choice\n\t\t- Open standards and protocols will allow for greater composability and network effects\n\t- Blockchain technologies like Bitcoin, particularly with Layer 2 and Layer 3 solutions, can provide a foundation for secure, efficient, and scalable value transfer in XR/AI ecosystems\n\t\t- Bitcoin's decentralized, trustless architecture aligns well with the open, permissionless ethos of the metaverse\n\t\t- Layer 2 solutions like Lightning Network can enable fast, low-cost microtransactions for virtual goods and services\n\t\t- Layer 3 protocols can enable additional functionality and interoperability on top of the core Bitcoin blockchain, including governance models\n\t- Cryptographic tokens and smart contracts can enable new forms of value creation, ownership, and exchange in XR/AI environments\n\t\t- Unique and fungible digital objects (RGB20/21) can provide provable ownership and scarcity for virtual assets at scale\n\t\t- Decentralised autonomous organizations (DAOs) can enable new forms of community governance and collaboration\n\t- Interoperability and composability will be key for enabling value transfer across different XR/AI platforms and experiences\n\t\t- Open standards for identity, asset ownership, and data portability will allow users to seamlessly move between virtual worlds\n\t\t- Bridges and cross-chain protocols can enable value transfer and communication between different blockchain networks\n\t- Decentralised finance (DeFi) protocols can provide new avenues for earning, investing, and monetising value in XR/AI ecosystems\n\t\t- Virtual real estate, goods, and services can be tokenized and traded on decentralized exchanges\n\t\t- Lending, borrowing, and staking protocols can provide new ways to generate yield and incentivize participation\n\t- Privacy and security will be critical considerations for value transfer in open XR/AI networks\n\t\t- Zero-knowledge proofs and other advanced cryptographic techniques can enable privacy-preserving transactions and interactions\n\t\t- Multi-party computation and secure enclaves can allow for trustless collaboration and data sharing between AI agents\n-\n- [Disney invests $1.5bn in Fortnite maker Epic Games to create new ‘universe’ | Walt Disney Company | The Guardian](https://www.theguardian.com/film/2024/feb/07/disney-fortnite-merger-epic-games-new-universe)\n-",
        "link_types": [
            "Artificial General Intelligence",
            "Singularity",
            "Spatial Computing"
        ],
        "file_size": 10077
    },
    {
        "id": "Proprietary Large Language Models.md",
        "name": "Proprietary Large Language Models",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n- ## Closed source Large Language Models: and [[AI Companies]]\n\t- ![1712680210067.jpeg](../assets/1712680210067_1712686278817_0.jpeg)\n\t- [LinkedIn post from Peter Gostev](https://www.linkedin.com/posts/peter-gostev_we-are-seeing-some-clear-categories-emerge-activity-7183501457684365314-iihT?)\n\t-\n\t- ### OpenAI & ChatGPT\n\t\t- 🟢 ChatGPT mobile [app revenue suggests](https://techcrunch.com/2023/10/09/chatgpts-mobile-app-hit-record-4-58m-in-revenue-last-month-but-growth-is-slowing/) around 250,000 users of their pro service **globally**. That is much lower than I thought... Let's assume only one in ten paying users install the app. That's still 2.5M users, which is about 0.003% of the eligible population.\n\t\t- They have released a [Prompt engineering\n\t\t- OpenAI API](https://platform.openai.com/docs/guides/prompt-engineering) guide.\n\t\t- I have a [[Prompt Engineering]] section too.\n\t\t- The GPT \"store\" / app experience.\n\t\t- A note about GPTs. They really are quite powerful. Think of them as an app builder, containing an AI agent, in a box, with [bidirectional internet](https://medium.com/@michaelev3/connecting-custom-gpts-to-google-apis-726dc2cdb54d), and the ability to build code. (such as which is an excellent coding assistant [Grimoire](https://chat.openai.com/g/g-n7Rs0IK86-grimoire)). - 🟢 They are the most advantage you can get for $20 a month, if you have tasks that you repeat, and you're not a coder. **\n\t\t- Note they now want $25 if you want to keep your data out of their training set.**\n\t\t\t- {{{tweet https://twitter.com/ConsensusNLP/status/1724872225780625419}}}\n\t\t- This is called \"Actions\" and is only in the GPTs or via the API (or both)\n\t\t- 🟢 Microsoft integrates OpenAI right across their suites under the [[Microsoft CoPilot]] brand.\n\t\t  id:: 659a922a-e819-4baa-b323-c07b3cf85290\n\t\t- This is pure speculation, but it feels like Microsoft might eventually effectively take over, being more experienced, mature, and canny.\n\t\t- The novel structural reason for OpenAI existing the way it did (a non-profit with a \"fuse\" for runaway AI) has been broken.\n\t\t- Keep an eye out for the remaining canary in the coal mine which is OpenAI declaring [[Artificial Intelligence]], isolating Microsoft from that element of their models. They might pretend [[Artificial Superintelligence]] for commercial reasons.\n\t- ### Anthropic\n\t\t- Smaller, unsure how much smaller, it's a fork of people from OpenAI, but has radically exceeded earning expectations.\n\t\t- [[Constitutional AI]], like Asimov's laws of robotics\n\t\t- 🟢 [anthropics/sleeper-agents-paper: Contains random samples referenced in the paper \"Sleeper Agents: Training Robustly Deceptive LLMs that Persist Through Safety Training\". (github.com)](https://github.com/anthropics/sleeper-agents-paper)\n\t\t- {{twitter https://twitter.com/natfriedman/status/1777739863678386268/photo/1}}\n\t- ### Grok from Musk is pretty bad, but..\n\t\t- People haven't appreciated the strength of the business model Musk has\n\t\t- His is the only unified language and vision company in the world at this scale that can handle real world interactions.\n\t- ### Google Gemini\n\t\t- Incredible million token context and [[Multimodal]]\n\t\t- Not as capable as Claude3 but writes more human readable text than ChatGPT\n\t\t- [Gemini 1.5 and Google’s Nature – Stratechery by Ben Thompson](https://stratechery.com/2024/gemini-1-5-and-googles-nature/)\n\t\t- For me the interesting one is Nano, which is natively multimodal (4 bit 1-3B) and fits in a phone.\n\t\t- I think we'll look back at Nano as having signalled the future.\n\t- ### Salesforce\n\t\t- Slack. Don't discount Salesforce. Again, if you use slack, stick with this for now. **All** of the tools are coming to **all** of the platforms.\n- # Actionable LLM advice:\n\t- Stick with the tools in the ecosystem you have already bought, until you need more. If your data is in Google use Google. If it's in Microsoft use Microsoft. If you use Runway / Mid journey then please do continue.\n\t- The edge isn't between vendors, it's a deep understanding of what problems you need it to solve, and the disposition of your data, or business technical edge.\n\t- Importance of unique business strategies over proprietary technology. [Harvard Business Review](https://hbr.org/2023/12/strategy-not-technology-is-the-key-to-winning-with-genai).\n\t\t- Necessity for firms to create value beyond technical features.\n\t\t- Focus on building strong brands and exceptional customer experiences.\n\t\t- Significance of strategic human resource management, including talent retention and skill development.\n\t- Sort your data management protocols out. Nobody wants to, but things are getting confusing. For me that's as simple as logseq and github.\n\t\t- Nearly 10,000 data points that reach well into active code and research. (graph).\n\t- The OpenAI kerfuffle last year has alerted companies to the fragility of single providers.\n\t- Consider how business critical the tooling is becoming over time for your business. Have a **NOW / NEXT / LATER** plan. Have and understand options but don't waste too much time exploring them, focus is king.\n\t- There are now many cloud middleware solutions that will handle the prompt realignment, load balancing, pricing etc across the whole [[Proprietary Large Language Models]] [[landscape]].\n\t- I think open source will win in the end because SO many people in the world will be forced and/or want not to use these few hyper centralised providers. **This is a contentious opinion**.\n\t- {{embed ((659fe0be-a52a-42ef-8f50-73695a802945))}}\n\t- https://www.reddit.com/r/StableDiffusion/comments/18tqyn4/midjourney_v60_vs_sdxl_exact_same_prompts_using/\n\t- If your business needs custom **models** then still do as much with off the shelf as you can. You need to be mindful of ethics and the law. This is non-trivial. The team here can help.\n\t- Regardless of the scale and technical proficiency of your team, these tools, especially the open source ones, can provide a rapid way to ask your customers **\"is this what you mean?\"**. People are bad at specifying, but good at instinctive validation. You can then go and manufacture a properly optimised and legally compliant toolchain.\n- This is a [[presentation]] side, and the next slide is [[Proprietary Image Generation]]",
        "link_types": [
            "AI Companies",
            "Prompt Engineering",
            "Microsoft CoPilot",
            "Artificial Intelligence",
            "Artificial Superintelligence",
            "Constitutional AI",
            "Multimodal",
            "Proprietary Large Language Models",
            "landscape",
            "presentation",
            "Proprietary Image Generation"
        ],
        "file_size": 6317
    },
    {
        "id": "Transformers.md",
        "name": "Transformers",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\t - The transformer architecture was proposed by Vaswani et al. in the paper \"[Attention is All You Need](https://arxiv.org/abs/1706.03762)\" published in 2017..\n\t- It introduced the concept of self-attention mechanism to capture dependencies between different words in a sequence.\n\t- This approach outperformed traditional recurrent neural networks (RNNs) on various natural language processing (NLP) tasks.\n\t- Building upon the transformer, Radford et al. introduced \"Generative Pre-trained Transformer\" or GPT, in their paper \"[Improving Language Understanding by Generative Pre-training](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf)\" in 2018. GPT demonstrated impressive performance on language generation and understanding tasks.\n\t- It utilized a large unsupervised neural network trained on a massive amount of text data.\n\t- In 2018, Google AI introduced BERT (Bidirectional Encoder Representations from Transformers) in the paper \"[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\" by Devlin et al.\n\t- BERT achieved state-of-the-art results on a wide range of NLP tasks such as question answering and sentiment analysis. It introduced a new pre-training objective called Masked Language Modeling (MLM) to train a deep bidirectional representation of language.\n\t- In 2019, Dai et al. proposed Transformer-XL in the paper \"[Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](https://arxiv.org/abs/1901.02860)\". Transformer-XL addressed the limitation of the standard transformer regarding its inability to handle long-range dependencies. It introduced the Relative Positional Encoding and Segment-Level Recurrence mechanisms, which improved the model's ability to capture long-term context.\n\t- Facebook AI introduced RoBERTa (A Robustly Optimized BERT Pretraining Approach) in 2019.\n\t- RoBERTa was developed by Liu et al. and detailed in their paper \"[RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)\". It achieved better performance than BERT by optimizing the training process and using larger batch sizes.\n\t- The model was trained with significantly more data and for a longer duration, and this approach dominated the field until recently.al results.\n- {{video https://www.youtube.com/watch?v=wjZofJX0v4M}}\n-",
        "link_types": [],
        "file_size": 2437
    },
    {
        "id": "Bitcoin As Money.md",
        "name": "Bitcoin As Money",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ### Bitcoin as a money\n\t- Nwosu, cofounder of Coinfloor exchange in the UK, and cofounder of the aforementioned Fedimint and says that a digital money needs the following four characteristics:\n\t\t- that it be technically mature.\n\t\t- it should have strong community support and network effect. We have seen that this is more simply a feature of money itself.\n\t\t- that there should be regulatory clarity around the asset, a feature which even Bitcoin currently struggles with.\n\t\t- it should demonstrate a core use case of ‘store of value’ which sounds simple enough, but again is contestable because of the volatility of Bitcoin.\n\t- #### Spending it\n\t\t- Since this book seeks to examine transfer of value within a purely digital environment it is necessary to ask the question of whether Bitcoin is money. This short [‘story’](https://bitcoin-zar.blogspot.com/2018/07/duality-excerpt-by-satoshi-nakomoto.html),purportedly written by Nakamoto, is a fabulous look at the money values of the technology, irrespective if it’s provenance. In it is the following text:\n\t\t\t- “Here, for once, was this idea that you could generate your own form of money. That’s the primary and sole reason, is because it was related to this thing called money. It wasn’t about the proficiency of the code or the novelty, it was because it had to do with money. It centred around money. That is something people cared about. After all, plenty of projects on Sourceforge at the time were just as well coded, well maintained, if not better, by teams, and even if someone else had created the blockchain before me, had it been used for something else beyond currency, it probably would not have had much of an outcome.\n\t\t- Again, irrespective of the author here, this point seems to ring true.The memetic power of Bitcoin is in it’s proximity to ‘money’, and the potential of the separation of money from the state.\n\t\t- It is beyond argument that the Bitcoin network is a rugged message passing protocol which achieves a high degree of consensus about the entries on it’s distributed database.\n\t\t- Ascribing monetary value to those database entries is a social consensus problem, and this itself is a contested topic. The most useful ‘hot take’ here is that Bitcoin behaves most like [a‘property’](https://twitter.com/saylor/status/1395788419301773312),while it’s network behaves far more like a monetary network which is created and supported by the [value of the Bitcointokens](https://saito.tech/an-response-to-paul-krugman-from-a-keynesian-bitcoiner/).\n\t\t- Jack Mallers, of Strike [presentation to theIMF](https://www.youtube.com/watch?v=jb-45m9f76I) identified thefollowing challenges which he claims are solved by the bitcoin monetarynetwork.\n\t\t\t- Speed\n\t\t\t- Limited transparency and dependability\n\t\t\t- High cost\n\t\t\t- Lack of interoperability\n\t\t\t- Limited Coverage\n\t\t\t- Limited accessibility\n\t\t- He further identifies the attributes of the ideal global money.\n\t\t\t- Uncensorable\n\t\t\t- Unfreezable\n\t\t\t- Permissionless\n\t\t\t- Borderless\n\t\t\t- Liquid\n\t\t\t- Digital\n\t\t- Mallers has recently announced USA focused partnerships which leverage his Strike product to enable spending Bitcoin, through Lightning, as Dollars in much of the [point ofsale](https://www.ncr.com/point-of-sale-pos-systems) infrastructure in the USA. This is a huge advance as it immediately enables the vendors both online and at physical locations to either save 3% costs for card processors, or else pass this on as a discount. Crucially for ‘Bitcoin as a money’ it also allows the vendors to receive the payment **as**Bitcoin, not Dollars. A possible further and highly significant feature is that it might now be possible to divest of Bitcoin in the USA, buying goods, without a capital gains tax implication. Mallers claims to have legislative backing for this product, but the devil will likely be in the detail. The likely mechanism for this product is that the EPOS partner sends a Lighting request to Strike, which liquidates some of their Bitcoin holding to a dollar denominated stable coin, but in a tax free jurisdiction such as El Salvador. This stablecoin will then be sent to the EPOS handing partner such as NCR. Stablecoin to Dollar transactions in the USA are much murkier and likely don’t cost anything for these companies. This agent will then authorise the Dollar denominated sale to the American digital till. Crucially nobody has a US capital gains tax exposure in this chain, and all of the settlements were near free, and instantaneous, with ‘cash finality’ for everyone except the EPOS company. They are likely actually exposed to a small risk here because uptake will be very low level. The novelty opportunity will likely cover any potential exposure to stablecoin collapse. This isa radical upgrade on the normal flow of divesting Bitcoin for American users.\n\t\t- Using this open product to spend Bitcoin as Bitcoin to vendors might be available through Shopify globally. Again, it’s too new to be sure. Promisingly a [Deloittestudy](https://www2.deloitte.com/content/dam/Deloitte/us/Documents/technology/us-cons-merchant-getting-ready-for-crypto.pdf) has found that 93% of businesses accepting Bitcoin have seen revenue and brand perception improve, and 75% of USA sales execs plan to accept digital assets at some point in the next 2 years. This ambition in the US markets is likely to benefit from the proposed $200 tax exempt law for purchasing goods and services with Bitcoin.\n\t\t- Of these recent developments in Lightning [Lyn Aldensays](https://twitter.com/LynAldenContact/status/1512188883101966351):itSome people naturally dismiss \\[strike\\] because they don’t want to spend their BTC; they want to save it. However, the more places that accepted BTC at point of sale (on-chain or Lightning or otherwise), the more permissionless the whole network is. This is because, if all you can do with BTC is convert it back into fiat on a major exchange, then it’s easy to isolate it, effectively blacklist addresses, etc. But if you can directly spend it on goods and services across companies and jurisdictions, it’s harder to isolate. There are now plenty of vendors that make this easy for merchants to implement, and the merchant can still receive dollars if they want (rather than BTC), or can decide their % split. Since it’s an open network, anyone can build on it, globally. And then when you add fiat-to-BTC-to-fiat payments over Lightning, it gets even more interesting because it doesn’t necessarily need to be a taxable event. Lightning wallets with a BTC balance and a USD/stable coin balance. Lower fees than Visa and others.\n\t\t- ##### African adoption\n\t\t\t- Africa has one of the most fragmented banking, payment, and currency systems in the world, which makes simple financial tasks like paying a bill, sending money, or accepting money extremely difficult. Over half of Africa does not have access to a bank account, so people hold and save everything in cash, which is often stolen and loses value due to inflation. It is also difficult to get money in and out of many African countries because only about 40% of people have active internet access, and must rely on financial institutions. Bitcoin is being used in Africa as an alternative form of money that resolves these issues. It is being taught in education centers in underdeveloped areas, giving children the opportunity to learn about and use Bitcoin as a way to access financial services that have been unavailable to them for generations. However, the rest of the country may have difficulty implementing the use of Bitcoin due to issues such as a lack of electricity and internet access, as well as government policies that centralize power.\n\t- ##### Bitcoin based FIAT\n\t\t- More interestingly for metaverse applications Mallers has opened this section of the company to interact with the public Lightning network, allowing people with a self hosted wallet or node to pay directly for goods across America, settling immediately in Dollars, using their Bitcoin, at zero cost. **This opens the possibility to buy from US based(Dollar denominated) metaverse stores, using the capabilities of the stack assembled at the end of the book**. The implications globally are unclear at this time.\n\t\t- [Stablesats](https://stablesats.com/) is another approach which uses exclusively lightning bitcoin but makes the value stable against the US dollar using an algorithm. This is a very interesting option and will be explored in detail at some point.\n\t- #### Saving with it\n\t\t- The Bitcoin community believes that [Bitcoin is the ultimate money](https://svetski.medium.com/why-bitcoin-not-shitcoin-6cc826f4fa52),a [‘store ofvalue’](https://www.coindesk.com/business/2022/01/07/jpmorgan-sees-more-crypto-adoption-in-2022-debates-bitcoins-status-as-store-of-value/),chance to [separate money fromstate](https://www.forbes.com/sites/leeorshimron/2020/06/30/bitcoin-is-the-separation-of-money-and-state/?sh=49294a8356db),increase [equality ofopportunity](https://www.washingtonpost.com/national/locked-out-of-traditional-financial-industry-more-people-of-color-are-turning-to-cryptocurrency/2021/12/01/a21df3fa-37fe-11ec-9bc4-86107e7b0ab1_story.html)and [ubiquity ofaccess](https://iai.tv/articles/the-rich-get-richer-the-poor-get-bitcoin-auid-1766),while others view it as [‘ratpoison’](https://www.cnbc.com/2021/06/22/a-third-of-investors-think-bitcoin-is-rat-poison-jpmorgan-survey-says.html),or a [fraudulent Ponzi scheme](https://jacobinmag.com/2022/01/cryptocurrency-scam-blockchain-bitcoin-economy-decentralization).[[ponzi2021alden]]A notable exclusion from the negative rhetoric is Fidelity, the global investment manager, who have always been positive and have [recentlysaid](https://www.fidelitydigitalassets.com/articles/bitcoin-first?sf253214177=1):it“Bitcoin is best understood as a monetary good, and one of the primary investment theses for bitcoin is as the store of value asset in an increasingly digital world.”\n\t\t- The following paraphrases Eric Yakes, author of [‘The 7thProperty’](https://yakes.io/book/). Again, this is an Austrian economics perspective, and like much economic theory the underlying premise [iscontested](https://medium.datadriveninvestor.com/do-you-understand-the-austrian-vs-keynesian-economic-debate-2f4b152c6a6b)[[maurel2012keynesian]]:it“Paper became money because it was superior to gold in terms of divisibility and portability BUT it lacked scarcity. People reasoned that we could benefit from the greater divisibility/portability of paper money as long as it was redeemable in a form of money that was scarce. This is when money needed to be “backed” by something.  Since we changed money to paper money that wasn’t scarce, it needed to be backed by something that was. Since the repeal of the gold standard, politicians have retarded the meaning of the word because our money is no longer backed by something scarce.  So, what is bitcoin backed by? Nothing.  Sound money, like gold, isn’t “backed”. Only money that lacks inherent monetary properties must be backed by another money that maintains those properties. The idea that our base layer money needs to be backed by something is thinking from the era of paper money. Bitcoin does not require backing, it has inherent monetary properties superior to any other form of money that has ever existed.”\n\t\t- The 2022 ARK Big Ideas report again provides some useful market insight. They posit that demand for the money features of Bitcoin could drive the price of the capped supply tokens to around 1M pounds per Bitcoin as inFigure<a href=\"#fig:BitcoinShareOfMoney\" data-reference-type=\"ref\" data-reference=\"fig:BitcoinShareOfMoney\">4.5</a>.Take this with the usual pinch of salt, as Ark have been performing notably badly lately with their predictions.\n\t\t- ![](./assets/2d8ba8fa2b6d41395e8ef074ee3664d4a29df00e.jpg)\n\t\t- Potential market exposure to Bitcoin as a money\n\t\t- Perhaps more than any of these takes, it is worth considering the current public perception of the technology as a money and store of value. This [twitterthread](https://twitter.com/saquon/status/1480738426236375041) from professional sportsman Saquon Barkley, to his half million followers on the platform, captures the mood. He is one of a handful of athletes now being [paid directly](https://www.buybitcoinworldwide.com/athletes/) in Bitcoin.\n\t\t- it“I want my career earnings to last generations. The average NFL career is 3 years and inflation is real. Saving and preserving money over time is hard, no matter who you are. In today’s world: How do we save? This is why I believe in bitcoin. Almost all professional athletes make the majority of their career earnings in their 20s. With a lack of education, inaccessible tools, and inflation, a sad yet common reality is many enter bankruptcy later on. We can do better. We need to improve financial literacy. Bitcoin is a proven, safe, global, and open system that allows anyone to save money. It is the most accessible asset we’ve ever seen.”\n\t\t- This ubiquity of access is what probably most distinguishes Bitcoin. Previously it could be argued that only the most wealthy could access the ‘means’ to store their labour without loss of value over time(through inflation). To be clear, inflation is an important part of the money system, somewhat within the control of the central banks, and approximate to taxation. It applies equally to all holders of the moneys upply. Asserting that money should be replaced by a ‘hard asset’ such as Bitcoin, in the place of the more controllable utility of money, is likely both a fantasy, and wrong minded. This conflation of money and property is a confusion caused by Bitcoin’s proximity to money, and it’s‘ money like’ network, and is extremely commonplace.\n\t\t- These narrative takes are all rooted in the popular idea that Bitcoin isa ‘hedge against inflation’; an increasingly fragile take, as the price plummets with global markets. The Bitcoin community seems somewhat confused about the nature of money, which is predictable because we can see in these sections that money is pretty confusing. Money is the fluid, elastic,[[cagan1958demand]] and thin ‘working credit’ layer on top of historical human production, which provides transaction convenience, and tools for credit. Value is effectively swapped in and out of this layer through the actions of central banks, controlling inflation into acceptable margins. Simplistically this is done through manipulation of interest rates (the easiness of credit), quantitative easing (buying of assets) and quantitative tightening (selling of assets). To give a quick high level view of central bank activity we can use the PESTLE framework:\n\t\t\t- Political:\n\t\t\t\t- Government policies and regulations can impact central banks by influencing monetary policies.\n\t\t\t\t- Political stability and government credibility can impact the confidence in central banks and currency.\n\t\t\t- Economic:\n\t\t\t\t- Economic growth and inflation rates influence central bank decisions on monetary policy.\n\t\t\t\t- The level of debt and balance of payments can impact a central bank’s ability to control monetary policy.\n\t\t\t- Sociocultural:\n\t\t\t\t- Consumer behaviour and demographics can influence demand for money and credit.\n\t\t\t\t- Attitudes towards saving and borrowing can impact the economy and central bank decisions.\n\t\t\t- Technological:\n\t\t\t\t- Technological advancements can change the way money is distributed and managed, such as the increasing use of digital        currencies.\n\t\t\t\t- Technology can also influence the accuracy of economic data, affecting the decisions of central banks.\n\t\t\t- Legal:\n\t\t\t\t- Central banks are subject to laws and regulations, such as those related to banking and finance.\n\t\t\t\t- Changes in laws and regulations can impact central bank policies and operations.\n\t\t\t- Environmental:\n\t\t\t\t- Environmental factors, such as natural disasters, can affect the economy and central bank decisions.\n\t\t\t\t- The focus on sustainability and reducing carbon emissions can impact the decisions of central banks.\n\t\t- Fiat money is primarily it not a long term store of value, as Austrian economists perhaps believe it should be. This function is left to assets. The Austrian thesis of ‘hard money’ (which cannot be ‘debased’ by government action) seems somewhat naïve when one considers that credit exists anywhere in the world (ie, the creation of paper money through loans) then this would be used to buy up a hard money asset in the long run, causing a scarcity crisis. This is what happened to gold in the middle of the last century.\n\t\t- Fundamentally, Bitcoin isn’t money (in the traditional sense) because it’s not an IOU, which money certainly is. It’s a bearer instrument, novel asset class, with money like properties, as identified above. As said again and again it functions most like a ‘property’ which can be invested in by anyone, with all the attendant risks of that property class to the holder. Lyn Alden says it sits [somewhere between](https://www.lynalden.com/what-is-money/) a saving tool, and an investment, acting as “programmable commodity money”.\n\t\t- [Andrew M. Bailey](https://andrewmbailey.com/) says it“in an ideal worldwhere governments honour the rights of citizens, they don’t spy, they don’t prohibit transactions, they manage a sound money supply, and they make sound decisions, the value of bitcoin is very low; we’re just notin an ideal world”\n\t\t- Another potentially important differentiating affordance is censorship resistance. There’s really nothing else like it for that one feature. With that said Bitcoin is only a viable ‘money like thing’ when viewed in the layers described in this book, [and elsewhere](https://giacomozucco.com/layers-before-bitcoin)[[Bhatia2021]].The base chain layer is an apex secure store of value. Whatever layer 2ultimately emerges is the transactional layer which could replace day today cash money, while the hypothetical layer 3 might be useful for complex financial mechanisms and contracts operating automatically, and also provides the opportunity for using the security model of the chain to support other digital assets, including government currencies through stable coins. All these things have a natural home in borderless social spaces.",
        "link_types": [
            "ponzi2021alden",
            "maurel2012keynesian",
            "cagan1958demand",
            "Bhatia2021"
        ],
        "file_size": 18467
    },
    {
        "id": "Stable Coins.md",
        "name": "Stable Coins",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ## Stable-coins\n\t- [Jeremy Allaire](https://x.com/jerallaire/status/1803432989113593890)\n\t\t- ```\n\t\t  What does it look like when 10% of global economic money is stablecoins, \n\t\t  and when credit intermediation moves from fractional reserve lending to \n\t\t  onchain credit markets built from the ground up on safer, digital cash \n\t\t  instruments (e.g. stables), and opens up credit and debt to the long tail\n\t\t  of supply and demand in the same way that Amazon did for commerce and \n\t\t  AdWords did for advertising?\n\t\t  All of this is achievable over the next 10+ years.  \n\t\t  The time goes by fast, but when you zoom out and look at what has\n\t\t  been accomplished and how that sets us up for the future, \n\t\t  it’s hard not to be insanely optimistic right now.\n\t\t  ```\n\t- Stable Coins are ‘crypto like’ instruments which are ‘pegged’ at a 1:1ratio with nationally issued Fiat currencies. In fact they usually correspond to units of privately issued debt underwritten by a variety of different assets. This is (depending on the issuing company’s model)a [far morerisky](https://www.americanbanker.com/opinion/ststablecoins-are-backed-by-reserves-give-us-a-break)unit of money than the nominal currency that they represent, but they offer significant utility. They allow the user to self custody the cryptographic bearer instrument representing the money themselves, as with blockchain. This may afford the user less friction in that they can transmit the instrument through the newer financial rails which are emerging. Once again, this is likely a product most useful to [emergingmarkets](https://www.cigionline.org/articles/the-future-of-fintech-is-unfolding-in-africa/?),those living under oppressive regimes, currencies [suffering from highinflation](https://www.bloomberg.com/news/articles/2022-07-03/argentines-seek-hedging-in-crypto-after-economy-minister-resigns),and countries who rely on the dollar as their currency, and within digitally native metaverse applications. These are enormous global uses though. The use in the west is prominently for ‘traders’ on exchanges at this time. /par The caveat of such products is that such ‘units’ of money can be frozen by the issuer, and they are subject to the third party risk of the issuer defaulting on the underlying instrument, instantly wiping out the value.\n\t- <iframe src=\"https://medium.com/@nic__carter/five-perspectives-on-stablecoins-5bc20076270a\" style=\"width: 100%; height: 600px\"></iframe>\n\t- [Five perspectives on stablecoins. Evaluating the state of the academic… | by Nic Carter | May, 2024 | Medium](https://medium.com/@nic__carter/five-perspectives-on-stablecoins-5bc20076270a)\n\t- Klages-Mundt et al. wrote a paper in 2020, which explains the details ofthe different mechanisms and risks.\n\t- The following text paraphrases Spencer noon of on-chain analytics company “OurNetwork”, who provides an [usefulsummary](https://twitter.com/spencernoon/status/1524752048121466883) of the paper.\n\t- There are two major classes of stablecoins:\n\t\t- Custodial: entrusted by off-chain collateral assets like fiat dollars that sit in a bank. Requires trust in third party.\n\t\t- Non-custodial (aka decentralized): fully on-chain and backed by smart contracts & economics. No trusted parties.\n\t- In custodial stablecoins, custodians hold a combination of assets(currencies, bonds, commodities, etc.) off-chain, allowing issuers(possibly the same entity) to offer digital tokens of an reserve asset.The top 2 custodial stablecoins today are USDT and USDC. There are 3types of custodial stablecoins.\n\t\t- Reserve Fund: 100% reserve ratio. Each stablecoin is backed by a unit of the reserve asset held by the custodian. A useful example of this the [USDF banking consortium](https://www.americanbanker.com/news/bank-stablecoin-consortium-usdf-gets-a-ceo-grows-to-9-members).\n\t\t- Fractional Reserve Fund: The stablecoin is backed by a mix of both reserve assets and other capital assets.\n\t\t- Central Bank Digital Currency (CBDC): A digital form of central bank money that is widely available to the general public. CBDCs are in their nascency as today only 9 countries/territories have launched them, many of them small.\n\t- Custodial stablecoins have three major risks:\n\t\t- Counterparty Risk (fraud, theft, govt seizure, etc.)\n\t\t- Censorship Risk (operations blocked by regulators, etc.)\n\t\t- Economic Risk (off-chain assets go down in value)\n\t- Each can result in the stablecoin value going to zero.\n\t- [Stablecoins and national security: Learning the lessons of Eurodollars | Brookings](https://www.brookings.edu/articles/stablecoins-and-national-security-learning-the-lessons-of-eurodollars/)\n\t- They are collectively likely to outstrip VISA this year\n\t\t- ![Image](https://pbs.twimg.com/media/GCAQhOBaoAAqs-D?format=jpg&name=medium)\n\t- Over 1/3 Made a Purchase in Stablecoins in Latin America, Says Latest MasterCard New Payments Index 2022: Reporting on Fintech,\n\t- Crypto, and Blockchain Activity in Africa<https://bitcoinke.io/2022/07/latin-america-in-mastercard-new-payments-index-2022/>\n\t- According to the latest MasterCard New Payments Index 2022, over one third of people in Latin America made a purchase using\n\t- stablecoins in the past year.\n\t      *  https://bitcoinmagazine.com/legal/u-s-treasury-introduces-cbdc-digital-dollar-working-group\n\t      rbi monetary museum: India's e-rupee unpopular as central banks push digital currency\n\t\t- The Economic Times https://economictimes.indiatimes.com/industry/banking/finance/banking/indias-e-rupee-unpopular-as-central-banks-push-digital-currency/articleshow/99049236.cms?from=mdr\n- ## By the numbers\n\t- It’s worth taking a look at these tokens individually, to get a feel forthe trade-offs, and figure out how they might be useful for us in our proposed metaverse applications. It’s important to know that these tokenised dollars and/or other currencies are issued on top of the public blockchains we have been detailing throughout. Which tokens areon what blockchains is constantly evolving, so it’s not really worth enumerating specifics. In a metaverse application it would be necessary to manage both the underlying public blockchain and the stablecoin issued on top of it, making the interaction with the global financial system perversely more not less complex. In the following list of a fewof the major coins, the first hyperlink is the whitepaper if it’s available.\n\t\t- [USDC](https://f.hubspotusercontent30.net/hubfs/9304636/PDF/centre-whitepaper.pdf) is a dollar backed coin issued by a consortium of major players in the space, most notably Circle, and Coinbase. It’s has a better transparency record than tether but is still not backed 1:1 by actual dollars in reserve. It may or may not be a fractional reserve asset. It’s well positioned to take advantage of regulatory changes in the USA, and seems to be quietly lobbying to be the choice of a government endorsed digital dollar, at least a significant part of a central bank digital currency initiative. It’s too early to tell how this will work out, but it has [substantial ‘legacy finance backing’](https://www.forbes.com/sites/ninabambysheva/2022/04/13/blackrocks-newest-investment-paves-the-way-for-digital-assets-on-wall-street/?). It is the only stablecoin to increase slightly in value (depegging upward) in the wake of the UST implosion. This ‘flight to quality’ shows the advantage of the work that CENTRE put into regulatory compliance. It runs on Ethereum, Algorand, Solana, Stellar, Tron, Hedera, Avalanche and Flow blockchains. At this time USDC may be [under speculative attack](https://twitter.com/Excellion/status/1567472488589963264) by Chinese exchange Binance, in favour of their own offering BUSD, and is losing market share. Payment provider Stripe supports USDC as of 2024.\n\t\t\t- https://twitter.com/collision/status/1783559623511011535\n\t\t\t- {{twitter https://twitter.com/collision/status/1783559623511011535}}\n\t\t- Binance USD is the dollar equivalent token from global crypto exchange behemoth Binance. It’s released in partnership with Paxos, who have a strong record for compliance, and transparency. Paxos also offer USDP. Both these stablecoins claim to be 100% backed by dollars, or US treasuries. They are regulated under the more restrictive New York state financial services and have a monthly [attestation report](https://paxos.com/attestations/).\n\t\t- [MakerDAO Dai](https://makerdao.com/en/whitepaper#abstract) is an Ethereum based stablecoin and one of the older offerings. It’s been ‘governed’ by a DAO since 2014. ‘Excess collateral’, above the value of the dai-dollars to be minted, is voted upon before being committed to the systems’ cryptographic ‘vaults’ as a backing for the currency. These dai can then be used across the Ethereum network. Despite the problems with DAOs, and the problems with Ethereum, DAI is well liked by its community of users and has a healthy billion dollars of issuance. They may be [dangerously exposed](https://thedefiant.io/tornado-impact-makerdao-dai) to the new crackdown in the USA, and there is [internal talk](https://twitter.com/bantg/status/1557733094899138560) of pro-actively abandoning DAI altogether.\n\t\t- [TrueUSD](https://trueusd.com/pdf/TUSD_WhitePaper.pdf) claims to be fully backed by US dollars, held in escrow. It runs on the Ethereum blockchain. They have attestation reports [available on demand](https://real-time-attest.trustexplorer.io/truecurrencies) and claim fully insured deposits. It’s not quite that simple in that a portion of the backing is ‘cash equivalents’.\n\t\t- [Gemini GUSD](https://www.gemini.com/static/dollar/gemini-dollar-whitepaper.pdf) claim reserves are “held and maintained at State Street Bank and Trust Company and within a money market fund managed by Goldman Sachs Asset Management, invested only in U.S. Treasury obligations.” which seems pretty clear.\n\t\t- [TerraUSD](https://assets.website-files.com/611153e7af981472d8da199c/618b02d13e938ae1f8ad1e45_Terra_White_paper.pdf) (UST) **was** a more experimental stable coin, and one of a set of currency representations within the network. It worked in concert with the LUNA token on the Cosmos blockchain in order to keep it’s dollar stability. It was not backed in the same way as the other tokens, instead relying on an arbitrage mechanism using LUNA. In essence the protocol paid users to destroy LUNA and mint UST when the price was above one dollar, and vice versa. This theoretically maintained the dollar peg. There was much concern that this model of [‘algorithmic stable coin’](https://mirror.xyz/damsondao.eth/OVeBrmrfcWm7uKLlA2Q4W1XTVkFU3cMKfNWhgf7mQuM) is unstable.[[clements2021built]] The developers of the Terra tried to address this concern by [buying enormous amounts](https://etherscan.io/address/0xad41bd1cf3fd753017ef5c0da8df31a3074ea1ea) of Bitcoin, which they quickly had to employ to address UST drifting downward from $1. This failed to address the ‘great depegging’, with LUNA crashing to essentially zero, destroying some $50B of capital. It will now likely act as a cautionary tale to other institutions considering Bitcoin as a ‘reserve asset’. An [earlier version of this book](https://github.com/GMCyberFoundry/Metaverse/blob/b06547bf290392d2ff02e5142dae7386d888a9de/Book/04_money.tex#L186) highlighted the specific variation of the risk which quickly manifested.\n\t\t- ### Tether\n\t\t\t- [Tether](https://tether.to/en/whitepaper/) is the largest of the stablecoins, with some $70B in circulation, and the third largest ‘crypto’. This has been a meteoric rise, attracting the ire and scrutiny of [regulators](https://www.cftc.gov/PressRoom/PressReleases/8450-21) and [investigators](https://www.bloomberg.com/news/features/2021-10-07/crypto-mystery-where-s-the-69-billion-backing-the-stablecoin-tether). There was considerable doubt that Tether had sufficient assets backing their synthetic dollars, but the market seems not to mind. Recently however they have transitioned to being backed by US treasury bills, a perfect asset for this use case. It’s resilience against ‘bank runs’ was tested in May 2022 when $9B was redeemed directly for dollars in a few days following the UST crash (more on this later). They are [shortly to launch](https://tether.to/en/tether-to-launch-gbpt-tether-tokens-pegged-to-the-british-pound-sterling/) a GBP version for the UK. It’s an important technology for this metaverse conversation because of intersections with Bitcoin through the Lightning network. Tether might actually provide everything needed. It’s only as safe as the trust invested in the central issuer though, and the leadership and history of the company [are questionable](https://www.wsj.com/articles/tether-ownership-and-company-weaknesses-revealed-in-documents-11675363340). It’s notable and somewhat ironic that it’s perhaps better and more transparently backed than most banks, and probably all novel fiat fintech products. We can employ the asset through the Taro technology described earlier but we would rather use something with higher regulatory assurances.\n\t\t\t\t- [Paolo Ardoino 🍐 on X: \"Today Tether takes the majority stake in @BlackrockNeuro_ and unveils the ultimate pillar of its long term vision and strategy: Tether Evo🧠🦾 First of all, this investment (same as energy, mining, ...) is done outside of stablecoin reserves, with our own company profits (last…\" / X (twitter.com)](https://twitter.com/paoloardoino/status/1784938950525661578)\n\t\t\t\t- {{twitter https://twitter.com/paoloardoino/status/1784938950525661578}}\n\t\t\t- Paolo Ardoino, Tether’s chief technology officer, said in a podcast episode with The Block that USDT is increasingly used for value transfers, making up about **40**% of all token usage, compared to 60% of crypto trading.\n\t\t\t\t- 40% of USDT is now real world use cases, with Tron emerging as the blockchain of the moment.\n\t\t\t\t- Tether as a company makes billions of dollars of profit per year and has global adoption and network effect. The company has around 20 employees. They will likely remain pre-eminent in the synthetic dollar market.\n\t\t\t\t- The USA is positioning to exclude USDT within it's borders, by capping such assets at $10B for [National security reasons.](https://www.brookings.edu/articles/stablecoins-and-national-security-learning-the-lessons-of-eurodollars/)\n\t\t\t\t- Tether is potentially the natural inheritor of the global [[Eurodollar]] system.\n-\n-",
        "link_types": [
            "clements2021built",
            "Eurodollar"
        ],
        "file_size": 14511
    },
    {
        "id": "Comparison of GPT4 and Gemini Ultra.md",
        "name": "Comparison of GPT4 and Gemini Ultra",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- This analysis aims to highlight the strengths, weaknesses, and unique features of each model in various scenarios, including basic inquiries, local search functionalities, trip planning, email composition, data analysis, language tasks, coding capabilities, AI ethics, and creative tasks.\n\t-\n\t- ### **Performance and Speed:**\n\t\t- **ChatGPT-4**: Speed varies; sometimes faster than Gemini Ultra.\n\t\t- **Gemini Ultra**: Also varies in speed; comparable to ChatGPT-4.\n\t- ### **Formatting and Presentation:**\n\t\t- **ChatGPT-4**: More verbose, standard text formatting.\n\t\t- **Gemini Ultra**: Utilizes bold text and larger fonts for clarity.\n\t- ### **Functionality:**\n\t\t- #### Basic Inquiries:\n\t\t- Both models perform similarly in explaining basic concepts and answering various questions.\n\t- #### Local Search:\n\t\t- **ChatGPT-4**: Provides links to sources, no map integration.\n\t\t- **Gemini Ultra**: Integrates with Google Maps, offering a more convenient visualization but limits the number of suggestions.\n\t- #### Trip Planning:\n\t\t- **ChatGPT-4**: Comprehensive, text-based information without embeds.\n\t\t- **Gemini Ultra**: Faster, with embeds for a more engaging presentation.\n\t- #### Email Composition:\n\t\t- **ChatGPT-4**: Generates detailed emails.\n\t\t- **Gemini Ultra**: More succinct; allows direct drafting in Gmail through export feature.\n\t- #### Data Analysis and Visualization:\n\t\t- **ChatGPT-4**: Can interpret and visualize data from uploaded files.\n\t\t- **Gemini Ultra**: Lacks direct upload and visualization capabilities for data files.\n\t- #### Language Tasks:\n\t\t- Both models handle translation and grammar correction competently.\n\t- #### Coding and Development:\n\t\t- **ChatGPT-4**: Strong coding assistance, including SQL queries and web development.\n\t\t- **Gemini Ultra**: Offers code generation with an export option to Replit, though sometimes less detailed than ChatGPT-4.\n\t- ### **Integration Capabilities:**\n\t\t- **ChatGPT-4**: Supports file uploads for direct data analysis.\n\t\t- **Gemini Ultra**: Offers export features for emails, Google Sheets, and Replit, enhancing workflow integration.\n\t- ### **Ethical Considerations and Safety:**\n\t\t- Both models demonstrate awareness of ethical guidelines, refusing to provide information on sensitive or harmful topics.\n\t- ### **Creative Tasks:**\n\t\t- **ChatGPT-4**: Generates creative content with detailed formatting.\n\t\t- **Gemini Ultra**: Offers succinct creative outputs and sometimes provides more engaging formatting options.\n\t- ### **Conclusion:**\n\t\t- Both ChatGPT-4 and Gemini Ultra have their unique strengths and areas for improvement. ChatGPT-4 excels in detailed explanations, data analysis capabilities, and coding assistance, making it highly versatile for technical tasks and creative writing. Gemini Ultra, on the other hand, showcases strong integration features, such as direct exports to Gmail, Google Sheets, and Replit, and provides a more user-friendly presentation with its formatting choices and map integrations.",
        "link_types": [],
        "file_size": 3048
    },
    {
        "id": "Proprietary AI Video.md",
        "name": "Proprietary AI Video",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ## OpenAi Sora\n  id:: 661d5f76-bd9c-493d-afc1-efcec299ed24\n\t- proprietary\n\t- OpenAI's Sora model represents a notable advancement in AI video generation. It demonstrates the ability to generate videos up to one minute in 1080p resolution and produce high-resolution images. Sora's flexibility in handling various aspect ratios and resolutions indicates its adaptability in content creation. Its development leverages insights from prior research, including Vision Transformers and advanced training methodologies.\n\t- {{video https://www.youtube.com/watch?v=GqsCMPWaYac}}\n\t-\n\t- **Introduction to Sora**\n\t\t- A groundbreaking AI video generation model by OpenAI, Sora is designed to transform text instructions into realistic and imaginative video scenes, marking a significant advancement in creative AI technologies.\n\t- **Technical Overview**\n\t\t- **Advanced Diffusion Model**\n\t\t\t- Employs a sophisticated diffusion process that starts from static noise and incrementally refines to generate high-resolution videos, showcasing an unparalleled leap in video realism and complexity.\n\t\t- **Transformer Architecture**\n\t\t\t- Leverages the Transformer model's capabilities for deep understanding and generation of content, adapted here to interpret and create complex visual narratives, ensuring dynamic and coherent video storytelling.\n\t\t\t- [twitter link to the render loading below](https://twitter.com/sainingxie/status/1758433676105310543)\n\t\t\t  {{twitter https://twitter.com/sainingxie/status/1758433676105310543}}\n\t\t\t- [twitter link to the render loading below](https://twitter.com/thatguybg/status/1759935959792312461)\n\t\t\t  {{twitter https://twitter.com/thatguybg/status/1759935959792312461}}\n\t\t\t- **Patch-Based Data Representation**\n\t\t\t\t- Innovatively represents videos and images as collections of smaller data units, akin to language model tokens, enabling precise and granular control over video generation and editing.\n\t- {{twitter https://twitter.com/drjimfan/status/1758355737066299692?s=46}}\n\t- **Creative and Professional Applications**\n\t\t- Opens up endless possibilities for filmmakers, advertisers, educators, and content creators to produce cinema-quality visuals, educational materials, and immersive experiences effortlessly.\n\t- **Democratization of Video Production**\n\t\t- Simplifies the video creation process, enabling individuals and small teams to produce content that rivals big studio outputs.\n\t- **Enhancement of Creative Expression**\n\t\t- Allows creators to bring intricate visions and stories to life through simple text prompts, expanding visual storytelling horizons.\n\t- **Technical Insights**\n\t\t- Designed to scale language model capabilities to visual data, converting videos into patches for efficient processing and diverse video/image handling.\n\t\t- Features a video compression network for temporal and spatial video compression, operating within a [[latent space]].\n\t\t- Uses a diffusion transformer architecture, effectively scaling video generation and improving sample quality with increased compute.\n\t- **Innovative Features**\n\t\t- Works with videos at native sizes to offer sampling flexibility and improve composition and framing.\n\t\t- Leverages descriptive captioning technique, enhancing video fidelity and quality from text prompts.\n\t\t- Can animate still images and extend videos, including seamless interpolation between two videos, showcasing versatility.\n\t- **Emerging Capabilities**\n\t\t- Exhibits capabilities like 3D consistency, long-range coherence, object permanence, and world interaction simulation.\n\t\t- Suggests potential as a tool for simulating physical and digital environments, aiding in the development of capable simulators.\n\t\t- Videos can serve as a basis for constructing detailed 3D scenes using techniques like Neural Radiance Fields (NeRFs), potentially revolutionizing 3D content creation and interaction.\n\t\t- Rapid prototyping and realization of 3D environments and narratives enhance VR and AR immersion and interactivity.\n\t\t- Enables generation of characters, objects, and worlds through text and voice prompts, making 3D content creation more intuitive and accessible.\n\t\t- Already being used to create 360 spherical video.\n\t- **Research and Discussion**\n\t\t- [Video generation models as world simulators (openai.com)](https://openai.com/research/video-generation-models-as-world-simulators) research paper highlights Sora's technical foundation and its role in simulating the physical world.\n\t\t- Discussions emphasize Sora's potential in democratizing video creation and the need for granular output control for artistic purposes.\n- ## Google Veo\n  id:: 664465de-5bd3-4169-a90b-c03f117bef04\n\t- [Google DeepMind on X: \"Introducing Veo: our most capable generative video model. 🎥 It can create high-quality, 1080p clips that can go beyond 60 seconds. From photorealism to surrealism and animation, it can tackle a range of cinematic styles. 🧵 #GoogleIO https://t.co/6zEuYRAHpH\" / X (twitter.com)](https://twitter.com/GoogleDeepMind/status/1790435824598716704)\n\t- {{twitter https://twitter.com/GoogleDeepMind/status/1790435824598716704}}",
        "link_types": [
            "latent space"
        ],
        "file_size": 5154
    },
    {
        "id": "Mixed reality.md",
        "name": "Mixed reality",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\n#Public page\n\t - automatically published\n- # Spatial and Augment Reality\n- ## Apple Vision Pro\n\t- [This thing is mind-blowing 🤯 This demo is better than Apple's actual ads for the Vision Pro. Apple launched the Vision Pro a few days ago,… | Instagram](https://www.instagram.com/reel/C2-G8WgsLSj/?igsh=am93cXF4OWppa29l)\n\t-\n\t- This review (for me) asks the right questions, finally, of \"spatial\".\n\t - https://www.theverge.com/24054862/apple-vision-pro-review-vr-ar-headset-features-price\n\t- Is using the Vision Pro so good that I’m willing to mess up my hair every time I put it on?\n\t- Is it so good that I want to lug it around in its giant carrying case instead of my laptop bag?\n\t- Is it so good that I want to look at the world around me through screens instead of with my own eyes?\n\t- Do I prefer using a computer in there rather than out here.\n\t  \n\t  I stopped working in VR when I tore down my venerable 17 year old augmented virtuality system. That was the right mix, for me, but untenably expensive. Most people will just continue to regard the Apple HMD as an interface that does Apple credit, that they will probably never use. \n\t  \n\t  They don't know that most of the owners will never use them either, but I do.\n- {{video https://www.youtube.com/watch?v=aqTIB_q40bo}}\n- [twitter link to the render loading below](https://twitter.com/bilawalsidhu/status/1759060086977143132)\n{{twitter https://twitter.com/bilawalsidhu/status/1759060086977143132}}\n\t - Meta research paper finally nails down focus with waveguide AR glasses [Waveguide holography for 3D augmented reality glasses | Nature Communications](https://www.nature.com/articles/s41467-023-44032-1)\n- [CES (Pt. 2), Sony XR, DigiLens, Vuzix, Solos, EverySight, Mojie, TCL color µLED – KGOnTech (kguttag.com)](https://kguttag.com/2024/01/24/ces-pt-2-sony-xr-digilens-vuzix-solos-everysight-mojie-tcl-color-%c2%b5led/)\n- [Campus](https://techcrunch-com.cdn.ampproject.org/c/s/techcrunch.com/2022/09/09/roblox-rdc-2022/amp/)\n- Vircadia\n- O3DE\n- [server](https://www.reddit.com/r/O3DE/comments/pbovl9/can_i_develop_my_own_dedicated_server_with_o3de/)\n- [Global lighting](https://www.co3dex.com/blog/image-based-lighting-1/#/)\n- Unreal\n- [Technically this might be a decade away since like everything the primay user base will be mobile mixed realitym, which is contingent on 5G](https://www.matthewball.vc/all/forwardtothemetaverseprimer)\n- book, the metaverse and how it will revolutise everything\n\t- ball2022metaverse\n\t- challenges\n- bandwidth\n\t- latency\n\t- global shared truth\n\t- form factor\n\t- gpu processing\n- [[Humans, Avatars , Character]]\n- [the many challenges of XR hardware](https://www.matthewball.vc/all/why-vrar-gets-farther-away-as-it-comes-into-focus)\n- HCI\n- MoveAI\n- [Meta's wrist reader](https://www.from-the-interface.com/wrist-interfaces/)\n- [Touch music interface](https://scitechdaily.com/groundbreaking-new-technology-allows-people-to-listen-to-music-through-touch/)\n- Interface and tracking\n- Pose estimations\n- [Standable](https://www.standablevr.com/)\n- [Dense face fields from Microsoft](https://microsoft.github.io/DenseLandmarks/)\n- Viveverse web3 nonsense\n- [Meetungs ARE the work](https://medium.com/@ElizAyer/meetings-are-the-work-9e429dde6aa3)\n- Identity\n- [Strongnode identity article on venturebeat](https://venturebeat.com/virtual/identity-in-the-metaverse-creating-a-global-identity-system/)\n- [Solid-lite](https://solid-lite.org/)\n- legal / governance / privacy / safeguarding\n- legal jeopardy for celebrities\n- [Gang sexual assault vice article](https://www.vice.com/en/article/3abpg3/woman-says-she-was-virtually-gang-raped-in-facebooks-metaverse?)\n- [not enough training on safety in africa](https://www.thecable.ng/safeguarding-africans-safety-and-freedom-in-the-metaverse/amp)\n- [How Regulation Will Apply To The Metaverse](https://www.forbes.com/sites/nisaamoils/2023/03/01/how-regulation-will-apply-to-the-metaverse/?)\n- [Podcast on the law](https://www.reply.com/en/metaminutes-s3-e5-legal-challenges-and-regulation-for-the-metaverse)\n- [dai.ki blog post](https://dai.ki/navigating-ai-governance-a-comprehensive-look-at-existing-and-new-eu-and-us-ai-regulations/)\n- Bio vertical\n\t- [NGL protein fold model viewer](https://github.com/nglviewer/ngl)\n\t- [OpenBioML discord](discord.gg/AMRdyPjwBb)\n\t- [Nanome on quest pro](https://www.youtube.com/watch?v=Q-V5EQ-FBMc)\n\t- [Openfold github](https://github.com/aqlaboratory/openfold)\n\t- [Pymol2 open source visualisation](https://github.com/schrodinger/pymol-open-source)\n\t- Alphafold OpenAI\n\t- [Biological structure diffusion](https://github.com/RosettaCommons/RFdiffusion)\n- The RFdiffusion code allows for the running of RFdiffusion simulations. The code is written in Python and is available on GitHub. The code includes a number of features, such as the ability to run simulations on multiple processors and the ability to output results in a variety of formats.\n- [Diagnostics](https://www.amazon.co.uk/AI-Revolution-Medicine-GPT-4-Beyond/dp/0138200130)\n- Market research\n- [Addidas](https://www.adidas.com/into_the_metaverse/mint)\n- [Bubblepunk interiors ML art](https://www.bubblepunk.io/bubblepunk-interiors)\n- [What is a chief metaverse officer (bloomberg)](https://www.bloomberg.com/news/articles/2022-09-22/what-is-a-chief-metaverse-officer-and-do-you-need-one)\n- [Userbase struggles (coindesk)](https://www.coindesk.com/markets/2022/04/06/metaverse-majors-struggle-as-user-base-falls-short-of-market-expectations/?outputType=amp)\n- [Protecting Brands in the Metaverse’s Uncertain Legal Landscape](https://wwd.com/business-news/technology/metaverse-lawsuit-nike-stockx-hermes-metabirken-fashion-1235247763/)\n- [Market research global impact](https://www.analysisgroup.com/globalassets/insights/publishing/2022-the-potential-global-economic-impact-of-the-metaverse.pdf)\n- [McDonalds in the metaverse](https://www.businessinsider.com/mcdonalds-metaverse-virtual-online-restaurant-trademark-delivers-food-web3-nft-2022-2)\n- [Universal music metaverse / web3 team](https://www.musicweek.com/labels/read/universal-music-group-s-digital-strategy-team-creates-key-roles-for-web3-and-the-metaverse/087103)\n- Narratives and convergence\n- [With the help of generative AI it may be possible to democratise the externalisation of complex narratives, with these new narratives shaping the outcomes of society through the medium of the metaverse](https://www.epsilontheory.com/narrative-and-metaverse-pt-3-the-luther-protocol/#.YjyHbnLIE5k.twitter)\n- [A lot of metaverse recently has just been convergence as companies take their existing simulation and repackage it for the moment.](https://thedriven.io/2022/05/23/nissan-and-mitsubishi-unveil-electric-mini-vehicles-and-test-drives-in-metaverse/)\n- Games is the main convergence: from globalblock \"\"More companies are entering the metaverse as global electronics giant Sony has announced their own metaverse push in the latest annual corporate strategy meeting. Sony said this will be a more focused approach, as they aim to use metaverse-inspired experiences to engage users. As Sony owns PlayStation Brands, one of the biggest install userbases in the world, they are in an amazing position to make an impact. They have also revealed that prior investments in Epic, makers of the Fortnite game, and Bungie, another gaming studio, are part of this push.\"\n- -\n- [Epsilomn theory thesis on metaverse](https://www.epsilontheory.com/narrative-and-metaverse-pt-3-the-luther-protocol/#.YjyHbnLIE5k.twitter)\n- [Epic games programming language for the metaverse](https://www.geekmetaverse.com/epic-games-launches-verse-the-metaverse-programming-language/)\n- [Fortnite is the metaverse](https://www.ign.com/articles/how-fortnite-is-the-antidote-to-metaverse-skepticism)\n- [epic unreal for fortnite](https://store.epicgames.com/en-US/p/fortnite--uefn?)\n- Why you should use now generative AI in your metaverse company. Or maybe not\n\t - The Ghost Howls https://skarredghost.com/2023/02/11/generative-ai-metaverse-company/\n- BlackRock digs further into crypto with metaverse ETF https://financefeeds.com/blackrock-digs-further-into-crypto-with-metaverse-etf/\n- China’s iPhone production hub of Henan bets its future on the metaverse | South China Morning Post https://www.scmp.com/tech/policy/article/3194092/chinas-iphone-production-hub-henan-bets-its-future-metaverse\n- Cutting Through the Hotel Hype of the Blockchain, Web3 and the Metaverse | https://hoteltechnologynews.com/2022/08/cutting-through-the-hotel-hype-of-the-blockchain-web3-and-the-metaverse/\n- Experts highlight trust and safety practices for the metaverse https://www.techtarget.com/searchcio/news/252525336/Experts-highlight-trust-and-safety-practices-for-the-metaverse\n- Global Metaverse Market Analysis Report 2022: Blockchain https://www.globenewswire.com/news-release/2022/08/30/2506629/0/en/Global-Metaverse-Market-Analysis-Report-2022-Blockchain-Solutions-in-Support-of-the-Metaverse-Market-will-Reach-148-6-Billion-by-2027.html\n- Identity Management Institute Launches the Metaverse Security Center and Certified Metaverse Security Consultant (CMSC)™ Certification https://www.prnewswire.com/news-releases/identity-management-institute-launches-the-metaverse-security-center-and-certified-metaverse-security-consultant-cmsc-certification-301689276.html\n- Is the metaverse good for business? Why blending the virtual and the real remains a matter of much debate | Fortune https://fortune.com/2022/07/13/business-metaverse-dropbox-brainstorm-tech/\n- Laws and Issues in the Metaverse (2)\n\t - Lexology https://www.lexology.com/library/detail.aspx?g=5a0cc4c0-a876-474e-a719-f528b71b68ee\n- Laying the Foundation of the Metaverse, Streaming Video, Social, Gaming, and Broader Digital Advertising Markets to Collectively Clear US$2 Trillion by 2030 https://www.abiresearch.com/press/laying-the-foundation-of-the-metaverse-streaming-video-social-gaming-and-broader-digital-advertising-markets-to-collectively-clear-us2-trillion-by-2030/\n- Major crypto exchange announces its arrival in the metaverse https://cointelegraph.com/news/major-crypto-exchange-announces-its-arrival-in-the-metaverse\n- Metaverse exploitation and abuse to rise in 2023: Kaspersky https://cointelegraph.com/news/metaverse-exploitation-and-abuse-to-rise-in-2023-kaspersky\n- Metaverse Market Size, Share & Industry Report 2020-2030 https://www.strategicmarketresearch.com/market-report/metaverse-market\n- Metaverse Real Estate Gets Reality Check https://therealdeal.com/2022/08/04/metaverse-real-estate-gets-reality-check/\n- Nissan and Mitsubishi unveil electric mini vehicles, and test drives in metaverse https://thedriven.io/2022/05/23/nissan-and-mitsubishi-unveil-electric-mini-vehicles-and-test-drives-in-metaverse/\n- Nvidia Sees a Metaverse Populated With Lifelike Chatbot Avatars\n\t - CNET https://www.cnet.com/tech/computing/nvidia-sees-a-metaverse-populated-with-lifelike-chatbot-avatars/\n- Room' Offers a Non-Facebook Way to Connect Coworkers in the Metaverse https://uk.pcmag.com/vr-1/143198/room-offers-a-non-facebook-way-to-connect-coworkers-in-the-metaverse\n- The Architecture of the Metaverse (So Far) | ArchDaily https://www.archdaily.com/988639/the-architecture-of-the-metaverse-so-far\n- The battle to build a child-friendly metaverse | Tech News https://tech.hindustantimes.com/tech/news/the-battle-to-build-a-child-friendly-metaverse-71655616713236.html\n- The Metaverse Casino That Wasn’t https://www.coindesk.com/layer2/sinweek/2022/08/29/the-metaverse-casino-that-wasnt/\n- The World's First Virtual Reality Avatar Fashion Week Is On The Metaverse This Week https://womenlovetech.com/the-worlds-first-virtual-reality-avatar-fashion-week-is-on-the-metaverse-this-week/\n- Top 10 Metaverse Platforms that will Replace Social Media in Future https://www.analyticsinsight.net/top-10-metaverse-platforms-that-will-replace-social-media-in-future/\n- Top 15 Metaverse Companies To Watch Out For !! https://www.cryptotimes.io/top-15-metaverse-companies-to-watch-out-for/\n- We're Ready for the Metaverse but the Technology Is Not. Here's Why.\n\t - Decrypt https://decrypt.co/100781/were-ready-for-the-metaverse-but-the-technology-is-not-heres-why\n- [The Photorealistic Metaverse | Welcome to Cornerstone, Cornerstone is a gamified metaverse experience distributed to you via the web browser. Create, co-develop, and monetize your creative idea in the new digital realm.](https://cornerstone.land/)\n- [Mega Yacht Sold for $650,000 in Metaverse, Becomes Most-Expensive NFT in Sandbox Virtual World | Technology News , A mega yacht has been sold for a whopping $650,000 (roughly Rs. 4.8 crore) in the Sandbox virtual gaming world. The pricey digital asset was released by metaverse developer Republic Realm as part of a luxury NFT series.](https://gadgets.ndtv.com/cryptocurrency/news/mega-yacht-sold-usd-650000-metaverse-most-expensive-nft-sandbox-virtual-world-2630187)\n- [Facebook whistleblower warns Metaverse will repeat ‘all the harms’,Frances Haugen says she is worried about privacy and safety inside Meta’s impending Metaverse. Her accusations of profit before safety are still red hot.](https://cointelegraph.com/news/facebook-whistleblower-warns-metaverse-will-repeat-the-harms)\n- [Virtual production and the future of generative art](https://virtualproducer.io/generative-ai-and-the-future-of-filmmaking/)\n- [Zuckerburg disengages from metaverse](https://www.thestreet.com/technology/mark-zuckerberg-quietly-buries-the-metaverse)\n- [Metahouse Could be First of Many\n\t - Los Angeles Business Journal digital twin of a mansion](https://labusinessjournal.com/featured/metahouse-could-be-first-of-many/)\n- [The Future is a Dead Mall\n\t - Decentraland and the Metaverse: Clickbait Title: I spent three months living in the metaverse and now I'm starvingThe metaverse salespeople have a weird fixation with Animal Crossing, in sp...](https://www.youtube.com/watch?v=EiZhdpLXZ8Q)\n- https://www.infosys.com/iki/perspectives/metaverse-insider-guide.html\n- [Everyone abandoning metaverse](https://www.reddit.com/r/CryptoCurrency/comments/128hqkw/meta_microsoft_and_disney_are_reversing_their/)\n- [The Internet Is Ruined. The Metaverse Can Still Be Saved: In this nascent stage, there are opportunities for virtual worlds to avoid the mistakes of the past.](https://www.wired.com/story/metaverse-ethics/)\n- The article discusses how the internet has ruined the Metaverse, and how it can still be saved. It argues that the internet has made the Metaverse less accessible and has made it more difficult to find information. However, it also states that the Metaverse can still be saved if people are willing to work together to make it more accessible and user-friendly.\n- Omniverse\n- [Free to individuals](https://blogs.nvidia.com/blog/2022/01/04/omniverse-available-free-to-creators/)\n- [Full RTX rendering](https://www.youtube.com/watch?v=Jm155QkRjl0&feature=youtu.be)\n- [AI assisted blended character plugin](https://blogs.nvidia.com/blog/2023/02/15/blender-alpha-release-omniverse/?ncid=so-link-466434#cid=ov01_so-link_en-us)\n- [NVIDIA Unveils Powerful AI, Simulation and Creative Tools for Creators and Developers of Virtual Worlds | NVIDIA Blog](https://blogs.nvidia.com/blog/2022/08/09/omniverse-siggraph/)\n- Open metaverse\n- [Open metaverse discord from linux foundation](https://discord.gg/openmetaverse)\n- [Free 1 Million objects](https://huggingface.co/datasets/allenai/objaverse)\n- Usability\n- [bridging the real and the virtual like mcdonalds home delivery](https://www.businessinsider.com/mcdonalds-metaverse-virtual-online-restaurant-trademark-delivers-food-web3-nft-2022-2)\n- Virtual land\n- virtual\n- [hybrid land linking real and virtual (including digital twin)](https://labusinessjournal.com/featured/metahouse-could-be-first-of-many/)\n- Simple geo-referencing of physical place in mixed reality\n- Digital assistants\n- [MultiOn digital assistant](https://multion.ai/)\n- [LEON open source assistant](https://docs.getleon.ai/)\n- [Open source assistant github of issues](https://github.com/LAION-AI/Open-Assistant/issues)\n- Avatars\n- [Free VRChat Models & Avatars | VRCMods (other)](https://vrcmods.com/)\n- [CLIP-Actor Text-Driven Recommendation and Stylization for Animating Human Meshes](https://clip-actor.github.io/)\n- Displaytech\n- [CREAL lens display](https://creal.com/2023/05/19/creals-breakthrough-ar-display-real-depth-with-a-classic-lens/)\n- Autostereoscopic\n- [nanomaterials paper](https://www.mdpi.com/2079-4991/12/3/429#)\n- [Bubbles and speakers](https://www.youtube.com/watch?v=7VLdMXnM0lU)\n- [lightfield labs](https://www.lightfieldlab.com/)\n- The Wall Street Journal has reported that Meta Quest, formerly known as Oculus, had over 6 million monthly active users as of October 2022. This news has generated discussion on the r/virtualreality subreddit, with users speculating about the future of VR and Meta Quest's upcoming products. Some users believe that VR needs more content to attract more users, while others express excitement over the release of Undead Citadel and the possibility of a Starfield VR game. Users also discuss the potential of streaming headsets like the Quest working on the PlayStation 5 and the importance of storytelling in VR games. Some users express disappointment in the launch of the remastered edition of San Andreas and its impact on Quest sales, while others joke about the perceived death of VR. https://www.reddit.com/r/virtualreality/comments/12lpsvf/rumor_meta_quest_had_more_than_6_million_monthly/ Meta urged to prevent minors entering the metaverse https://www.bloomberg.com/news/articles/2023-04-14/meta-urged-to-halt-plans-allowing-minors-into-the-metaverse?leadSource=uverify%20wa\n- It's a valuable tool for video gaming, film industry, and metaverse applications that require 3D scenes. The article discusses how the internet has ruined the metaverse, and how it can still be saved. It argues that the internet has made the metaverse less accessible and more difficult to navigate, and that this has had a negative impact on its potential. The article suggests that the metaverse can still be saved if we take steps to improve its accessibility and make it easier to use.\n   <https://www.wired.com/story/metaverse-ethics/> Exploring Why the Metaverse Hasn't Taken Off as Expected: The metaverse has quickly turned from a profitable utopia into a cash-guzzling dystopia.The text provides an overview of the Metaverse, a virtual world that has not yet taken off as expected. The text describes the potential reasons for this, including the lack of a clear business model and the difficulty of creating an immersive experience.\n   <https://www.bbntimes.com/technology/exploring-why-the-metaverse-hasn-t-taken-off-as-expected> Unfortunately, the requested website (mirror-next-hop.forbes.com) is not accessible and the current session has been terminated with an access denied error (403). Further information can be obtained by contacting the website administrators using the provided reference code (217.138.196.24 2023-06-26T16:51:46.121Z). https://www.forbes.com/sites/charliefink/2023/05/07/this-week-in-xr-after-ai-sucks-the-air-out-of-the-metaverse-it-will-remake-xr/ The Building the Metaverse YouTube channel features a range of videos discussing the use of generative AI and large language models (LLMs) in game development and world-building. One video features a discussion with Kayla Comalli, co-founder and CEO of Lovelace Studios, about their platform Nyric, which generates entire worlds from a text prompt using generative AI technologies like ChatGPT. Other videos on the channel cover topics such as generative art assets for games, AI storytelling and narrative, generative graphics workflow for games, and the use of generative AI in game production. The channel also features discussions with individuals in related fields, such as Edward Saatchi of Fable Studio, who talks about virtual beings and simulated worlds, and Adam B. Levine of Blockade Labs, who discusses Skybox AI and game development. Additionally, there are videos discussing the potential applications of AI in other areas, such as defense and longevity. The channel provides a valuable resource for those interested in learning about the intersection of generative AI and gaming, as well as related topics. https://www.youtube.com/watch?v=fsg83BvsXww The article discusses the potential risks and opportunities of motion tracking data in extended reality (XR) and the metaverse. While this data is often presumed to be innocuous, recent studies have shown that it has the potential to profile and deanonymize XR users, posing a significant threat to security and privacy in the metaverse. The article highlights the need for increased awareness and caution regarding the collection and use of motion data in XR and metaverse experiences. https://arxiv.org/abs/2306.06459 Beauty company Coty has created a metaverse for its 11,000 global employees, using technology from Spatial. The virtual campus is based on 3D tech and tools from Spatial, and aims to develop upskilling and future innovation for Coty brands. The campus includes features such as text and vocal chat forums, screen and filesharing, customisable avatars and location exploration and quest fulfilment, as well as a \"phygital\" rewards system. Coty and Spatial said the campus was a significant milestone in crafting \"new models for scalable gamified experiences\". https://drugstorenews.com/coty-enters-metaverse-campus-global-workforce Tencent Cloud has announced its commitment to support the development of the Web3 ecosystem at the first global Web3 summit. The cloud business of Tencent has unveiled a development roadmap for a full suite of blockchain API services and its Tencent Cloud Metaverse-in-a-Box offering. The platform will provide technical support for Web3 and work with industry partners to nurture the Web3 ecosystem. Tencent Cloud plans to promote sustainable growth by offering Web3 builders cloud solutions credits, marketing workshops and publicity opportunities. It has also signed a Memorandum of Understanding with Ankr, a Web3 infrastructure provider, to jointly develop a full suite of blockchain API services. The API services will cover security, storage, identity management, middleware, development tools, and data analytics, among other areas. https://www.tencentcloud.com/dynamic/news-details/100437?lang=en&pg=\n   <https://www.tencentcloud.com/dynamic/news-details/100437?lang=en&amp;pg=>\n- The concept of a \"predictive metaverse\", an artificial intelligence (AI)-powered advanced form of a virtual world that could predict and anticipate its users' intentions and behaviors, is offering new ways to improve engagement, creativity and personalised learning in [[education]], according to an article in eSchool News by Roger James Hamilton, Founder and CEO of Genius Group. As virtual reality worlds become increasingly sophisticated and realistic, they are also becoming more intelligent and able to analyse data in real-time to deliver tailored recommendations and feedback to individual users, for example to optimise the virtual marketplace to improve user experience and increase sales. https://www.eschoolnews.com/educational-leadership/2023/04/21/predictive-metaverse-the-future-of-guided-learning/\n- Reddit and its partners use cookies and similar technologies to improve the quality of its website, personalize content and advertising, measure advertising effectiveness, and ensure the proper functionality of its platform. By accepting all cookies, users agree to the use of cookies. However, by rejecting non-essential cookies, Reddit may still use certain cookies to ensure the proper functionality of its platform. Reddit's Cookie Notice and Privacy Policy provide more information about its use of cookies. Recently, Meta, Microsoft, and Disney have reversed their bets on the metaverse. Posts related to this topic on r/CryptoCurrency have been removed by moderators. https://www.reddit.com/r/CryptoCurrency/comments/128hqkw/meta_microsoft_and_disney_are_reversing_their/ Exokit, Adrian's opensource mixed reality toolkit for web <https://github.com/exokitxr/exokit>\n- [[Apple]] has acquired Mira, a Los Angeles-based startup that creates AR headsets for various companies and the US military. The acquisition, which was confirmed by [[Apple]], follows the company's launch of its $3,499 mixed reality headset, the Vision Pro. Two former Mira employees said that Jony Ive, [[Apple]]'s former design chief, was an advisor to the startup at one point. Mira's military contracts include a small agreement with the US Air Force and a $702,351 agreement with the Navy while its contract with Nintendo World provides headsets for the Mario Kart ride at its theme parks in Japan and LA's Universal Studios. It is currently unknown if [[Apple]] will continue Mira's military contracts. https://www.theverge.com/2023/6/6/23751350/[[apple]]-mira-ar-headset-startup\n- These posts include insights on the development of XR technology, possible applications, and innovations in the field. https://www.linkedin.com/posts/reneschulte_visionpro-ar-vr-activity-7072953336156602369-_2pL?utm_source=share&utm_medium=member_android\n- [This text is a brief description of a position paper published by the OMA3 Portaling and Mapping Working Group (PMWG) on the transformative technology of portals in the metaverse. The position paper provides insights into the potential of a universal portal system to reshape digital interaction for consumers, businesses, and platforms. It highlights the development process, strategic approach, and vision of OMA3 in setting new standards for the Web3 universe. The paper invites readers to comment on it by creating an issue or commenting in the Google Doc. It also encourages individuals to join OMA3 and participate in the Portaling and Mapping Working Group if they would like to contribute to the project. The paper is licensed under a Creative Commons Attribution 4.0 International License.](https://github.com/oma3dao/portal-position-paper)\n- [The Open Metaverse Alliance for Web3 (OMA3) has announced the Inter-World Portaling System (IWPS) project, aimed at creating standards for seamless travel between metaverse platforms. OMA3, based in Zug, Switzerland, is a consortium of top metaverse companies in Web3. The IWPS project will allow users to walk through inter-world portals and travel between metaverse platforms such as Alien Worlds, My Neighbor Alice, and Sandbox. OMA3 believes that IWPS has the potential to enhance accessibility and engagement within the digital realm by bridging disparate metaverse environments. They compare IWPS to the development of transportation technology like railroads and highways in the industrial revolution and the introduction of the HTTP standard in the digital realm, both of which facilitated the free flow of goods, services, and information. OMA3 has released a position paper outlining the importance of IWPS and inviting participation and comments from the Web3 metaverse community. They see the development and standardization of IWPS as the next frontier in the evolution of the metaverse, enabling new levels of connectivity, commerce, and shared experiences.](https://venturebeat.com/games/oma3-offers-way-for-users-to-travel-between-blockchain-gaming-worlds-in-the-metaverse/)\n- [Beatoven.ai is a website that uses advanced AI music generation techniques to create unique, mood-based music for videos and podcasts. Users can start by choosing a genre or style that suits their theme and then make cuts to reflect different moods throughout their content. With a rich selection of 16 moods to choose from, users can easily find the right mood for each cut. Once the desired moods have been selected, users can hit compose and let the AI algorithm generate a unique track for them.   The website is useful for various types of content creators, including agency/production houses, YouTube creators, podcast creators, indie game developers, audiobook producers, and web3 and metaverse companies. It offers a range of benefits, such as packing a punch in videos, creating a signature sound for YouTube channels, making intro and outro sections special for podcasts, designing themes and background music for games, elevating audio books with atmospheric music, and providing background music for metaverse experiences.   Beatoven.ai also allows users to customize the length, genre, mood, and instruments of their tracks. The resulting music is production-ready with industry-standard mixing and mastering.   The licensing terms for the music on Beatoven.ai grant users a perpetual license for usage on their chosen platforms. All copyrights for the music created on the website belong to Beatoven Private Limited.   The website offers a free membership option, allowing users to create and download music for the first 15 minutes of their projects. There is also a premium pricing plan available for unlimited usage.   Overall, Beatoven.ai is a versatile and user-friendly platform that offers customized, royalty-free music for a wide range of content creators.](https://www.beatoven.ai/)\n- [A predictive metaverse is an advanced virtual world powered by AI and machine learning algorithms. It can predict and anticipate the actions and behaviors of its users, allowing for personalized recommendations, predictions, and feedback. This concept is becoming increasingly appealing to content creators and educators in the field of education, as it can improve engagement and creativity and create personalized learning programs.  In a predictive metaverse, AI algorithms can analyze real-time data to understand the preferences, behaviors, and intentions of users. This information can then be used to optimize the virtual world and improve the user experience. For example, an AI algorithm could predict user behavior in a virtual marketplace, such as what they are likely to buy and when they are likely to buy it. This data can be used to optimize the marketplace and increase sales.  While the term metaverse is often associated with the gaming industry, its potential applications in education are significant. The predictive metaverse can enhance virtual learning by providing personalized guidance and support to students. It can help create immersive learning experiences and improve student engagement and motivation.  As virtual worlds become more sophisticated and realistic, the predictive metaverse holds great promise for the future of guided learning. By harnessing the power of AI and machine learning, educators can create personalized learning experiences that cater to the unique needs and preferences of each student. This technology has the potential to revolutionize education by providing tailored instruction, real-time feedback, and personalized recommendations, ultimately improving student outcomes and overall learning experiences.](https://www.eschoolnews.com/educational-leadership/2023/04/21/predictive-metaverse-the-future-of-guided-learning/)\n- [This text is a Reddit post from the r/CryptoCurrency subreddit. The post mentions that Meta (formerly known as Facebook) as well as Microsoft and Disney are reversing their bets on the metaverse. However, the post has been removed by the subreddit moderators. The comments in the post discuss the current hype around artificial intelligence (AI) and the need for companies to hop on that trend. Some users express their opinions that these companies went about their approach to the metaverse in the wrong way. The post also includes comments about the ownership of a bot that has received a high number of moons (a cryptocurrency earned on the Reddit platform) and speculation on the future of meta platforms like Meta. The post is followed by a list of related crypto news articles from various sources, covering topics such as refunds in crypto scams, acquisitions of Bitcoin, changes in cryptocurrency taxes, and the launch of web3 games by Ubisoft.](https://www.reddit.com/r/CryptoCurrency/comments/128hqkw/meta_microsoft_and_disney_are_reversing_their/)\n- [Tencent Cloud, the cloud business of global tech company Tencent, has announced its commitment to support the development of the Web3 ecosystem. The company unveiled its development roadmap for a full suite of blockchain API services and its Tencent Cloud Metaverse-in-a-Box offerings. It aims to provide a strong technological foundation for Web3 builders and be the digital enabler for the Web3 industry. Tencent Cloud will collaborate with Web3 partners to accelerate the adoption of Web3. The company also signed a Memorandum of Understanding (MoU) with Web3 infrastructure provider Ankr to jointly develop a full suite of blockchain API services. Additionally, Tencent Cloud announced strategic collaborations with Avalanche, Scroll, and Sui, three other Web3 blockchain partners, to build a stronger foundational infrastructure for global builders. The collaboration with Avalanche will explore blockchain solutions for enterprise customers, while the partnership with Scroll aims to scale Ethereum through an open-sourced zk-Rollup. The collaboration with Sui will optimize the on-chain gaming experience. Furthermore, Tencent Cloud introduced Tencent Cloud Metaverse-in-a-Box, a comprehensive solution that integrates infrastructure, products, SDKs, and low-code solutions. The Metaverse-in-a-Box allows businesses to develop metaverse applications rapidly. Tencent Cloud hosted its first global Web3 summit, Tencent Cloud Web3 Build Day, to discuss the latest blockchain landscape and development trends in Web3 games and social networks.](https://www.tencentcloud.com/dynamic/news-details/100437?lang=enandpg=)\n-\n- BrahmGAN is a cutting-edge 3D content creation tool that uses advanced technology such as NeRF, GAN, and Blockchain to create 3D content effortlessly, without requiring technical expertise or complex software. The tool is designed for industries such as eCommerce, XR, and Gaming. BrahmGAN's NeRF solutions for VR Services are capable of creating stunning worlds within days. The company is based in Bengaluru and Singapore. Interested parties can contact them via email at info@brahmgan.com or join their mailing list to stay updated on their latest developments. http://www.brahmGAN.ai\n- Hallway is an app that empowers creators to tell their stories using avatars instead of their real faces, making it easy for anyone to express their creativity without the limitations of video as a medium. It is a single-camera app that supports a variety of avatars and requires no custom hardware or clunky setups. The app is currently taking VTuber and 2D/3D artist intakes to join the waitlist for early access. Hallway provides a new avenue for creators to express themselves and join the next generation of creators. http://joinhallway.com/\n- BrahmGAN is an AI-based 3D content creation platform that uses advanced technologies like NeRF, GAN, and Blockchain for quick and decentralized content creation. BrahmGAN's text-to-3D tools enable users to create 3D content without technical expertise or complex software. BrahmGAN caters to industries like XR, gaming, and eCommerce and uses NeRF for video to 3D, and Blockchain for democratizing 3D content creation globally. BrahmGAN has offices in Bangalore and Singapore and has clients like Taanga Studios. http://www.brahmGAN.ai\n- [In this post on Reddit, a user shares their experience developing a C++ library for running Stable Diffusion, an AI image generation model. They explain that the library does not rely on Python and can use the GPU for executing the AI models involved. The user's main motivation for developing this library was to use its image synthesis capabilities in real-time 3D software written in C++.   The user shares their first results, which include a simple library available as an integration-ready MIT licensed Nuget package, capable of running Stable Diffusion models in ONNX format. They note that the code is currently targeting Windows, but only a small portion related to image editing tasks relies on the WinAPI, which can easily be replaced for other platforms.  Several redditors comment on the post, expressing interest in the library and discussing their own experiences with Stable Diffusion and C++ implementations in machine learning. Some users appreciate the user interface design of the library, while others discuss the advantages and disadvantages of using Python for machine learning tasks.  The user also mentions that they are working on an Xbox release and have already generated Stable Diffusion images on the Xbox. There are further discussions on related topics, such as RAID arrays, graphics libraries for Rust, and C++ language support in Xcode 15.  Overall, the post provides an overview of a C++ library for running Stable Diffusion and highlights the user's experiences and progress in developing it.](https://www.reddit.com/r/cpp/comments/143olej/an_open_source_library_for_running_stable/)\n- [The text is a Reddit post discussing the process of generating and applying AI-generated images to a 3D model. The poster shares the results of their image generation using AI and provides details about the rendering process. They mention using Blender and a custom UV map to project the generated image onto the face of the 3D model.  The poster explains that they manually removed diffuse and specular reflections during the AI image generation stage and conducted additional tests to bring out more details. They aim to create a color map that can be used without adjustments.  Other users in the comments ask about the training process and suggest alternative methods for projection mapping. The poster responds, stating that they did additional training with images that suppress shadows, light, and AO. They also mention that the AI-generated image was baked into a custom UV map before rendering.  Some users express interest in learning the process and suggest creating a tutorial. The original poster mentions that the process takes a lot of time and effort and that the results may vary. They recommend referring to their previous test articles for more information on AI image generation.  The post concludes with a list of related posts from other subreddits discussing topics such as computer vision, AI-generated avatars, and visualizations in Stable Diffusion.](https://www.reddit.com/r/StableDiffusion/comments/11ol47u/3d_model_face_color_map_generation_test3/)\n- The article discusses Reddit's use of cookies and similar technologies to provide a better experience to users. By accepting all cookies, users agree to Reddit's use of cookies to provide and maintain their services, personalize content and advertising, and measure advertising effectiveness. If users reject non-essential cookies, Reddit may still use certain cookies to ensure the proper functionality of the platform. Additionally, the article includes a user-generated post on using Mixamo, a free website with a large library of 3D animations, for character posing. Several commenters offer their own suggestions and recommendations for related tools and workflows on different subreddits. https://www.reddit.com/r/StableDiffusion/comments/11owo31/something_that_might_help_ppl_with_posing/\n- Mixed reality, spatial, metaverse and telecollaboration\n- [The text discusses the use of cookies and similar technologies on Reddit's platform. By accepting all cookies, users agree to the use of cookies to improve their experience, deliver and maintain services, personalize content and advertising, and measure the effectiveness of advertising. Rejecting non-essential cookies still allows Reddit to use certain cookies for proper platform functionality. The text also mentions that more information can be found in the Cookie Notice and Privacy Policy.  The rest of the text is a Reddit post from the r/StableDiffusion subreddit. The post discusses a generalist model that the OP (original poster) will be releasing soon. The model is capable of creating images with resolutions ranging from 1024 to 1080p, and it is fine-tuned on SD 2.1 768X. The model can generate a variety of images, including photorealism, paintings, and anime. The OP shares some example images generated during the training process and invites others to test prompts for image creation. The post receives several comments and discussions about the model's capabilities, potential uses, and suggestions for improvement.  Additionally, the text includes a list of other posts from various subreddits such as r/3dsmax, r/colorists, and r/StableDiffusion. These posts cover topics related to rendering, color grading, using AI-generated visuals, and showcasing artistic works.](https://www.reddit.com/r/StableDiffusion/comments/13j78fo/some_examples_of_the_generalist_model_i_will_be/)\n- Scan the World is a museum of sculptures, artifacts, and statues made possible through 3D scanning and printing technology. The scans of these historical pieces are free to download for accessibility, educational and cultural heritage purposes. Scan the World uses photogrammetry to capture these high-resolution scans, from digital archaeology to downloadable monuments and buildings, 3D printing enthusiasts will be able to find it at the museum. The museum offers more than 20 categories ranging from Africa to South America and everything in between, and it ranks objects based on popularity, date published, and views. Visitors have instant access to the MyMiniFactory library, which is community-powered with users able to upload their 3D printable designs as well. The ultimate goal of Scan the World is to make historical and artistic objects more widely available to people around the world. It’s the perfect solution for those who want to own an authentic, accurate replica of an important sculpture, artifact, or more. https://www.myminifactory.com/category/scan-the-world\n- LinkedIn uses both essential and non-essential cookies to provide, secure, analyze and improve their services, as well as show users relevant ads on and off the platform, according to their Cookie Policy. Users can accept or reject non-essential cookies for this use and can update their choices at any time in their settings. In a post by Rene Schulte, the Head of 3D & Quantum CoPs at Microsoft, he shared resources for Unity developers to prepare for developing for Apple's VisionPro and visionOS. The post sparked conversations and comments from other professionals in the AR/VR industry, including discussions about AR's utility, developments in volumetric video and tracking, and the use of digital twins in building. https://www.linkedin.com/posts/reneschulte_visionpro-ar-vr-activity-7072953336156602369-_2pL?utm_source=share&utm_medium=member_android\n- [The text discusses a research paper on a diffusion model called 3DiM for 3D novel view synthesis. The model takes a single input view and generates consistent and sharp completions across many views. It uses a pose-conditional image-to-image diffusion model that takes a source view and pose as inputs and generates a novel view for a target pose as output. The model employs stochastic conditioning, where a random conditioning view is selected from previously generated views at each denoising step, to improve 3D consistency. The paper introduces a new evaluation methodology called 3D consistency scoring to assess the 3D consistency of the generated objects. The model is geometry-free, does not rely on hyper-networks or test-time optimization, and can easily scale to a large number of scenes.  The paper presents samples generated by 3DiM trained on the ShapeNet dataset. The model achieves high fidelity and approximate 3D consistency in generating completions from a single view. It also demonstrates the model's effectiveness by generating 3D objects from in-the-wild images downloaded from the internet. The paper compares 3DiM to prior work on the SRN ShapeNet benchmark and shows that 3DiM outperforms other methods in terms of generating sharp samples. The paper also discusses the technical details of 3DiM, including its generation process using stochastic conditioning and the modifications made to the image-to-image UNet model to achieve high-quality results.  Overall, the paper highlights the effectiveness of diffusion models for 3D novel view synthesis and introduces novel techniques, such as stochastic conditioning and 3D consistency scoring, to improve the quality and consistency of generated views. The proposed model, 3DiM, shows promising results in generating realistic and consistent 3D objects from a single input view.](https://3d-diffusion.github.io/)\n- [The paper presents a monocular depth estimation method using denoising diffusion models. The goal is to generate accurate depth maps from single RGB images. The authors address the problem of noisy and incomplete depth maps in the training data by using step-unrolled denoising diffusion, an L1 loss, and depth infilling during training.  To overcome the limited availability of supervised training data, the authors leverage pre-training on self-supervised image-to-image translation tasks. Despite the simplicity of the approach, their model achieves state-of-the-art (SOTA) performance on the indoor NYU dataset and near SOTA results on the outdoor KITTI dataset.  The approach involves infilling missing depth in ground truth depth maps using nearest neighbor interpolation. Then, noise is added to the depth map and a neural network is trained to predict the noise given the RGB image and noisy depth map. During fine-tuning, one step of the forward pass is unrolled and the ground truth depth map is replaced with the model's prediction.  The DepthGen model achieves an absolute relative error of 0.074 on the indoor NYU dataset and a competitive relative error of 0.064 on the outdoor KITTI dataset, demonstrating its accuracy in depth estimation.  The paper also introduces a text-to-3D pipeline that combines DepthGen with off-the-shelf text-to-image and text-conditioned image completion models. This pipeline allows for generating 3D point clouds from text prompts.  In conclusion, the proposed method of monocular depth estimation using diffusion models achieves state-of-the-art performance, even with limited supervised training data. The approach is simple yet effective and can be integrated into a text-to-3D pipeline for generating 3D scenes from text prompts.](https://depth-gen.github.io/)\n- [The text provided is a collection of video titles and descriptions related to Blender, AI, and 3D design. The videos cover topics such as creating isometric rooms, using AI in 3D design, Unreal Engine, toon shading in Blender, QR code art, GPT (Generative Pre-trained Transformer) engineering, creating Ghibli-style characters, new features in Blender 3.6, animation in Blender, and adding vegetation in Twinmotion. The videos are created by various individuals and brands, including vertex vendor, Unreal Sensei, Quick QR Art, ENFANT TERRIBLE, Matt Wolfe, Ian Wootten, Brandon's Drawings, Polyfjord, Charlie Barber, and vishal panjeta. The text also mentions a Google company and provides information about cookie usage and privacy settings when using Google services.](https://www.youtube.com/watch?v=GZO7TAlVE_8)\n- [WebXR is a device API that allows for VR/AR experiences through web browsers. However, monetization has been a major issue for the platform, with indie creators struggling to capture value. Most WebXR apps appear as prototypes because developers find it difficult to justify investing more resources into the ecosystem. The current ways people pay for WebXR content include purchasing tickets, using cryptocurrency for virtual land, and accessing certain features by login or ownership of bot handles. The process of paying for WebXR content can be made easier and more frictionless by integrating payment methods like Apple Pay or Google Pay while in VR. Artists can get paid through various means such as commissions, Patreon, grants, VC investment, and event tickets. Non-payment based monetization strategies like advertising are also being explored. A list of 101 ideas for WebXR monetization includes platforms like Patreon and Github Sponsors, virtual market stalls, virtual land parcels, and in-world advertising. Other strategies include payment processing integration with platforms like PayPal or Discord, creating virtual actors and performers, storytelling, and podcast sponsorships. Advertisements targeted at 18-44 year old males interested in software, gaming, and VR have shown promising results. A Github repository for WebXR monetization examples is in progress. Despite these efforts, monetization in the WebXR ecosystem is still a work in progress, and more exploration and innovation is needed.](https://hackmd.io/@xr/monetization)\n- The paper proposes a system called CLIP-Actor, which animates a 3D human mesh to conform to a text prompt by recommending a motion sequence and optimizing mesh style attributes. The system's novelty lies in its ability to recommend motion that conforms to the prompt in a pose-agnostic and temporally-consistent manner while leveraging multi-frame human motion and rejecting poorly rendered views. The authors demonstrate that CLIP-Actor produces plausible and human-recognizable style 3D human mesh in motion with detailed geometry and texture solely from a natural language prompt. The paper's methodology shows that CLIP-Actor is an effective and efficient way to generate plausible results when the pose of an artist-designed mesh does not conform to the text prompt from the beginning. The research has been sponsored by the Korean government's grant funded by the Institute of Information & communications Technology Planning & Evaluation (IITP). https://clip-actor.github.io\n- [The paper CLIP-Actor: Text-Driven Recommendation and Stylization for Animating Human Meshes proposes a system for animating human meshes based on text prompts. The system, called CLIP-Actor, generates motion sequences and optimizes mesh style attributes to conform to a given text prompt.  The authors highlight a limitation of previous work, which struggled to produce realistic results when the starting pose of a pre-designed mesh did not align with the text prompt. To address this issue, CLIP-Actor leverages a large-scale human motion dataset with language labels to build a text-driven human motion recommendation system. It suggests a motion sequence that aligns with the given prompt in a coarse-to-fine manner.  In addition, the authors introduce a novel neural style optimization technique that adds detail and texture to the recommended mesh sequence in a temporally-consistent and pose-agnostic manner. They also propose spatio-temporal view augmentation and mask-weighted embedding attention techniques to stabilize the optimization process by incorporating multi-frame human motion and rejecting poorly rendered views.  The results of CLIP-Actor demonstrate its ability to generate plausible and human-recognizable 3D human meshes in motion with detailed geometry and texture solely from natural language prompts.  The paper includes the BibTeX citation for academic referencing and acknowledges the support received from the Institute of Information and Communications Technology Planning and Evaluation (IITP) in Korea for funding the research.  The website containing the paper and code is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. The source code for the system is mainly borrowed from Keunhong Park's Nerfies website, and feedback and questions can be directed to Kim Ji-Yeon.](https://clip-actor.github.io)\n- [Magic123 is a two-stage solution for generating high-quality, textured 3D meshes from a single unposed image. The first stage optimizes a neural radiance field to create a coarse geometry, while the second stage uses a memory-efficient differentiable mesh representation to produce a high-resolution mesh with realistic textures. The 3D content is learned through reference view supervision and guided by both 2D and 3D diffusion priors. The system includes a tradeoff parameter that controls the balance between exploring novel geometries and achieving precise results. Textual inversion and monocular depth regularization are employed to ensure consistent appearances across views and prevent degenerate solutions. Magic123 outperforms previous image-to-3D techniques, as demonstrated through experiments on synthetic benchmarks and real-world images.  The Magic123 pipeline consists of two stages: coarse and fine. In the coarse stage, an Instant-NGP neural radiance field is optimized to reconstruct a rough geometry. In the fine stage, a DMTet mesh is initialized from the coarse output and optimized to generate a high-resolution mesh with textures. Textural inversion is used in both stages to preserve object geometry and ensure consistent textures across views.  Example generated objects from Magic123 show photo-realistic 3D representations created from single images. The system offers a tradeoff between 2D and 3D priors, allowing for exploration and imagination in geometry generation or precise results with reduced details. By combining both priors and adjusting the tradeoff parameter, Magic123 consistently produces identity-preserving 3D content with fine-grained geometry and visually appealing textures.  Quantitative evaluations on the NeRF4 and RealFusion15 datasets demonstrate the effectiveness of Magic123 compared to previous state-of-the-art approaches. The system achieves top performance across various metrics, showcasing its ability to generate high-quality 3D representations.  The article credits DreamFusion authors for their website templates, and the text is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.](https://guochengqian.github.io/project/magic123/)\n- [The paper Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors presents a two-stage approach for generating high-quality, textured 3D meshes from a single unposed image.   In the first stage, a neural radiance field is optimized to create a coarse geometry. In the second stage, a memory-efficient differentiable mesh representation is used to generate a high-resolution mesh with visually appealing texture.   To learn the 3D content, reference view supervision and novel views guided by a combination of 2D and 3D diffusion priors are employed in both stages. A trade-off parameter controls the balance between exploration and exploitation of the generated geometry.   Textual inversion and monocular depth regularization techniques are also used to ensure consistent appearances across views and prevent degenerate solutions.   The approach, called Magic123, outperforms previous image-to-3D techniques according to extensive experiments on synthetic benchmarks and real-world images.   The code, models, and generated 3D assets are available on GitHub.](https://huggingface.co/papers/2306.17843)\n- This is a conversation and code change history on the GitHub platform for the \"dream-textures\" repository. It appears that the main topic of discussion is the addition of a new feature called \"Project Dream Texture operator\". This feature involves the use of depth-to-image projection to apply a texture to a mesh based on user input. The conversation includes comments and feedback from users who have tested the feature, as well as responses from the repository owner who is implementing the changes. There are also code commits and updates to various files related to the feature and its implementation. https://github.com/carson-katri/dream-textures/pull/409\n- This text appears to be a GitHub pull request for the \"dream-textures\" repository, with the pull request titled \"Add Project Dream Texture operator\". The pull request adds functionality that allows users to project a texture onto a mesh using a text prompt and depth data. The pull request includes a log of commits and comments from users who have tested the functionality and provided feedback. It seems that the pull request has been approved by at least two reviewers and has been merged into the main branch of the repository. https://github.com/carson-katri/dream-textures/pull/409\n         | \n       |\n-\n-\n- [SDFStudio is a unified and modular framework for neural implicit surface reconstruction. It provides an implementation of three major implicit surface reconstruction methods: UniSurf, VolSDF, and NeuS. The framework also supports various scene representations, point sampling strategies, and incorporates advances in monocular cues, geometry regularization, and multi-view consistency. The modular implementation of SDFStudio makes it easy to transfer ideas from one method to another. The repository includes documentation, datasets, and examples for users to get started.  To use SDFStudio, users need to set up the environment by installing CUDA and creating a Conda environment. The framework requires Python 3.7 or higher. Users can install the necessary dependencies, including PyTorch and tiny-cuda-nn, using pip. After installing the dependencies, users can clone the SDFStudio repository and install it using pip. Tab completion can be enabled for better user experience.  To train a model, users can download test data and train a model on a specific dataset using the provided commands. SDFStudio supports different models and parameters can be modified to train different models. The training progress can be tracked using visualization tools such as the viewer, Tensorboard, or Weights and Biases.  Once a model is trained, users can export the mesh and render it. The repository provides commands for extracting the mesh and rendering it. Video rendering and customization of the camera path are also supported. Advanced options include training models other than NeuS-facto and modifying the configuration.  SDFStudio is built on top of the Nerfstudio project and incorporates contributions from various developers. If the library is used or the documentation is found useful, the authors request users to consider citation.  The repository includes a comprehensive README file that provides detailed instructions and explanations for using SDFStudio. It also provides information about the contributors, license, and other resources.](https://github.com/autonomousvision/sdfstudio)\n- [The text summarizes a GitHub repository called CLIP-Actor, which is a pytorch implementation for the ECCV 2022 paper, CLIP-Actor: Text-Driven Recommendation and Stylization for Animating Human Meshes. CLIP-Actor is a system for text-driven motion recommendation and neural mesh stylization for human mesh animation. The repository contains code developed on Ubuntu 18.04 with Python 3.7, CUDA 10.2, and PyTorch 1.9.0. The system requirements include Python 3.7, CUDA 10.2, and a single GPU with a minimum of 24 GB RAM. The repository provides instructions for setting up the environment and installing the required dependencies. It also provides instructions for downloading the necessary body models and datasets. The repository includes example commands to generate stylized 4D human avatars based on prompts, such as a scuba diver is scuba diving or Freddie Mercury is dancing. The outputs include final video files, stylized .obj files, colored render views, and screenshots. The repository includes a citation for the paper and acknowledges the prior work that inspired the CLIP-Actor implementation.](https://github.com/youwang-kim/clip-actor)\n- [Mixed reality design guidelines from Meta](https://developer.oculus.com/resources/mr-design-guideline/)",
        "link_types": [
            "Humans, Avatars , Character",
            "education",
            "Apple",
            "Apple",
            "Apple",
            "Apple",
            "apple"
        ],
        "file_size": 59845
    },
    {
        "id": "Depth Estimation.md",
        "name": "Depth Estimation",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- PatchFusion [zhyever/PatchFusion: An End-to-End Tile-Based Framework for High-Resolution Monocular Metric Depth Estimation (github.com)](https://github.com/zhyever/PatchFusion)\n  title:: Depth Estimation\n- Marigold, [prs-eth/Marigold: Marigold: Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation (github.com)](https://github.com/prs-eth/Marigold)\n- DMD-Mix, [[2312.13252v1] Zero-Shot Metric Depth with a Field-of-View Conditioned Diffusion Model (arxiv.org)](https://arxiv.org/abs/2312.13252v1)\n- ZoeDepth. [[2302.12288] ZoeDepth: Zero-shot Transfer by Combining Relative and Metric Depth (arxiv.org)](https://arxiv.org/abs/2302.12288)\n- [Depth Anything Web\n\t - a Hugging Face Space by Xenova](https://huggingface.co/spaces/Xenova/depth-anything-web) runs in a browser using js",
        "link_types": [],
        "file_size": 862
    },
    {
        "id": "Hardware and Edge.md",
        "name": "Hardware and Edge",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- #Public page automatically published\n- # Wearables\n\t- ### Meta Ray Bans\n\t\t- ![rbm-plp-hero-d-data.mp4](../assets/rbm-plp-hero-d-data_1718993826789_0.mp4)\n\t\t- The Meta Ray-Ban smart glasses, developed in partnership with EssilorLuxottica, offer a range of advanced features in a [stylish form factor](https://about.fb.com/news/2023/09/new-ray-ban-meta-smart-glasses/). Here's a technical overview:\n\t\t- #### Hardware\n\t\t\t- Camera: 12 MP ultra-wide camera for photos and 1080p video recording\n\t\t\t- Processor: Qualcomm Snapdragon AR1 Gen1 Platform\n\t\t\t- Audio: Custom-designed speakers with improved bass and directional audio\n\t\t\t- Microphones: Five-microphone array for immersive audio recording\n\t\t\t- Battery: Redesigned charging case with up to 36 hours of total use\n\t\t- #### Key Features\n\t\t\t- Hands-free photo and video capture\n\t\t\t- Live streaming to Facebook and Instagram\n\t\t\t- Voice commands for various functions\n\t\t\t- Open-ear audio for music and calls\n\t\t\t- Water-resistant (IPX4 rating)\n\t\t\t- Integration with Meta AI assistant\n\t\t- #### Design\n\t\t\t- Available in Wayfarer and new Headliner styles\n\t\t\t- Multiple color options, including transparent frames\n\t\t\t- Prescription-lens compatible\n\t\t\t- Reduced weight and slimmer profile for improved comfort\n\t- The Meta Ray-Ban smart glasses have been well-received, with reports indicating that around 1 million units have been shipped since their launch. To be clear, this modality of vision AR and AI is the future of **all** of this stuff. VR is still very poorly adopted and unloved, given the investment.\n\t- To reach this Meta is developing full AR glasses codenamed Orion, [slated for release in 2027](https://www.theverge.com/2023/2/28/23619730/meta-vr-oculus-ar-glasses-smartwatch-plans). These glasses are designed to work in tandem with a neural interface wristband, allowing for gesture-based control and potentially revolutionizing how we interact with digital content in the physical world.\n\t- ### [Rabbit](https://www.rabbit.tech/)\n\t  id:: 659e5979-c2de-4138-b2df-ede79790ee6d - 🟢 **Description:** A pocket companion that mediates between the user and all their other web services\n\t\t- **Features:**\n\t\t\t- Designed by Teenage Engineering Co\n\t\t\t- Agentic (connect it to your data and it does stuff)\n\t\t\t\t- Needs to be connected to a lot of different user data sources\n\t\t\t- I'm sceptical, but it's a nice effort.\n\t\t\t- It's **cheap**, I would totally give this to a kid over a mobile phone. £200 all in?!?\n\t\t\t- It sold out immediately.\n\t\t\t- {{tweet https://twitter.com/rabbit_hmi/status/1744781083831574824}}\n\t\t\t-\n\t- ### Oura Smart Ring\n\t\t- **Description**: A ring that tracks overall health, focusing on sleep quality, activity levels, and readiness. Finland, not new, fairly mature.\n\t\t- **Features**:\n\t\t\t- Sleep tracking with detailed stages\n\t\t\t- Body temperature sensor\n\t\t\t- Heart rate and HRV tracking\n\t\t\t- 7-day battery life\n\t\t\t- Waterproof and sleek design\n\t\t- **AI Aspect**: Employs AI to analyze data and provide personalized health insights and recommendations.\n\t- ### Amazfit Smart Ring\n\t\t- {{tweet https://twitter.com/AmazfitGlobal/status/1745524225589547012}}\n\t- ### Rewind Pendant\n\t\t- **Description**: A wearable device designed to aid memory by passively capturing audio throughout the day.\n\t\t- **Features**:\n\t\t\t- Auto-records ambient sound\n\t\t\t- Privacy-focused with user-controlled storage\n\t\t\t- Lightweight and can be worn as a necklace\n\t\t\t- Integrates with an app for audio playback\n\t\t- **AI Aspect**: Uses AI to intelligently capture and categorize important sound bites.\n\t- ### Humane Ai Pin\n\t\t- [twitter link to the render loading below](https://twitter.com/jaredostdiek/status/1768674773389713645)\n\t\t  {{twitter https://twitter.com/jaredostdiek/status/1768674773389713645}}\n\t\t- **Description**: A wearable device focused on interaction and connectivity, emphasizing humane and natural tech usage.\n\t\t- **Features**:\n\t\t\t- Connects with various apps and services\n\t\t\t- Aims for minimal and non-intrusive notifications\n\t\t\t- Includes a camera and interactive display\n\t\t\t- Designed to promote ethical AI and user-friendly interfaces\n\t\t- **AI Aspect**: Integrates AI for intuitive interactions and ambient computing.\n\t\t- This attempt at a wearable has been roundly panned by early adopters and reviewers.\n\t\t\t- {{video https://www.youtube.com/watch?v=TitZV6k8zfA}}\n\t- ### Apollo Neuro\n\t\t- **Description**: A wearable wellness device that uses touch therapy to help the body adapt to stress.\n\t\t- **Features**:\n\t\t\t- Delivers gentle vibrations to improve stress resilience\n\t\t\t- Modes for sleep, focus, relaxation, and more\n\t\t\t- Wearable on the wrist or ankle\n\t\t\t- App-controlled\n\t\t- **AI Aspect**: Utilizes AI to personalize and adapt therapy based on user feedback and usage patterns.\n\t- ### Pavlok 3\n\t\t- **Description**: A behavior modification wearable that uses mild electric shock to help break bad habits. (weird)\n\t\t- **Features**:\n\t\t\t- Delivers a mild shock to discourage bad habits\n\t\t\t- Tracks sleep, steps, and hand motions\n\t\t\t- Programmable via an app\n\t\t\t- Community challenges and support\n\t\t- **AI Aspect**: Utilizes AI to learn patterns and optimize intervention timing.\n\t- ### Yopi\n\t\t- **Description**: A voice-based wellness coach focused on improving breathing and reducing stress.\n\t\t- **Features**:\n\t\t\t- Monitors breathing patterns\n\t\t\t- Provides real-time feedback and coaching\n\t\t\t- Portable and pairs with smartphones\n\t\t\t- Focus on breathing exercises and meditation\n\t\t- **AI Aspect**: Uses AI to customize breathing exercises and track progress.\n\t- ### ChatGPT (and whatever Siri becomes) is coming to watches\n\t\t- **Description**: A concept of smartwatches integrated with AI for interactive and adaptive communication.\n\t\t- **Features**:\n\t\t\t- Voice and text-based interaction with AI\n\t\t\t- Integration with various apps and services\n\t\t\t- Notifications, reminders, and AI-driven suggestions\n\t\t\t- Continuous updates and learning capabilities\n\t\t- **AI Aspect**: Incorporates a conversational AI model for real-time communication and assistance.\n\t\t- [Translation earbuds |Translator | language translation device – Mymanu®](https://mymanu.com/) -\n- # Open Source\n\t- [ADeus](https://github.com/adamcohenhillel/ADeus?tab=readme-ov-file#setup-hardware---coral-ai-device)\n\t\t- **Description**: An open source AI wearable device that captures what you say and hear in the real world and then transcribes and stores it on your own server. You can then chat with Adeus using the app, and it will have all the right context about what you want to talk about\n\t\t- a truly personalized, personal AI.\n\t- [OwlAIProject/Owl: A personal wearable AI that runs locally (github.com)](https://github.com/OwlAIProject/Owl)\n\t\t- **Owl** is an experiment in human-computer interaction using wearable devices to observe our lives and extract information and insights from them using AI. Presently, only audio and location are captured, but we plan to incorporate vision and other modalities as well. The objectives of the project are, broadly speaking:\n\t- [Hey Ollama](https://www.reddit.com/r/LocalLLaMA/comments/1b9hwwt/hey_ollama_home_assistant_ollama/)\n\t\t- For HA<->Ollama: [https://github.com/jekalmin/extended_openai_conversation](https://github.com/jekalmin/extended_openai_conversation)\n\t\t- Hardware: [https://www.espressif.com/en/news/ESP32-S3-BOX-3](https://www.espressif.com/en/news/ESP32-S3-BOX-3)\n\t\t- [https://github.com/ollama/ollama/blob/main/docs/openai.md](https://github.com/ollama/ollama/blob/main/docs/openai.md)\n\t\t- [https://github.com/kahrendt/microWakeWord/issues/2](https://github.com/kahrendt/microWakeWord/issues/2)\n\t\t- [https://github.com/jaymunro/esphome_firmware/blob/main/wake-word-voice-assistant/esp32-s3-box-3.yaml](https://github.com/jaymunro/esphome_firmware/blob/main/wake-word-voice-assistant/esp32-s3-box-3.yaml)\n\t\t- Actually you can do full two way conversations! Here's a PR someone has in progress to officially add it to esphome - [https://github.com/esphome/firmware/pull/173](https://github.com/esphome/firmware/pull/173)\n\t- [AI in a Box (crowdsupply.com)](https://www.crowdsupply.com/useful-sensors/ai-in-a-box)\n\t\t- ```Your very own private AI that you can ask questions and get answers, all in a tiny box! The first AI that you can talk to, and that talks back, **running locally with no internet connection** so your conversations and data are completely secure. No account, setup, or subscription are needed, just plug in the box and start chatting. Need closed captions for a live event, or just to help in situations where you have trouble hearing a conversation? We’re using the latest in AI technology to display subtitles based on the audio input, which are output on the built-in display and through an HDMI connector for external monitors or screens.```\n\t\t  id:: 65d5d2b5-36a9-4cac-8efe-18bb9e2559d4\n\t\t- [usefulsensors/useful-transformers: Efficient Inference of Transformer models (github.com)](https://github.com/usefulsensors/useful-transformers)\n\t\t- ![](https://www.crowdsupply.com/img/6605/75c87a10-e0cc-4acf-9f3b-6c498c986605/useful-sensors-ai-box-ready_jpg_md-xl.jpg) -\n- # Phones\n\t- ## Samsung Galaxy S24 Series Local AI Inferencing Features\n\t\t- Live Translate for real-time voice and text translations directly within the phone app, functioning without the need for an internet connection.\n\t\t- Chat Assist in Samsung Keyboard for real-time translation in 13 languages, enabling on-device translation for messages.\n\t\t- Android Auto's capability to summarize messages and suggest relevant replies, powered by on-device AI, for safer driving experiences.\n\t\t- Note Assist for generating AI-powered summaries of notes taken within Samsung Notes, improving organization and retrieval of information.\n\t\t- Transcript Assist uses on-device AI for transcribing and summarizing voice recordings, identifying different speakers and translating content.\n\t\t- Edit Suggestion feature that uses on-device AI to suggest photo edits, enhancing the photography experience without the need for server processing.\n\t\t- Generative Edit for intelligently filling in parts of an image background, providing users with AI-powered content creation tools.\n\t- ## Google sub second inferencing on a phone.\n\t\t- [Paper page\n\t\t- MobileDiffusion: Subsecond Text-to-Image Generation on Mobile Devices (huggingface.co)](https://huggingface.co/papers/2311.16567)\n-\n- # Training and inferencing hardware\n\t- Chips and [[Hardware and Edge]] and things.\n\t\t- [Cristiano Amon: generative AI is ‘evolving very, very fast’ into mobile devices (ft.com)](https://www.ft.com/content/dbc0984b-4801-4aeb-bcab-480704c34161)\n\t\t\t- We’re developing separate computing for AI. Because you can run things on a CPU, you can run things on a GPU, but the GPU and the CPU on your phone are busy doing other stuff. So if you’re going to run AI pervasively, you want to have dedicated accelerated computing — that’s why we also have the NPU [neural processing unit].\n\t\t\t- You’re going to see devices launch in early 2024 with a number of [[Proprietary Large Language Models]] use cases. It has the potential to create a new upgrade cycle on smartphones. And what we want is that eventually you’re going to say, you know, “I’ve been keeping my phone for the past four years . . . Now I need to buy a new phone because I really want this gen AI capability\n\t\t\t- We are seeing gen AI coming into VR. We see an incredible potential for augmented reality and mixed reality glasses, especially as you use audio and large language models as an interface. We have been very bullish about spatial computing being the new computing platform, and we see a lot of promising developments coming: we see what Meta is doing, we see what is happening on the Android ecosystem with Google and Samsung. We are just at the beginning.\n\t\t- Bloomberg reports Sam Altman is in talks to raise money for a ‘global’ network of fabricators building hardware for AI. Sam Altman's plan to establish a global network of AI chip factories could revolutionize the tech industry, reducing dependence on existing semiconductor giants and ensuring a steady supply of AI advancements.\n\t\t- [The Groq LPU™ Inference Engine - Groq](https://wow.groq.com/lpu-inference-engine/) Asic\n\t\t- [Chat with RTX Now Free to Download | NVIDIA Blog](https://blogs.nvidia.com/blog/chat-with-rtx-available-now/)\n\t\t- [AMD Instinct™ MI300 Series Accelerators](https://www.amd.com/en/products/accelerators/instinct/mi300.html)\n\t\t- [IBM custom board](https://www.marktechpost.com/2022/10/27/ibm-research-introduces-artificial-intelligence-unit-aiu-its-first-complete-system-on-chip-designed-to-run-and-train-deep-learning-models-faster-and-more-efficiently-than-a-general-purpose-cpu/)\n\t\t- [Nvidia jetson AI](https://www.okdo.com/p/nvidia-jetson-agx-orin-64gb-developer-kit/)\n\t\t- [install cuda](https://dev.to/ajeetraina/install-cuda-on-jetson-nano-2b06)\n\t\t- [Qualcomm phone SD](https://www.theverge.com/2023/2/23/23611668/ai-image-stable-diffusion-mobile-android-qualcomm-fastest)\n\t\t- [Esperanto RISC V](https://www.esperanto.ai/)\n\t\t- [The MetaVRain asic claims 900x speed increases} on general GPU problems](https://hdh4797.wixsite.com/dhan/project-1)\n\t\t- [Google android etc](https://developers.google.com/learn/topics/on-device-ml)\n\t\t- [Intel meteor lake?](https://www.pocket-lint.com/what-is-meteor-lake-and-how-will-intel-leverage-ai-in-future/)\n\t\t- [Shopify handy](https://github.com/Shopify/handy)\n\t\t- [Comparison of GPUs](https://timdettmers.com/2023/01/16/which-gpu-for-deep-learning/)\n\t\t- [LLM on Intel XEON optmised](https://community.intel.com/t5/Blogs/Tech-Innovation/Artificial-Intelligence-AI/Numenta-and-Intel-Accelerate-Inference-20x-on-Large-Language/post/1471636)\n\t\t- [TPU v4 matrix multiplier](https://cloud.google.com/blog/topics/systems/tpu-v4-enables-performance-energy-and-co2e-efficiency-gains)\n\t\t- [Tinygrad tinybox](https://github.com/geohot/tinygrad/blob/master/docs/showcase.md#stable-diffusion)\n\t\t- [Snapdragon 8 inference](https://www.phonescoop.com/articles/article.php?a=22911) Qualcomm has launched its latest flagship chip, the Snapdragon 8 Gen 2, which is expected to power most Android smartphones next year. The new chip is more power-efficient and powerful compared to its predecessor Gen 1, and features significant improvements and new features in AI. The new Qualcomm AI engine offers an AI performance improvement of up to 4.35x and up to 60% better power efficiency. There is a new direct link between the Hexagon AI cores and the Spectra imaging cores, providing real-time semantic segmentation, and the Sensing Hub has two AI processors and more memory for smarter always-on features. The Kryo CPU cores have also been updated, with four performance cores and three efficiency cores, optimising them for legacy 32-bit apps. On the GPU side, the new Adreno cores support hardware-accelerated raytracing and Unreal Engine 5's Metahumans technology. The X70 modem supports 4-carrier aggregation for downlink speeds of up to 10 Gbps, while the onboard FastConnect 7800 system is the first to support Wi-Fi 7 with High Band Simultaneous Multi-Link. https://www.phonescoop.com/articles/article.php?a=22911\n- # Consumer Hardware\n\t- [Sideloaded app stores are coming to iOS in the EU (thenextweb.com)](https://thenextweb.com/news/sideloaded-app-stores-ios-eu-how-work)\n\t- [AI HoloBox: ChatGPT-Powered Holographic Desktop Companion by AI HoloBox — Kickstarter](https://www.kickstarter.com/projects/752925986/ai-holobox-chatgpt-powered-holographic-desktop-companion?)\n\t-\n- **I don't personally think any of these wearables and gadgets \"break through\" vs watches, but I can see the next generation of watching inferring a LOT more and containing MUCH more functionality. People will wear watches. Sometimes.**\n- # HCI and interfaces\n\t- [Doublepoint launches gesture-touch tech for wearable devices | VentureBeat](https://venturebeat.com/games/doublepoint-launches-gesture-touch-tech-for-wearable-devices/)\n\t- [Meta's wrist reader](https://www.from-the-interface.com/wrist-interfaces/)\n- # Edge\n\t- Edge compute refers to the practice of processing and analyzing data as close to the source as possible, which is typically at the edge of a network. This approach aims to reduce latency and network congestion by performing computations and running applications on devices such as sensors, gateways, or edge servers located near the data source. By moving computational tasks closer to where the data is generated, edge compute enables real-time and low-latency decision-making.\n\t- Edge AI, also known as AI at the edge or on-device AI, refers to the deployment of artificial intelligence and machine learning algorithms on edge devices. By bringing AI capabilities closer to the data source, Edge AI eliminates the need to transmit large volumes of data to the cloud for processing. This approach enables real-time inference and decision-making directly on devices with limited computing resources, such as smartphones, drones, or IoT devices. Edge AI has several advantages, including reduced latency, improved privacy and security, offline functionality, and the ability to operate in disconnected or bandwidth-constrained environments.\n\t- Fog compute, on the other hand, extends the concept of edge compute by introducing a hierarchical architecture. It involves distributing computing resources, storage, and applications between the cloud and edge devices. In the fog computing model, intermediate fog nodes are deployed between edge devices and the cloud, enabling them to process and store data. This approach reduces the need for data to be transmitted to traditional data centers or the cloud, allowing for faster response times, increased security, and better bandwidth utilization.\n\t- Overall, the combination of edge compute, fog compute, and edge AI introduces a distributed computing paradigm that brings processing, storage, and intelligence closer to the data source. This not only improves performance and efficiency but also enables new use cases and applications in various domains, including IoT, smart cities, autonomous vehicles, and industrial automation.\n\t- These systems will drive the compute to less ‘constrained’ but somewhat less capable AI systems, distributing the access but increasing risks. [[Update Cycle]]\n\t\t- [Andrej Karpathy's Baby Llama Runs on Samsung Galaxy Watch 4Baby Llama Runs on Samsung Galaxy Watch 4 (analyticsindiamag.com)](https://analyticsindiamag.com/andrej-karpathys-baby-llama-runs-on-samsung-galaxy-watch-4/)\n\t\t- Baby llama [[Large language models]] with Llama.c is 700 lines of C code!  [karpathy/llama2.c: Inference Llama 2 in one file of pure C (github.com)](https://github.com/karpathy/llama2.c)\n\t\t- ###### Edge AI compute and APUs\n\t\t- [Qualcomm phone chip](https://www.theverge.com/2023/2/23/23611668/ai-image-stable-diffusion-mobile-android-qualcomm-fastest) offers low power and high speed Stable Diffusion on mobiles\n\t\t- IBM have introduced the [concept of the AIU](https://research.ibm.com/blog/ibm-artificial-intelligence-unit-aiu), for high speed and low power training\n\t\t- Nvidia’s [latest in the Jetson](https://www.okdo.com/p/nvidia-jetson-agx-orin-64gb-developer-kit/) Edge AGX line is a high performance general AI unit for industrial applications\n\t\t- Esperanto Risc V chip [claims incredible performance](https://www.esperanto.ai/News/risc-v-startup-esperanto-technologies-samples-first-ai-silicon/) gains\n\t\t- The MetaVRain asic [claims 900x speed increases](https://hdh4797.wixsite.com/dhan/project-1) on general GPU problems\n\t\t- Microsoft are rumoured to be looking to mitigate the staggering costs of running ChatGPT ($1M/day) using forthcoming [hardware of their own design](https://www.theinformation.com/articles/microsoft-readies-ai-chip-as-machine-learning-costs-surge?)\n\t\t- [Cerebras systems](https://www.cerebras.net/) have built an AI architecture from the ground up and claim incredible numbers.\n\t\t- [Ushering in the Thermodynamic Future\n\t\t- Litepaper (extropic.ai)](https://www.extropic.ai/future)\n\t\t- Tenstorrent Grayskull [[Hardware and Edge]]  [Cards\n\t\t- Tenstorrent](https://tenstorrent.com/cards/) -\n- # Displays\n\t- ### Displays & Headset Hardware\n\t\t- Awaiting a bit more market stability for this section. Of note is thatMicrosoft seems to be [abandoningHololens](https://www.windowscentral.com/microsoft/microsoft-has-laid-off-entire-teams-behind-virtual-mixed-reality-and-hololens),and Apple seem to have postponed their commodity AR headset.\n\t\t- Microsoft think that creating the Perfect Illusion, that of alife-likeness in VR will require a field of view of 210 horizontal and135 vertical, 60 pixels per degree subtended, and a refresh rate of 1800Mhz according to Microsoft. They expect this by as soon as2028.[[cuervo2018creating]]\n\t\t- With the advent of[WebGPU](https://developer.chrome.com/docs/web-platform/webgpu/)alongside WebGL everything is likely to converge on the browserexperience.\n\t\t- {{renderer :linkpreview,https://skarredghost.com/2024/04/01/valve-deckard-leaked/}}\n\t- #### The Apple in the Room\n\t\t- Following the announcement of The Apple Vision Pro we start to see theconvergence of spatial computing, mixed reality, locally appliedtransformer based AI, and business. They have perhaps removed “gorillaarm syndrome”[[boring2009scroll]] where hands in the sky interfaces arepotentially uncomfortable over long periods.[[hansberger2017dispelling]]Nathan Gitter and Amy DeDonato from the Apple Design team [introducespatial design for thedevice](https://developer.apple.com/videos/play/wwdc2023/10072/).\n\t- ##### Spatial operating systems\n\t\t- - Enabling users to design experiences not previously possible.\n\t\t- - The presentation outlines how to keep apps familiar, be human-centered, take advantage of space, enhance immersion, and make apps authentic to the platform.\n\t\t- - The world serves as an infinite canvas for new apps and games.\n\t\t- - Existing app elements should be kept familiar with common elements like sidebars, tabs, and search fields.\n\t\t- - In a spatial platform, interfaces are placed within windows to make them easily accessible and part of the user’s surroundings.\n\t- ##### Windows in Spatial Design\n\t\t- - Windows are designed with a new visual language, made of a glass material that provides contrast with the world, awareness of surroundings, and adapts to different lighting conditions.\n\t\t- - Windows can be moved, closed, and resized by users, with windows facing the user during movement.\n\t\t- - Windows are flexible and can be resized to fit comfortably within the user’s view.\n\t\t- - Choosing Window Size and Layout Windows are designed to be flexible, adapting to content, and the window size should be chosen based on this. Windows can change size dynamically based on context.\n\t\t- - Apps can use multiple windows to display content side by side or show distinct actions, but should ideally stick to a single window to avoid user overwhelm.\n\t- ##### Designing with Points\n\t\t- - Interfaces are designed with points to ensure they scale well and remain legible at different distances.\n\t\t- - Points allow designers to set the size of interface elements with familiar units. Human-Centered Design\n\t\t- - Good spatial design places the user at the center, accounting for their field of view and movement.\n\t\t- - The most important content should be placed in the center of the field of view and use landscape layouts.\n\t\t- - Ergonomics should also be considered, placing content along a natural line of sight for comfort.\n\t\t- - Designers should avoid placing content behind users or anchoring content to their view as it can be disorienting.\n\t\t- - Spatial design should aim to create stationary experiences that require minimal movement from users.\n\t\t- ##### User Mobility\n\t\t- The presentation emphasizes the importance of designing applicationsthat require minimal movement from users. It recommends usingsystem-level recentering methods to adjust the app’s view when a usermoves.\n\t\t- ##### Space Utilization\n\t\t- The importance of optimizing an app’s usage of space is discussed, asthe available physical space for users can vary. It advises againstconstraining your app based on the physical space available and insteadcreating an app that can function in any amount of space.\n\t\t- ##### Dimensionality\n\t\t- The use of depth and scale in designing the user experience isemphasized. Depth can help with hierarchy and focus, and scale can beused to emphasize content. The text warns against overusing depth,especially with text, and encourages developers to experiment with scaleto achieve the desired user experience.\n\t\t- ##### Immersiveness\n\t\t- The passage introduces the concept of an immersion spectrum, where anapp can transition between various states of immersion based on theuser’s experience. The importance of smooth transitions, designing withconsideration to user focus, thoughtful blending with reality, andkeeping the user comfortable are emphasized.\n\t\t- ##### Sound Design\n\t\t- It also highlights the importance of using spatial audio to enhance theimmersive experience of an app, which includes attaching sound toobjects and creating soundscapes.\n\t\t- ##### User Comfort\n\t\t- Recommendations for moving an immersive app, focusing on avoidingdisorienting fast movements and instead recommending fade out and fadein techniques to keep the user comfortable during motion.\n\t\t- ##### Transitions\n\t\t- It highlights the importance of clear, intuitive methods for enteringand exiting immersive experiences. It suggests using easily recognizablesymbols, such as arrows for expanding or collapsing views.\n\t\t- ##### Authenticity\n\t\t- Emphasizes creating an authentic experience that takes full advantage ofthe platform’s capabilities. An example given is Freeform, which uses alarge creative space allowing users to view all their content at once.\n\t\t- ##### Key Moments\n\t\t- Focusing on a “key moment” that provides a unique spatial or immersiveexperience is recommended. This could involve enhancing a moment withdepth and scale or transforming the user’s space to create a unique andmemorable experience.\n\t- Lightfield\n\t\t- [Light Field Lab](https://www.lightfieldlab.com/#tech)\n\t- [Infitec shows holographic projection screens (installation-international.com)](https://www.installation-international.com/ise-daily/infitec-shows-holographic-projection-screens)\n\t- [HYPERVSN is a 3D Integrated Holographic System for advertising, digital signage, events.](https://hypervsn.com/)\n\t- {{video https://www.youtube.com/watch?v=DxkIo-2Jzzo&}}\n\t-\n\t-\n- # Brain\n\t- Apple has submitted a patent application that raises some serious privacy and ethical concerns.\n\t- [From this post](https://www.linkedin.com/feed/update/urn:li:activity:7196781454519877632/)\n\t- ![1715807554519.jpeg](../assets/1715807554519_1716117593773_0.jpeg)\n\t- The US Patent and Trademark Office lists application 2023/0225659 as a “biosensing device” built into Apple’s earbuds to measure “biological signal parameters from a user.”\n\t\t- 👉 Electroencephalography (EEG). In other words, the aim is to directly record the user’s brain waves from tiny sensors positioned within the ear canal.\n\t\t- 👉 Electromyography (EMG). This records muscle movements and the information can be used to help understand facial expressions and jaw movements related to emotion.\n\t\t- 👉 Electrooculography (EOG) tracks eye movements, particularly side-to-side.\n\t\t- 👉 Electrocardiogram (ECG) typically measures the electrical activity of the heart.\n\t\t- 👉 Galvanic skin response (GSR), which provides an indirect measure of emotional arousal – that is, the strength of an emotional response.\n\t\t- 👉 Blood volume pulse (BVP). This is measured using photoplethysmography and provides information about heart rate (HR) and heart rate variability (HRV).\n\t- In other words, the aim is to collect a very comprehensive set of neurological and biometric data from the user. Creepy, right?!\n\t- It’s unclear to me how you could even record meaningful data from within the ear.\n\t- If this kind of interface goes ahead it should be\n\t\t- 1. Voluntary. Participants should not be forced or deceived into providing physiological or neurological data. Volunteers at liberty to stop at any time.\n\t\t- 2. Limited. Personal data may only be collected for a specific, explicit and legitimate purpose. This purpose must be clearly stated, and only stored as long as needed to complete that purpose.\n\t\t- 3. Transparent. Requires informed consent including being aware the data are being collected and knowing the risks involved, including whether the information will be shared with other organizations.\n\t\t- 4. Autonomy. Free from manipulation. Participants should not be forced or deceived into making decisions they would not otherwise make.\n\t\t- 5. Valid. Must be based on valid science and led by scientifically trained staff.\n\t- To my mind, this application potentially violates 4 out of 5 of these principles (I don’t see any evidence of manipulation) and this makes me deeply uneasy!",
        "link_types": [
            "Hardware and Edge",
            "Proprietary Large Language Models",
            "Update Cycle",
            "Large language models",
            "Hardware and Edge",
            "cuervo2018creating",
            "boring2009scroll",
            "hansberger2017dispelling"
        ],
        "file_size": 29100
    },
    {
        "id": "Scene Capture and Reconstruction.md",
        "name": "Scene Capture and Reconstruction",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ## NeRFs\n\t- **Early Foundations of NeRF:**\n\t\t- **Early Photography and Photosculpture (ca 1850):** Pioneers in photography began experimenting with aerial photogrammetry and photosculptures, creating 3D representations from multiple 2D photographs, laying groundwork for future 3D capture technologies.\n\t\t\t- [More on early photography](https://hackaday.com/2022/10/02/in-a-way-3d-scanning-is-over-a-century-old/)\n\t- **Plenoptic Function and Light Fields (1908 & 1936):**\n\t\t- Gabriel Lippmann introduces the concept of the **plenoptic function** which evolves into the **light field** concept, simplifying the capture and representation of light as it travels through space.\n\t- **Advances in Computing and Graphics (1960-1980s):**\n\t\t- The development of lasers, holograms, and computer graphics sets the stage for more advanced 3D representations and the capture of light fields.\n\t- **Lightfield Camera Arrays and Image-Based Rendering (2000):**\n\t\t- The introduction of lightfield camera arrays and image-based rendering techniques brings light fields into practical use, although it remains complex and niche.\n\t\t\t- [Stanford light field camera array 2004](http://graphics.stanford.edu/projects/lightfield/)\n\t- **Generative AI and Inverse Rendering Birth of NeRF (2020):**\n\t\t- **Neural Radiance Fields (NeRF):** A breakthrough in 2020 with the introduction of NeRF, offering an efficient way to recreate 3D scenes from 2D images using neural networks.\n\t\t\t- [First NeRF paper, 2020](https://www.matthewtancik.com/nerf)\n\t- **Realtime NeRF and Commercial Applications (2022):**\n\t\t- **NVIDIA's Instant-NGP:** Accelerates NeRF processing, enabling real-time rendering on consumer-grade hardware and facilitating wider adoption and practical applications in various fields.\n\t\t\t- [NVIDIA instant-ngp 2022](https://github.com/NVlabs/instant-ngp)\n\t- **The Future of NeRF:**\n\t\t- The continuous development of NeRF is expected to integrate more seamlessly with web browsers, game engines, and potentially transform large-scale mapping, video conferencing, and real-time interactive applications.\n\t\t\t- [Google's Project Starline](https://blog.google/technology/research/project-starline-expands-testing/)\n- <iframe src=\"https://mohamad-shahbazi.github.io/inserf/\" style=\"width: 100%; height: 600px\"></iframe>\n- **Links and Image Sources:**\n\t- [SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model | Research AI at Meta](https://ai.meta.com/research/publications/scenescript-reconstructing-scenes-with-an-autoregressive-structured-language-model/)\n\t\t- ![Screenshot 2024-03-22 192251.png](../assets/Screenshot_2024-03-22_192251_1711135500802_0.png)\n\t- [RealityCapture 3D Models from Photos and/or Laser Scans (capturingreality.com)](https://www.capturingreality.com/)  **FREE**\n\t- [A Short 170 Year History Of Neural Radiance Fields (NeRF), Holograms, And Light Fields](radiancefields.com/history-of-neural-radiance-fields/)\n\t- [ProNeRF: Learning Efficient Projection-Aware Ray Sampling for Fine-Grained Implicit Neural Radiance Fields (kaist-viclab.github.io)](https://kaist-viclab.github.io/pronerf-site/)\n\t- [Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields](https://jonbarron.info/zipnerf)\n\t- [Home](https://github.com/3a1b2c3/seeingSpace/wiki/Hands-on:-Getting-started-and-Nerf-frameworks)\n\t- [InseRF: Text-Driven Generative Object Insertion in Neural 3D Scenes (mohamad-shahbazi.github.io)](https://mohamad-shahbazi.github.io/inserf/)\n\t- [NeRFLiX: Increased NeRF Quality And Floater Removal | Neural Radiance Fields](https://neuralradiancefields.io/nerflix-increased-nerf-quality-and-floater-removal)\n\t- [A Short 170 Year History Of Neural Radiance Fields (NeRF), Holograms, And Light Fields | Neural Radiance Fields](https://neuralradiancefields.io/history-of-neural-radiance-fields)\n\t- [Home | MMLab@NTU](https://www.mmlab-ntu.com/project/vtoonify)\n\t- [RecolorNeRF](https://sites.google.com/view/recolornerf)\n\t- [Rob Sloan on LinkedIn: #nerfstudio #nerfstudio #polycam #nerf #nerfacto #polycam #neuralnetworks… | 11 comments](https://www.linkedin.com/posts/robcsloan_nerfstudio-nerfstudio-polycam-activity-6999169160379297792-SN4F)\n\t- [MoyGcc/vid2avatar: Vid2Avatar: 3D Avatar Reconstruction from Videos in the Wild via Self-supervised Scene Decomposition (CVPR2023)](https://github.com/MoyGcc/vid2avatar)\n\t- [HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video](https://grail.cs.washington.edu/projects/humannerf)\n\t- [Axie Infinity: Infinite Opportunity or Infinite Peril?](https://naavik.co/business-breakdowns/axie-infinity)\n\t- [NVlabs/instant-ngp](https://github.com/NVlabs/instant-ngp)\n\t- [SpecNeRF (limacv.github.io)](https://limacv.github.io/SpecNeRF_web/)\n\t- [UniSDF (fangjinhuawang.github.io)](https://fangjinhuawang.github.io/UniSDF/)\n\t- [SIGNeRF (jdihlmann.com)](https://signerf.jdihlmann.com/) fast nerf scene editing\n\t- [GARField: Group Anything with Radiance Fields](https://www.garfield.studio/)\n\t- [Byplay](https://www.byplay.io/) is camera motion tracking for mobile\n\t-\n- The neural radiance field Wikipedia is very good [Neural radiance field Wikipedia](https://en.wikipedia.org/wiki/Neural_radiance_field)\n- # LIDAR\n\t- [vectr-ucla/direct_lidar_inertial_odometry: [IEEE ICRA'23] A new lightweight LiDAR-inertial odometry algorithm with a novel coarse-to-fine approach in constructing continuous-time trajectories for precise motion correction. (github.com)](https://github.com/vectr-ucla/direct_lidar_inertial_odometry)\n-\n- [Nerfs](https://www.matthewtancik.com/nerf)\n- All of the LIDAR, [[NeRFs]], [[Gaussian splatting and Similar]] etc are hopefully going to end up in here\n- [History of NeRFs](https://neuralradiancefields.io/history-of-neural-radiance-fields/)\n- waiting on capture\n- use polycam\n\t- try the BTS cam?\n- [viewier](https://github.com/sxyu/volrend)\n- Windows NeRF environment to WebGL\n- [install windows NeRF](https://github.com/bycloudai/instant-ngp-Windows)\n- check out mip nerf 360s\n\t- [Record3D](https://github.com/marek-simonik/record3d_unity_streaming)\n- [github of links](https://github.com/yenchenlin/awesome-NeRF)\n- [nerfs with polycam](https://www.linkedin.com/posts/robcsloan_nerfstudio-nerfstudio-polycam-activity-6999169160379297792-SN4F?utm_source=share&utm_medium=member_desktop)\n- [Polycam developer mode instructions](https://docs.nerf.studio/en/latest/quickstart/custom_dataset.html#polycam-capture)\n- [Nerf to animated people oneshot](https://elicit3d.github.io/)\n- [4K ultra high res nerfs with code](https://paperswithcode.com/paper/4k-nerf-high-fidelity-neural-radiance-fields)\n- [code](https://github.com/frozoul/4K-NeRF)\n- [city modelling](https://www.reddit.com/r/deeplearning/comments/zowgqn/neural_rendering_reconstruct_your_city_in_3d/)\n- [more city modelling](https://waymo.com/research/block-nerf/)\n- [field guide](https://github.com/3a1b2c3/seeingSpace/wiki/Hands-on:-Getting-started-and-Nerf-frameworks)\n- [NeRF SLAM](https://github.com/ToniRV/NeRF-SLAM)\n- [NeuralUDF surface capture](https://www.xxlong.site/NeuralUDF/)\n- [stablisation paper](https://arxiv.org/abs/2102.06205)\n- [nerfs without neural nets](https://alexyu.net/plenoxels/)\n- [NeuS2: Fast Learning of Neural Implicit Surfaces\n  for Multi-view Reconstruction](https://vcai.mpi-inf.mpg.de/projects/NeuS2/)\n- [Original 2020 nerf paper](https://www.matthewtancik.com/nerf)\n- [Recolour NeRF](https://sites.google.com/view/recolornerf?pli=1)\n- [Volinga Nerf into Unreal](https://volinga.ai/)\n- [Text2Nerf4D](https://make-a-video3d.github.io/)\n- [Robust nerfs which deal with occlusion](https://robustnerf.github.io/public/)\n- [Blender integration](https://github.com/JamesPerlman/NeRFRenderCore/blob/main/src/integrations/blender.cuh)\n- [Rapidnerf VR integration with erase](https://github.com/NVlabs/instant-ngp#vr-controls)\n- [Nerf to large scale geom](https://bakedsdf.github.io/)\n- [ELICIT,ELICIT creates free-viewpoint motion videos from a single image by constructing an animatable NeRF representation in one-shot learning. Offcial website of 'One-shot Implicit Animatable Avatars with Model-based Priors'](https://elicit3d.github.io/)\n- [GitHub frozoul/4K-NeRF: Official implementation of arxiv paper   4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions   , Official implementation of arxiv paper   4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions   - GitHub frozoul/4K-NeRF: Official implementation of arxiv paper   4K-NeRF: High Fidelity Neural Radiance Fields at Ultra High Resolutions](https://github.com/frozoul/4k-nerf)\n- [ClimateNeRF,-](https://climatenerf.github.io/)\n- [GitHub ToniRV/NeRF-SLAM: NeRF-SLAM: Real-Time Dense Monocular SLAM with Neural Radiance Fields.](https://github.com/tonirv/nerf-slam)\n- [HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video,HumanNeRF: Free-viewpoint Rendering of Moving People from Monocular Video](https://grail.cs.washington.edu/projects/humannerf/)\n- [editing nerfs with instructions](https://instruct-nerf2nerf.github.io/)\n- [instruct2nerf twitter thread](https://mobile.twitter.com/bilawalsidhu/status/1638919452392583169)\n- [Render without cuda using just pytorch](https://github.com/taichi-dev/taichi-nerfs)\n- [Nerf with free camera trajectory](https://totoro97.github.io/projects/f2-nerf/)\n- [Language embedded nerfs (LERFS)](https://www.lerf.io/)\n- [Splatting paper, go where you like](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/)\n- [nerf RPN](https://github.com/lyclyc52/NeRF_RPN)\n- [google indoor reconstruction from nerfs](https://ai.googleblog.com/2023/06/reconstructing-indoor-spaces-with-nerf.html)\n- [focal length for capture](https://neuralradiancefields.io/whats-the-best-focal-length-to-take-a-nerf/)\n- The paper [Zip-NeRF](https://jonbarron.info/zipnerf/): Anti-Aliased Grid-Based Neural Radiance Fields\" proposes a technique that combines ideas from rendering and signal processing to combat aliasing in grid-based representations of neural radiance fields (NeRF). NeRF's learned mapping from spatial coordinates to colors and volumetric density can be accelerated through the use of grid-based representations, but they lack an explicit understanding of scale and often introduce aliasing. The proposed technique combines mip-NeRF 360 and Instant NGP to yield error rates that are 8%-77% lower than either prior technique and trains 24x faster than mip-NeRF 360. The technique uses multisampling to approximate the average NGP feature over a conical frustum, and the method produces prefiltered renderings that do not flicker or shimmer, even as the camera moves laterally. Moreover, their improvements to proposal network supervision result in a prefiltered proposal output that preserves the foreground object for all frames, preventing an artifact called z-aliasing where foreground content alternately appears and disappears as the camera moves towards or away from the scene content. The proposed method shows promising results for accelerating NeRF training while combating aliasing in grid-based representations.\n- [baked nerf mesh paper](https://bakedsdf.github.io/)\n- [Facebook VR nerf](https://neuralradiancefields.io/venturing-beyond-reality-vr-nerf/)\n- RP-Lidar + Raspberry pi + ROS RTAB-MAP\n- [RTAB-Map](http://introlab.github.io/rtabmap/)\n- [Reality Scan](https://www.unrealengine.com/en-US/blog/realityscan-is-now-free-to-download-on-ios)\n- [Drone SLAM](https://www.youtube.com/watch?v=CEC5UwPV9gY)\n- [Adobe substance3d](https://www.substance3d.com/)\n- [3DPresso](https://3dpresso.ai/viewer?seq=mr3.yg5isic8KGJZ1DAjW5VMc)\n- [Apple point cloud rendering](https://machinelearning.apple.com/research/pointersect)\n- [Nvidia NeuralAngelo](https://research.nvidia.com/labs/dir/neuralangelo/)\n- [OmniMotion track all pixels](https://huggingface.co/papers/2306.05422)\n- [Leica handheld scanner](https://leica-geosystems.com/products/laser-scanners/autonomous-reality-capture/leica-blk2go-handheld-imaging-laser-scanner)\n- [Meshroom open source photogrammetry](https://alicevision.org/#meshroom)\n- [Nira.app](https://nira.app/)\n- [Houdini mesh from google earth](https://github.com/xjorma/EarthMeshHoudini?)\n- [DiffusionLight: Light Probes for Free by Painting a Chrome Ball](https://diffusionlight.github.io/index.html)\n- [MocapEvery (jiyewise.github.io)](https://jiyewise.github.io/projects/MocapEvery/)",
        "link_types": [
            "NeRFs",
            "Gaussian splatting and Similar"
        ],
        "file_size": 12401
    },
    {
        "id": "Comparison of SDXL and Midjourney v6.md",
        "name": "Comparison of SDXL and Midjourney v6",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- ![ubk23oi2c99c1.webp](../assets/ubk23oi2c99c1_1704039598306_0.webp){:height 341, :width 636}\n- ![on7mfoi2c99c1.webp](../assets/on7mfoi2c99c1_1704039674387_0.webp)\n- ![oucsvni2c99c1.webp](../assets/oucsvni2c99c1_1704039919084_0.webp)\n- ![qtok2ri2c99c1.webp](../assets/qtok2ri2c99c1_1704039927334_0.webp)\n- ![wpwpuni2c99c1.webp](../assets/wpwpuni2c99c1_1704039947390_0.webp)\n- ![vrjm6oi2c99c1.webp](../assets/vrjm6oi2c99c1_1704039961984_0.webp)\n- [(2) Midjourney V6.0 vs SDXL, exact same prompts, using Fooocus (details in a comment) : StableDiffusion (reddit.com)](https://www.reddit.com/r/StableDiffusion/comments/18tqyn4/midjourney_v60_vs_sdxl_exact_same_prompts_using/)",
        "link_types": [],
        "file_size": 731
    },
    {
        "id": "collaborative.md",
        "name": "collaborative",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n",
        "link_types": [],
        "file_size": 14
    },
    {
        "id": "contents.md",
        "name": "contents",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- This is a structured sidebar for presentations of the knowledge graph.\n\t- Structure id:: 65a2d52f-6436-4535-a1f8-1764fb8017d1\n\t\t- 🟢 [Convergence and Disruption in Digital Society](logseq://graph/mainKnowledgeGraph?page=HOST-Webpage)\n\t - ...because of GenAI...\n\t\t- About me - 🟢 [Human and Agent Tele-collaboration](logseq://graph/mainKnowledgeGraph?block-id=65a27c11-be79-431f-93ff-fc4b96368c70) - 🟢 [Recent projects](logseq://graph/mainKnowledgeGraph?block-id=659a922a-ac22-484e-9a3f-921390ea68cc)\n\t\t- 🟢 [Purpose of the presentation](logseq://graph/mainKnowledgeGraph?block-id=659a922a-6a0b-4ace-a79a-ad00199e398e)\n\t - A now / next / later run through GenAI\n\t - [QR CODE & Questions for the Audience](logseq://graph/mainKnowledgeGraph?block-id=659a922a-0f77-4dc5-a0dd-f76f2793423f) \n\t\t\t  so I can pitch this right.\n\t\t- [History of the ML/AI ](logseq://graph/mainKnowledgeGraph?page=Overview%20of%20ML%20techniques) (skipped) - 🟢 [Deep Learning](logseq://graph/mainKnowledgeGraph?block-id=659a9232-2320-494a-b922-968029718ad5)\n\t\t- Proprietary (closed) GenAI - 🟢 [Closed source LLMs](logseq://graph/mainKnowledgeGraph?page=Proprietary%20Large%20Language%20Models)\n\t - Actionable LLM Advice (skipped)\n\t - [Closed source image (skipped)](logseq://graph/mainKnowledgeGraph?block-id=659a9229-ed15-4932-a207-eb2daa96786e)\n\t - [Closed source video (skipped)](logseq://graph/mainKnowledgeGraph?block-id=659a922a-1d6b-4ae8-82ad-8d7c2814f25f) - 🟢 [Text to 3D and metaverse](logseq://graph/mainKnowledgeGraph?block-id=659a9247-f51f-4b45-9673-df22ec0476dd)\n\t\t- Open and tunable Generative AI - 🟢 [Open ecosystems](logseq://graph/mainKnowledgeGraph?block-id=65a2a38f-41a4-4b7f-bcc7-face3f9ef222)\n\t - [Custom AI for your business](logseq://graph/mainKnowledgeGraph?block-id=659a9231-4d21-415e-8b07-25b215e6b712)\n\t\t\t\t- logseq://graph/mainKnowledgeGraph?block-id=65a2a38f-41a4-4b7f-bcc7-face3f9ef222\n\t\t- Next and Later - 🟢 [The Predictions Slide](logseq://graph/mainKnowledgeGraph?block-id=65a2a968-c150-4dca-8ddc-902f29a8d7e0)\n\t\t- [Close (and QR code, and questions?)](logseq://graph/mainKnowledgeGraph?block-id=65a2d496-5dba-4847-8826-5fab107690d2)\n\t\t-\n- [THE OTHER predictions slide](logseq://graph/mainKnowledgeGraph?block-id=659a9246-af6b-4582-9368-3b688130d703) Backup Slide!\n-",
        "link_types": [],
        "file_size": 2353
    },
    {
        "id": "Suggested Reading Order.md",
        "name": "Suggested Reading Order",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- I have been working on learning, and learning how to store that knowledge for myself and others since 2019 when I stopped being Technical Director of the [[Octave Multi Model Laboratory]] which followed on from the [[National Industrial Centre for Virtual Environments]].\n- This website contains cross linked, well annotated, deeply cited knowledge across GenAI, Telepresence, Large Scale Display Systems, Distributed Systems, LLMs, Immersive Collaborative Spaces (metaverse), Politics, Law, Social Change, [[Convergence]], [[Disruption]] , and all the other things I have [studied for decades](https://scholar.google.com/citations?user=Etx-Au4AAAAJ&hl=en).\n- It is increasing in size all the time. If you want upskilling on these things then I can give a physical or remote tour through the subset of knowledge that's right for -your- company or personal research needs. Afterwards, you will get a link to a page on my website which contains the knowledge graph suitable for you to extend and build upon the presentation.\n- This graph is also the engine behind another new project we're starting; avatar based conversational agents backed by this knowledgebase, under [[Dreamlab]]\n- # Suggested Order\n\t- I originally started this [as a book.](https://arxiv.org/abs/2207.09460), so there **is** a natural reading order of sorts. I am still working on making this more of a \"flow\" so if it looks wrong just skip about. Some of these high level pages are dozens of pages each, and there are hundreds of such pages, with only a few highlighted here.\n\t- There's possibly around 1000 book equivalent pages overall.\n\t- ## Preamble\n\t\t- [[Introduction to me]] explains my research at a very high level\n\t- ### Web things\n\t\t- [[Semantic Web]]\n\t\t- [[Spatial Web]]\n\t\t- [[Decentralised Web]]\n\t\t- [[Politics, Law, Privacy]]\n\t- ## Decentralisation\n\t\t- [[Blockchain]]\n\t\t- [[Ethereum]]\n\t\t- [[Bitcoin]]\n\t\t- [[Lightning and Similar L2]]\n\t\t- [[BTC Layer 3]]\n\t\t- [[RGB]]\n\t\t- [[nostr]]\n\t\t- [[Digital Asset Risks]]\n\t\t- [[NFTs]]\n\t\t- [[Digital Objects]]\n\t- ## Money and Value\n\t\t- [[Bitcoin As Money]]\n\t\t- [[Money]]\n\t- ## Identity\n\t\t- [[Distributed Identity]]\n\t- ## Digital Objects\n\t\t- [[NFTs]]\n\t\t- [[Digital Objects]]\n\t- ## Spatial\n\t\t- [[Metaverse and Telecollaboration]]\n\t\t- [[Definitions and frameworks for Metaverse]]\n\t\t- [[Spatial Computing]]\n\t\t- [[Metaverse and Spatial Risks]]\n\t- ## Artificial Intelligence\n\t\t- [[Overview of Machine Learning Techniques]]\n\t\t- [[Proprietary Large Language Models]]\n\t\t- [[Proprietary Image Generation]]\n\t\t- [[Proprietary Video VP & 3D]]\n\t\t- [[Open Generative AI tools]]\n\t\t- [[State of the art in AI]]\n\t\t- [[AI Adoption]]\n\t\t- [[Soon-Next-Later (AI futurology)]]\n\t\t-\n- This is a very new page and will be subject to a [[Update Cycle]] soon",
        "link_types": [
            "Octave Multi Model Laboratory",
            "National Industrial Centre for Virtual Environments",
            "Convergence",
            "Disruption",
            "Dreamlab",
            "Introduction to me",
            "Semantic Web",
            "Spatial Web",
            "Decentralised Web",
            "Politics, Law, Privacy",
            "Blockchain",
            "Ethereum",
            "Bitcoin",
            "Lightning and Similar L2",
            "BTC Layer 3",
            "RGB",
            "nostr",
            "Digital Asset Risks",
            "NFTs",
            "Digital Objects",
            "Bitcoin As Money",
            "Money",
            "Distributed Identity",
            "NFTs",
            "Digital Objects",
            "Metaverse and Telecollaboration",
            "Definitions and frameworks for Metaverse",
            "Spatial Computing",
            "Metaverse and Spatial Risks",
            "Overview of Machine Learning Techniques",
            "Proprietary Large Language Models",
            "Proprietary Image Generation",
            "Proprietary Video VP & 3D",
            "Open Generative AI tools",
            "State of the art in AI",
            "AI Adoption",
            "Soon-Next-Later (AI futurology)",
            "Update Cycle"
        ],
        "file_size": 2766
    },
    {
        "id": "Agentic Mycelia.md",
        "name": "Agentic Mycelia",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- [metaverseOntologies.mkv](../assets/metaverseOntologies_1715158785294_0.mkv)\n- https://docs.google.com/presentation/d/1J1yWFpaOV6RaRlcbSEclOUk3i4xtzupYSkhmoBUWcDs/edit?usp=sharing\n- # Approaches to AI scaffolding\n\t- ## Standards\n\t\t- Human managed glossaries with AI support for authoring and global comprehensibility\n\t\t\t- Positives:\n\t\t\t\t- Readable and explainable for humans\n\t\t\t\t- Controlled and mediated by experts\n\t\t\t\t- Sensible foundation for legal frameworks\n\t\t\t\t- Facilitates communication and collaboration\n\t\t\t\t- Promotes interoperability\n\t\t\t- Negatives:\n\t\t\t\t- Inflexible and unresponsive to change\n\t\t\t\t- Reductionist, risking oversimplification\n\t\t\t\t- May limit innovation and creativity\n\t\t\t\t- Challenging to reach consensus among stakeholders\n\t\t\t\t- Potential for excluding diverse perspectives\n\t\t- AI agent managed complex ontologies and tacit contracts\n\t\t\t- Positives:\n\t\t\t\t- Personalised and adaptable to individual needs\n\t\t\t\t- Responsive and dynamic, evolving with the metaverse\n\t\t\t\t- Provides end-to-end support for human users\n\t\t\t\t- Less reductionist, preserving complexity\n\t\t\t\t- Supports diversity and flexibility\n\t\t\t- Negatives:\n\t\t\t\t- Non-deterministic, leading to unpredictable outcomes\n\t\t\t\t- Legally inscrutable, challenging to establish accountability\n\t\t\t\t- Might trend towards incomprehensibility over time\n\t\t\t\t- Requires complex negotiations between humans and AI\n\t\t\t\t- Risks associated with economically empowered AI agents\n- ## Toward an agentic mycelium for emergent digital spaces\n\t- An experiment in AI manufactured ontologies with pinnacle foundation models.\n\t\t- Around 4 days work with Gemini 1.5, ClaudeAI, GPT4\n\t\t- Quickly derived a complete, consistent ontological representation of 500 pages across 5 years of research. Web Ontology Language based.\n\t\t- This was too complex for progressing forward so was simplified to Linked-JSON, a subset of JSON-LD.\n\t\t- This ontology was notionally embedded into a wider substrate of agentic actors, and similar diagrams were created (all in the same 4 days).\n\t\t- This seems to generate the near term plausibility of an automated approach to continuous complex ontology and knowledge graph creation by machines.\n\t\t- The degree of success was a surprise, not all of the workflow has been saved as it was exploratory, but much is available online.\n- ### Methodology\n\t- In this experiment I used a combination of Claude 3 Opus, ChatGPT4, and Google Gemini Advanced 1.5.\n\t- [[Google]] [[Gemini]] 1.5 did the heavy lifting here but Claude 3 Opus did the final pass and expanded the text, which I then adapted.\n\t- I uploaded the public pages of this knowledge graph, which represent a decent proportion of my thinking into the million token context of Gemini.\n\t- This was how I started the conversation with Gemini. The full text is available on request but it is non-deterministic and quite messy, representing the way I interact with these conversational systems more than a systematic approach.\n\t\t- I build [[Chain of Thought]] scaffolds in [[Large language models]] using [[Diagrams as Code]], and this methodology  reflects my [[Prompt Engineering]] approach.\n\t\t\t- Current large language models benefit greatly from being asked to create diagrams as code, in a guided manner.\n\t\t\t- These complex code structures can convey meaning and linkages, creating knowledge graphs which implicitly contain their own logical checks.\n\t\t\t- Human comprehension is radically increased during the co-creations.\n\t\t\t- The code can be used to rapidly bootstrap another LLM, bringing the different power and potential of another model into an already advanced conversation.\n\t\t- Systemising this is planned work for later in the research arc.\n\t\t- ```text \n\t\t  I would like to set this discussion diagrammatically in a wider context and scope. \n\t\t  Let's decide that this ontology that we've been working on represents one notional domain of a wider connected digital society, \n\t\t  with it's emergent human/AI social constructs, preferences, compliances, audiences, jurisdictions, opt in rule sets etc. \n\t\t  Here's a way to start that conversation with you.\n\t\t  \n\t\t  - Make a diagram for the metaverse mycelium\n\t\t  \t- onboarding agents at the interactive edge assist human actors in setting up their preferences, tolerances, \n\t\t      limit choices (for instance but not limited to enforcing proximity of their avatar to others as a safeguarding feature). \n\t\t      These interactions would be cryptographically verified between human and AI actors, with a single use seal based \n\t\t      global commitment capability. The decisions at this onboarding stage would start to inform a living contract of sorts, \n\t\t      which might (but would likely not) have consequence in law. This should be part of the T&C of the system.\n\t\t  \t- Scene agents with a global view of a metaverse / space instance. These would handle access, governance, \n\t\t      in group cryptography, warnings, reputation management, real time language translation, enforcement and recording \n\t\t      and later auditable destruction of any and all interactions within it's scope.\n\t\t  \t- Such scene AI agents should constantly make available an up-to-date scene ontology (like the one we have been working on) \n\t\t      in machine and human readable Linked-JSON, reflecting the settings negotiated with the user base of the space. This knowledge \n\t\t      graph and ontology feeds out to transfer agents\n\t\t  \t- Transfer agents occupy the interstices between worlds and handle machine-machine translation, protocol translation, \n\t\t      ingress, routing, egress, web2 and messenger interfaces, agentic routing (user agents can be given access to shopping web etc), \n\t\t      reputation transfer and adaptation, token, digital object transfer and variations, and money swaps. \n\t\t      These mycelial connective agents also communicate through pass through and translation with jurisdictional legal and enforcement \n\t\t      agents and human on the edge, passing public linked-json schema and appropriate minimal metadata.\n\t\t  \t- This Human and machine readable Linked-JSON automatic arbitration between end points, automatically translates at best \n\t\t      effort between adjacent metaverse / space instances, each of which is providing a clear and automated obtological window into it's \n\t\t      own world, choices, and user styles.\n\t\t  \t- Jurisdictional / Legal agents on the edge (provide continuous access to non private human readable transfer agent Linked-JSON) \n\t\t  \t    \n\t\t  This is an example of my thinking, can you see what I am trying to do here? \n\t\t  Give me a detailed diagram as code mermaid which shows a representation of the ontology we have been working on, \n\t\t  interfacing with the mycelial network of agents, value, other automated ontological representations of spaces \n\t\t  (use an industrial co-working space, a feminist support group metaverse, fortnite, and roblox as examples). \n\t\t  Add in the edge interfaces as we have discussed. I don't mind a large and detailed diagram but it should not be too \n\t\t  crowded so choose an appropriate rendering platform and style and iterate until you are happy with the result we have engineered.  \n\t\t  \t- first summarise back and explain your thinking. \n\t\t      Try to identify shortfalls, extensions, expansions, important additional features, and justifications. \n\t\t      Work methodically and step by step explaining the rationale, then make the diagram code.\n\t\t  ```\n\t- This was the final prompt to [[Anthropic Claude]] 3 Opus, which merged in the previously developed [[Metaverse Ontology]] was lightly shaped into the output below.\n\t\t- ```text\n\t\t  this is the Linked-JSON ontology we made for the instance that is now called Omniverse digital twin. \n\t\t  Use the detail therein to expand the leaf with this example, but in our new diagrammatic notation. \n\t\t  You can also do this job using a totally new and more appropriate approach if that is advantageous\n\t\t  ```\n\t- # The Agentic Mycelia:\n\t\t- ## A Scaffold for Interconnected Metaverse Instances\n\t\t\t- This document explores the concept of the \"Agentic Mycelia,\" a framework for interconnected metaverse instances operating within a decentralized and AI-driven ecosystem.\n\t\t\t\t- The framework emphasizes:\n\t\t\t\t\t- Interoperability\n\t\t\t\t\t- User empowerment\n\t\t\t\t\t- Adaptable governance\n\t\t\t\t- It enables seamless interactions and value exchange across diverse virtual worlds.\n\t\t- ## Core Principles\n\t\t\t- ### Unified PKI architecture\n\t\t\t\t- The Agentic Mycelia leverages BIP39 (Basic key derivation from mnemonic seed phrase) to generate mnemonic seed words and derive a binary seed from them. BIP32 is then used to derive the path `m/44'/1237'/<account>'/0/0` (according to the Nostr entry on SLIP44) for object creation, identification and root ownership.\n\t\t\t\t- Objects belonging to a scene are represented as sub-accounts (key pairs) derived from the scene's top-level key. Similarly, objects belonging to users or their agents inherit from the appropriate root key of those users. This approach provides deterministic proof of ownership, but remains private by default.\n\t\t\t\t- Transfer of ownership would be managed downstream by use of the [RGB protocol](https://docs.rgb.info/rgb-contract-implementation/schema/non-inflatable-fungible-asset-schema).\n\t\t\t\t- By incorporating BIP32 for key derivation and object identification, the Agentic Mycelia establishes a robust and decentralized foundation for identity management and ownership within the interconnected metaverse ecosystem. It is compatible with file encryption, the nostr communication protocol, Bitcoin and Lightning, through Segwit keys.\n\t\t\t- ### Interoperability\n\t\t\t\t- Metaverse instances within the Mycelia should be able to communicate and exchange information, assets, and value seamlessly.\n\t\t\t\t- This requires:\n\t\t\t\t\t- Standardized protocols\n\t\t\t\t\t- Ontologies\n\t\t\t\t\t- Translation mechanisms\n\t\t\t- ### User Empowerment\n\t\t\t\t- Users should have control over their data, identity, and experiences within the metaverse.\n\t\t\t\t- This involves:\n\t\t\t\t\t- Self-sovereign identity solutions\n\t\t\t\t\t- Privacy-preserving technologies\n\t\t\t\t\t- User-centric governance models\n\t\t\t- ### Adaptable Governance\n\t\t\t\t- Each metaverse instance should have the autonomy to establish its own rules, regulations, and governance structures while remaining compatible with the broader Mycelia network.\n\t\t\t\t- This necessitates AI-driven governance models that can adapt to changing needs and user preferences.\n\t\t- ## Key Components\n\t\t\t- ### Metaverse Instances\n\t\t\t\t- Individual virtual worlds with unique themes, functionalities, and communities.\n\t\t\t\t- Examples include:\n\t\t\t\t\t- #### Omniverse Digital Twin\n\t\t\t\t\t\t- A virtual replica of a real-world environment or system.\n\t\t\t\t\t\t- Utilizes the Linked-JSON ontology we designed, including:\n\t\t\t\t\t\t\t- MetaverseEntity and its subclasses\n\t\t\t\t\t\t\t\t- MetaverseAgent\n\t\t\t\t\t\t\t\t- MetaverseScene\n\t\t\t\t\t\t\t\t- SceneObject\n\t\t\t\t\t\t\t\t- DigitalAsset\n\t\t\t\t\t\t\t\t- VirtualEconomy\n\t\t\t\t\t\t\t- Relationships between entities\n\t\t\t\t\t\t\t\t- MetaverseAgent participates in MetaverseScene\n\t\t\t\t\t\t\t\t- MetaverseScene governed by GovernanceStructure\n\t\t\t\t\t\t\t\t- DigitalAsset has Owner and Creator\n\t\t\t\t\t\t\t\t- VirtualEconomy regulated by EconomicPolicy\n\t\t\t\t\t\t- Example Linked-JSON snippets:\n\t\t\t\t\t\t\t- ```json\n\t\t\t\t\t\t\t  {\n\t\t\t\t\t\t\t    \"@id\": \"narrativegoldmine:MetaverseEntity\",\n\t\t\t\t\t\t\t    \"@type\": [\n\t\t\t\t\t\t\t      \"narrativegoldmine:Class\",\n\t\t\t\t\t\t\t      \"Linked-JSON:Class\",\n\t\t\t\t\t\t\t      \"http://www.w3.org/2002/07/owl#Class\"\n\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#comment\": [\n\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t        \"@value\": \"The root type encompassing all entities within the metaverse.\"\n\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#label\": [\n\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t        \"@value\": \"Metaverse Entity\"\n\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#subClassOf\": [\n\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t        \"@id\": \"https://schema.org/Thing\"\n\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t    ]\n\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t  ```\n\t\t\t\t\t\t\t- ```json\n\t\t\t\t\t\t\t  {\n\t\t\t\t\t\t\t    \"@id\": \"narrativegoldmine:participatesIn\",\n\t\t\t\t\t\t\t    \"@type\": [\n\t\t\t\t\t\t\t      \"http://www.w3.org/2002/07/owl#ObjectProperty\"\n\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#domain\": [\n\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t        \"@id\": \"narrativegoldmine:MetaverseAgent\"\n\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#range\": [\n\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t        \"@id\": \"narrativegoldmine:MetaverseScene\"\n\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t    ]\n\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t  ```\n\t\t\t\t\t- #### Roblox Event\n\t\t\t\t\t\t- A user-generated event within the Roblox platform.\n\t\t\t\t\t\t- Incorporates user-generated content and event-specific governance.\n\t\t\t\t\t- #### Unreal-based MMORPG\n\t\t\t\t\t\t- A massively multiplayer online role-playing game built using the Unreal Engine.\n\t\t\t\t\t\t- Features PvP interactions and MMORPG-specific governance.\n\t\t\t\t\t- #### Global Business Conference\n\t\t\t\t\t\t- A virtual platform for hosting business conferences and networking events.\n\t\t\t\t\t\t- Provides networking tools and conference-specific governance.\n\t\t\t\t\t- #### Feminist Global Advocacy and Support Metaverse\n\t\t\t\t\t\t- A virtual space dedicated to feminist advocacy and support.\n\t\t\t\t\t\t- Prioritizes privacy, security, and advocacy-specific governance.\n\t\t\t\t- ### Scene Agents\n\t\t\t\t\t- AI entities responsible for managing specific functions within each metaverse instance.\n\t\t\t\t\t- Roles include:\n\t\t\t\t\t\t- #### AI Governance\n\t\t\t\t\t\t\t- Implementing and enforcing rules and regulations.\n\t\t\t\t\t\t\t- Utilizing the governance-related entities from the ontology, such as GovernanceStructure and MetaversePolicy.\n\t\t\t\t\t\t\t- Example Linked-JSON snippets:\n\t\t\t\t\t\t\t\t- ```json\n\t\t\t\t\t\t\t\t  {\n\t\t\t\t\t\t\t\t    \"@id\": \"narrativegoldmine:GovernanceStructure\",\n\t\t\t\t\t\t\t\t    \"@type\": [\n\t\t\t\t\t\t\t\t      \"narrativegoldmine:Class\",\n\t\t\t\t\t\t\t\t      \"Linked-JSON:Class\",\n\t\t\t\t\t\t\t\t      \"http://www.w3.org/2002/07/owl#Class\"\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#comment\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@value\": \"Represents the governance models and structures within the metaverse.\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#label\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@value\": \"Governance Structure\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#subClassOf\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@id\": \"narrativegoldmine:MetaverseEntity\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ]\n\t\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t\t  ```\n\t\t\t\t\t\t\t\t- ```json\n\t\t\t\t\t\t\t\t  {\n\t\t\t\t\t\t\t\t    \"@id\": \"narrativegoldmine:governedBy\",\n\t\t\t\t\t\t\t\t    \"@type\": [\n\t\t\t\t\t\t\t\t      \"http://www.w3.org/2002/07/owl#ObjectProperty\"\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#domain\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@id\": \"narrativegoldmine:MetaverseScene\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#range\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@id\": \"narrativegoldmine:GovernanceStructure\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ]\n\t\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t\t  ```\n\t\t\t\t\t\t- #### Reputation Management\n\t\t\t\t\t\t\t- Tracking and evaluating user behavior and trustworthiness.\n\t\t\t\t\t\t\t- Leveraging the ReputationScore entity from the ontology.\n\t\t\t\t\t\t\t- Example Linked-JSON snippet:\n\t\t\t\t\t\t\t\t- ```json\n\t\t\t\t\t\t\t\t  {\n\t\t\t\t\t\t\t\t    \"@id\": \"narrativegoldmine:ReputationScore\",\n\t\t\t\t\t\t\t\t    \"@type\": [\n\t\t\t\t\t\t\t\t      \"narrativegoldmine:Class\",\n\t\t\t\t\t\t\t\t      \"Linked-JSON:Class\",\n\t\t\t\t\t\t\t\t      \"http://www.w3.org/2002/07/owl#Class\"\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#comment\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@value\": \"Represents an agent's reputation score.\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#label\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@value\": \"Reputation Score\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ]\n\t\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t\t  ```\n\t\t\t\t\t\t- #### Environmental Conditions\n\t\t\t\t\t\t\t- Controlling weather, lighting, and other environmental factors.\n\t\t\t\t\t\t\t- Utilizing the EnvironmentalConditions entity from the ontology.\n\t\t\t\t\t\t\t- Example Linked-JSON snippet:\n\t\t\t\t\t\t\t\t- ```json\n\t\t\t\t\t\t\t\t  {\n\t\t\t\t\t\t\t\t    \"@id\": \"narrativegoldmine:EnvironmentalConditions\",\n\t\t\t\t\t\t\t\t    \"@type\": [\n\t\t\t\t\t\t\t\t      \"narrativegoldmine:Class\",\n\t\t\t\t\t\t\t\t      \"Linked-JSON:Class\",\n\t\t\t\t\t\t\t\t      \"http://www.w3.org/2002/07/owl#Class\"\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#comment\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@value\": \"Represents the environmental conditions within a metaverse scene.\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#label\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@value\": \"Environmental Conditions\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ]\n\t\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t\t  ```\n\t\t\t\t\t\t- #### Virtual Economy\n\t\t\t\t\t\t\t- Facilitating economic activities and asset exchange.\n\t\t\t\t\t\t\t- Leveraging the VirtualEconomy, EconomicPolicy, and Marketplace entities from the ontology.\n\t\t\t\t\t\t\t- Example Linked-JSON snippets:\n\t\t\t\t\t\t\t\t- ```json\n\t\t\t\t\t\t\t\t  {\n\t\t\t\t\t\t\t\t    \"@id\": \"narrativegoldmine:VirtualEconomy\",\n\t\t\t\t\t\t\t\t    \"@type\": [\n\t\t\t\t\t\t\t\t      \"narrativegoldmine:Class\",\n\t\t\t\t\t\t\t\t      \"Linked-JSON:Class\",\n\t\t\t\t\t\t\t\t      \"http://www.w3.org/2002/07/owl#Class\"\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#comment\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@value\": \"Represents the economic system within the metaverse, including trade, ownership, and currency exchange.\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#label\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@value\": \"Virtual Economy\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#subClassOf\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@id\": \"narrativegoldmine:MetaverseEntity\"\n\t\t\t\t\t\t\t\t      },\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@id\": \"_:N7734f53c103846fba0f7f099a17df575\"\n\t\t\t\t\t\t\t\t      },\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@id\": \"_:Nd9e50a6e98a54130bbc92b9a80ca3bfb\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ]\n\t\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t\t  ```\n\t\t\t\t\t\t\t\t- ```json\n\t\t\t\t\t\t\t\t  {\n\t\t\t\t\t\t\t\t    \"@id\": \"narrativegoldmine:regulatedBy\",\n\t\t\t\t\t\t\t\t    \"@type\": [\n\t\t\t\t\t\t\t\t      \"http://www.w3.org/2002/07/owl#ObjectProperty\"\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#domain\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@id\": \"narrativegoldmine:VirtualEconomy\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#range\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@id\": \"narrativegoldmine:EconomicPolicy\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ]\n\t\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t\t  ```\n\t\t\t\t- ## Transfer Agents\n\t\t\t\t\t- Specialized agents operating between metaverse instances, enabling interoperability.\n\t\t\t\t\t- Responsibilities include:\n\t\t\t\t\t\t- ### Machine-Machine Translation\n\t\t\t\t\t\t\t- Converting data and protocols between different platforms.\n\t\t\t\t\t\t- ### Value Translation\n\t\t\t\t\t\t\t- Facilitating real-time exchange of currencies and assets across instances.\n\t\t\t\t\t\t- ### Digital Object Variations\n\t\t\t\t\t\t\t- Managing and adapting digital assets for different environments.\n\t\t\t\t\t\t\t- Utilizing the Varset entity from the ontology to handle variations.\n\t\t\t\t\t\t\t- Example Linked-JSON snippet:\n\t\t\t\t\t\t\t\t- ```json\n\t\t\t\t\t\t\t\t  {\n\t\t\t\t\t\t\t\t    \"@id\": \"narrativegoldmine:Varset\",\n\t\t\t\t\t\t\t\t    \"@type\": [\n\t\t\t\t\t\t\t\t      \"narrativegoldmine:Class\",\n\t\t\t\t\t\t\t\t      \"Linked-JSON:Class\",\n\t\t\t\t\t\t\t\t      \"http://www.w3.org/2002/07/owl#Class\"\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#comment\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@value\": \"Represents a set of variations or alternate versions of a metaverse scene or object.\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#label\": [\n\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t        \"@value\": \"Varset\"\n\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t    ]\n\t\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t\t  ```\n\t\t\t\t\t\t- ### Safeguarding\n\t\t\t\t\t\t\t- Implementing security measures and user protection mechanisms.\n\t\t\t\t\t\t- ### Law Enforcement Handshake\n\t\t\t\t\t\t\t- Interacting with legal authorities as needed.\n\t\t\t\t\t\t- ### PKI Infrastructure\n\t\t\t\t\t\t\t- Integrating public key infrastructure for secure communication and transactions.\n\t\t\t\t\t- ## Onboarding Agents\n\t\t\t\t\t\t- Edge agents assisting users with:\n\t\t\t\t\t\t\t- ### Preference Setup\n\t\t\t\t\t\t\t\t- Configuring privacy settings, accessibility options, and other preferences.\n\t\t\t\t\t\t\t\t- Utilizing the PrivacySetting entity from the ontology.\n\t\t\t\t\t\t\t\t- Example Linked-JSON snippet:\n\t\t\t\t\t\t\t\t\t- ```json\n\t\t\t\t\t\t\t\t\t  {\n\t\t\t\t\t\t\t\t\t    \"@id\": \"narrativegoldmine:PrivacySetting\",\n\t\t\t\t\t\t\t\t\t    \"@type\": [\n\t\t\t\t\t\t\t\t\t      \"narrativegoldmine:Class\",\n\t\t\t\t\t\t\t\t\t      \"Linked-JSON:Class\",\n\t\t\t\t\t\t\t\t\t      \"http://www.w3.org/2002/07/owl#Class\"\n\t\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#comment\": [\n\t\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t\t        \"@value\": \"Represents an agent's privacy preferences within the metaverse.\"\n\t\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t\t    ],\n\t\t\t\t\t\t\t\t\t    \"http://www.w3.org/2000/01/rdf-schema#label\": [\n\t\t\t\t\t\t\t\t\t      {\n\t\t\t\t\t\t\t\t\t        \"@value\": \"Privacy Setting\"\n\t\t\t\t\t\t\t\t\t      }\n\t\t\t\t\t\t\t\t\t    ]\n\t\t\t\t\t\t\t\t\t  }\n\t\t\t\t\t\t\t\t\t  ```\n\t\t\t\t\t\t\t- #### Living Contract Formation\n\t\t\t\t\t\t\t\t- Establishing a dynamic agreement between the user and the Mycelia network.\n\t\t\t\t\t\t\t\t- Outlining rights, responsibilities, and terms of engagement.\n\t\t\t\t\t- ### Jurisdictional/Legal Agents\n\t\t\t\t\t\t- Agents ensuring compliance with legal frameworks and regulations.\n\t\t\t\t\t\t- Tasks include:\n\t\t\t\t\t\t\t- #### Monitoring Network Activity\n\t\t\t\t\t\t\t\t- Observing interactions and transactions for potential violations.\n\t\t\t\t\t\t\t- #### Providing Transparency\n\t\t\t\t\t\t\t\t- Offering human-readable reports and data access to relevant authorities.\n\t\t\t\t\t\t\t- #### Enforcing Legal Standards\n\t\t\t\t\t\t\t\t- Collaborating with law enforcement agencies as needed.\n\t\t\t\t- ### Interfaces and Interactions\n\t\t\t\t\t- Inter-Instance Communication\n\t\t\t\t\t\t- Scene Agents within each instance communicate with Transfer Agents to exchange information and facilitate cross-instance activities.\n\t\t\t\t\t- Value Exchange\n\t\t\t\t\t\t- Virtual economies within each instance connect through Transfer Agents for real-time value translation and asset exchange.\n\t\t\t\t\t- User Interaction\n\t\t\t\t\t\t- Users interact with Scene Agents within each instance and with Onboarding Agents at the network edge.\n\t\t\t\t\t- External Interface\n\t\t\t\t\t\t- Jurisdictional/Legal Agents provide an interface between the Mycelia network and external legal systems.\n\t\t- # Implications for Human Users\n\t\t\t- The Agentic Mycelia framework offers several benefits for human users:\n\t\t\t\t- ## Seamless Navigation\n\t\t\t\t\t- Users can easily move between different metaverse instances while maintaining their identity and preferences.\n\t\t\t\t- ## Enhanced Privacy and Security\n\t\t\t\t\t- Self-sovereign identity and privacy-preserving technologies empower users to control their data and protect their privacy.\n\t\t\t\t- ## Economic Opportunities\n\t\t\t\t\t- The interconnected virtual economy allows for new forms of economic activity and value creation.\n\t\t\t\t- ## Community Governance\n\t\t\t\t\t- AI-driven governance models facilitate user participation in decision-making and policy-setting.\n\t\t\t\t- ## Safe and Secure Environment\n\t\t\t\t\t- Safeguarding measures and law enforcement interaction ensure a secure and protected user experience.\n- # Diagrams as code (mermaid)\n- ```mermaid\n  graph TD\n      A[Agentic Mycelia]\n      A --> B(Interoperability)\n      A --> C(User Empowerment)\n      A --> D(Adaptable Governance)\n  \n      B --> E(Standardized Protocols)\n      B --> F(Ontologies)\n      B --> G(Translation Mechanisms)\n  \n      C --> H(Self-Sovereign Identity)\n      C --> I(Privacy-Preserving Technologies)\n      C --> J(User-Centric Governance)\n  \n      D --> K(AI-Driven Governance Models)\n      D --> L(Adapts to Changing Needs)\n      D --> M(User Preference Driven)\n  \n      N[Metaverse Instances]\n      N --> O(Omniverse Digital Twin)\n      N --> P(Roblox Event)\n      N --> Q(Unreal-based MMORPG)\n      N --> R(Global Business Conference)\n      N --> S(Feminist Global Advocacy and Support)\n  \n      T[Scene Agents]\n      T --> U(AI Governance)\n      T --> V(Reputation Management)\n      T --> W(Environmental Conditions)\n      T --> X(Virtual Economy)\n  \n      Y[Transfer Agents]\n      Y --> Z(Machine-Machine Translation)\n      Y --> AA(Value Translation)\n      Y --> AB(Digital Object Variations)\n      Y --> AC(Safeguarding)\n      Y --> AD(Law Enforcement Handshake)\n      Y --> AE(PKI Infrastructure)\n  \n      AF[Onboarding Agents]\n      AF --> AG(Preference Setup)\n      AF --> AH(Living Contract Formation)\n  \n      AI[Jurisdictional/Legal Agents]\n      AI --> AJ(Monitoring Network Activity)\n      AI --> AK(Providing Transparency)\n      AI --> AL(Enforcing Legal Standards)\n  \n      AM[Interfaces and Interactions]\n      AM --> AN(Inter-Instance Communication)\n      AM --> AO(Value Exchange)\n      AM --> AP(User Interaction)\n      AM --> AQ(External Interface)\n  \n      AR[Implications for Human Users]\n      AR --> AS(Seamless Navigation)\n      AR --> AT(Enhanced Privacy and Security)\n      AR --> AU(Economic Opportunities)\n      AR --> AV(Community Governance)\n      AR --> AW(Safe and Secure Environment)\n  \n      style A fill:#FFD700,stroke:#333,stroke-width:4px\n      style N fill:#87CEEB,stroke:#333,stroke-width:2px\n      style T fill:#90EE90,stroke:#333,stroke-width:2px\n      style Y fill:#FFA07A,stroke:#333,stroke-width:2px\n      style AF fill:#ADD8E6,stroke:#333,stroke-width:2px\n      style AI fill:#F08080,stroke:#333,stroke-width:2px\n      style AM fill:#AFEEEE,stroke:#333,stroke-width:2px\n      style AR fill:#20B2AA,stroke:#333,stroke-width:2px\n  \n  \n  ```\n- ```mermaid\n  sequenceDiagram\n      participant User\n      participant AIAgent\n      participant Nostr\n      participant Bitcoin\n      participant Lightning\n      participant RGB\n      participant NosDAV\n      participant GitHub\n      participant Logseq\n      participant SolidLite\n      participant LinkedJSON\n      participant Omniverse\n      participant USD\n  \n      User->>+Logseq: Define agent tasks and rewards\n      Logseq->>+GitHub: Store agent configurations\n      GitHub->>+AIAgent: Trigger agent update\n      AIAgent->>+Nostr: Subscribe to relevant events\n      Nostr->>+AIAgent: Deliver relevant events\n      AIAgent->>+Logseq: Retrieve task configurations\n      Logseq->>+AIAgent: Provide task configurations\n      AIAgent->>+NosDAV: Retrieve required data\n      NosDAV->>+AIAgent: Provide requested data\n      AIAgent->>+RGB: Request single-use seal\n      RGB->>+AIAgent: Provide single-use seal\n      AIAgent->>+Nostr: Perform task and publish results\n      Nostr->>+User: Deliver task results\n      User->>+Lightning: Send payment for task completion\n      Lightning->>+Bitcoin: Settle payment transaction\n      Bitcoin->>+AIAgent: Confirm payment receipt\n      AIAgent->>+Nostr: Publish payment confirmation\n      Nostr->>+User: Deliver payment confirmation\n      User->>+SolidLite: Interact with decentralized application\n      SolidLite->>+LinkedJSON: Retrieve structured data\n      LinkedJSON->>+SolidLite: Provide structured data\n      SolidLite->>+Nostr: Publish user actions\n      Nostr->>+AIAgent: Deliver user actions\n      AIAgent->>+Omniverse: Retrieve virtual environment data\n      Omniverse->>+AIAgent: Provide virtual environment data\n      AIAgent->>+USD: Manipulate 3D assets\n      USD->>+AIAgent: Provide updated 3D assets\n      AIAgent->>+Omniverse: Update virtual environment\n      Omniverse->>+Nostr: Publish virtual environment updates\n      Nostr->>+User: Deliver virtual environment updates\n      User->>+Nostr: Publish feedback and interactions\n      Nostr->>+AIAgent: Deliver user feedback and interactions\n      AIAgent->>+NosDAV: Store interaction data\n      NosDAV->>+AIAgent: Confirm data storage\n      AIAgent->>+Nostr: Publish interaction confirmation\n      Nostr->>+User: Deliver interaction confirmation\n  ```\n- # Conclusion\n\t- The Agentic Mycelia presents a vision for a decentralized and interconnected metaverse ecosystem.\n\t\t- It emphasizes:\n\t\t\t- Interoperability\n\t\t\t- Adaptable governance\n\t\t\t- User empowerment\n\t\t\t- Control of personal data",
        "link_types": [
            "Google",
            "Gemini",
            "Chain of Thought",
            "Large language models",
            "Diagrams as Code",
            "Prompt Engineering",
            "Anthropic Claude",
            "Metaverse Ontology"
        ],
        "file_size": 27981
    },
    {
        "id": "Microsoft Work Trends Impact 2024.md",
        "name": "Microsoft Work Trends Impact 2024",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- This Microsoft  LinkedIn report contains very interesting findings ![2024_Work_Trend_Index_Annual_Report_663d45200a4ad.pdf](../assets/2024_Work_Trend_Index_Annual_Report_663d45200a4ad_1715414237615_0.pdf)\n- | Statistic | Value |\n  |-----------|-------|\n  | Percentage of global knowledge workers using generative AI | 75% |\n  | Percentage of AI users who started using it less than 6 months ago | 46% |\n  | Percentage of AI users who say it helps them save time | 90% |\n  | Percentage of AI users who say it helps them focus on their most important work | 85% |\n  | Percentage of AI users who say it helps them be more creative | 84% |\n  | Percentage of AI users who say it helps them enjoy their work more | 83% |\n  | Percentage of emails read in under 15 seconds | 85% |\n  | Ratio of emails read to emails sent | 4 to 1 |\n  | Percentage of time Microsoft 365 users spend on emails, chats, and meetings | 60% |\n  | Percentage of time Microsoft 365 users spend in creation apps like Word and PowerPoint | 40% |\n  | Percentage of leaders who agree their company needs to adopt AI to stay competitive | 79% |\n  | Percentage of leaders who worry about quantifying the productivity gains of AI | 59% |\n  | Percentage of leaders who worry their organization's leadership lacks a plan and vision to implement AI | 60% |\n  | Percentage of AI users who are bringing their own AI tools to work (BYOAI) | 78% |\n  | Percentage of AI users at small and medium-sized companies who are bringing their own AI to work | 80% |\n  | Percentage of AI users reluctant to admit using AI for their most important tasks | 52% |\n  | Percentage of AI users who worry using AI on important work tasks makes them look replaceable | 53% |\n  | Percentage of people who struggle with the pace and volume of work | 68% |\n  | Percentage of people who feel burned out | 46% |\n  | Increase in hiring for technical AI talent in the past eight years | 323% |\n  | Percentage of leaders who wouldn't hire someone without AI skills | 66% |\n  | Percentage of leaders who would rather hire a less experienced candidate with AI skills than a more experienced candidate without them | 71% |\n  | Percentage of leaders who say early-in-career talent will be given greater responsibilities with AI | 77% |\n  | Percentage of US executives not currently investing in AI tools or products for employees | 45% |\n  | Percentage of AI users globally who have received AI training from their company | 39% |\n  | Percentage of companies planning to offer training on generative AI this year | 25% |\n  | Percentage of leaders concerned about having enough talent to fill roles in the year ahead | 55% |\n  | Percentage of cybersecurity, engineering, and creative design leaders concerned about having enough talent | 60%+ |\n  | Percentage of people who worry AI will replace their job | 45% |\n  | Percentage of people considering quitting in the year ahead | 46% |\n  | Increase in job applications per role in the US since last fall | 14% |\n  | Percentage of US professionals considering a new job this year | 85% |\n  | Projected change in skills globally by 2030 (from 2016) | 50% |\n  | Projected acceleration of skills change due to generative AI | 68% |\n  | Percentage of this year's LinkedIn Jobs on the Rise in the US that didn't exist 20 years ago | 68% |\n  | Percentage of recruiters already creating new roles tied to generative AI usage | 12% |\n  | Growth of Head of AI roles over the past five years | 3x |\n  | Growth of Head of AI roles in 2023 | 28% |\n  | Increase in use of LinkedIn Learning courses to build AI aptitude among non-technical professionals in the past six months | 160% |\n  | Increase in LinkedIn members globally adding AI skills to their profiles | 142x |\n  | Percentage of people who say they need AI skills to remain competitive in the job market | 76% |\n  | Percentage of people who say AI can help them get promoted faster | 69% |\n  | Percentage of people who say AI skills will broaden their job opportunities | 79% |\n  | Percentage of recruiters updating job descriptions to reflect generative AI usage in the role | 22% |\n  | Additional application growth for LinkedIn job posts mentioning artificial intelligence or generative AI over the past two years | 17% |\n  | Percentage of early-in-career and individual contributor employees who said AI access would influence their choice of employer | 54% |\n  | Percentage of AI power users who say AI makes their overwhelming workload more manageable | 92% |\n  | Percentage of AI power users who say AI boosts their creativity | 92% |\n  | Percentage of AI power users who say AI helps them focus on the most important work | 93% |\n  | Percentage of AI power users who say AI helps them feel more motivated | 91% |\n  | Percentage of AI power users who say AI helps them enjoy work more | 91% |\n  | How much more likely AI power users are to frequently experiment with different ways of using AI compared to other respondents | 68% |\n  | How much more likely AI power users are to frequently pause before a task and ask if AI can help compared to other respondents | 49% |\n  | How much more likely AI power users are to keep trying if they don't get the perfect AI response the first time compared to other respondents | 30% |\n  | How much more likely AI power users are to research and try new AI prompts compared to other respondents | 56% |\n  | Percentage of AI power users who use AI to start their day | 85% |\n  | Percentage of AI power users who use AI to get ready for the following workday | 85% |\n  | How much more likely AI power users are to use AI to catch up on missed meetings compared to other respondents | 56% |\n  | How much more likely AI power users are to use AI to analyze information compared to other respondents | 51% |\n  | How much more likely AI power users are to use AI to design visual content compared to other respondents | 49% |\n  | How much more likely AI power users are to use AI to interact with customers compared to other respondents | 49% |\n  | How much more likely AI power users are to use AI to brainstorm or problem-solve compared to other respondents | 37% |\n  | How much more likely AI power users are to redesign their business processes and workflows with AI compared to other respondents | 66% |\n  | How much more likely AI power users are to hear from their CEO about the importance of using generative AI at work compared to other respondents | 61% |\n  | How much more likely AI power users are to hear from the leader of their department about the importance of using generative AI at work compared to other respondents | 40% |\n  | How much more likely AI power users are to hear from their manager's manager about the importance of using generative AI at work compared to other respondents | 42% |\n  | How much more likely AI power users are to receive encouragement from leadership to consider how AI can transform their function compared to other respondents | 53% |\n  | How much more likely AI power users are to say their company encourages innovation compared to other respondents | 18% |\n  | How much more likely AI power users are to say their company has a virtual learning program compared to other respondents | 37% |\n  | How much more likely AI power users are to have received training on prompt writing compared to other respondents | 37% |\n  | How much more likely AI power users are to have received training on how to use AI for their role or function compared to other respondents | 35% |\n  | How much more likely AI power users are to have received training on specific AI use cases such as writing or analyzing data compared to other respondents | 32% |",
        "link_types": [],
        "file_size": 7664
    },
    {
        "id": "GANs.md",
        "name": "GANs",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n",
        "link_types": [],
        "file_size": 14
    },
    {
        "id": "Calculating Empires.md",
        "name": "Calculating Empires",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- Calculating Empires is a large-scale research visualization project and exhibition that explores the interconnected history of technology and power [from 1500 to the present day](https://calculatingempires.net/about.html)\n- <iframe src=\"https://calculatingempires.net/\" style=\"width: 100%; height: 600px\"></iframe>\n- Created by researcher-artists Kate Crawford and Vladan Joler, it aims to contextualise current developments in [[Artificial Intelligence]] by examining how technology and power structures have [co-evolved over five centuries](https://www.e-flux.com/announcements/573730/calculating-empires/)\n- <iframe src=\"https://knowingmachines.org/research\" style=\"width: 100%; height: 600px\"></iframe>\n- The centerpiece of the exhibition is the [Calculating Empires Map Room](https://knowingmachines.org/publications/calculating-empires), which features two massive 12-meter long maps.\n- One map focuses on communication and computation, covering the evolution of communication devices, interfaces, data practices, and computational architectures.\n- The other map explores control and classification, examining how technologies have been integrated into social systems of [[Surveillance]] , [[education]] , colonialism, [[Cyber Security and Military]]\n- It starts in the 1500s, examining pivotal developments like the Gutenberg printing press and new maritime trade routes that expanded European [[Politics, Law, Privacy]]\n- It takes a long-term view to reveal recurring patterns in how technology and power structures have developed over centuries.\n- The visual style is inspired by sources like [Aby Warburg's \"Atlas\" project](https://warburg.library.cornell.edu/about/), using evocative imagery to trace historical evolutions.\n- It aims to provide critical perspective on current AI developments by placing them in a broader historical context of technological power.\n- The exhibition also includes a recreation of the creators' earlier work \"[Anatomy of an AI System\"](https://www.moma.org/collection/works/401279).",
        "link_types": [
            "Artificial Intelligence",
            "Surveillance",
            "education",
            "Cyber Security and Military",
            "Politics, Law, Privacy"
        ],
        "file_size": 2041
    },
    {
        "id": "Digital Objects.md",
        "name": "Digital Objects",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n- # Digital Objects & NFTs\n\t- Nonfungible tokens are a whole ‘class’ of digital token, separate and distinct from everything discussed to this point. They are generally[recognised inlaw](https://www.signaturelitigation.com/nfts-recognised-as-property-lavinia-deborah-osbourne-v-1-persons-unknown-2-ozone-networks-inc-trading-as-opensea/)as property in their own right.[[moringiello2021property; @fairfield2021tokenized]] In the Initial Coin Offering (ICO) and project tokens detailed earlier, and limitingthis description to the Ethereum network for now, a project launching anERC-20 token commits contract code to the blockchain, and this contractthen mediates the issuance and management of millions or billions oftokens associated with that project, and it’s use case.[ERC-20](https://ethereum.org/en/developers/docs/standards/tokens/erc-20/)is a [fungible](https://en.wikipedia.org/wiki/Fungibility) tokenissuance. Each of the projects’ tokens is interchangeable with any othertoken. They’re all the same from the point of view of the user.\n\t- Rather than the ERC-20 contract type used for fungible token issuance, NFTs predominantly use the ERC-721 protocol on Ethereum (just different instructions). It’s the case that most NFTs in the 2021/2 hype bubble are algorithmically generated sets of themed art (so-called PFP-NFT). Tens of thousands of distinct tokens are ‘minted’, each one being a complex transaction commitment to the Ethereum blockchain, along with its associated gas fee. These minting events were much-hyped social occasions (before the [2022 market crash](https://www.theguardian.com/technology/2022/jul/02/nft-sales-hit-12-month-low-after-cryptocurrency-crash?)), and happened very quickly, with users clamouring to create art with randomly allocated features from the art schema associated with the project. Lucky winners could find themselves with an NFT art piece with more than an average number of ‘rare’ features. If the overall mint becomes more popular, then the secondary market for all of those mints goes up, and because of the liquidity premium, they can go up a lot. The perceived rarer mints go up a lot more. This whole process is [very energy intensive](https://memoakten.medium.com/the-unreasonable-ecological-cost-of-cryptoart-2221d3eb2053) on the chain, and the vast majority of these projects simply [trend to zero value](https://www.turing.ac.uk/blog/non-fungible-tokens-can-we-predict-price-theyll-sell). In response to this appalling cost-benefit analysis, the Ethereum Foundation has proposed [EIP-2309](https://eips.ethereum.org/EIPS/eip-2309) to make minting NFTs more efficient. They say, “This standard lets you mint as many as you like in one transaction!”\n\t- The Ethereum Foundation gives their somewhat constrained view of [NFTs on their website](https://ethereum.org/en/nft/) and it’s a useful primer. On that page, they detail some of the use cases, as listed below, with a critique added:\n\t\t- Digital content; this is the dominant use case right now. Much more on this later.\n\t\t- Gaming items; again more on this later, it’s an obvious enough use case but [complex politics](https://climatereplay.org/nfts/nft-digital-ownership-pledge/) in the intersection of games and crypto have stalled the adoption curve.\n\t\t- Domain names; this is just starting to reach for applications now, why not a database with the ISP/host?\n\t\t- Physical items; seemed like a clear over-reach as the transfer of the NFT does not imply the transfer of the object, but this is emerging as the growth use case.\n\t\t- Investments and collateral; while this was an emergent option in the space, it’s likely been a bubble, as owners of the tokens cast around for additional liquidity, and loan businesses chased yield with higher risk. The [recent implosion](https://newsletter.banklesshq.com/p/three-arrows-capital-grayscale-maker-lido) of lenders and funds in the crypto space was partly a function of supposedly world-class risk managers accepting jpegs as collateral.\n\t- Moving away from Ethereum, NFTs can be minted on most of the other levelone chains. Solana is a great newcomer example. Sol is a terrible chainwith regards to decentralisation, but thanks to that it’s far cheaperand faster to mint NFTs on it, and it was becoming a [troublingcompetitor](https://markets.businessinsider.com/news/currencies/ethereum-eth-killers-nfts-defi-solana-cardano-wax-crypto-investing-2022-1)for Eth before the FTX ponzi scheme collapse destroyed it’s market value(Figure<a href=\"#fig:solnfts\" data-reference-type=\"ref\" data-reference=\"fig:solnfts\">[fig:solnfts]</a>).\n\t  ![image](./assets/c79e0ea22ab5fa6fac6fa22abbe87ab19f6ef244.jpg){:height 1068, :width 913}\n\t- The same might be true for Cardano’s ADA, though ADA is struggling tohold onto it’s market position despite some technical advances. It’sworth reiterating here that the nature of these digital tools likelymakes for a ‘winner take all’ market dynamic over time. With fees beingcentral to this generative NFT use case it’s possible to see that highlycentralised, fast, and cheap chains will capture and eventually dominatethe space. Remember that this likely (game theoretic) outcome might aswell be a database running without the stark inefficiencies ofblockchain. The whole NFT space is a gamble on consumer enthusiasm forspending money continuing to outpace logic.\n\t- Astonishingly, according to a JPMorgan insider market report ([reportedon in apodcast](https://www.coindesk.com/podcasts/the-breakdown-with-nlw/jpmorgan-bitcoin-shows-some-merit-as-a-store-of-value/)),only around 2 million people have ever actually interacted with NFTs.One analysis suggests that a single entity accounts for 3 of the top 4holders, having made 32,000 ETH from the NFT boom. This suggests heavymarket manipulation and is far from the egalitarian landscape claimed inthe hype. Tellingly it’s thought around [10% of the tradingvolume](https://uk.finance.yahoo.com/news/three-arrows-wanted-100m-nft-161811450.html)on market leading platform ‘Super Rare’ was by the now bankrupt venturecapital firm ‘Three Arrows’.\n\t- With that said NFTs have clearly allowed [digital and new mediaartists](https://en.wikipedia.org/wiki/List_of_most_expensive_non-fungible_tokens)to connect with audiences without gatekeepers. Established mediators andcurators of art have been caught totally wrongfooted, and NFTs seem togive a way for them to be cut out completely. There are suggestions ofapplications beyond this initial digital art scope. This is acompounding, and disrupting paradigm change.\n- ## Key use cases\n\t- ### Art\n\t\t- The recent surge of interest in NFT’s during early 2021 has largely been driven by digital art NFT’s, despite the origins of digital art NFT’s started much earlier in 2014. New York artist [Kevin McCoy’s *Quantum*](https://www.mccoyspace.com/project/125/) is widely recognised as the first piece of art created as an NFT. However it was during early2021 that art NFT’s started to gain significant attention; by the end of2021, nearly [£31b had beenspent](https://www.paymentscardsandmobile.com/state-of-the-blockchain-nfts-explode-onto-scene-in-2021/)on NFT purchases, a considerable and exponential growth given [2020sales ofasciitilde£71m](https://raritysniper.com/news/nfts-exploded-in-2021-with-25-billion-in-sales/)High profile digital artists such as *Beeple* whose [recent recordingbreaksale](https://www.forbes.com/sites/abrambrown/2021/03/11/beeple-art-sells-for-693-million-becoming-most-expensive-nft-ever/?sh=3f237d1c2448)of his NFT *“The first 5000 days”* (Figure<a href=\"#fig:first5000days\" data-reference-type=\"ref\" data-reference=\"fig:first5000days\">[fig:first5000days]</a>)at Christies (a long established British auction house, specialising in high profile precious work of art) for £52.9m helped bring NFT’s into the public spotlight and wider give them global attention.\n\t\t  ![image](./assets/348ebd1d1b622796f691fdcedc6d6207ec79739d.jpg)\n\t\t- Art as NFT’s offer the following advantages:\n\t\t\t- ##### Immutable Nominal Authenticity\n\t\t\t\t- Art fraud such as false representation, forgeries, plagiarism have beena reoccurring blight since art has existed; artists and works of arthave been open to abuse by forgers, black market profiteers and evenfellow artists laying claim to works of art of others. Unless a work ofart is sold, exhibited or listed, documenting when and who created it,the *nominal authenticity,* which Dutton states as the *“correctidentification of the origins, authorship, or provenance of anobject”*[[dutton2003authenticity]] can be increasingly mutable over aperiod of time, dependent on a multitude of factors, including; theartists existing profile, how widely and where the work of art isexhibited, if the work of art is commissioned by a patron, if it’s sold,and profile of the buyer/collector. At its most basic level, once a workof art is ‘minted’ as an NFT (publishing the art work as a unique tokenon the blockchain) this functions as an immutable publicly accessibleproof of ownership and by extension proof of creation. The act ofminting is not purely limited to digital art; all an artist requires isa digital representation of any physical art (sculpture, physicalpainting, installation etc..) which can be used as a proxy allowingartists to record the date of creation/origin of a physical piece of arton the blockchain, a buyer purchasing the NFT can be provided the actualphysical artwork as part of the NFT. Nominal authenticity becomes secureand immutable for the lifetime of the blockchain (by no means assured).\n\t\t\t- ##### Secure Digital Provenance\n\t\t\t\t- [Provenance](https://en.wikipedia.org/wiki/Provenance) (or the chain ofcustody) is an important aspect in works of art, antiques andantiquities. Provenance not only helps assign work to an artist but alsodocuments ownership history. Digital provenance, an inherent feature ofNFT’s means provenance now no longer becomes what has historicallysometime been a contentious detective’s game at the best of times; onethat is open to fraud, misinterpretation and entirely reliant on goodrecord keeping.\n\t\t\t\t- Since provenance can contribute to the value of a piece of art(benefiting both the creator and collector) the use of the blockchain asan open, secure ledger is a far more trustworthy system than traditionalmethods of artistic provenance that were cobbled together; oftenconsisting of a mix of physical and digital documents spanning private &public sale receipts, art/museum gallery exhibitions and private recordkeeping). Digital provenance provided when an artist ‘mints’ a piece ofart into an NFT allows artists and collectors to record a secure,permanent unalterable history of transactions for a specific piece ofart, providing future collector complete trust in the origin and custodyof a piece of art.\n\t\t\t- ##### Decentralised automated royalty payments\n\t\t\t\t- Traditionally if a piece of art is sold, the first sale may (but notalways) benefit the artist financially, however secondary and anysubsequent sales would only ever financially benefit thebuyer/collector; the original artist would rarely benefit. However If awork of art is minted into an NFT, royalty payments can be predeterminedand automated in perpetuity directly by the use of a ‘smart contract’.Smart contracts are small, automated scripts/programs that runautomatically and independently of a buyer/seller; pre-determinedconditions are set by the buyer; these trigger when certain conditionsare met i.e. These cannot yet be enforced “on chain” and the NFT auctionhouses online have engaged in a race to the bottom and stopped enforcingroyalty payments through their systems. This element might not even bepossible, though there is some hope that we could enable this in thecomplex logic offered by the RGB protocol.\n\t\t\t- ##### On sale transfer\n\t\t\t\t- 20% of total sale amount into digital wallet of the creator. 80% oftotal sale amount into digital wallet of the seller.\n\t\t\t\t- Once the royalty payment rate is set by the artist/creator, futureroyalties of all sales can be paid directly to the artist/creatoraccount (via a digital wallet) without the need of a third party(traditionally a gallery/agent etc..).\n\t\t\t\t- Smart contract driven NFT’s means that even if piece of art is resold 5,10 or even a 100,000 times moving through 5, 10 or even a 100,000different collectors; a pre-determined royalty payment rate set by thecreator would still guarantee the artist/creator is paid directly fromeach and every future sale.\n\t\t\t\t- Historically provenance for works of art may span across generations,for instance Gabriël Metsu’s oil on canvas painting *The Lace Maker’s*provenance, first recorded in 1722, now spans 300 years of ownership,including from a British Baron in the 19superscriptth century to anAmerican philanthropist in the 20superscriptth century.) Metsu diedyoung at the age of 38, leaving a widow; neither his/herrelatives/descendants benefit from his original work, 300 years laterthis would be near impossible to facilitate with traditional systems, aseven legal contracts are open and prone to the ravages of time.\n\t\t\t\t- NFT smart contracts hold an incredibly potential; an artists descendantsfinancially benefiting directly from the resale of a piece of work longafter the artist/museum’s/gallery or even state have turned to dust aslong as the original creator’s digital wallet is accessible, *theblockhain becomes an everlasting digital patron* ensuring\n\t\t\t\t- NFT art currently suffers from the same failure of decentralisationalready discussed in the Ethererum technology stack, but this iscompounded by the normalisation of intermediate art brokers [continuingto custody](https://moxie.org/2022/01/07/web3-first-impressions.html)the NFTs even after sale. They are usually selling a pointer to theirown servers. The market is nascent and evolving, but it’s currently notdelivering on it’s core promise.\n\t\t\t\t- Proof of ownership is intuitively a pretty obvious application for thetechnology, but again it’s hard to justify the expense when the benefitsare so slim. [Bulldogs on theblockchain](https://www.bullishlybred.com/) is a clear gimmick, andmight even incentivise poor behaviours as there are two products herewhich are not necessarily aligned. Much has been written over the yearsabout [deeds to property](https://propy.com/browse/propy-nft/) beingpassed through blockchains, cutting out the middle man, but in the eventthat a house deed NFT was hacked and stolen it’s obviously not the casethat the property would then pass to the hacker.\n\t\t\t\t- One of the most interesting companies is Yuga Labs, who launched theincredibly popular Bored Ape Yacht club set of 10,000 algorithmicallygenerated NFTs. These Ethereum based NFTs were based loosely on the‘Crypto Punks’ model of PFP-NFT (variously profile picture project,picture for proof, and picture for profile\n\t\t\t\t- no definition remainsuncontested for long). Yuga launched with a better commercialisationmodel for the holders, and a strong marketing drive into celebritycircles. They now regularly change hands for hundreds of thousands ofpounds. Even this ‘blue chip’ NFT is not without [seriouscriticism](https://twitter.com/coryklippsten/status/1538909505236283392):it“I’d put it at 99.99% the project is in fact a deliberate troll,intentionally replete with Nazi symbols and esoteric racist dogwhistles”\n\t\t\t\t- Yuga recently bought the artistic rights to the commercial reuse ofsimilarly popular (and preceding) Punks set. This is interesting becausethey have again handed the commercial re-use rights to the owners of theindividual NFTs. This raises the same [confusingproblem](https://www.bloomberg.com/news/articles/2022-03-21/bored-ape-nft-spinoff-venture-gone-sour-sparks-legal-fight)with attaching commercial rights to an easily stolen token as NFTs forreal estate does. This has been demonstrated recently when Seth Greenhad a Bored Ape stolen after [creating an animated show around it’sIP](https://www.buzzfeednews.com/article/sarahemerson/seth-green-bored-ape-stolen-tv-show).Many more contradictions and ambiguities in NFT licenses are emerging.Galaxy Digital have [surveyed thelandscape](https://www.galaxy.com/research/insights/a-survey-of-nft-licenses-facts-and-fictions/):it“Contrary to the ethos of Web3, NFTs today convey exactly zeroownership rights for the underlying artwork to their token holders.Instead, the arrangements between NFT issuers and token holders resemblea distinctly web maze of opaque, misleading, complex, and restrictivelicensing agreements, and popular secondary markets like OpenSea provideno material disclosures regarding these arrangements to purchasers.Something more is required, and that ‘something’ is a legal agreementbetween the owner of the image—known as the ‘copyright holder’ and theNFT holder specifying what rights the NFT holder has with respect to theimage. To the extent an NFT purchaser has any rights to the imageassociated with his or her NFT at all, those rights flow not from his orher ownership of the token, but from the terms and conditions containedin the license issued by the NFT Project governing the NFT holder’spurchase and use of the image. Accordingly, for the vast majority of NFTprojects, owning the NFT does not mean you own the corresponding digitalcontent that is displayed when you sync your wallet to OpenSea. Thatcontent, as it turns out, is owned and retained by the owner of thecopyright associated with that digital content, typically the NFTproject. After reviewing the most used license agreements for NFTprojects, it becomes apparent that NFT standards and smart contracts donot recognize off-chain law.” There may already be a response from theindustry to this in the shape of [a16z’s “can’t be evil” licenseproposal](https://a16zcrypto.com/introducing-nft-licenses/).\n\t\t\t\t- Even so, the community around these collections is incredibly strong,mixing developers, artists, the rich and famous, and the fortunate andearly, into a cohesive community who communicate online. The developer‘good will’ is enormous, and it seems possible that this will lead tofaster and broader innovation around the collections, and out into[metaverseapplications](https://twitter.com/yugalabs/status/1505014986556551172?).The brand is strong, and the individual NFT items both benefit from, andreinforce that brand, while adding personal narratives and humaninterest.\n\t\t\t\t- As a gauge of how frothy this market still is it’s interesting to lookat the APE token which Yuga just launched. They airdropped 10,000 of thetokens free to each of the 10,000 NFT holders. This instantly created amulti-billion dollar market cap, and a top 50 ‘crypto’ out of thin air,based purely on their brand. It’s clear that there is both brand, and amarket here.\n\t\t\t\t- A recent report from \"Base Layer\" tries to capture the community‘feature’ of big brand NFTs. [“Crypto culturedecoded”](https://baselayer.so/crypto-culture-decoded) explains that isis these online communities which are the attraction not necessarily theart. This is a powerful ‘in group’ argument, though speculation remainsthe most likely underpinning.\n\t\t\t\t- While it is likely that this is currently a speculative bubble, that is[waning already](https://www.bbc.co.uk/news/business-61102759) (Figure<a href=\"#fig:monkey\" data-reference-type=\"ref\" data-reference=\"fig:monkey\">[fig:monkey]</a>),it seems certain that the technology is here to stay in some form.\n\t\t\t\t  ![image](./assets/8b0f2b24b70d1083878b139fb04cb6001e4acf56.jpg)\n\t\t\t- #### Computer & Video Games\n\t\t\t\t- Computer & Video games are a huge global business, exponential globalgrowth over the last 30 years has seen this grow to a point where it haseclipsed both the [global movie and North American sportsindustries](https://www.businessinsider.com/video-game-industry-revenues-exceed-sports-and-film-combined-idc-2020-12?r=US&IR=T)combined.\n\t\t\t\t- A global industry with revenues over £120b, [with asciitilde half thepeople on the planet](https://www.wepc.com/news/video-game-statistics/)playing some form of games in 2021.\n\t\t\t\t- As the games industry has evolved and matured over the last 40 years,secondary markets have emerged, most notably the ‘second hand’ gamesresale market. The rise of ‘retro’ gaming, has demonstrated the secondhand market is a lucrative one for private resellers, an unopened copyof Super Mario Bros for the Nintendo Entertainment System [recentlyselling for£1.5M](https://www.nytimes.com/2021/08/06/business/super-mario-bros-sale-record.html)to the extent the market has seen [speculators looking to cashin](https://www.businessinsider.com/retro-gaming-market-being-overtaken-by-speculators-2021-9?r=US&IR=T)on the huge global interest in retro/second hand games.\n\t\t\t\t- Despite publishers and developers increasingly moving to non-physicaldigital only’ games, the demand for used games remains incredibly high.\n\t\t\t\t- Whilst some retailers have adapted their business models to includereselling of retro/second hand games, the vast majority ofpublisher/developers/retailers aren’t able to directly benefit from theemerging retro/second hand games market. The potential of *video gamesas NFT’s* presents a huge opportunity for publishers, developers andplayers alike, offering the following advantages:\n\t\t\t- ##### Royalty Sales on Pre-owned Games\n\t\t\t\t- ; A predetermined proportion of any resale of a used game can automatedin perpetuity via smart contracts; once these are set by the publisher,future royalties of all sales can be paid directly to thepublishers/developers wallets (a digital account) without the need of athird party (traditionally a retail entity). Traditionally only theinitial first sale of a game would financially benefit thepublisher/developer/retailer, secondary and subsequent sales would onlyever financially benefit the purchaser, with many developers/publishersarguing this is hurting the wider industry through the loss ofsignificant income generated by the secondary and subsequent sales,sometimes over the course of decades. However the use of NFT’s smartcontracts means that if a game is sold/resold through 10,000 collectors;a pre-determined royalty payment rate set by the publisher would stillguarantee the publisher (and or developer/retailer) takes a proportionof any future sales.\n\t\t\t- ##### Monetisation of User Generated Content:\n\t\t\t\t- Games as a NFT’s offer ability to monetise UGC: User generated content.Video games such as [Nintendo’s *PokemonGo*](https://www.businessofapps.com/data/pokemon-go-statistics/) *(166million players)*, [Bungie’s *Destiny2*](https://techacake.com/destiny-2-player-count/#:~:text=The%20total%20player%20base%20of,to%20be%2038%20million%20players.&text=According%20to%20the%20source%2C%20the,in%20terms%20of%20player%20population.)*(38 million players)* or [miHoYo’s GenshinImpact](https://fictionhorizon.com/how-many-people-play-genshin-impact/#:~:text=Genshin%20Impact%20had%20approximately%209,million%20users%20in%20June%202021.)(*9 million players* ) all have large, established and significantplayer bases. What is noteworthy, the games are designed to encourageplayers may spend hundreds, or in some cases thousands of hours on onegame alone; according to[Destinytracker.com](https://destinytracker.com/destiny/leaderboards/all/minutesplayedtotal?grouped=true&page=1),the top players have amassed total play times over 20,000 hours, closeto 1,000 days or asciitilde 3 years, which is incredible feat givenDestiny 2 only launched 5 years ago in 2017.\n\t\t\t\t- Destiny/Pokemon Go and Genshin Impact revolve around a central key gamemechanic; players investing significant amounts of time collecting ingame digital assets; characters/weapons/items, often classed as ‘rare’or ‘exotic’ or ‘5 Star’. These collectibles usually found by acombination of the accrual of in-game time, completing quests,purchasing additional in-game items/boosters, and luck (‘RNG’). Playersare often encouraged to share their collections of rarecharacters/weapons/ objects through in-game achievements, triumphs,scores acting as a mark of distinction/status symbol.\n\t\t\t\t- Traditionally there has been nothing that went beyond sharing the*digital badge* (i.e triumph/achievement/accomplishment) on a on socialmedia/gamer’s platform profile. However NFT’s offer the ideal system fordevelopers/publishers and even players to monetise usergenerated/customised data (such as a players unique save game data),simultaneously allowing: a) creation of an additional monetisedecosystem to meet player demands i.e. some players who are willing tomonetise and ‘sell’ their invested time in a particular product/serviceto other players with little time but willing to pay other players for‘grinding’ (progressing laborious in game tasks) and a more advancedin-game progression point. The potential to providepublishers/developers with an additional long-term income stream,providing a better ROI on computer & video game development, which inmany instances can cost hundreds of millions in development costsspanning 5/10 years, is undeniable.\n\t\t\t\t- This use case is where our focus lies, as it is now far easier for users to generate content with the support of AI. Note that ideas also can count as content.\n\t\t\t- ##### Play to earn revenue models\n\t\t\t\t- This is morally dicey at this time and early startups like [AxieInfinity are in serioustrouble](https://www.bloomberg.com/news/features/2022-06-10/axie-infinity-axs-crypto-game-promised-nft-riches-gave-ruin).A (long) [video by DanOlsen](https://www.youtube.com/watch?v=YQ_xWvX1n9g) highlights thestructural problems with both play to earn and NFTs. On chain analysissuggested that 40% of accounts in 200 current Web3 games [arebots](https://gallery.usejigger.com/).\n\t\t\t- ##### Monetizing In game collectibles\n\t\t\t\t- customisable in game assets (vanity items such as cosmetic characterskins/clothing or collectible items that offer player advantages(newweapons/vehicles/mods etc,..)\n\t\t\t\t- Traditional gamers have pushed back on the seemingly useful idea ofintegrating NTFs with traditional games. This may be in part becauseEthereum mining has kept graphics card prices high for a decade.\n\t\t\t\t- [HBARpartnerships](https://www.prnewswire.com/news-releases/hbar-foundation-and-ubisoft-partner-to-support-growth-of-gaming-on-hedera-network-301474971.html)\n\t\t\t\t- [Critique from Marc Petit of Epic andUnreal](https://finance.yahoo.com/news/epic-games-vp-people-have-lost-interest-in-the-metaverse-200725562.html).\n\t\t\t\t- {{twitter https://twitter.com/justinkan/status/1491270239967154178}}\n\t\t\t\t- [Link to Tweet](https://twitter.com/justinkan/status/1491270239967154178)\n\t\t\t\t\t- Justin Kan, co-founder of twitch: it“NFTs are a better business modelfor games. Many gamers seem to be raging hard against game studiosselling NFTs. But NFTs are also better for players. Here’s why I thinkblockchain games will be the predominant business model in gaming in tenyears. NFTs are a better business model for funding games . Example:recently I invested in a new web3 game SynCityHQ. They are building amafia metaverse and raised $3M in their initial NFT drop.  NFTs give studios access to a new capital market for raising capitalfrom the crowd.NFTs can be a better ongoing model for games. Web3 gameswill open economies, and by building the games on open and programmableassets (tokens + NFTs) they will create far more economic value thanthey could from any one game. Imagine Fortnite, but other developers canbuild experiences on top of the V-Bucks and skins. Epic would get aroyalty every time any transaction happens. As big as Fortnite is today,Open Fortnite could be much bigger, because it will be a true platform.NFTs are better for gamers Allowing gamers to have ownership of theassets they buy and earn in game allows them to participate in thepotential growth of a game. It lets gamers preserve some economic valuewhen they switch to playing something new. But what about the criticismsof NFTs?  Here are my thoughts on the common FUDs: \"It’s just a money grab on thepart of the studios!\"  Game studios already switched over to the model of selling in-gameitems, cosmetics, etc to players long ago. But currently the digitalstuff players are buying isn’t re-sellable. NFT ownership is strictlybetter for players. \"The games aren’t real games.\" This reminds me ofthe criticism of free-to-play in 2008, when the games were Mafia Wars /FarmVille. We haven’t had time for great developers to create incredibleexperiences yet. Everyone investing in games knows there are great teamsbuilding. \"Game NFTs aren’t really decentralized because they rely onmodels / assets inside centralized game clients.\" Crypto is as much amovement as it is a technology. Putting items on a blockchain is whatgives people trust that they have participatory ownership...which makepeople willing to buy in to the game. These assets are “backed” byblockchain. The fact that these item collections are NFTs will makeother people willing to build on top of them. \"NFTs are bad for theenvironment.\" Solana and L2s solve this. NFT games are better forplayers and for game developers. Like the free-to-play revolutionchanged gaming, so will blockchain. The games of the future will befully robust, with open and programmable economies.”\n\t\t\t- ### Broader and metaverse uses\n\t\t\t\t- So far according to a16z NFTs break down into:\n\t\t\t\t\t- Profile pictures: These were discussed at the start of the chapter and have felt ubiquitous on Twitter over the last couple of years. The major projects will likely hold value, but the hype cycle will likely lead to all profile NFTs going in and out of fashion. There’s potentially a fresh wave of this same kind of low key identity hype possible in the metaverse, and indeed the two plausible both intersect and converge.\n\t\t\t\t\t- Art and Music: Art has also been discussed above. Peter Thiel, the billionaire venture capitalist who founded PayPal has invested in expanded NTF use cases. The first is ‘Royal’ which is experimentally [selling limited NFT tokens](https://royal.io/) which contractually entitle the holder to a portion of music artist royalties. Spotify are experimenting with music NFTs (and of course in the metaverse). This is an early adopter area, and again likely converges with our planned uses cases as more complex tooling appears. For instance Tim Exile of [Endless.fm](https://endlesss.fm/) talks about digital assets extending to the building blocks of co-created music, and wished to build a music creator economy which distributes value to creators at the instant of the final value transaction with the consumer.\n\t\t\t\t\t- Gaming: As discussed there’s pushback from the gaming community, but huge investment from the likes of Lego, Blizzard, Epic, Ubisoft etc.\n\t\t\t\t\t- Gig tickets: Not only the straightforward use of [transferable tickets for events](https://news.yahoo.com/psg-sells-us-220-000-030927515.html) as NFTs on a blockchain (which is impossible due to the cost right now) but also onward monetisation of ticket stubs as memorabilia. The NBA is [already looking at this](https://deadspin.com/investing-in-nft-ticket-stubs-is-likely-one-of-the-nba-1848991991).\n\t\t\t\t\t\t- *“The team sells the ticket for face value many many years ago, but when that stub is being sold now for much more many times over, the team gets none of that money,” York explained. “But with an NFT stub that changes. Let’s say a new rookie enters the NBA next season and he turns out to be the next LeBron James. That ticket stub from his first game, as an NFT, the team can put a commission on it — 20 percent or however much, the NBA decides that. In 10 years when it’s worth a lot of money, I or whoever owns that NFT, can sell it for say $100,000. The NBA can still collect 20 percent of that sale, because it’s all on a smart contract.”*\n\t\t\t\t- It seems so obvious that this will extend to the virtual events space in the metaverse.\n\t\t\t\t\t- Utility: These are broadly ‘membership’ style tokens, and this seems like a sensible fit. Peter Thiel (again) for instance launches a [political funding NFT](https://www.ztonft.com/) from Blake Masters to support his senate ambitions. To be clear, Thiel is a fundamentalist libertarian, and at the very least [highly eccentric](https://gizmodo.com/peter-thiel-bitcoin-talk-miami-2022-1848764790). This is not necessarily a positive for the technology.\n\t\t\t\t\t- Virtual worlds are a huge application for NFTs, and this seems like it would be a natural fit for our collaborative mixed reality application. In reality the $2B of sold so far is mostly ‘allocations’ in nascent ecosystems, being sold as highly speculative assets, without even a metaverse to use. The majority of that amount is the hyped ‘Otherland’ plots sold under the Bored Apes brand.\n\t\t\t\t\t- “Full stack” luxury brands. [Nic Carter describes](https://medium.com/@nic__carter/redeem-and-retain-nfts-are-the-future-of-luxury-goods-760f00dbce23) a mating of physical and virtual luxury goods. His is a useful article on the future direction, and he has also [provided a primer on NFTs](https://medium.com/@nic__carter/why-nfts-are-hard-to-explain-48f0ab0a35bf). There are many such examples already, such as [Tiffanys ‘NFTiff’\n\t\t\t\t- cryptopunks](https://nft.tiffany.com/faq/) collaboration which will automatically generate royalties for Tiffanys and parent company Louis Vitton in perpetuity. Such products prove provenance, create new aftermarket opportunities, and unlock metaverse applications.\n\t\t\t\t- It is completely reasonable to assert that these use cases could be accomplished without the use of NFT technology, and is part of the hype bubble.\n\t\t\t\t- Twitter user Cantino.Eth offers an exhaustive roundup of what they think future uses might be. It’s a [thread full of industry insider jargon](https://twitter.com/chriscantino/status/1542930648750608387)) but it’s indicative of a shift in focus from speculation to ‘building’ asthe market conditions change.\n\t\t\t\t- {{twitter https://twitter.com/chriscantino/status/1542930648750608387)}}\n\t\t\t\t- Some of the more interesting (less arcane)use cases identified in the thread are summarised very briefly below,again with comments as to how this might pertain to our metaverse applications.\n\t\t\t\t\t- Hobby tokens, demonstrating interest in an activity. This is potentially a metaverse adaptation of badges on a blazer in the real world, and might serve to drive communities in a metaverse. The same is true for activism and political alighnment. It’s a great idea and worth developing.\n\t\t\t\t\t- Professional Networks and qualification badges, like a LinkedIn qualification panel, but in the metaverse. A cisco NFT in the metaverse for a CCNA qualification makes intuitive sense.\n\t\t\t\t\t- Badges to indicate membership of distributed projects within a metaverse. This allows users to identify avatars with shared goals in the metaverse.\n\t\t\t\t\t- Retail incentives, like brand loyalty stamps or rewards for participation in marketing, or early access programmes. This is a true in a metaverse marketplace as it is in a real world coffee shop.\n\t\t\t\t\t- Multiplayer communities with incentives to hit collective milestones. “Collecting as a team sport”. This again seems like a great and intuitive opportunity, but is perhaps less suitable for our more business focussed space. User content submission and automatic monetisation when reused by brands, bonded to an NFT contract.\n\t\t\t\t\t- Customer Cohort NFTs: early adopters of successful brands would be able to prove the provenance of their enthusiasm for a new product, and this might unlock brand loyalty bonuses. It seems this wouldn’t be a transferable NFT, and is more like the “soulbound” idea advanced by Meta.\n\t\t\t\t\t- Education and Customer Support, think an NFT of a great score on reddit community support forums. A trusted community member badge, but visible in the metaverse. This is somewhat like the web of trust model advanced earlier in the book.\n\t\t\t\t\t- NFTs as contracts is far more likely in the metaverse than it has proved to be in real life. This is how ‘digital land’ and objects will be transferred anyway, but with the addition of contractual conditionals with external inputs more subtle products may appear.\n- ### Objects in our collaborative mixed reality\n\t- There has been a recent shift away from the ‘toxic’ moniker of NFT and toward ‘Digital objects’, and seem to be judged crucial to metaverse applications. The success of avatar [‘collectibles’ markets](https://medium.com/coinmonks/reddit-nft-success-ca2685163576)in the Reddit ecosystem, and Meta (ex Facebook) similarly divesting themselves of the NFT term seem to suggest a pivot point in the industry. Meta were encouraging adoption through zero fee incentives but were likely hanging their monetisation of their whole rebrand on taking a huge cut from NFT content creators on their platform. This seems to have failed and they are [windingup](https://help.instagram.com/1824155514623095) that part of their business.\n\t- We have potential paths to digital assets within future layer 3technologies ([RGB](https://www.rgb.tech/) & Pear Credits), but they’renot yet fit for purpose. There are compromise options already available,as below.\n\t- #### Liquid tokens\n\t\t- We have seen that Liquid from Blockstream is a comparatively mature andbattle tested sidechain framework, based upon Bitcoin. It is possible toissue tokens on Liquid, and these have their own hardware walletavailable. This makes the technology a strong contender for our uses.\n\t- #### Ethereum\n\t\t- While it’s been discounted elsewhere it’s hard to ignore the networkeffect of Eth NFTs. If the aspiration is to attract the bulk of the‘legacy’ creator/consumer markets then it will be necessary to supportintegration of Metamask into any FOSS stack. This isn’t a huge technicalchallenge, nor is it particularly of interest to our use cases at thisstage, but it remains a possibility. The main problems remain the slowspeed and high expense of the system.\n\t- #### Solana\n\t\t- Solana is both cheap and fast, because it’s very highly centralised. Itseems unlikely that it’s worth this level of compromise. It has alsobecome embroiled with the fallout from the enormous FTX exchange fraud,threatening the existence of the assets (NFTs) issued and stored uponit.\n\t- #### Peerswap\n\t\t- It may be possible to use “Peerswap” to execute rebalancing andsubmarine swaps into and out of Liquid assets on the sidechain in asingle tx. This is anunder explored area at this time.\n\t- #### FROST on Bitcoin\n\t\t- It **might** be possible to transfer ownership of a UTXO on the Bitcoin base chain using FROST.[[komlo2020frost]] In this Schnorr & Taproot basedthreshold signature system it’s possible to [add and removesignatories](https://btctranscripts.com/sydney-bitcoin-meetup/2022-03-29-socratic-seminar/)and thresholds of signing without touching the UTXO itself. In principle(though not yet in practice) this might allow transfer of UTXOownership.\n\t- #### Spacechains\n\t\t- It feels like spacechains are almost ready, so this is worth keeping aneye on. It’s the ‘cleanest’ way to issue assets using Bitcoin becausethere’s no additional speculative chain. As briefly explained in theearlier section Bitcoin is destroyed to create a new chain which theninherits the security of Bitcoin through onward mining. This new assetor chain is able to accrue value and trade independently based purely onit’s value to the buyer, not as a function of a wider speculative bubbleattached to a token with multiple use cases.\n\t- #### Pear credit\n\t\t- One slow moving contender at this stage is Pear Credit from Hypercore. This section needs a full explanation later. For now a [blog post on thesubject](https://medium.com/@observer1/tether-announced-the-launch-of-pear-credit-8d4f66ccd97b)will have to do.\n\t- ##### BRC-20\n\t\t- BRC-20 tokens are fungible tokens that are created by attaching a JSONto satoshis through Bitcoin ordinals. The JSON code bit defines everycharacteristic of the BRC-20 token including the minting, anddistribution, the bitcoin network decodes this information once they aredeployed. BRC-20 tokens are minted and spent like normal tokens. BRC-20tokens utilize Ordinals inscriptions of JSON (JavaScript ObjectNotation) data to deploy token contracts, mint, and transfer tokens.Currently, the BRC-20 token standard allows creating a BRC-20 token withthe deploy function, minting an amount of BRC-20 tokens with the mintfunction, and transferring an amount of BRC-20 tokens via the transferfunction. It’s notable that for purely fungible assets that don’trequire smart contract functionality (which is most of them) BRC-20 issuperior to Ethereum’s ERC-20 in simplicity, security, and the fairnessof the minting process. The community seems very split on this use ofthe chain, and it’s impact on transaction fee markets.\n\t- ##### Litecoin, Vertcoin, and other networks\n\t\t- It is also possible to use the whole suit of ordinal based ideas on anyother chain such as Litecoin, the long standing Bitcoin fork which is used somewhat as a technical testbed for Bitcoin. This might develop into a far more appealing option, though again, it’s too early to be sure.\n\t\t- [Runes on Litecoin! : r/litecoin (reddit.com)](https://www.reddit.com/r/litecoin/comments/1ckwnu6/runes_on_litecoin/)\n\t- #### Satoshi Ordinals, inscriptions, and RUNES\n\t\t- Ordinal inscriptions commit digital data directly in bitcoin. The ability to store NFTs on the bitcoin blockchain offers the security, immutability, and decentralization that is fundamental to bitcoin’s design.The use of Taproot has allowed Ordinals to store large files on the bitcoin blockchain, by exploiting cheap space which was designed to add more complex ‘script-path spend’ scripts. Their creator Rodarmor says the following of them:\n\t\t\t- *\"Inscriptions are digital artifacts, and digitalartifacts are NFTs, but not all NFTs are digital artifacts. Digital artifacts are NFTs held to a higher standard, closer to their ideal. Foran NFT to be a digital artifact, it must be decentralized, immutable,on-chain, and unrestricted. The vast majority of NFTs are not digitalartifacts. Their content is stored off-chain and can be lost, they areon centralized chains, and they have back-door admin keys. What’s worse,because they are smart contracts, they must be audited on a case-by-casebasis to determine their properties. Inscriptions are unplagued by suchflaws. Inscriptions are immutable and on-chain, on the oldest, mostdecentralized, most secure blockchain in the world. They are not smartcontracts, and do not need to be examined individually to determinetheir properties. They are true digital artifacts.”*\n\t\t- Ordinals work by individually tracking single satoshis and repurposingthem as digital artefacts, using the convention of [“ordinal theory”](https://docs.ordinals.com/overview.html) to ascribe non-fungible features to the satoshis in a consistent and coherent manner. They can contain various forms of digital content, such as images, audio, video, and pdfs, even [playablegames](https://ordinals.com/inscription/6edf80efbbae537b554340c31496439b57bef65357a57f21cbb547bc6287d7bfi0).The Inscriptions are stored entirely on the bitcoin blockchain, taking advantage of the Taproot upgrade to store the NFT data in Taproot. The bytes remain in the original minted transaction, but the ownership can be passed around by ‘spending’ the UTXO which contained the satoshi forward, not transferring that data, which remains linked to the original ordinal only. There is a [file explorer for these digitalobjects](https://ordinals.com/). This hardly seems the [orgy ofinefficiency](https://twitter.com/adam3us/status/1619836529718996993?)suggested by Adam Back, but there are certainly storage considerations. While this is considered a waste of Bitcoin block space by many, it is possible that the main concern here is the discount that these taproot scripts enjoy, allowing a skewing of the use of money to commit to the chain toward frivolity. The costs associated with committing data to the ledger will likely rise alongside all other operations on the chain, and already represents an unacceptably bar for our requirements.\n\t\t- The older Bitcoin community pushed back on the technology as “spamming the blockchain”, [something discussed since 2019](https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2019-September/017306.html).The cost works out around 50k satoshis per 100k bytes of data, which is comparatively reasonable. Our issue with this approach is that richer nations will be able to push out developing economy financial use cases with the more fun, but frivolous data storage and scarcity application.\n\t\t- In what seems to be a fascinating case study on ownership one ‘BoredApe’ owner moved coveted their Ethereum NFT by destroying it on theoriginal chain in order to migrate to Bitcoin. Yuga labs stated thatthis NFT owner had destroyed their asset, giving up any right they mighthave had. Yuga can now presumably create and sell another copy of thisimage. It’s fair to say that ownership of digital art is far from asettled matter, as pointed out by Low.[[low2022emperor]] We do not planon attaching itany legal assertions to our use of digital objects at thelowest level. What people do with them will be up to them and the openmarket. Neither does this exclude users of the open source stack fromattempting to attach their own restrictions to IP associated with theirwork.\n\t\t- There is also likely to be a considerable impact on the size of the **full** Bitcoin blockchain where the approach to become commonplace. What was a 500 gigabyte file with a fairly linear growth rate might likely become many terabytes over the coming years. The overall workaround for this would be ‘pruned nodes’ vs ‘archival nodes’, similar to the Ethereum approach, with those likely only run in places where prosecutions for illegal data on the chain seem unlikely. Curiously this won’t effect users of the system who choose to run their own nodes, asthe software is configured to throw away this extraneous data prior to the timestamp of the last software upgrade. Concerns that this might price out participation from emerging markets are overblown from an infrastructure point of view, but potentially valid from a fee competition standpoint. This perhaps drives Lightning adoption. Nobody seems too sure, though Kaloudis, senior researcher at Coindesk describes the tradeoffs and tensions at this time.[[Kaloudis2023]] As seems to be the norm now, there is [Nostr integration](https://nosft.xyz/) coming to Ordinals.\n\t\t- The recent announcement by Yuga Labs, the team behind the popular NFTcollection Board Ape Yacht Club and the stewards of CryptoPunks, thatthey are getting into the ordinals space with their new collection,12-Fold, has generated a lot of reactions from the crypto community.This move is variously seen as significant highlighting the potentialfor Bitcoin-based NFTs, or just a naked cash grab. Yuga are at pains topoint out the ownership and self-custody aspects, which are fundamentalprinciples of Bitcoin and better than their current product lines.\n\t\t- As a small technical aside, the move towards inscriptions and ordinals has also led to a surge in interest in partially signed Bitcoin transactions (PSBT), which allows multiple people to use Bitcoin collaboratively. This is an important standard for multi-sig agreements and more, and facilitates the secure transfer of the ordinals, giving them a huge boost.\n\t\t- A [browser extension called ‘Unisat’](https://unisat.io/brc20) acts as awallet which supports non-fungible and also fungible [‘sets’ oftokens](https://twitter.com/LeonidasNFT/status/1650243884973191168).This is likely one to watch closely and we have tested the system on both testnet (with a 1024 byte limit) and main net (as a [single inscription](https://ordinals.com/inscription/4819948774f979f26a8295000675072b626f2c51cbfc0bf614afbb16bbec4266i0) costing £20).\n\t\t- This is obviously far too expensive for the bulk of our use cases withinthe metaverse, and we will use RGB for this in the end (as we havealways intended). Ukolova, the director of the board for LNP/BP Standards Association which develops the RGB protocol and product stack[wrote an opinionpiece](https://bitcoinmagazine.com/culture/are-ordinals-really-good-for-bitcoin)on Ordinals which is worth finishing on. The article discusses thelimitations of using Ordinals in the context of Bitcoin, particularlywith regards to privacy, scalability, and technical difficulties. WhileOrdinals may offer a unique way to represent ownership of rare andexpensive assets, they do not provide additional privacy features beyondwhat is already offered by Bitcoin’s pseudonymous nature. RGB puts allof the data of the asset on the client side, ensuring peer-to-peerverification without relying on any third parties or miners. Theprotocol also applies zero-knowledge cryptographic primitives such asbulletproofs to bring privacy to holders and creators.\n\t\t- In response to criticism, or perhaps just to build, Rodamor, the creator of Ordinals, and inscriptions, has released RUNES which allow fungible token issuance on Bitcoin. This has led to another explosion in fee prices as more degens flock to release early pump and dump meme tokens.\n\t\t- <iframe src=\"https://rodarmor.com/blog/runes/\" style=\"width: 100%; height: 600px\"></iframe>\n\t\t-\n- #### Taproot Assets\n\t- Taproot Assets is a new protocol that leverages the Taproot upgrade inBitcoin and brings asset issuance capabilities to the Bitcoin network.This allows for secure, fast, and scalable transactions,interoperability with Lightning Network, and improved privacy andefficiency.\n\t\t-\n\t\t- Issuance of assets on the Bitcoin blockchain\n\t\t-\n\t\t- Powered by the Taproot upgrade for privacy and scalability\n\t\t-\n\t\t- Deposit assets into Lightning channels for instant transactions and low fees\n\t\t-\n\t\t- Transfer assets over the existing Lightning Network\n\t- ##### Benefits /Limitations and Risks\n\t\t-\n\t\t- Light client-friendly and low verification costs\n\t\t-\n\t\t- Atomic swaps between assets and BTC\n\t\t-\n\t\t- Supports unique and non-unique assets, as well as collections\n\t\t-\n\t\t- Facilitates multi-signature and co-signatory arrangements\n\t\t-\n\t\t- Channels can be created alongside BTC channels in the same UTXO\n\t\t-\n\t\t- Potential future features include confidential transactions and zero-knowledge proofs (perhaps integrating ZeroSync metioned elsewhere)\n\t\t-\n\t\t- Allows minting or moving of an unbounded number of assets in a single on-chain transaction\n\t\t-\n\t\t- Takes advantage of existing network effects to improve scalability\n\t\t-\n\t\t- Addresses blockchain congestion problems and prepares for mass adoption\n\t\t-\n\t\t- May 2021 saw a spike in transactions and fees, largely due to BRC-20 token mining and trading\n\t\t-\n\t\t- At this time the system only runs on testnet. It is hard to imagine a time when Lightning Labs would be prepared to sign their corporate name to the security of potentially billions of dollars denominated assets.\n\t\t-\n\t\t- LND has suffered technical issues in the past, and may again, with the potential for complete chaos in a monopolar technical system.\n- # Misc\n\t- In games\n\t\t- [DrDisrespect tweet](https://twitter.com/DrDisrespect/status/1632430208379928576)\n\t\t- [Polygon generative art game](https://github.com/beamable/genamon-polygon/)\n- This includes [[UDA]] from [[DIBA]] and [[Digital Objects]]\n\t- [RGB explainer slides](https://docsend.com/view/he8x9erkjmphphvn)\n\t- [rgb tokens](https://twitter.com/iris_wallet/status/1639189676845047808)\n\t- [RGB minimal fork for tether](https://t.me/rgbtelegram/36013)\n\t- [Iris wallet](https://play.google.com/store/apps/details?id=com.iriswallet.testnet)\n\t- [Diba wallet and marketplace](https://diba.io/)\n\t- [RGB / Nostr integration](https://twitter.com/lnp_bp/status/1656211884775821313)\n\t- [Zerosync client side validation?](https://twitter.com/ZeroSync_/status/1656721507060416514)\n- [NIP88](https://github.com/nostr-protocol/nips/pull/512)\n- [9th proof of folding for single use seals](https://github.com/adambor/The9thProofOfFolding)\n- Inscriptions\n\t- [By The Numbers: How Do Inscriptions Affect Bitcoin Blocksize: Bitcoin Inscriptions have increased the average size of the cryptocurrency's blocks; here's how this could impact the blockchain.](https://bitcoinist.com/the-numbers-inscriptions-affect-bitcoin-blocksize/)\n\t- [OpenOrdex is a decentralized exchange for ordinal numbers. It allows users to buy and sell ordinal numbers using a variety of methods, including Inscription, which is a process by which users can add their own numbers to the exchange.](https://openordex.org/)\n- The text provides a brief overview of the jnews_ajax_url variable and how it can be used to make AJAX requests.\n- NFTs\n\t- [UK Government Scraps NFT Launch Plan For Now: UK government had unveiled its intention to introduce its very own NFTs through the Royal Mint. This announcement was made last year in April.](https://bitcoinist.com/uk-government-scraps-nft-launch-plan-for-now/)\n- [Taproot assets](https://github.com/lightninglabs/taproot-assets)\n- https://block21m.substack.com/p/most-bitcoin-inscriptions-belong-d6d\n- [Hackers Stole Thousands of Dollars Worth of NFTs from Collectors](https://www.vice.com/amp/en/article/v7mw7b/nifty-gateway-hacked-nfts)\n  title:: Hackers Stole Thousands of Dollars Worth of NFTs from Collectors\n  url:: https://www.vice.com/amp/en/article/v7mw7b/nifty-gateway-hacked-nfts\n  Tags:: DigitalObjects\n- [Stacks Art](https://www.stacksart.com/collections/stacks-punks/7452)\n  title:: Stacks Art\n  url:: https://www.stacksart.com/collections/stacks-punks/7452\n  Tags:: DigitalObjects\n- [Home | ethereum.org](https://ethereum.org/en)\n  title:: Home | ethereum.org\n  url:: https://ethereum.org/en\n  Tags:: DigitalObjects\n- [NYC man sells fart for $85, cashing in on NFT craze](https://nypost.com/2021/03/18/nyc-man-sells-fart-for-85-cashing-in-on-nft-craze)\n  title:: NYC man sells fart for $85, cashing in on NFT craze\n  url:: https://nypost.com/2021/03/18/nyc-man-sells-fart-for-85-cashing-in-on-nft-craze\n  Tags:: DigitalObjects\n- [Steam bans blockchain and NFT games](https://www.gamesindustry.biz/articles/2021-10-15-steam-reportedly-bans-blockchain-and-nft-games)\n  title:: Steam bans blockchain and NFT games\n  url:: https://www.gamesindustry.biz/articles/2021-10-15-steam-reportedly-bans-blockchain-and-nft-games\n  Tags:: DigitalObjects\n- [MELANIA TRUMP on Twitter / X](https://twitter.com/melaniatrump/status/1471468919810670603?s=21)\n  title:: MELANIA TRUMP on Twitter / X\n  url:: https://twitter.com/melaniatrump/status/1471468919810670603?s=21\n  Tags:: DigitalObjects\n- [The Guardian view on Damien Hirst’s NFTs: posing a burning question | Editorial](https://www.theguardian.com/commentisfree/2022/oct/16/the-guardian-view-on-damien-hirsts-nfts-posing-a-burning-question)\n  title:: The Guardian view on Damien Hirst’s NFTs: posing a burning question | Editorial\n  url:: https://www.theguardian.com/commentisfree/2022/oct/16/the-guardian-view-on-damien-hirsts-nfts-posing-a-burning-question\n  Tags:: Economics, DigitalObjects\n- [Crypto Tony on Twitter / X](https://twitter.com/CryptoTony__/status/1407678604402638858?s=20)\n  title:: Crypto Tony on Twitter / X\n  url:: https://twitter.com/CryptoTony__/status/1407678604402638858?s=20\n  Tags:: DigitalObjects\n- [From the Cyberpunk community on Reddit: Looking for Artists and Developers for NFTsForSale.com](https://www.reddit.com/r/Cyberpunk/comments/mhbsbt/looking_for_artists_and_developers_for)\n  title:: From the Cyberpunk community on Reddit: Looking for Artists and Developers for NFTsForSale.com\n  url:: https://www.reddit.com/r/Cyberpunk/comments/mhbsbt/looking_for_artists_and_developers_for\n  Tags:: DigitalObjects\n- [Funky AI-generated spiraling medieval village captivates social media](https://arstechnica.com/information-technology/2023/09/dreamy-ai-generated-geometric-scenes-mesmerize-social-media-users)\n  title:: Funky AI-generated spiraling medieval village captivates social media\n  url:: https://arstechnica.com/information-technology/2023/09/dreamy-ai-generated-geometric-scenes-mesmerize-social-media-users\n  Tags:: DigitalObjects\n- [Gala Games](https://app.gala.games/nodes)\n  title:: Gala Games\n  url:: https://app.gala.games/nodes\n  Tags:: DigitalObjects\n- [John Reed Stark on Twitter / X](https://twitter.com/johnreedstark/status/1666780985189433347?%5Cn=)\n  title:: John Reed Stark on Twitter / X\n  url:: https://twitter.com/johnreedstark/status/1666780985189433347?%5Cn=\n  Tags:: DigitalObjects\n- [Bored Ape NFT accidentally sells for $3,000 instead of $300,000](https://www.bbc.co.uk/news/technology-59638565)\n  title:: Bored Ape NFT accidentally sells for $3,000 instead of $300,000\n  url:: https://www.bbc.co.uk/news/technology-59638565\n  Tags:: DigitalObjects\n- [HM Treasury on Twitter / X](https://twitter.com/hmtreasury/status/1510971092072079360)\n  title:: HM Treasury on Twitter / X\n  url:: https://twitter.com/hmtreasury/status/1510971092072079360\n  Tags:: Economics, DigitalObjects\n- [15 NFT Use Cases That Could Go Mainstream](https://finance.yahoo.com/news/15-nft-cases-could-mainstream-164631131.html)\n  title:: 15 NFT Use Cases That Could Go Mainstream\n  url:: https://finance.yahoo.com/news/15-nft-cases-could-mainstream-164631131.html\n  Tags:: DigitalObjects\n- [Elon Musk on Twitter / X](https://twitter.com/elonmusk/status/1371549960030842893)\n  title:: Elon Musk on Twitter / X\n  url:: https://twitter.com/elonmusk/status/1371549960030842893\n  Tags:: DigitalObjects\n- [Chads NFT\n\t- Collection](https://opensea.io/collection/chads-nft)\n\t  title:: Chads NFT\n\t- Collection\n\t  url:: https://opensea.io/collection/chads-nft\n\t  Tags:: DigitalObjects\n- [On holding back the strange AI tide](https://www.oneusefulthing.org/p/on-holding-back-the-strange-ai-tide)\n  title:: On holding back the strange AI tide\n  url:: https://www.oneusefulthing.org/p/on-holding-back-the-strange-ai-tide\n  Tags:: DigitalObjects\n- [Di₳mondHODL on Twitter / X](https://twitter.com/DiamondsHODL/status/1488185982541131777?s=20&t=E6nZ0OJB6lIZtidDiXj_0Q)\n  title:: Di₳mondHODL on Twitter / X\n  url:: https://twitter.com/DiamondsHODL/status/1488185982541131777?s=20&t=E6nZ0OJB6lIZtidDiXj_0Q\n  Tags:: DigitalObjects\n- [starryai\n\t- AI Art Generator App\n\t- AI Art Maker](https://www.starryai.com/)\n\t  title:: starryai\n\t- AI Art Generator App\n\t- AI Art Maker\n\t  url:: https://www.starryai.com/\n\t  Tags:: DigitalObjects\n- [Meta Newsroom on Twitter / X](https://twitter.com/MetaNewsroom/status/1564281969134927872)\n  title:: Meta Newsroom on Twitter / X\n  url:: https://twitter.com/MetaNewsroom/status/1564281969134927872\n  Tags:: DigitalObjects\n- [15 NFT Use Cases That Could Go Mainstream](https://finance.yahoo.com/news/15-nft-cases-could-mainstream-164631131.html)\n- [Beeple NFT Sells For $69.3 Million, Becoming Most-Expensive Ever](https://www.forbes.com/sites/abrambrown/2021/03/11/beeple-art-sells-for-693-million-becoming-most-expensive-nft-ever?sh=3f237d1c2448%7D%7Brecent)\n- [Bored Ape NFT accidentally sells for $3,000 instead of $300,000](https://www.bbc.co.uk/news/technology-59638565)\n- [Epic welcomes blockchain and NFT games as Steam bans them](https://www.gamesindustry.biz/articles/2021-10-18-epic-welcomes-blockchain-and-nft-games-as-steam-bans-them)\n- [From the Cyberpunk community on Reddit: Looking for Artists and Developers for NFTsForSale.com](https://www.reddit.com/r/Cyberpunk/comments/mhbsbt/looking_for_artists_and_developers_for)\n- [Hackers Stole Thousands of Dollars Worth of NFTs from Collectors](https://www.vice.com/amp/en/article/v7mw7b/nifty-gateway-hacked-nfts)\n- [Join the Clean-NFTs Discord Server!](https://discord.com/invite/X2BefZVtWh)\n- [NYC man sells fart for $85, cashing in on NFT craze](https://nypost.com/2021/03/18/nyc-man-sells-fart-for-85-cashing-in-on-nft-craze)\n- [OpenSea, the largest NFT marketplace](https://opensea.io/)\n- [Priceless NFT Artwork Vandalized With Spray Paint Tool](https://www.theonion.com/priceless-nft-artwork-vandalized-with-spray-paint-tool-1846574103)\n- [Steam bans blockchain and NFT games](https://www.gamesindustry.biz/articles/2021-10-15-steam-reportedly-bans-blockchain-and-nft-games)\n- [The Guardian view on Damien Hirst’s NFTs: posing a burning question | Editorial](https://www.theguardian.com/commentisfree/2022/oct/16/the-guardian-view-on-damien-hirsts-nfts-posing-a-burning-question)\n- [The NFT Bay is the galaxy's most resilient NFT BitTorrent site!](https://thenftbay.org/search.html)\n- [UK Treasury outlines plan to regulate stablecoins and issue an NFT](https://www.theblockcrypto.com/post/140451/uk-treasury-outlines-plan-to-regulate-stablecoins-and-issue-an-nft)\n- [Zero to One Origins: Chapter Graphics NFT](https://www.ztonft.com/%7D%7Bpolitical)\n- [https://blog.chainalysis.com/reports/nft-market-report-preview-2021/%7D%7Binjected](https://blog.chainalysis.com/reports/nft-market-report-preview-2021/%7D%7Binjected)\n- [https://gadgets.ndtv.com/cryptocurrency/news/mega-yacht-sold-usd-650000-metaverse-most-expensive-nft-sandbox-virtual-world-2630187%22/%3E](https://gadgets.ndtv.com/cryptocurrency/news/mega-yacht-sold-usd-650000-metaverse-most-expensive-nft-sandbox-virtual-world-2630187%22/%3E)\n- [https://opensea.io/collection/fees-wtf-nft?search%5BsortAscending%5D=false&search%5BsortBy%5D=PRICE%7D%7Bbuy](https://opensea.io/collection/fees-wtf-nft?search%5BsortAscending%5D=false&search%5BsortBy%5D=PRICE%7D%7Bbuy)\n- [https://uk.finance.yahoo.com/news/three-arrows-wanted-100m-nft-161811450.html%7D%7B10/%](https://uk.finance.yahoo.com/news/three-arrows-wanted-100m-nft-161811450.html%7D%7B10/%)\n- [https://www.bloomberg.com/news/articles/2022-03-21/bored-ape-nft-spinoff-venture-gone-sour-sparks-legal-fight%7D%7Bconfusing](https://www.bloomberg.com/news/articles/2022-03-21/bored-ape-nft-spinoff-venture-gone-sour-sparks-legal-fight%7D%7Bconfusing)\n- [https://www.bloomberg.com/news/features/2022-06-10/axie-infinity-axs-crypto-game-promised-nft-riches-gave-ruin%7D%7BAxie](https://www.bloomberg.com/news/features/2022-06-10/axie-infinity-axs-crypto-game-promised-nft-riches-gave-ruin%7D%7BAxie)\n- [https://www.coingecko.com/en/nft/bored-ape-yacht-club%7D%7Bbubble](https://www.coingecko.com/en/nft/bored-ape-yacht-club%7D%7Bbubble)\n- [https://www.minecraft.net/en-us/article/minecraft-and-nfts%7D%7Bbanned](https://www.minecraft.net/en-us/article/minecraft-and-nfts%7D%7Bbanned)\n-\n- [[Digital Asset Risks]]\n-\n-",
        "link_types": [
            "moringiello2021property; @fairfield2021tokenized",
            "dutton2003authenticity",
            "komlo2020frost",
            "low2022emperor",
            "Kaloudis2023",
            "UDA",
            "DIBA",
            "Digital Objects",
            "Digital Asset Risks"
        ],
        "file_size": 62939
    },
    {
        "id": "Death of the Internet.md",
        "name": "Death of the Internet",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- This isn't a new problem, but seems perhaps to be accelerating.\n\t- ![image.png](../assets/image_1707220464151_0.png){:height 853, :width 500}\n- https://twitter.com/emollick/status/1741287767773163626?\n\t- {{tweet https://twitter.com/emollick/status/1741287767773163626?}}\n- ## Google search is broken. Google lied.\n\t- [An Anonymous Source Shared Thousands of Leaked Google Search API Documents with Me; Everyone in SEO Should See Them](https://sparktoro.com/blog/an-anonymous-source-shared-thousands-of-leaked-google-search-api-documents-with-me-everyone-in-seo-should-see-them/)\n\t\t- \"Google no longer rewards scrappy, clever, SEO-savvy operators who know all the right tricks. They reward established brands, search-measurable forms of popularity, and established domains that searchers already know and click. From 1998 – 2018 (or so), one could reasonable start a powerful marketing flywheel with SEO for Google. In 2024, I don’t think that’s realistic, at least, not on the English-language web in competitive sectors.\"\n\t- [Google Search Is Now a Giant Hallucination (gizmodo.com)](https://gizmodo.com/google-search-ai-overview-giant-hallucination-1851499031) [[Death of the Internet]] [[Google]]\n\t- [The new AI Google search is incredibly wasteful](https://www.scientificamerican.com/article/what-do-googles-ai-answers-cost-the-environment/)\n\t- {{renderer :linkpreview,https://www.scientificamerican.com/article/what-do-googles-ai-answers-cost-the-environment/}}\n- ## AI augmented search is wasteful\n\t- ![Screenshot 2024-06-13 091134.png](../assets/Screenshot_2024-06-13_091134_1718266390338_0.png){:width 600}\n\t\t- In conversation with [Doug Weir, Director of the Conflict and Climate Observatory.](https://ceobs.org/)\n\t-\n\t- ### Energy Consumption and Climate Impact of AI search\n\t\t- The rapid adoption in internet search has significant [implications for energy consumption](https://www.theverge.com/2023/10/10/23911059/ai-climate-impact-google-openai-chatgpt-energy) and climate change, and excluding much of the world from viable knowledge discovery.\n\t\t- **Data Centers and Energy Use**\n\t\t\t- GenAI relies on massive data centers, which consume [substantial amounts of energy](https://mit-genai.pubpub.org/pub/8ulgrckc/release/2). Talk is now shifting to gigawatt datacentres [[Leopold Aschenbrenner]] . The International Energy Agency (IEA) projects that data centers' electricity consumption will double by 2026, equivalent to Japan's current total consumption. These data centers are primarily powered by fossil fuels, [contributing significantly to greenhouse gas emissions](https://e360.yale.edu/features/artificial-intelligence-climate-energy-emissions).\n\t\t\t- Training a single AI model can emit up to 626,000 pounds of carbon dioxide equivalent, nearly five times the lifetime emissions of the average American car.\n\t\t\t- The carbon footprint of GenAI models is exacerbated by their [energy-intensive nature](https://www.technologyreview.com/2023/12/01/1084189/making-an-image-with-generative-ai-uses-as-much-energy-as-charging-your-phone/) and the need for frequent hardware replacements, which contribute to electronic waste.\n\t\t- **Comparison to Traditional Search**:\n\t\t\t- Adding AI to Google Search increases its energy use more than tenfold, potentially matching the electricity usage of a small country like Ireland.\n\t\t\t- In contrast, traditional search engines like Google's original search engine use significantly less energy, with an estimated 0.3 watt-hours per search.\n\t- ### Economic Exclusion\n\t\t- **Global Accessibility**:\n\t\t\t- Despite the growing adoption of GENAI, approximately 33% of the global population remains offline, limiting access to these energy-intensive tools.\n\t\t\t- **Cost and Accessibility Barriers**:\n\t\t\t\t- The high energy costs associated with GENAI data centers are passed on to users, making these services less accessible to those in lower-income regions or with limited internet infrastructure.\n\t\t\t\t- The economic burden of GENAI adoption can further exacerbate existing digital divides, excluding those who cannot afford the necessary infrastructure or energy costs.\n\t\t\t- **Alternative Approaches**:\n\t\t\t\t- Researchers suggest that more specialized, less carbon-intensive models could be used for specific tasks, [reducing energy consumption](https://www.techtarget.com/sustainability/feature/Generative-AIs-sustainability-problems-explained) and making these tools more accessible to a broader audience.\n\t\t\t\t- The only other option is a phase transition to a new internet paradigm, with higher signal to noise, through aligned incentives and cryptographically assured end points.\n- ## Billionaires are monetising users\n\t- Advertising is a \"Rube Goldberg Machine\" that has twisted incentives and is no longer fully scrutable.\n\t\t- [You Think You Know How Misinformation Spreads? Welcome to the Hellhole of Programmatic Advertising | WIRED](https://www.wired.com/story/death-of-truth-misinformation-advertising/)\n\t- ### People have noticed\n\t\t- Science fiction author and all round thinker Cory Doctorow has been highlighting all this for a long time\n\t\t- [Platform decay - Doctorow](https://en.wikipedia.org/wiki/Enshittification?)\n\t\t- {{renderer :linkpreview,https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/}}\n\t\t\t- https://pluralistic.net/2024/04/04/teach-me-how-to-shruggie/\n\t\t- [‘Enshittification’ is coming for absolutely everything (ft.com)](https://www.ft.com/content/6fb1602d-a08b-4a8c-bac0-047b7d64aba5)\n\t\t- {{renderer :linkpreview,https://www.benlandautaylor.com/p/the-ddos-attack-of-academic-bullshit}}\n\t\t\t- https://www.benlandautaylor.com/p/the-ddos-attack-of-academic-bullshit\n\t\t- {{renderer :linkpreview,https://injuly.in/blog/darker-internet/index.html}}\n\t\t\t- https://injuly.in/blog/darker-internet/index.html\n\t\t- {{renderer :linkpreview,https://www.wheresyoured.at/are-we-watching-the-internet-die/}}\n\t\t\t- https://www.wheresyoured.at/are-we-watching-the-internet-die/\n\t\t- <iframe src=\"https://www.theguardian.com/technology/article/2024/may/19/spam-junk-slop-the-latest-wave-of-ai-behind-the-zombie-internet\" style=\"width: 100%; height: 600px\"></iframe>\n- ## Attention is too concentrated\n\t- We have become dependant on algorithmically generated personal feeds, we have lost the capacity to explore our digital society\n\t\t- [Where have all the websites gone? (fromjason.xyz)](https://www.fromjason.xyz/p/notebook/where-have-all-the-websites-gone/)\n\t- These platforms are very vulnerable and exposed to manipulation, especially as the previous guardrails are removed for profit margins.\n\t- These technologies are reductionist, which feels like a shortcut, but is actually a simplification across the manifold of American English, and is likely making people intellectually lazy.\n\t- Increasingly there will be no other choice, trending toward [[Human vs AI]].\n- ## Changes to information sources\n\t- Social media platforms, particularly Facebook and Instagram, are undergoing a significant shift by reducing the emphasis on political content. Meta, the parent company of these platforms, has introduced measures to minimize the presence of political content, such as the launch of the Threads app, which aims to de-emphasize news and politics ([The Verge](https://www.theverge.com/2022/10/24/23425082/meta-threads-app-political-news-content-reduction-facebook-instagram)).\n\t- This move is part of a broader trend where social media giants are altering their algorithms to prioritize personal content over news and politics, potentially impacting public engagement and democracy ([The New York Times](https://www.nytimes.com/2022/10/24/technology/meta-threads-political-content.html)).\n\t- Simultaneously, the influence of traditional or [[legacy media]] is experiencing a substantial decline. With the rise of social media and digital platforms, the reach and impact of legacy media have been radically reduced, leading to a transformation in the way information is disseminated and consumed.\n\t\t- Note that many are now signing deals with [[OpenAI]] etc\n\t- Twitter has also undergone significant changes and is perceived as a mere shadow of its former self. The platform has been criticized for various issues, including the spread of misinformation, harassment, and a decline in user engagement.\n\t\t- Twitter / X is now likely to join a 'race to the bottom', with [NSFW communities](https://techcrunch.com/2024/03/29/x-confirms-plans-for-nsfw-communities/?) driven by GenAI bots likely taking the platform by storm.\n\t\t- [Twitch U-turns on 'artistic nudity' policy - BBC News](https://www.bbc.co.uk/news/technology-67747949)\n\t- TikTok, a Chinese-owned social media platform, has been gaining prominence and is characterized by its opaque nature. As it ascends in popularity, concerns have been raised about its potential impact on shaping public opinion and its susceptibility to external influence.\n\t- Amidst these changes, there is a notable shift towards \"the private internet,\" including chat groups, Discord, fringe social media platforms, and Telegram groups. This trend has led to the fragmentation of views and discussions, raising concerns about the potential for echo chambers and polarization.\n- ## AI Advertising Trojan Horse Sites\n\t- Fake sites which cater to name based searches such as minor celebrities are automatically updated thousands of times a day to rise to the top of Google searchs.\n\t- [The rise of obituary spam - The Verge](https://www.theverge.com/24065145/ai-obituary-spam-generative-clickbait)\n\t- [Celebrity Wiki ⋆ Richest People, Trending Biography, Famous Birthdays! (celebsagewiki.com)](https://www.celebsagewiki.com/)\n- ## The Dark Forest Thesis\n\t- [The Dark Forest Theory of the Internet | by Yancey Strickler | Medium](https://ystrickler.medium.com/the-dark-forest-theory-of-the-internet-7dc3e68a7cb1)\n\t- [The Expanding Dark Forest and Generative AI (maggieappleton.com)](https://maggieappleton.com/ai-dark-forest)\n\t- In Liu Cixin's sci-fi trilogy *The Three Body Problem*, the dark forest theory suggests that the universe is full of life, but it remains silent and hidden to survive, like animals in a dark forest at night when predators are out.\n\t- The internet is becoming like a dark forest:\n\t\t- In response to ads, tracking, trolling, hype, and predatory behaviors, people are retreating to safer, private spaces online\n\t\t- These \"dark forests\" of the internet are non-indexed, non-optimized, and non-gamified environments where depressurized conversation is possible\n\t\t- Examples include private channels, group chats, and newsletters sent to select groups\n\t\t- Podcasts are another \"dark forest\" where meaning is expressed through intonation and interaction, allowing for more forgiving communication compared to the internet at large\n- ## Bots Proliferate\n\t- ![paste (6).png](../assets/paste_(6)_1718746134411_0.png)\n\t-\n\t- Jailbroken foundation models can already solve Capcha human checks, and this will soon be possible with open source models. At this point the internet will possibly explode with bot activity.\n\t\t- ![1706810932954.jpeg](../assets/1706810932954_1717339896749_0.jpeg){:width 600}\n\t- It's important to note that as the web dies, we will increasingly be forced to use [[Agents]] to mediate information, and this will mean increased [[Global Inequality]] as the remaining tatters of the free internet become badlands.\n\t\t- [Andrew Gao on X: \"the singularity is literally here. Devin ended up talking to ANOTHER AI (McDonalds' AI recruiter)!! The future of the web is #agents talking to agents. Luckily, Devin convinced Olivia to give me an interview :) Peep the video https://t.co/oYJG8JzIIO\" / X (twitter.com)](https://twitter.com/itsandrewgao/status/1786880819170320678)\n\t- [Andrew Gao on X: \"#Devin helped me get a job at McDonalds 🍔🍟 I will have a job post-AGI! (seriously, it's gotten really good at browser automation, watch) 📽️ Part 2: auto-applying to @cognition_labs with Devin 👇🧵 https://t.co/oBm20nOCvx\" / X (twitter.com)](https://twitter.com/itsandrewgao/status/1786879644651991549)\n\t\t- {{twitter https://twitter.com/itsandrewgao/status/1786879644651991549}}\n\t- Bots that persuade bots that persuade bots\n\t\t- https://www.linkedin.com/posts/emollick_two-weird-things-that-are-going-to-happen-activity-7180768944067072000-Gmtq?\n\t- Google search is dying under the shifting signal to noise problem.\n\t\t- [AI Has Made Google Search So Bad People Are Moving to TikTok & Reddit | by Ronke Babajide | Bouncin’ and Behavin’ Blogs | Medium](https://medium.com/bouncin-and-behavin-blogs/ai-has-made-google-search-so-bad-people-are-moving-to-tiktok-reddit-6ac0b4801d2e)\n\t- According to Imperva, 47.4% of all internet traffic in 2022 was bots ([reference](https://www.imperva.com/blog/bad-bot-report-2022-edition/)) though this is contested by industry internet tracker [CHEQ](https://cheq.ai/) .\n\t- An ex-CIA expert suggested up to 80% of Twitter accounts could be bots ([reference](https://finance.yahoo.com/news/cia-expert-says-80-twitter-222337217.html)).\n\t\t- [The majority of traffic from Elon Musk's X may have been fake during the Super Bowl, report suggests | Mashable](https://mashable.com/article/x-twitter-elon-musk-bots-fake-traffic)\n\t- Russian bots are inflating Instagram influencer follower counts into the tens of millions ([reference](https://www.adweek.com/social-marketing/study-15-million-russian-instagram-influencers-followers-are-bots/)).\n\t- Ticketmaster says bots snatch up concert tickets before fans get access ([reference](https://www.cnbc.com/2017/05/23/ticketmaster-and-live-nation-face-class-action-lawsuit.html)).\n\t- [(1) X (twitter.com)](https://twitter.com/lorda26/status/1753451790778225095) ancient spam account posts a generated image description with no image, drawing swarms of admiring text-spam bots which generate imaginary human reactions (read the replies) to an image which doesn’t actually exist\n- ## Rise of Bots Aligns With Dead Internet Theory\n\t- Originally a conspiracy theory, the dead internet theory suggests online activity is increasingly driven by bots, AI and algorithms rather than genuine human interactions. [Wikipedia page on dead internet theory](https://en.wikipedia.org/wiki/Dead_Internet_theory)\n\t- Corporations and governments are flooding the internet with bots and AI-generated content to push propaganda and influence behaviour \n\t  ([Deep fakes Verge article](https://www.theverge.com/23341528/ai-fake-faces-personalities-bots-misinformation)). ([Fake Ted Cruz site](https://www.tedcruzforhumanpresident.com/)).\n- ## Concerns Over AI's Influence on Online Content\n\t- The collective impact of these developments creates a potentially more precarious environment for the manipulation of public opinion through artificial intelligence (AI). As political discourse becomes decentralized across various platforms and the emphasis on political content diminishes on major social media platforms, there is a growing risk of AI being exploited to manipulate public sentiment and political narratives.\n\t- Europol raised concerns about AI's overwhelming presence in online content ([reference](https://www.euractiv.com/section/digital/news/europol-sounds-alarm-on-ai-in-online-content-slamming-tech-giants/)).\n\t- Experts warn internet is saturated with bots, [disinformation](https://counterhate.com/research/the-disinformation-dozen/) and biases that undermine perceptions of genuine interactions ([reference](https://www.forbes.com/sites/ajdellinger/2019/04/24/the-bots-that-are-changing-reddit/?sh=7d6d25b94e23)).\n\t- The internet is becoming balkanised as large data aggregators like reddit close their APIs and prevent scraping. This is already having a meaningful effect on internet search.\n\t- 'Background tokens' is a term used on the [[latent space]] podcast to describe pre LLM unpolluted data. This legacy data is the last state of human discourse.\n\t- A fascinating unexpected second order impact of this is that future models may skew more right wing as those sites [welcome the scraping.](https://www.wired.com/story/most-news-sites-block-ai-bots-right-wing-media-welcomes-them/?)\n\t- [AI and Leviathan: Part III by Samuel Hammond (secondbest.ca)](https://www.secondbest.ca/p/ai-and-leviathan-part-iii)\n- ## Mental health [[Social contract and jobs]]\n\t- [Fraudulent studies are undermining the reliability of systematic reviews – a study of the prevalence of problematic images in preclinical studies of depression | bioRxiv](https://www.biorxiv.org/content/10.1101/2024.02.13.580196v1) [[Death of the Internet]] [[Deepfakes and fraudulent content]]\n\t- [Jonathan Haidt Wants You to Take Away Your Kid’s Phone | The New Yorker](https://www.newyorker.com/news/the-new-yorker-interview/jonathan-haidt-wants-you-to-take-away-your-kids-phone)\n\t\t- Jonathan Haidt, a social psychologist and the author of the book \"The Anxious Generation: How the Great Rewiring of Childhood is Causing an Epidemic of Mental Illness\". The main points covered in the interview are:\n\t\t\t- Haidt argues that a whole generation has been damaged by growing up with unrestricted access to social media and an overprotected childhood, leading to a sharp increase in anxiety, depression, and self-harm among teenagers, especially girls, starting around 2012.\n\t\t\t- He attributes this to the rapid adoption of smartphones and social media platforms between 2010 and 2015, which radically changed childhood by replacing real-life interactions and play with excessive screen time and exposure to harmful online content.\n\t\t\t- Haidt presents evidence from correlational and experimental studies to support his claim that social media use causes mental health issues, while acknowledging the need for more research.\n\t\t\t- He argues that the benefits of social media are outweighed by its negative impact on child development, as it deprives children of essential real-life experiences, such as play, adventure, and healthy risk-taking.\n\t\t\t- Haidt advocates for changing social norms and implementing restrictions on social media use, such as banning phones in schools and limiting access to social media platforms for children under 16, rather than an outright ban on technology.\n\t\t- <iframe src=\"https://jonathanhaidt.com/anxious-generation/\" style=\"width: 100%; height: 600px\"></iframe>\n- ## Tik Tok tick tock [[Death of the Internet]] [[Surveillance]] [[Politics, Law, Privacy]]\n\t- [TikTok is China's next big weapon in the battle for personal data (axios.com)](https://www.axios.com/2019/07/20/tiktok-china-online-privacy-personal-data)\n\t- [TikTok: Beneath Its Fun Exterior Lies A Sinister Purpose (forbes.com)](https://www.forbes.com/sites/enriquedans/2020/06/28/tiktok-beneath-its-fun-exterior-lies-a-sinisterpurpose/)\n\t- [forbes.com/sites/emilybaker-white/2022/10/20/tiktok-bytedance-surveillance-american-user-data/](https://www.forbes.com/sites/emilybaker-white/2022/10/20/tiktok-bytedance-surveillance-american-user-data/)\n\t- [For Gen Z, TikTok Is the New Search Engine - The New York Times (nytimes.com)](https://www.nytimes.com/2022/09/16/technology/gen-z-tiktok-search-engine.html)\n\t- [TikTok’s search engine repeatedly delivers misinformation to its majority-young user base, report says | CNN Business](https://edition.cnn.com/2022/09/18/business/tiktok-search-engine-misinformation/)\n\t- [Revealed: how TikTok censors videos that do not please Beijing | TikTok | The Guardian](https://www.theguardian.com/technology/2019/sep/25/revealed-how-tiktok-censors-videos-that-do-not-please-beijing)\n\t- [The U.S. Is Right to Worry About TikTok | Lawfare (lawfaremedia.org)](https://www.lawfaremedia.org/article/us-right-worry-about-tiktok)\n- # Potential Green Shoots\n\t- There is a chance to build on recent advances in long running projects like [[Solid]]. This is all wrapped up with [[webid]] and [[Decentralised Web]] monikers.\n\t- Using AI to reduce conspiracy theory beliefs https://osf.io/preprints/psyarxiv/xcwdn [[Trust and Safety]] [[Death of the Internet]] the flips side being that they are very capable of [persuasion](https://www.anthropic.com/news/measuring-model-persuasiveness).\n\t- [2403.18802.pdf (arxiv.org)](https://arxiv.org/pdf/2403.18802.pdf) [[Trust and Safety]]\n\t\t- 1) Most surprisingly: \"LLM agents can achieve superhuman rating performance\" on fact checking when given access to Google!\n\t\t  2) Bigger models are more factual than smaller ones, as expected\n\t\t  3) LLMs are 20x cheaper than human fact-checkers, even taking into account the number of calls the [[Large language models]] had to make.\n\t\t- 4) [AI Outperforms Humans in Moral Judgments - Neuroscience News](https://neurosciencenews.com/ai-llm-morality-26041/)\n\t- ### Forcing function to trusted end points\n\t\t- *AI will permanently put an end to the \"post truth\" era: this is the subject for another post, but clearly our prior epistemic standards no longer apply. the cost of creating arbitrary image or video content is effectively 0, so unsigned content will no longer by considered reliable (once people have learned to lately mistrust online content). to be considered reliable in the future, content will have to be signed, attested to, and timestamped (likely on a blockchain).* - [Carter](https://x.com/nic__carter/status/1797635177973158182)\n\t-\n- ## A handy simulator\n\t- [Sebby37/Dead-Internet: Y'all thought the dead internet theory wasn't real, but HERE IT IS (github.com)](https://github.com/Sebby37/Dead-Internet)\n- ## Other links\n\t- [Nobody Knows What’s Happening Online Anymore - The Atlantic](https://www.theatlantic.com/technology/archive/2023/12/internet-information-trends-virality-tracking/676888/)\n\t- [W3C SN dystopia](https://www.w3.org/DesignIssues/diagrams/solid/SN-dystopia.svg)\n\t- [Welcome to Geriatric Social Media (theatlantic.com)](https://newsletters.theatlantic.com/galaxy-brain/63609043b606fe00376a82da/welcome-to-geriatric-social-media/)\n\t- [Social Media Broke Up With News. So Did Readers. - The Atlantic](https://www.theatlantic.com/technology/archive/2023/11/social-media-news-readership-decline/675890/)\n\t- [Technology is the Problem - Shyam Sankar](https://www.shyamsankar.com/p/technology-is-the-problem) [[Death of the Internet]] [[Social contract and jobs]]\n\t- [The Toilet Theory of the Internet - The Atlantic](https://www.theatlantic.com/technology/archive/2024/05/google-generative-ai-search-toilet-theory/678411/) [[Death of the Internet]]\n\t- [[Death of the Internet]] [John Robb: \"Networked Tribalism, AI, and Asteroids\" | The Great Simplification #110 - YouTube](https://www.youtube.com/watch?v=b2n_Jk37cLE)\n\t-\n-",
        "link_types": [
            "Death of the Internet",
            "Google",
            "Leopold Aschenbrenner",
            "Human vs AI",
            "legacy media",
            "OpenAI",
            "Agents",
            "Global Inequality",
            "latent space",
            "Social contract and jobs",
            "Death of the Internet",
            "Deepfakes and fraudulent content",
            "Death of the Internet",
            "Surveillance",
            "Politics, Law, Privacy",
            "Solid",
            "webid",
            "Decentralised Web",
            "Trust and Safety",
            "Death of the Internet",
            "Trust and Safety",
            "Large language models",
            "Death of the Internet",
            "Social contract and jobs",
            "Death of the Internet",
            "Death of the Internet"
        ],
        "file_size": 22600
    },
    {
        "id": "Surveillance.md",
        "name": "Surveillance",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # Surveillance Capitalism\n\t- Surveillance capitalism is a term coined by Harvard Business School professor Shoshana Zuboff to describe the business model of using data collected from individuals to target advertising and influence behaviour. The concept of surveillance capitalism emerged in the late 20th and early 21st centuries with the rise of technology companies thatspecialize in gathering and analyzing personal data.\n\t- The history of surveillance capitalism can be traced back to the early days of the internet. In the 1990s, companies such as DoubleClick andOmniture began collecting data on internet users’ browsing habits inorder to target advertising. As the internet grew in popularity, these companies were able to gather an increasing amount of data on individuals, allowing them to more effectively target advertising and increase profits.\n\t- The advent of smart phones and mobile technology in the 2000s further expanded the reach of surveillance capitalism. With the widespread adoption of smart phones and mobile apps, companies were able to collect even more data on individuals, including location data and information about their physical activity. This data was used to target advertising and influence behaviour, leading to the rise of companies such as Google and Facebook, which have become dominant players in the digital advertising market.\n\t- The use of data collected from individuals to influence behaviour has also been used to influence political campaigns. In the 2016 USpresidential election, Cambridge Analytica, a data analytics firm, used data collected from Facebook users to influence voter behaviour. The firm used the data to target advertising and create psychological profiles of individuals, allowing them to more effectively influence voter behaviour.\n\t- The business model of surveillance capitalism has been widely criticised for its ethical implications. Critics argue that the collection and useof personal data without consent is a violation of individuals’ privacyand that the use of data to influence behaviour is manipulative and unethical. In recent years, there have been calls for greater regulationof the tech industry to address these concerns.\n\t- Surveillance capitalism has led to significant compliance overheads for companies that collect and use personal data. There are a number of laws and regulations that have been put in place to protect individuals’ privacy, such as the General Data Protection Regulation (GDPR) in theEuropean Union and the California Consumer Privacy Act (CCPA) inCalifornia, USA. These laws require companies to obtain consent from individuals before collecting and using their data, and to provide individuals with the right to access, correct, and delete their data.\n\t- Complying with these laws can be costly and time-consuming for companies. They may need to hire additional staff to handle data privacy compliance, and may also need to invest in new technology to manage andprotect personal data. In addition, companies are at risk of significant fines if they fail to comply with these laws.\n\t- In terms of who profits from surveillance capitalism, the primary beneficiaries are technology companies such as Google and Facebook,which have become dominant players in the digital advertising market.These companies collect and analyse large amounts of personal data,which they use to target advertising and influence behaviour. This allows them to generate significant profits from advertising revenue.\n\t- On the other hand, those who suffer the most negative impact from surveillance capitalism are individuals, whose personal data is collected and used without their consent. They are also at risk of theirprivacy being violated, and their personal data being misused. Additionally, the collection and use of personal data can lead to themanipulation of individuals’ behaviour and decision-making, which can have negative consequences for their lives and society at large.\n\t- Moreover, the business model of surveillance capitalism has also been criticized for creating a power imbalance between companies and individuals. Companies have access to vast amounts of personal data,which they can use to influence behaviour and make decisions that affect individuals’ lives. This can lead to a lack of privacy and autonomy for individuals, and can also lead to discrimination and bias indecision-making.\n\t- This is collectively an erosion of the demarcation between data, state surveillance, banking, and political leadership globally.\n\t- The term \"surveillance state\" refers to a state in which government agencies have the power to collect and analyze large amounts of personal data, often without the consent of individuals. The rise of surveillance capitalism has led to concerns about the potential for the creation of a surveillance state, as government agencies may use the data collected by companies for surveillance purposes.\n\t- There have been instances where government agencies have used data collected by companies for surveillance purposes. For example, in theUnited States, the National Security Agency (NSA) has been accused of using data collected by companies such as Google and Facebook for surveillance purposes. The agency’s PRISM program, which was revealed byEdward Snowden in 2013, was designed to collect and analyse data from internet companies in order to identify and track individuals. Europe is[clear about it’sintentions](https://www.patrick-breyer.de/en/posts/chat-control/) to mandate their complete access to all encrypted personal communications in forthcoming legislation.\n\t- The use of data collected by companies for surveillance purposes canhave significant implications for individuals’ privacy and civil liberties. It can also lead to a lack of transparency and accountability, as government agencies may use the data without the knowledge or consent of individuals. In addition, the use of data for surveillance purposes can lead to discrimination and bias indecision-making, as well as a chilling effect on free speech and the exercise of other rights.\n\t- Akten has been [talkingabout](https://memoakten.medium.com/all-watched-over-by-machines-of-loving-grace-8c2464aa6fda)the phase transition from digital surveillance to pernicious corporateAI in terms of a modern ‘religion’ for many years.[[bayer2023artificial]]He feels that despite public awareness of privacy invasion, there hasbeen no significant outcry or unanimous demand for privacy. Instead,most individuals seem to find comfort in the belief that a higher forceis watching and protecting the virtuous, while punishing wrongdoers. The concept of a ‘digital deity’ emerge from his thinking in this context,reflecting the role that religion and traditional gods have played in providing ethical frameworks, security, discipline, power, and other societal functions. More recently O’Gieblyn has been drawing the same conclusions,[[o2021god]] explicitly linking religiosity to the imperative to ‘create a godhead’ simply because it can be done, not pausing to discuss if it should be. Rosenberg calls this ‘a threat to EpistemicAgency’[[rosenbergmanipulation]]More recently the Harari, author ofSapiens[[harari2014sapiens]] [said ofAI](https://forumlive.frontiersin.org/agenda/speakers/2977577): it“For thousands of years, prophets and poets and politicians have used language and storytelling in order to manipulate and to control people and to reshape society. Now AI is likely to be able to do it. And once it can... it doesn’t need to send killer robots to shoot us. It can get humans to pull the trigger. We need to act quickly before AI gets out ofour control. Drug companies cannot sell people new medicines without first subjecting these products to rigorous safety checks.” (AI will be discussed in detail in a later chapter).\n\t- Klein at the New York Times has been [writing against thispoint](https://www.nytimes.com/2023/03/12/opinion/chatbots-artificial-intelligence-future-weirdness.html)for some time. His well articulated fear, is that the current model where three major Western companies, with similar highly competitive capitalist origins and values, should certainly not be in charge ofracing to monetise the most compelling and innately unknowable chat bot experience. As societies shift towards materialism and technological dependence, traditional gods lose their relevance, and the need for anew form of overseer arises. This digital deity, existing within therealm of technology and the cloud, perhaps represents an adaptation of primal human belief systems. This will be explored further in the AI/MLchapter later.\n\t- In conclusion, the rise of surveillance capitalism has led to concerns about the potential for the creation of a surveillance state, or worse,a new kind of omnipresent digital culturla authority. Corporations and government agencies may use the data collected by companies for surveillance purposes. This can have significant implications for individuals’ privacy and civil liberties. It’s important for laws and regulations to be in place to safeguard citizens’ rights and privacy inregards to the use of data by government agencies, and to hold them accountable for any misuse of data, and yet it seems the reality of the situation in ‘post Snowden’ seems far from that.\n\t- Surveillance Capitalism. As a quick round-up of this area, which is best researched elsewhere:\n\t\t- The global digital advertising market is expected to reach $335 billion by 2023.\n\t\t- In 2020, Google and Facebook accounted for 60% of the global digital advertising market.\n\t\t- The data brokerage industry, which includes companies that collect and sell personal data, is estimated to be worth $200 billion.\n\t\t- In 2020, Google and Facebook were reported to have data on over 4 billion active users.\n\t\t- As of 2021, the number of data breaches reported worldwide has grown from 4.1 billion in 2018 to 4.9 billion in 2020.\n\t\t- In 2013, it was revealed that the US National Security Agency (NSA) had been collecting the phone records of millions of Americans under its PRISM program.\n\t\t- In 2013, Edward Snowden leaked classified documents that revealed the scale of the NSA’s surveillance programs.\n\t\t- In the US, the Foreign Intelligence Surveillance Act (FISA) allows the government to conduct surveillance on non-US citizens outside the US without a warrant.\n\t\t- The UK’s Investigatory Powers Act 2016, also known as the \"snooper’s charter,\" gives government agencies wide-ranging powers to collect and analyze personal data.\n\t\t- In 2021, it was reported that the Chinese government has been collecting and analyzing the data of its citizens through a system of \"social cred* scores, which are used to monitor and control individuals’ behaviour.\n\t\t- Surveillance capitalism refers to the business model of collecting and analyzing personal data for the purpose of targeted advertising and other forms of monetization.\n\t\t- A recent study by the Center for Digital Democracy found that the top 100 global digital media companies are projected to generate over $1 trillion in revenue by 2020, much of which is derived from surveillance-based advertising.\n\t\t- The number of surveillance cameras in use worldwide is estimated to be over 1 billion, with the majority located in China.\n\t\t- A 2018 study by Comparitech found that the average person in the UK is captured on CCTV cameras over 300 times per day.\n\t\t- According to a report by the American Civil Liberties Union (ACLU), the FBI has access to over 640 million photographs for facial recognition searches, including driver’s license and passport photos.\n\t\t- The U.S. government’s use of surveillance technologies, such as drones and mass data collection, has been a subject of ongoing controversy and debate.\n\t\t- Some experts warn that the increasing use of surveillance technologies by governments and private companies could lead to the erosion of privacy rights and the creation of a *surveillance state.\"\n\t\t- In the USA senate hearing following the collapse of FTX Rep. Jesus Garcia described bitcoin and crypto as an industry that operates outside of the law and relies on hype, implying that the communities that have adopted bitcoin are ill-informed and vulnerable.\n\t\t- Bitcoin has been adopted by a variety of communities worldwide, particularly in countries such as Vietnam, the Philippines, Ukraine, India, Pakistan, Brazil, Thailand, Russia, and China.\n\t\t- There is an outsized level of adoption among Black Americans in the United States. This trend is not a result of targeted advertising by companies such as FTX, but rather a response to a legacy financial system that has limited individuals’ potential.\n\t\t- Marginalized early adopters of bitcoin still constitute a minority in their communities, but the worldwide adoption trend among these groups is on the rise.\n\t\t- The solutions that outsiders build in bitcoin will ultimately be the source of the technology’s promised revolution. Adoption in Africa and possibly India seems likely to be capable of driving this.\n\t\t- The paradigm shift will come from those who bring local, real-world focused use cases to their communities, separating bitcoin from the empty hype of speculation.\n\t\t- Marginalized communities will lead the industry’s recovery and redefine the purpose of bitcoin in the future.\n\t- ## Tech money in Civil Society\n\t\t- Big Tech firms donate substantial funds to charities, think tanks, academic research, and lobbying efforts to shape narratives and policy around tech regulation. [[Goldenfein Mann 2024]]\n\t\t- Tracking financial flows from Big Tech to DRCSOs is challenging due to limited transparency, but available data shows ongoing funding relationships.\n\t\t- Through class action cy pres settlements, Big Tech firms direct funds to DRCSOs that purport to represent class interests, but may actually advance the firms' preferred policy narratives.\n\t\t- Funding from Big Tech raises questions about potential conflicts of interest for DRCSOs and whether they truly represent the public interest as opposed to aligning with industry agendas.\n\t\t- The authors argue Big Tech philanthropy allows economic power to translate into political and cultural capital, enabling the firms to continue profiting from problematic data practices while avoiding meaningful regulation.\n\t- Much of the following text is paraphrased from the work of Guy Turner of‘The Coin Bureau’, and Lawyer and academic Eden Moglen, and needs more work because of it’s critical importance to the book. [[Update Cycle]]\n\t\t- The adoption of printing by Europeans in the 15th century led to concerns around access to printed material. The right to read and the right to publish were central subjects in the struggle for freedom of thought for most of the last half millennium. The basic concern was forthe right to read in private and to think, speak, and act based on a free and uncensored will. The primary antagonist for freedom of thought at the beginning of this struggle was the universal Catholic Church, an institution aimed at controlling thought in the European world through weekly surveillance of individuals, censorship of all reading material,and the ability to predict and punish unorthodox thought. In early modern Europe, the tools available for thought control were limited, but they were effective. For hundreds of years, the struggle centred around the book as a mass-manufactured article in Western culture, and whether individuals could print, possess, traffic, read, or teach from books without the permission or control of an entity empowered to punish thought. By the end of the 17th century, censorship of written material in Europe began to break down in waves throughout the European world,and the book became an article of subversive commerce, undermining the control of thought.\n\t- Currently, a new phase in human history is beginning as we are building a single extraneous digital nervous system, that will connect every human mind. Within two generations, every single human being will be connected to this network, in which all thoughts, plans, dreams, and actions will flow as nervous impulses. The fate of freedom of thought and human freedom as a whole will depend upon the organization of thisnetwork. Our current generation is the last in which human brains will be formed without contact with this network, and from now on, every human brain will be formed from early life in direct connection to the network, with input from generative AI/ML systems. This possibly results in humanity becoming a super organism of a sort, where each of us is buta neuron in the brain. Unfortunately, this generation has been raised to be consumers of media, which is now consuming us.\n\t- Anonymous reading is being determined against. Efforts discussed throughout this graph to ensure privacy, from Zimmerman and the cypherpunks onward, have been met with resistance from government efforts to monitor and control information flow. The outcome of the organization of this network, and the freedom it allows, is currently being decided by this generation.\n\t- It is not solely the ease of surveillance, nor solely the permanence of data, that is concerning, it is the relentless nature of living after the “end of forgetting”. Today’s encrypted traffic, which is used with relative security, will eventually be decrypted as more data becomes available for crypto analysis. This means that security protocols will need to be constantly updated and redone. Furthermore, no information is ever truly lost, and every piece of information can be retained and eventually linked to other information. This is the rationale behind government officials who argue that a robust social graph of the UnitedStates is needed. The primary form of data collection that should be of most concern is media that is used to spy on us, such as books that watch us read them and search boxes that report our searches to unknown parties. There is a lot of discussion about data coming out ofMeta/Facebook, but the true threat is code going in. For the past 15years, enterprise computing has been adding a layer of analytics on topof data warehouses, which is known as business intelligence. This allows for the vast amount of data in a company’s possession to be analysed and used to answer questions the company did not know it had. The real threat of Facebook is the business intelligence layer on top of theFacebook data warehouse, which contains the behaviour of nearly a billion people. Intelligence agencies from around the world want toaccess this layer in order to find specific classes of people, such as potential agents, sources, and individuals that can be influenced or tortured. The goal is to run code within Facebook to extract this information, instead of obtaining data from Facebook, which would be dead data once extracted. Facebook wants to be a media company andcontrol the web, but the reality is the true value of Facebook is the information and behaviour of it’s users, and the ability to mine that data. Distributed internet protocols are important in the context of government overreach into digital society and people’s private livesbecause they provide a level of decentralization and resilience that canhelp protect against censorship and surveillance.\n\t- For example, if a government were to attempt to censor or block access to a centralized internet service, it could potentially do so with relative ease. However, if that same service were distributed across anetwork of nodes, it would be much more difficult for the government to effectively censor or block access to it.\n\t- Another advantage of distributed protocols is that they are typically more resilient to attacks or failures. If one node in the network goes offline or is compromised, the others can continue to operate, ensuring that the service remains available. This can be especially important in situations where the internet is being used for critical communication,such as during a natural disaster or political crisis.\n\t- In addition to their benefits for censorship resistance and resilience,distributed protocols can also help protect people’s privacy. Because they do not rely on centralized servers or infrastructure, they can bemore difficult for governments or other entities to monitor or track.This can be especially important in countries where government surveillance is prevalent or where individuals may be at risk of persecution for their online activities.\n\t- There are a number of distributed protocols that have been developed specifically to address issues of censorship and privacy, and these will be covered in more detail later.\n\t- It is important to note that distributed protocols are not a silver bullet for censorship or privacy concerns. They can be vulnerable to certain types of attacks, such as those that target the nodes of the network, and they may not always be practical for certain types of applications. However, they do provide an important tool for those seeking to protect their freedom of expression and privacy online. They offer a valuable tool for those seeking to protect their freedom of expression and privacy online, and they will likely continue to play a critical role in the future of the internet.\n\t- In recent years, several countries have proposed or passed bills that would result in unprecedented levels of online censorship. One such example is Canada’s Bill C-11, also known as the Online Streaming Act.This bill was first proposed in November 2020 as Bill C-10, but failed to pass due to its controversial provisions. It was reintroduced inFebruary 2021 as Bill C-11 and was approved by the Canadian House ofCommons, the first step in the process of becoming law. If passed, the bill would give the Canadian Radio, Television and TelecommunicationsCommission (CRTC) the power to decide what content Canadians can view onYouTube and other social media platforms. The CRTC would also have the power to dictate what content creators can produce, with a focus on promoting \"Canadian content.\" Additionally, the bill would require certain broadcasters to contribute to the Canada Media Fund, which is used to fund mainstream media in Canada. The bill is currently being considered by the Canadian Senate, which will vote on it in February. If passed, it will then be debated by the Canadian Parliament. Tech companies such as YouTube have reportedly failed to convince the Senate to exclude user-generated content from the bill, indicating a high likelihood of it becoming law. The potential impact on the internet andfree expression in Canada is significant, as the bill would give the government significant control over online content and restrict the ability of individuals to share their views and perspectives.\n\t- In a similar vein the forthcoming RESTRICT act in the USA gives hugepowers without oversight to a single branch of the US government.\n\t\t- The bill is called the “Restricting the Emergence of Security Threats that Risk Information and Communications Technology Act”\n\t\t- It was initially thought to be about banning TikTok due to its connections to the Chinese government and the data it collects on its users.\n\t\t- The RESTRICT Act has very little to do with banning TikTok and instead grants the US Secretary of Commerce significant powers to determine which entities are foreign adversaries and what technology poses a risk to national security.\n\t\t- The bill defines critical infrastructure broadly, which means it could apply to almost anything the government deems necessary. Lobbyists will be allowed to advise the Secretary of Commerce on which products and services should be labeled as foreign adversaries, potentially leading to monopolies.\n\t\t- Fines and jail time for interacting with foreign adversaries or posing a risk to national security could reach up to $1 million, 20 years in prison, and asset seizures.\n\t\t- The bill aims to crack down on VPNs (Virtual Private Networks), which provide privacy and access to foreign websites.\n\t\t- There is no oversight for the actions taken by the Secretary of Commerce under this act, and neither Congress nor the courts can request information on these decisions.\n\t- The European Union (EU) has separated its online censorship efforts into two separate bills: the Digital Markets Act and the Digital Services Act. These bills were introduced in December 2020 and are part of the EU’s Digital Services package, which aims to be completed by 2030. The Digital Services package is the second phase of the EU’s digital agenda, which is being enforced through regulation in the public sector and through ESG investing in the private sector. Both the Digital Markets Act and the Digital Services Act were passed in spring 2022 and went into force in autumn 2022, but will not be enforced until later this year and early next year, depending on the size of the relevant entity. The Digital Markets Act aims to increase the EU’s competitiveness in the tech space by imposing massive fines on \"gatekeepers,\" or companies that maintain monopolies by giving preference to their own products and services. This could open the door to innovation in cryptocurrency in the EU, but also requires gatekeepers to provide detailed data about the individuals and institutions using their products and services to theE U. The Digital Services Act, on the other hand, aims to regulate the content that is available online, including user-generated content. It does this by requiring companies to remove illegal content within one hour of it being reported and by imposing fines for non-compliance. The act also requires companies to implement measures to protect users from illegal content and from \"other forms of harm,\" which is defined broadly and could include a wide range of content. The EU is also in the process of passing the Artificial Intelligence Regulation Act, which will be discussed later this year and is reportedly the first of its kind. All five bills in the EU’s Digital Services package are regulations, meaning they will override the national laws of EU countries. The potential impact on the internet and free expression in the EU is significant, as the Digital Services Act would give the government significant control over online content and restrict the ability of individuals to share their views and perspectives.\n\t- In the United States, two significant documents related to online censorship are the Kids Online Safety Act and the Supreme Court caseGonzalez v. Google. The Kids Online Safety Act was introduced inFebruary 2021 and is expected to pass later this year due to bipartisan support. The act requires online services to collect Know Your Customer(KYC) information to ensure that they are not showing harmful content tominors. It also gives the Federal Trade Commission (FTC) the power to decide when children have been made unsafe online and allows parents tosue tech companies if their children have been harmed online. The act has received criticism from both sides of the political spectrum and entities outside of Congress, as it is seen as giving too much power tothe government to regulate online content and could lead to increased censorship by tech companies.\n\t- The Supreme Court case Gonzalez v. Google involves the question of whether Google’s algorithmic recommendations supported terrorism and contributed to the 2015 terrorist attacks in Paris. The case has been picked up by the Supreme Court after being passed up by various courts of appeal. It is being heard alongside another case, Twitter v. Tumne, involving the role of Twitter’s algorithms in a terrorist attack in Istanbul. There are two potential outcomes for the case. If the Supreme Court sides with Gonzalez, it could increase the liability of social media companies under Section 230 of the Communications Decency Act, which allows them to moderate content to a limited extent without violating the First Amendment. Alternatively, the Supreme Court could declare Section 230 unconstitutional, which would make online censorship illegal but also hinder the use of algorithms on the internet. The ideal outcome, in theory, would be for the Supreme Court to side with Google and for Congress to change Section 230. However, giving Congress the power to change the law could lead to increased censorship and the potential for abuse of power.\n\t- In the UK forthcoming legislation will see tech company leaders liablefor [prison sentences](https://www.independent.co.uk/news/uk/politics/bill-mps-iain-duncan-smith-molly-russell-rishi-sunak-b2263353.html) if they fail in their duty to protect minors. This will doubtless lead to both stringent universal requirements for identity proof (KYC), and significantly muted and controlled content on the platforms.\n\t- Our research focuses on business to business use cases for distributed technologies, and will provide mechanisms for verifying who is communicating with whom, to avoid falling foul of these swinging global infringements on privacy.\n\t- It is the opinion of this book that information should befree[[swartz2008guerilla]]\n- ### Overview of Government Data Acquisition Practices\n\t- **Surveillance Capitalism**: This concept pertains to the commodification of personal data by private entities. The US government, among others, acquires this data for intelligence and enforcement purposes, circumventing traditional surveillance and legal protocols.\n\t- **Data Brokers' Role**: Data brokers are pivotal, operating businesses that amass and trade personal data without interacting directly with consumers. Their databases encompass a wide array, from social media behaviour to precise geolocation details.\n\t- #### THe TrUTh iS OuT ThERe\n\t\t- This was [[Anthropic Claude]] responding to a research formatted query about 'conspiracy theories' found online.\n\t\t- ![image.png](../assets/image_1719001668969_0.png){:width 600}\n\t\t- \"Open source response\"\n\t\t\t- CIA/MI5 Hacking Smart Devices\n\t\t\t\t- **Verdict:** Partly True. The CIA and MI5 have been known to engage in surveillance activities involving internet-connected devices through programs like Weeping Angel. This program was designed to hack into Samsung smart TVs, but it's important to note that the extent of this capability and its current status are classified.\n\t\t\t- CIA Infecting Car Control Systems\n\t\t\t\t- **Verdict:** Partly True. Vault 7 revealed a range of hacking tools developed by the CIA, including those capable of exploiting vulnerabilities in modern car systems. However, there's no concrete evidence to suggest that the CIA has used these tools to remotely take control of cars.\n\t\t\t- Tech Companies Providing NSA with Zero-Day Vulnerabilities\n\t\t\t\t- **Verdict:** True. Documents leaked by Edward Snowden revealed that tech companies like Microsoft did provide advance warnings about zero-day vulnerabilities to the NSA before disclosing them to the public. This was part of a broader program aimed at improving national cybersecurity and giving government agencies an early warning system.\n\t\t\t- NSA Breaking Tor Networks\n\t\t\t\t- **Verdict:** Partly True. While the NSA has been involved in efforts to compromise Tor, there's no conclusive evidence that they have successfully broken the network or can identify users with certainty. However, it is known that various intelligence agencies have attempted to exploit vulnerabilities in Tor.\n\t\t\t- NSA Intercepts Devices and Installs Malware Chips\n\t\t\t\t- **Verdict:** Partly True. The ANT/TAO Catalog, leaked by Edward Snowden in 2013, reveals the NSA's capabilities for intercepting and altering electronic devices, including installing malware or backdoors before they are delivered to customers. However, this catalog primarily focuses on exploiting vulnerabilities in targeted surveillance operations rather than mass production of compromised devices.\n\t\t\t- American-Made Electronics Allow Access via Radio Frequencies\n\t\t\t\t- **Verdict:** Partly True. The Cottonmouth-I and SURLYSPAWN projects, as mentioned in the Snowden leaks, involve the use of radio frequency (RF) signals to remotely access devices. However, these were designed for specific targeted surveillance operations rather than mass surveillance. It's true that many modern electronic devices emit RF signals or can be accessed through their wireless capabilities, but this does not inherently mean that all American-made electronics are compromised for remote access by the NSA or FBI without further context.\n\t\t\t- Backdoored Random Number Generators\n\t\t\t\t- **Verdict:** Partly True. The Dual Elliptic Curve Deterministic Random Bit Generator (Dual EC DRBG) algorithm, developed by NIST and NSA, has been criticized for its potential to contain a backdoor that could allow the NSA to break RSA encryption.\n\t\t\t- NSA Backdoors in CPUs\n\t\t\t\t- **Verdict:** Partly True. The claim refers to Intel ME (Management Engine) and AMD PSP (Platform Security Processor), which are both hardware-based security features integrated into modern CPUs. While these technologies can operate independently of the main system, there's no conclusive evidence that they were implemented at the NSA's request or are being used by the NSA specifically for mass surveillance. Their primary purpose is enterprise-level management and security rather than clandestine operations.\n\t\t\t- FBI Distributes Undetectable Malware\n\t\t\t\t- **Verdict:** Partly True. The claim likely refers to the FBI's use of malware for law enforcement purposes, such as tracking suspects or gaining access to encrypted data. While the FBI has been known to use such tools, it's not accurate to say that anti-virus software is legally not allowed to detect them. However, some of these tools may be designed to evade detection by common anti-virus programs.\n\t\t\t- Backdoored Random Number Generators\n\t\t\t\t- **Verdict:** Partly True. The Dual Elliptic Curve Deterministic Random Bit Generator (Dual EC DRBG) algorithm, developed by NIST and NSA, has been criticized for its potential to contain a backdoor that could allow the NSA to break RSA encryption. However, it's important to note that while the algorithm's vulnerabilities have been identified and it has been subsequently withdrawn from use, there's no conclusive evidence that the NSA actively exploited this backdoor to break RSA encryption on a widespread scale.\n- ### Legal Framework, International Agreements, and Concerns\n\t- **Minimal Legal Barriers**: The acquisition of commercial data by governments faces scant legal opposition, attributed to the classification of such data as \"publicly available.\" This status exempts it from the stringent privacy protections applicable to more confidential data.\n\t- **Privacy and Civil Liberties Issues**: The extensive gathering and utilisation of personal data by governmental entities elicit significant privacy alarms. Despite assurances of anonymisation, methods often exist to re-identify individuals, raising consent and privacy violation concerns.\n\t- **Data Sharing Agreements\n\t\t- Five Eyes Alliance**: International agreements like the Five Eyes (comprising Australia, Canada, New Zealand, the United Kingdom, and the United States) facilitate extensive data sharing for intelligence purposes. This raises the stakes for data privacy, with personal data potentially shared across borders without explicit consent from individuals.\n- ### The Influence of GDPR and the UK's Data Protection Framework\n\t- **General Data Protection Regulation (GDPR)**: The GDPR represents a robust data protection initiative, offering EU citizens significant control over their personal data. It mandates explicit consent for data processing and grants individuals the right to access and request the deletion of their data. However, its effectiveness is occasionally undermined by complex consent forms and the global nature of data flows which transcend its jurisdiction.\n\t- **The UK Data Protection Act**: Post-Brexit, the UK continues to uphold strong data protection standards, mirroring GDPR principles. However, future divergences may impact international data sharing, especially concerning agreements with entities in jurisdictions with differing privacy standards.\n- ### Technological Advancements and Their Dual-Edged Impact\n\t- **Rise of AI in Data Analysis**: AI's evolution has transformed data analysis, enabling the extraction of nuanced insights from vast datasets. This capability enhances government surveillance potential, making it more efficient but also raising ethical concerns.\n\t- **AI and Surveillance**: The misuse of AI for surveillance by state actors is a growing concern. AI can automate the monitoring of individuals on an unprecedented scale, necessitating stringent oversight.\n\t- **Data Encoded in AI Models**: Information about individuals becoming encoded in the latent spaces of foundational AI models poses unique challenges. This data embedding can inadvertently leak personal information, complicating efforts to protect individual privacy.\n- ### Prospects for Reform and the Future Landscape\n\t- **Judicial and Legislative Responses**: Legal frameworks globally are under pressure to evolve in response to technological advancements. Judicial interventions may set new precedents, while legislative reforms, informed by GDPR and other standards, could offer more comprehensive protections.\n\t- **Impact of AI Regulation**: The regulation of AI technologies, to prevent their misuse for surveillance, becomes increasingly critical. Ensuring transparency and accountability in AI operations is paramount to safeguarding civil liberties.\n\t- **International Cooperation**: Addressing the global nature of data privacy requires international cooperation. Agreements on data protection standards and ethical AI use are essential to navigating the complex web of data surveillance, sharing, and protection.\n- # Misc links\n- [Signal Foundation Warns Against EU's Plan to Scan Private Messages for CSAM (thehackernews.com)](https://thehackernews.com/2024/06/signal-foundation-warns-against-eus.html?m=1)\n- [Sealed Court Files Obscure Rise in Electronic Surveillance WSJ](https://www.wsj.com/articles/sealed-court-files-obscure-rise-in-electronic-surveillance-1401761770)\n- [Portfolio – Jennifer Valentino DeVries (jennifervalentinodevries.com)](https://jennifervalentinodevries.com/portfolio/)\n- # Government and Agency Involvement in AI\n\t- Former NSA Director Michael Hayden said:\n\t- ```text\n\t  \"we kill people based on metadata\"\n\t  ```\n\t- during a debate in 2014 at John Hopkins University. Hayden admitted that the U.S. government uses metadata, which refers to data about communications like phone records (numbers called, time, duration) rather than the actual content, as a basis for killing people in drone strikes against terrorist suspects abroad. Reports based on Snowden leaks alleged the NSA used metadata analysis to track potential targets for lethal drone operations.\n\t- OpenAI [has appointed](https://openai.com/index/openai-announces-leadership-transition/) Retired U.S. Army General Paul M. Nakasone to its Board of Directors and the Board's Safety and Security Committee. General Nakasone is a leading expert in cybersecurity, having previously served as the Director of the National Security Agency (NSA) and Commander of U.S. Cyber Command (USCYBERCOM).\n\t\t-\n\t\t- [(1) Edward Snowden on X: \"They've gone full mask-off: 𝐝𝐨 𝐧𝐨𝐭 𝐞𝐯𝐞𝐫 trust @OpenAI or its products (ChatGPT etc). There is only one reason for appointing an @NSAGov Director to your board. This is a willful, calculated betrayal of the rights of every person on Earth. You have been warned.\" / X (twitter.com)](https://twitter.com/Snowden/status/1801610725229498403)\n\t\t- {{twitter https://twitter.com/Snowden/status/1801610725229498403}}\n\t- <iframe src=\"https://www.eff.org/deeplinks/2024/04/us-senate-and-biden-administration-shamefully-renew-and-expand-fisa-section-702-0\" style=\"width: 100%; height: 600px\"></iframe>\n- [Chat Control: The EU’s CSEM scanner proposal – Patrick Breyer (patrick-breyer.de)](https://www.patrick-breyer.de/en/posts/chat-control/)\n-",
        "link_types": [
            "bayer2023artificial",
            "o2021god",
            "rosenbergmanipulation",
            "harari2014sapiens",
            "Goldenfein Mann 2024",
            "Update Cycle",
            "swartz2008guerilla",
            "Anthropic Claude"
        ],
        "file_size": 40266
    },
    {
        "id": "Digital Asset Risks.md",
        "name": "Digital Asset Risks",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # Risks and mitigations\n\t- Looking across the whole sector, this paragraph from the Bank ofInternational Settlement (BIS) [sums everythingup](https://www.bis.org/publ/arpdf/ar2022e3.htm):\n\t\t- \"..it is now becoming clear that crypto and DeFi have deeper structural limitations that prevent them from achieving the levels of efficiency, stability or integrity required for an adequate monetary system. In particular, the crypto universe lacks a nominal anchor, which it tries to import, imperfectly, through stable coins. It is also prone to fragmentation, and its applications cannot scale without compromising security, as shown by their congestion and exorbitant fees. Activity in this parallel system is, instead, sustained by the influx of speculative coin holders. Finally, there are serious concerns about the role of unregulated intermediaries in the system. As they are deep-seated, these structural shortcomings are unlikely to be amenable to technical fixes alone. This is because they reflect the inherent limitations of a decentralised system built on permissionless blockchains.”\n\t- This might seem like reason enough to stop here and wait for [[central bank digital currencies]], but Bitcoin is here now, is likely unstoppable in, and with mitigations in place might have uses if developed properly. Perhaps surprising the same BIS is [allowing up to2%](https://www.bis.org/press/p221216.htm) of bank reserves to be held in crypto assets, including Bitcoin, [according to their June 2022 BaselCommittee on Banking Supervisionreport](https://www.bis.org/bcbs/publ/d533.pdf), though the BIS chief believe the [“battle” against crypto](https://www.bloomberg.com/news/articles/2023-02-22/crypto-has-lost-battle-against-fiat-currency-bis-chief-agustin-carstens-says) has already been won.\n\t- [[Lightning and Similar L2]] are still considered to be experimental and not completely battle tested. There have been various attacks and a major double spend attack may be possible,[[https://doi.org/10.48550/arxiv.2208.01908]] but there have been no major problems in the years it’s been running with careful design choices and cybersecurity best practice it it likely a production ready component of our planning.\n- ## Sociopaths everywhere\n\t- In the wake of the [rampant crimespree](https://www.bloomberg.com/opinion/articles/2022-11-14/ftx-s-balance-sheet-was-bad) by Sam Bankman-Freid and his top teams at Alameda research and the Bahamas registered exchange ‘FTX’ the whole industry has suffered, and will continue to suffer, seismic shocks. There is a chance the sector will never recover, from the substantial negative sentiment in American democratic politics, and that we have already seen the top of the hype bubble. Fortunately this doesn’t diminish our use cases for these technologies, as we were never planning to speculate with the asset, but rather use the network.\n- ## Crypto assets\n\t- For \"crypto\" assets more generally it is useful to look at the recent [“whole government executiveorder”](https://www.whitehouse.gov/briefing-room/presidential-actions/2022/03/09/executive-order-on-ensuring-responsible-development-of-digital-assets/)signed by President Biden early in 2022. It was mainly framed in terms of “responsible innovation, and leadership” in the new space. The resulting, “Comprehensive Framework for Responsible Development of Digital Assets” is a product of multi agency collaboration and can be seen as 9 reports and a summary document, and has been long anticipated. The summary itself is neither particularly comprehensive nor a framework, and mainly serves to identifies high level risks, aspirations, and challenges, and strongly hints toward eventual development of a “digital dollar” (CBDC, expanded later).\n\t- The risks section of the original executive order shows how legislatorsare framing this, so it’s useful to break down here.\n\t\t- Consumer and business protections. This is likely to pertain to custodians and is much needed. Misselling is rife. Security presents a challenge.\n\t\t- Systemic risk, and market integrity are a concern. The legislators clearly worry about contagion risks from the sector.\n\t\t- Illicit finance (criminality and sanction busting etc) are a concern, but not particularly front and centre[[moser2013inquiry]]. Criminality in 2021 was a mere 0.15% of transactions according to Chainalysis, but this number varies year to year. There are claims that Iran have begun official overseas buying with cryptocurrencies, but again, the [numbers are small](https://finbold.com/iran-makes-the-first-ever-import-of-goods-using-cryptocurrency-worth-millions/). One of the better sections of the work is the US treasury department’s recently published ‘National Risk Assessments for Money Laundering, Terrorist Financing, and Proliferation Financing’. This is a comprehensive report and speaks to careful research across the space. It is broken into [three parts](https://home.treasury.gov/news/press-releases/jy0619). Perhaps surprisingly, while they do see activity in these areas, they do not rate the risk as very significant. Cash remains the main problem for illicit funding. There is some talk that the nature of public blockchain analysis allows greater oversight of these tools and that this is to the advantage of government and civil enforcement agencies.\n\t\t- Highlighting the need for international coordination suggests they are mindful of jurisdictional arbitrage. The partial regulatory capture of these technologies, where activity flows to globally more lenient legislative regimes, continues to be a concern. Many of the centralised exchanges for instance are located in tax havens such as Malta. As the world catches up with these products it is likely that this will be smoothed out.\n\t\t- Climate goals, diversity, equality and inclusion are mentioned. It seems that the “environment” aspect of ESG is more important then “social” and “governance” at this time.\n\t\t- Privacy and human rights are mentioned.\n\t\t- Energy policy is highlighted, including grid management and reliability, energy efficiency incentives and standards, and sources of energy supply.\n\t- The [latest summary report](https://www.whitehouse.gov/briefing-room/statements-releases/2022/09/16/fact-sheet-white-house-releases-first-ever-comprehensive-framework-for-responsible-development-of-digital-assets/)resulting from the above guidance actually adds little tangible meat to the bones. This possibly reflects the complexity of these issues. The recommendations seem to be broadly as follows, and are really a copy/paste of the executive order.\n\t\t- Carry on doing research into central bank digital currencies, but there’s no particular rush.\n\t\t- Support development of better instant payment methods both at home and globally.\n\t\t- Ensure consumer and systemic protections.\n\t\t- More monitoring, civil and criminal prosecutions.\n\t\t- Issue more rules and clarity in response to risks (this is actually likely net positive as rules are currently unclear).\n\t\t- Improve global reporting on users (KYC/AML).\n\t- The government rhetoric to date in the USA can be seen to be converging on an understanding of the technology, at different rates in different parts of government. One thing that seems to shine through is their ownperception of their global leadership on legislation on these matters. They seems to assume that what they decide will guide the world, and this may be true through their KYC/AML pressures.\n\t- A recent proposed [bi-partisan bill in theUSA](https://bitcoinmagazine.com/business/heres-whats-in-senator-lummis-bitcoin-bill)will likely help inform global law, though it is unlikely to pass itself. It encourages the use of Bitcoin as a medium of exchange by applying a tax exemption on transactions of less than $200. The issue of whether an asset is a commodity (a raw material thing) or a security (a promise) is left to a couple of major government agencies to unpick, with corresponding reporting requirements. Crucially for this book these nascent bills all regard both Bitcoin and Ethereum as sufficiently decentralised to [qualify ascommodities](https://www.coincenter.org/a-new-senate-bill-focuses-on-cryptocurrency-exchanges-heres-what-developers-and-users-should-keep-an-eye-on/),meaning they would enjoy more lenient oversight. Far more likely to pass is the [proposed DCCPAbill](https://www.agriculture.senate.gov/im./assets/doc/crypto_one-pager1.pdf)which has senior lawmaker support and would see commodities in the space regulated in such a way that trading of it could be halted in the USA. In this line of policy, exchanges will be required to do far more reporting, and would be penalised for trading against their customers. DOAs and DeFi are the big potential losers. In a maddening twist the Office of Government Ethics in the USA has banned anyone who owns digital assets from working on the legislation. This is an exceptional move and likely to result in poorly crafted laws in the first instance.\n\t- The most recent and troubling example is the US ban on any Ethereum assets which have been through a “mixer service” [that obfuscateshistory](https://www.coincenter.org/u-s-treasury-sanction-of-privacy-tools-places-sweeping-restrictions-on-all-americans/).This is a huge constraint on the code and smart contract itself, not just sanctions against individuals. It has [‘freespeech’](https://hoffmang9.github.io/free-speech/the-history-code-is-free-speech.html)and constitutional implications.[[anderson2002free]] More such actions and [arrests ofdevelopers](https://www.dw.com/en/dutch-investigators-say-developer-of-tornado-cash-arrested/a-62793823)are feared. It has led to Circle (who issue the USDC stable coin)blacklisting every [address sanctioned by the USgovernment](https://home.treasury.gov/policy-issues/financial-sanctions/recent-actions/20220808).Centrally issued digital assets are obviously neither uncensorable nor permissionless. This intersects (again) with the whole question of what decentralisation means and how effective it can be in it’s stated goal of circumventing global policies.\n- # Bitcoin technical risks\n\t- In addition it’s useful for this document to focus more on the technical challenges to the Bitcoin network.\n\t\t- The block reward is reduced every 4 years (epochs). This means a portion of the mining reward is trending to zero, and nobody knows what effect this will have on the incentives for [securing the network](https://www.truthcoin.info/blog/security-budget-ii-mm/) through proof of work.[[carlsten2016instability]] It is increasingly [being discussed](https://cryptostackers.substack.com/p/bitcoin-is-not-a-store-of-value?sd=pf&s=r) as the major eventual problem for the network.\n\t\t- Stablecoins are a vital transitional technology (described later) but do not meaningfully exist yet on the Bitcoin network. This may change.\n\t\t- Bitcoin lacks privacy by design. All transactions are publicly viewable. This is a major drag to the concept of BTC as a money. Upgrade of the network is possible, and has indeed been achieved for a Bitcoin fork called Litecoin.[[fuchsbauer2019aggregate]]\n\t\t- The Lightning network (described later) has terrible UX design at this time.\n\t\t- The basic ‘usability’ of the network is still poor in the main. Any problems which users experience demand a steep learning curve and risk loss of funds. There is obviously no technical support number people can call.\n\t\t- Only around one billion unspent transactions can be generated a year on the network. This means that it might become impossible for everyone on the planet to have their own Bitcoin address (with it’s associated underpinning UTXO).\n\t\t- Chip manufacture is concentrated in only a few companies and countries, as identified by [Matthew Pines](https://www.btcpolicy.org/authors/matthew-pines).\n\t\t- Potential constraints on monetary policy flexibility.\n\t\t- Future protocol changes.\n\t\t- Unanticipated effects on the domestic and international energy system.\n\t\t- Vulnerability to adversary attacks are [widely studied](https://braiins.com/blog/bitcoin-mining-attacks-explained)[[apostolaki2016hijacking; @apostolaki2017hijacking; @johnson2014game; @stinner2022proof]], and still pretty much completely speculative because of the complex nature of the attack surface.\n\t\t- Mining tends toward economy of scale concentration. Many are already on their [own specialised network](https://bitcoinfibre.org/) to connect to one another.\n\t\t- Future hard forks. There will doubtless be pressure to fork the code to add inflation, or ESG mitigations, or to fix the UNIX clock issue in 2106. Each fork is a risk.\n\t\t- Other unknown, unanticipated risks given Bitcoin’s limited 13-year history.\n\t\t- There is a “non-zero” chance that Bitcoin is a complex government intelligence agency construct, [much like Crypto AG was](https://en.wikipedia.org/wiki/Crypto_AG) toward the end of the last century.[[dymydiuk2020rubicon]]\n- # Risks (money, not technical)\n\t- Special thanks to economist Tim Millar for help with this section.\n\t- ## Risks to Bitcoin the money (intrinsic)\n\t\t- ### Geopolitics\n\t\t\t- It can be seen that following the invasion of Ukraine by Russia, that sanctions of various kinds were applied to the Russian economy. One of these was the previously discussed Swift international settlement network. Another whole category was the removal of support by private businesses domiciled outside of Russia and Ukraine, and pertinent here is that VISA, Mastercard, Paypal, and Western Union all removed support for their product rails. This means that while some cards and services still work, and will likely work again through Chinese proxies in the coming months, considerable disruption will be felt by Russian companies and individuals. This is not to say that this disruption is necessarily wrong, but it is clear now that all of these global financial transfer products and services are contingent on political factors. The same might be true of CBDC products if they gain traction globally. There is certainly no reason why all money within a physically delineated border could not be blocked or cancelled. This is not as true for Bitcoin at this time.\n\t\t\t- However, with enough political will it is technically plausible to incentivise miners with additional payments to exclude transactions from geolocated wallets. This would be mitigated by Tor, and in a global anonymous network it is very likely that a miner could be found at a higher price for inclusion in the next block.\n\t\t\t- We have already seen much negative political positioning related to the energy concerns in an earlier chapter. There are similar noises coming from policy makers with regard to the money utility of the technology. The United Nations [have made the following recommendations](https://unctad.org/system/files/official-document/presspb2022d8_en.pdf):\n\t\t\t\t- “Developing countries may have less room to manoeuvre, yet the regulation of cryptocurrencies is possible. The following policies, among others, have the potential to curb the further spread of the risks of cryptocurrencies and stablecoins:\n\t\t\t\t\t- Ensuring comprehensive financial regulation, through the following actions:\n\t\t\t\t\t- Require the mandatory registration of crypto-exchanges and digital wallets and make the use of cryptocurrencies less attractive, for example by charging entry fees for crypto-exchanges and digital wallets and/or imposing financial transaction taxes on cryptocurrency trading;\n\t\t\t\t\t- Ban regulated financial institutions from holding stablecoins and cryptocurrencies or offering related products to clients;\n\t\t\t\t\t- Regulate decentralized finance (such finance may, in fact, not be fully decentralized, given its central management and ownership, which form an entry point for regulation);\n\t\t\t\t\t- Restricting or prohibiting the advertisement of crypto-exchanges and digital wallets in public spaces and on social media. This new type of virtual, and often disguised, advertisement requires policymakers to expand the scope of regulation beyond traditional media. This is an urgent need in terms of consumer protection in countries with low levels of financial literacy, as even limited exposure to cryptocurrencies may lead to significant losses;\n\t\t\t\t\t- Creating a public payment system to serve as a public good, such as a central bank digital currency. In the light of the regulatory and technological complexity of central bank digital currencies and the urgent need to provide safe, reliable and affordable payment systems, authorities could also examine other possibilities, including fast retail payment systems.\n\t\t\t- This is tough talk. We have seen that the IMF is willing to make theirloans contingent on such regulation, and are increasingly [talking about banning](https://www.imf.org/en/News/Articles/2023/02/23/pr2351-imf-executive-board-discusses-elements-of-effective-policies-for-crypto-assets) the technology. This global response to the technology is a significant headwind, but like the internet itself, it’s very hard to actually stop these products being used.\n\t\t- ### Capture by traditional finance [[Update Cycle]]\n\t\t\t- As the popularity of Bitcoin continues to grow, traditional financial market incumbents have begun to take notice. In an effort to assert their dominance and protect their interests, these incumbents have turned to regulation and acquisition as means of capturing the growing markets. This is most clear in the ’alt coin’ space where traditional banks have leveraged their knowledge and marketing to transfer money from retail investors into their own venture capital operations. This is not to say that Bitcoin is immune from these harms.\n\t\t\t- One way that traditional financial market incumbents have sought to capture the bitcoin market is through the use of regulatory frame works. By working with government agencies (as described in previous chapters),to develop and implement regulations governing the use and trade of cryptocurrencies, these incumbents are able to limit competition and control the flow of capital into and out of the markets. They are also able to “print paper bitcoin”, running a fractional reserve operation, as happened in the FTX/Alameda fiasco.\n\t\t\t- We have already described how, in the United States, the Securities and Exchange Commission (SEC) has implemented regulations governing the issuance and trading of bitcoin-based securities. These regulations, which require issuers of bitcoin-based securities to register with the SEC and comply with a variety of reporting and disclosure requirements, have effectively made it difficult for small and independent players to enter the market.\n\t\t\t- Another way that traditional financial market incumbents have sought to capture the bitcoin market is through the use of partnerships and acquisitions. As the newer companies stumble and fail as a result of poor risk management and over-leverage it seems that Wall Street incumbents like Goldman Sax are [taking advantage of theopportunity](https://www.reuters.com/technology/goldman-sachs-hunt-bargain-crypto-firms-after-ftx-fiasco-2022-12-06/)at structural scale. By acquiring existing crypto companies, these incumbents are able to gain access to the technology, expertise, and customer base of these companies, giving them a significant advantage over their competitors.\n\t\t\t- For example, in 2017, the Chicago Mercantile Exchange (CME) partnered with the CBOE to launch bitcoin futures trading. This partnership allowed the CME and CBOE to tap into the growing market for bitcoin derivatives, while also providing a means for traditional financial market participants to gain exposure to bitcoin without having to hold the underlying asset. This is a crucial risk to the emerging technology as ownership of the underlying asset (self custody) was supposed to be the whole point of the technology. Ben Hunt of epsilon theory recently said:\n\t\t\t\t- “..if you don’t see that the crypto quote-unquote industry has become just as blindingly corrupt as the traditional Financial Services industry it was supposed to replace well you’re just not paying attention what made Bitcoin special is nearly lost and what remains is a false and constructed narrative that exists in service to Wall Street in Washington rather than in resistance; the Bitcoin narrative must be renewed and that will change everything”\n\t\t\t- The current line of attack by the US government sees stringent tax reporting law proposed for 2025, which will if enacted ban self custody of the asset. It remains to be seen whether the public will tolerate this push toward centralised [[Bitcoin ETF]] as the defacto asset.\n\t\t- ### Liquidity Lottery\n\t\t\t- Because holders of BTC are disincentived to sell the asset (assuming future gains) it is likely vulnerable to something [Kao called the‘liquiditylottery’](https://twitter.com/UrbanKaoboy/status/1526311908709502977).This is a supply/demand mismatch which he thinks could spell the end of the asset class in time. Macro analyst group[‘Doomberg’](https://doomberg.substack.com/) believe that this mispricing of the asset is the significant risk, and point out that if Bitcoin is approached within the framework of government controlled Fiat, then there is no [‘there there’](https://en.wiktionary.org/wiki/there_is_no_there_there). Bitcoin does not generate more fiat money within it’s ecosystem (as say an energy extraction company would), and as such is very suggestive of the features of a Ponzi. They have recently softened on this view, and are now clear to separate Bitcoin from the wider ‘crypto’ world, which they remain convinced are simply scams, wash trading magic beans without any productivity. The value is dependent on finding the ‘greater fool’ mentioned near the start of the book. [Doombergassert](https://doomberg.substack.com/p/dollars-ex-machina) that the price of the asset has been inflated by manipulation in the unregulated stablecoin markets (specifically Tether), and in the event of a ‘run for the exits’ there would be a serious repricing. This seems entirely possible, and perhaps even likely, below an unknown threshold of confidence. They are now asserting that if the manipulation and mispricing could be ‘washed out’ of Bitcoin then it would present an investment opportunity, and they estimate that price at around $3000. We think that the combination of global speed of exchange of value, generative AI, and bots which leverage the network to create value within the ecosystem of the network, that this thesis does not stand true, but there is no way to know for sure at this time.\n\t\t- ### Manipulation of price or the network\n\t\t\t- Bitcoin is still young and illiquid enough to be highly manipulable. Imagine for instance if a major organisation or nation state wished to accumulate a significant amount of the asset, but would prefer a lower price.\n\t\t\t- There is an unknown level of exposure to risk from centralised mining. If a few of the major mining pools were simultaneously infiltrated by a nation state actor then it might be possible to engineer a ‘deep re-org’ of a large transaction. This would be dealt with quickly and almost certainly be a transient attack, but the damage to the narrative might be substantial. The proposed solution to this known vulnerability is called [‘Stratum V2’](https://braiins.com/stratum-v2) in which the transaction in the blocks would be organised by pool miners or their delegates, with an increase in efficiency as a driving incentive. A similar vulnerability exists in the centralisation at the level of internet service providers.[[apostolaki2017hijacking]] This or some other flaw might lead to a selling cascade. Nobody knows just how vulnerable to selling cascades Bitcoin might be against a really serious challenge by an empowered actor, but it’s already high volatility is suggestive o frisk.\n\t\t- ### Rehypothecation\n\t\t\t- It’s vulnerable to rehypothecation (paper bitcoin managed by centralisedentities running a fractional reserve).\n\t\t\t- It seems that this image by Nassim Taleb is a cautionary tale. [[taleb2012antifragile]]\n\t\t\t   ![](./assets/38ea50962c15ec244e6f6b69d4f506f4e836b575.png)\n\t\t\t   Nassim Taleb’s Turkey Problem\n\t\t- ### Scaling\n\t\t\t- Scalability is always going to be a problem for Bitcoin, for all the reasons discussed in the blockchain chapter. There is no “ready to go” solution (except perhaps federations) that could onboard the whole world at this time because of the limited number of available UTXOs.\n\t\t\t- Finally, a lack of fungibility, and privacy by default in Bitcoin,trends towards blacklists and over time this could seriously compromisethe use of the asset.\n\t\t- ### Centralisation of the money over time\n\t\t- In a medium term future it’s possible to imagine a smart enough autonomous AI or ML actor managing to accrue Bitcoin through fast and smart ‘decisions’. This could unreasonably centralise the asset, and it would be impossible to claw this situation back. These constructs would last for the lifetime of the chain unless constrained by timelock multisigs for instance.\n- ## Bitcoin externalities (extrinsic)\n\t- This section is the risks that Bitcoin poses to external money systems, but it’s worth pointing out that a risk to wider society is clearly also a risk to Bitcoin itself.\n\t- ##### Inherent volatility\n\t\t- One of the better public analysts of the asset, sees the price eventually fluctuating somewhere between  $700k and  $300k.\n\t\t- https://twitter.com/davthewave/status/1072441941390974982/photo/1\n\t\t- {{twitter https://twitter.com/davthewave/status/1072441941390974982/photo/1}}\n\t\t- This is not how a money is supposed to work.\n\t\t- [Cycle theory revisited blogpost](https://davethewave.substack.com/p/cycle-theory-revisited?s=r)\n\t\t- Neither though is it the endless [“number go up”](https://stephanlivera.com/episode/147/) that speculators have been promised. The aims of the project have a cognitive dissonance right at the core. The volatility trends toward:\n\t- ##### Unfair distribution\n\t\t- By design the distribution of Bitcoin is likely ‘fair‘, in that everyone has been able to access and secure the asset long term without prejudice. This image from Twitter user @Geertjancap shows the distribution in 2021. Whether this is judged to be fair if the asset jumps to 10 times it’s current value, minting a new class of hyper rich holders, is another matter.\n\t\t- ![](./assets/3c46c793cd3e9cdedc88623cafee35ef0ac7ebf0.jpg)\n\t\t- https://twitter.com/Geertjancap/status/1380972132990136322/photo/1\n\t\t- {{twitter https://twitter.com/Geertjancap/status/1380972132990136322/photo/1}}\n\t\t- Bitcoin distribution is skewed to a few early holders, but it likely is fair.\n\t- ### The Bitcoin Culture\n\t- This pressure to emulate the early winners leads to:\n\t\t- ##### Endless HODL\n\t\t\t- It’s possible that there’s a problem with people not wanting to sell the asset, because they are predisposed to a particular fervour promoted within the community. This can be seen in the [glassnodedata](https://en.macromicro.me/charts/32355/bitcoin-supply-last-active-1plus-years-ago),where the black line in Figure<a href=\"#fig:notselling\" data-reference-type=\"ref\" data-reference=\"fig:notselling\">4.9</a>shows that the asset held for more than a year (illiquid) has increased over the years.\n\t\t\t- ![](./assets/71c52745c51ecfc78ab76daa5b5d6826e950ec39.jpg)\n\t\t\t- Supply of bitcoin that <a href=\"https://en.macromicro.me/charts/32355/bitcoin-supply-last-active-1plus-years-ago\">hasn’t moved</a> for over 1 year\n\t\t\t- There’s real recalcitrance about using the asset as a money, which potentially negatively impacts the security model[[Wouters2022]] and leads to:\n\t\t- ##### Reduction of funding source / liquidity in legacy finance\n\t\t\t- In the current financial system remuneration for labour performed in the  workforce is loaned into the money system, where it’s put to work providing liquidity for creation of more opportunity. This system actually works pretty well. The more of this deferred labour that’s taken out of the legacy system, the less work can be done with what remains. This isn’t to say that Bitcoin will cause a liquidity crisis, but there is possibly a cost if the current trend continues. This isn’t as bad as:\n\t\t- ##### Bitcoin collapse system shock\n\t\t\t- In the event of an existential collapse of the Bitcoin network the erasure of so much capital would certainly have a contagion effect on the whole global financial system. It’s hard to imagine what such an event could be, this being the nature of “black swans”. One cited example is the unravelling of cryptography by quantum computing. Some conspiracy theorists in the past have even speculated that Bitcoin isi tself a canary in the coal mine, engineered by the NSA to warn about emergent quantum computing somewhere in the world. It’s all pretty silly because without cryptography Bitcoin would be the least of humanities problems. The risk of ‘something’ does exist though. The same anti-fragile feature can’t be said about the technologies around Bitcoin, which gives us:\n\t\t- ##### Stablecoin collapse system shock\n\t\t\t- This is much more likely. Stablecoins are under regulated, centralised, under collateralised, ponzi like structures, which could quite clearly fall apart at any point. The contagion effects of this are unclear as they’re not yet too significant. They’re a risk nontheless, and may bean indicator of:\n\t\t- ##### Tech for techs sake yielding unexpected outcomes\n\t\t\t- The whole question of what Bitcoin addresses, whether it’s been properly thought about, what the end goals are, and what the risks are is significant. It’s a computer science and engineering solutions gone completely wild. It’s clearly got benefits and there’s clearly human appetite for this technology, but it’s probably running ahead of the knowledge base around it. This is most exemplified in:\n\t\t- ##### No agreed measurable end goal\n\t\t\t- Bitcoin is a game theoretic juggernaut, where success of the network breeds more success for the network. The was obviously a great design choice for the computer scientists trying to solve the problem of a secure, and scalable, electronic cash, which couldn’t be confiscated. Ironically for a global consensus mechanism it seems that nobody wants to discuss what constitutes a successful end point to this, and especially not what ‘successful’ endpoints for the game theory which have calamitous negative repercussions for wider society look like.[[warren2023bitcoin]] This might have implications for:\n\t\t- ##### National security / actual warfare\n\t\t\t- There’s some national security implications for Bitcoin which are discussed both in the [fringes](https://twitter.com/JasonPLowery/status/1512775981693648897?) and the [sectormedia](https://www.coindesk.com/layer2/2022/04/04/why-bitcoin-mining-is-a-matter-of-national-security/). Essentially, the industrial mining complexes which are more commonplace now, are easily identifiable targets, and provide nations with both some leverage over the global network, and a considerable source of income. The IMF correctly identifies these facilities as a way for nation states to [monetise their energyreserves](https://www.imf.org/en/Publications/GFSR/Issues/2022/04/19/global-financial-stability-report-april-2022) without the need for foreign markets, opening the door to sanction avoidance. In the case of smaller and developing nation states who are perhaps subject to financial penalties on the global stage for whatever reason, these facilities start to look like legitimate targets for cyber and conventional warfare. Lowry explain the potential strategic importance of Bitcoin in Softwar, [[Lowery2023]] though to be clear his motives are unclear and his thesis is neither peer reviewed nor publicly accessible. This ‘weaponisation’ of a neutral technology is already manifest in:\n\t\t- ##### Jurisdictional / legislative arbitrage\n\t\t\t- The reach of Bitcoin and it’s ability to undercut the global money systems, delivering savings for those with a first mover advantage, and the current paucity of agreed legislation has set up an interesting and rare condition. Bitcoin encourages something called jurisdictional arbitrage; the race to take advantage of the variance in national approaches to the asset class. This section could perhaps be explored asa list of opportunities, but from the viewpoint of our SME business use case it’s far more likely that these destabilising ‘features’ are risks:\n\t\t\t\t- **Difference in ‘crypto’ profit models**. Countries and jurisdictions can apply different charges for use of trading platforms and capital gains tax enjoys huge variance. Some countries are now competing to offer zero tax as a way to attract valuable tech mind share.\n\t\t\t\t- **Income tax** is harder to monitor in a truly international context. This is variously pitched around the world. It’s hard to monitor this stuff and tax at source like with company employees wages, because it’s basically designed to be hard to monitor. This results in:\n\t\t\t\t- **Passport perks**. Countries are already selling residence and company rights against Bitcoin marketing. There’s a lot of new ways to buy passports and citizenship based on ‘inclusion’ in this community now. It’s a terrible look. The early adopters can live international jetsetter lifestyles and ca benefit from:\n\t\t\t\t- **Business subsidies** such as those appearing in Switzerland, [Hondoras](https://davisclute.medium.com/visiting-a-startup-city-in-honduras-73d9c026ee6d), El Salvador, Africa etc. This means a new divide is emerging since some countries are in instead applying:\n\t\t\t\t- **KYC/AML** rules which make onboarding into this technology harder. Currently there’s a trend toward globally capturing information about people buying these assets, but it’s effectively tech warfare now with engineers, rapidly producing tools to circumvent slow and varied legislation. The best example of this remains El Salvador, where Bitcoin is legal tender, and has perhaps kickstarted:\n\t\t\t\t- **Bond issuances**. El Salvador are having a [faltering start](https://www.ft.com/content/4fa63c8c-51f5-4512-b522-76dd75e62916) to their promised bond issuance. It might be that all of this is a harbinger of the rise of:\n\t\t\t\t- **The Network State** is a proposal by Srinivasan.[[Srinivasan2022]] His is a transhumanist thesis which he describes:\n\t\t\t\t\t- “The fundamental concept behind the network state is to assemble a digital community and organize it to crowdfund physical territory. But that territory is not in one place — it’s spread around the world, fully decentralized, hooked together by the internet for a common cause, much like Google’s offices or Bitcoin’s miners. And because every citizen has opted in, it’s a model for 100% democracy rather than the minimum threshold of consent modelled by 51% democracies.”\n\t\t- ##### Hyperbitcoinization\n\t\t\t- All of the above starts to look like convergence on something the crypto community regularly describes to itself within it’s internal media. Hyperbitcoinization is a term coined in 2014 by Daniel Krawisz.[[krawisz2014hyperbitcoinization]] It is the hypothetical rise of Bitcoin to become the global reserve currency, and the demonetisation of all other store of value assets. This seems unlikely but is hinted at in a game theoretic analysis of both Bitcoin and current macro economics. Again, Bitcoin is a likely very poor replacement for money. The ability to monetise assets through banks, backed by law and contracts (the debt based system), is a highly refined human concept, while Bitcoin is afusion of Austrian economics, and a computer science project. The hyperbitcoinization idea finds it’s ultimate expression in Svalholm’s “Everything Divided by 21 Million”, a hypothetical re-accounting of all human production into the Bitcoin ledger.[[booth2022bitcoin]]\n\t\t\t- Nobody is sure what a [regular deflationary cycle](https://fredblog.stlouisfed.org/2022/07/inflation-and-deflation-with-a-fixed-money-supply/)might do to global supply chains. Malherbe et al. point out the inherent unsuitability of a deflationary asset such as Bitcoin as the global reserve currency[[malherbe2019cryptocurrencies]] and feel that perhaps other cryptocurrencies might be more suitable for adoption by governments. Interestingly this is the only paper to reference ‘Duality’(the only thing purportedly written by Satoshi Nakamoto after they left the project).\n\t\t\t- Writer and activist Cory Doctorow is [not a fan ofBitcoin](https://onezero.medium.com/the-byzantine-premium-8411521db843).He provides an excellent summary of what he sees as the [basic societalmistake](https://doctorow.medium.com/finance-caused-the-fall-of-rome-fd091fa02973)of the libertarian ideals around strong property rights and hard money. In a hyper bitcoinised world where debt law would be enforced by distributed code, it might be far harder to prevent the “fall of Rome” scenario he describes. It is notable that he is also [stronglyopposed](https://pluralistic.net/2023/03/09/autocomplete-worshippers/#the-real-ai-was-the-corporations-that-we-fought-along-the-way)to the current hype in AI and it’s possible this is just his stock in trade.\n\t\t\t- Fulgur Ventures (a venture capital firm) provide a [blog postseries](https://medium.com/@fulgur.ventures/the-roads-to-hyperbitcoinization-part-1-27dc84d0e5e5)about the route this might take. It’s important to note that Budish suggested that the usefulness of Bitcoin (and blockchain) cannot exceed the cost to attack it. The is highly suggestive that hyperbitcoinisation is impossible.[[budish2018economic]] It’s beyond the scope of this book to look at the implications of all this.",
        "link_types": [
            "central bank digital currencies",
            "Lightning and Similar L2",
            "https://doi.org/10.48550/arxiv.2208.01908",
            "moser2013inquiry",
            "anderson2002free",
            "carlsten2016instability",
            "fuchsbauer2019aggregate",
            "apostolaki2016hijacking; @apostolaki2017hijacking; @johnson2014game; @stinner2022proof",
            "dymydiuk2020rubicon",
            "Update Cycle",
            "Bitcoin ETF",
            "apostolaki2017hijacking",
            "taleb2012antifragile",
            "Wouters2022",
            "warren2023bitcoin",
            "Lowery2023",
            "Srinivasan2022",
            "krawisz2014hyperbitcoinization",
            "booth2022bitcoin",
            "malherbe2019cryptocurrencies",
            "budish2018economic"
        ],
        "file_size": 37982
    },
    {
        "id": "Research Tools.md",
        "name": "Research Tools",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n-\n- [Elicit: The AI Research Assistant](https://elicit.com/)\n\t- ## Elicit's Approach and Features\n\t\t- ### AI Research Assistant\n\t\t- Elicit is an AI research assistant that aims to make high quality reasoning abundant\n\t\t- Currently focused on text-based workflows, especially literature summarization and helping users understand what is known on a topic based on existing research\n\t\t- Long-term goal is to go further into reasoning and decision making\n\t\t- ### Systematic Review Automation\n\t\t- Elicit's workflow is inspired by the systematic review or meta-analysis process used to summarize scientific literature\n\t\t- Aims to automate this laborious process which typically involves teams of people working for over a year to find relevant papers, extract data, and summarize findings\n\t\t- Makes this capability more accessible for any research question\n\t\t- ### Key Features\n\t\t- Enter a research question and get back relevant papers along with AI-generated summaries of each paper with respect to the query\n\t\t- Extract structured data from papers into tabular format (e.g. population studied, methods used, interventions, outcomes)\n\t\t- Provide a description or instructions for data to extract, allowing custom extraction\n\t\t- Group or pivot extracted data by arguments, effects, interventions, techniques rather than just by paper\n\t\t- Notebook interface allows users to interactively search for papers, extract data, analyze results, and share templates of analysis with others\n\t\t- ### Approach to Building Elicit\n\t\t- Extensive testing of language model capabilities and designing human evaluation processes before powerful models were available\n\t\t- Breaking down complex reasoning tasks into granular steps that language models can be trained on and evaluated against\n\t\t- Intentionally not just training a model on a large dataset, but defining ideal step-by-step processes an expert would follow\n\t\t- Enables easier evaluation, troubleshooting and transparency into model's reasoning process\n- [[Research Tools]] [Undermind](https://www.undermind.ai/home/)\n- [Perplexity](https://www.perplexity.ai/) for [[Research Tools]].\n\t- [Tutorial: Perplexity Basics (youtube.com)](https://www.youtube.com/watch?v=ue4NU-U-hAE)\n- [storm · Streamlit (stanford.edu)](https://storm.genie.stanford.edu/)\n\t- https://github.com/stanford-oval/storm\n\t- Reader view, then page source then view as html then reflow with Claude\n- [Logseq Copilot (google.com)](https://chromewebstore.google.com/detail/logseq-copilot/hihgfcgbmnbomabfdbajlbpnacndeihl?pli=1)\n- [Logseq Quick Capture (google.com)](https://chromewebstore.google.com/detail/logseq-quick-capture/hdpmdgiddmjppbeahnglgagndmahlanc)\n- [AcademicAI](https://www.academicai.io/)\n-",
        "link_types": [
            "Research Tools",
            "Research Tools"
        ],
        "file_size": 2769
    },
    {
        "id": "Vision Pro.md",
        "name": "Vision Pro",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- I don't think the vision itself it's a technical mistake, they have the money, they made meaningful progress. I think they'll continue to support it, just there's not enough new technology the warrant anything \"next\", and famously No Moores Law In Optics\n- https://www.optica-opn.org/home/newsroom/2019/september/no_moore_s_law_in_optics/\n- The thermodynamics of the processing isn't getting much better, while the AI workloads ARE getting much bigger. Denser batteries are mooted but not available. They have \"maxed out\" around here, so they have to stop. Meanwhile there's just not market (really) for the one they have built. They can remain committed to the concept longer than the market can stay rational.\n- I think these things will eventually happen, but Meta accidentally stumbled on the likely direction of travel with the Ray Ban things. People who try the FRAME I bought, hacky and slow though it is, immediately \"sense\" the utility. People get tired of wow from heavy headsets. There's just not quite enough \"there there\".\n- # The good\n\t- Generally agreed to be the best technical attempt at a commercial headset\n\t- Exceptional space awareness.\n- # The bad\n\t- **Price**: $3,500 is very expensive, especially for a Gen 1 product.\n\t- **App Store Restrictions**: Not available outside the US without an American Apple ID.\n\t- **Heavy and Bulky**: Takes up significant space, uncomfortable for long sessions.\n\t- **Light Seal Design**: Weak magnets, often feels like it's going to break.\n\t- **Battery Dependency**: Requires the battery pack, no internal battery.\n\t- **Limited USB-C Port**: Only for charging, cannot connect to other devices.\n\t- **Motion Blur**: Using on a train or in motion causes blurriness and nausea.\n\t- **Field of View**: Feels like looking through binoculars, can feel tunnel-visioned.\n\t- **Heat and Discomfort**: Gets heavy and uncomfortable over time, especially for workouts.\n\t- **Sound Leakage**: Built-in speakers leak sound, potentially disturbing others.\n\t- **Limited Gaming**: Not many VR games compared to other VR platforms.\n\t- **No Window Management**: Inability to save window setups, basic interface.\n\t- **Share Experience**: Difficult to share experience with others easily.\n\t- **Productivity Issues**: Feels less productive compared to traditional setups.\n\t- **Public Use**: Looks awkward and attracts attention when used outside.\n- {{twitter https://twitter.com/tkexpress11/status/1780566909957910682?}}\n- [The Vision Pro is a big flop (disconnect.blog)](https://disconnect.blog/the-vision-pro-is-a-big-flop/)\n- [Apple can readily afford this experiment, they are operating at such scale that failure of the Vision Pro is meaningless](https://www.engadget.com/it-doesnt-matter-how-many-vision-pro-headsets-apple-sells-ming-chi-kuo-production-numbers-143112470.html?guccounter=1)",
        "link_types": [],
        "file_size": 2841
    },
    {
        "id": "nostr.md",
        "name": "nostr",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- [Decentralized publishing for the web (nostr.how)](https://nostr.how/en/what-is-nostr)\n- # Notes and Other Stuff by Relays\n\t- Nostr [pronounced no-star] is a decentralized open protocol that aims to improve the social media experience by addressing issues of censorship and data collection. The protocol operates by allowing users to post and view notes on servers called relays, and view and post these notes through apps called clients. The open nature of the protocol allows for competition and a free flow of information, as users can choose to use different relays or clients if they are censored. This is because the protocol is decentralized and controlled by no one.\n\t- The decentralized nature of Nostr means that there is no central authority that can control the flow of information. This is achieved through the use of relays and clients, which are run by different individuals or entities. Users have the freedom to choose which relays and clients they want to use, and as a result, their feeds are populated with content from the people they choose to follow. If a relay or client tries to censor a user, they can simply switch to a different one. This is a major advantage over traditional centralized social media platforms where one entity holds all the control over the flow of information and can censor or manipulate the content that users see.\n\t- Nostr is also not beholden to shareholders or investors. This means that the protocol can make decisions that prioritize the well-being and quality of discourse for users, rather than solely focusing on profit. This is in contrast to traditional social media networks like Twitter, Facebook, and TikTok, which are driven by the need to collect data on users and sell ads to generate revenue. In these centralized platforms, users’ data is collected, analyzed and sold to the highest bidder, often without the user’s knowledge or consent. Nostr, on the other hand, allows users to have more control over their data and the ability to monetize their content.\n\t- Nostr also tightly integrates Bitcoin Lightning to support the protocol. This will hopefully enable secure transmission of value alongside the information and interactions on the platform. It also gives users the ability to monetise their content.\n\t- This potential step-change improvement to the social media experience for everyday people addresses issues of censorship and data collection.\n\t- Nostr is “The simplest open protocol that is able to create a censorship-resistant global \"social\" network once and for all.” according to it’s github page. More than that it’s a client side validated proof of who a user is interacting with, hence being in this identity section. To be clear, it’s not a completely peer to peer system in that it uses (very dumb) relay servers, but this gives it some of the best characteristics of both paradigms. This has the following advantages for our metaverse application;\n\t\t- It’s lightweight, with minimal network overhead and complexity\n\t\t- It’s real-time using websockets\n\t\t- Anyone can run a relay server, so one can be run in the deployment in the final section of the book.\n\t\t- Each of the client peers connecting to the metaverse can be a relay and able to pass messages and proofs to the other clients without the metaverse server seeing the data or being online\n\t\t- It is itself Turing Complete and therefore able to execute any code within it’s message protocol\n\t\t- There are multiple usable libraries and tools\n\t\t- It’s under active development with a diverse and experienced community\n\t\t- It’s based on the same underlying cryptographic technology we are using elsewhere, indeed with it’s use of Taproot keys the identity system is global\n\t\t- It provides the identity proof that we need to validate users and objects into a virtual space\n\t\t- It enables message passing\n\t\t- It scales to be a social network as required\n\t\t- It need not rely on anything outside of a relay hosted on the metaverse server\n\t\t- It can be scaled to provide one to many bulletin board style applications within the metaverse\n\t\t- We can use it in private, group, and public modes as required\n\t\t- It integrates with the torrent network allowing storage and external referencing of arbitrary data\n\t\t- It can easily operate outside of the walled garden of the metaverse, extending the reach of the messages\n\t- Nostr is incredibly promising, and integrating these relays in the metaverse servers and clients of the proposed technology stack in this book might allow us globally provable identity, with privacy by design. It can provide message passing. If all entities in the collaborative mixed reality scenegraphs are also Nostr key pairs then schema can be applied consistently with the economic layer using the same key system as Bitcoin. Nostr has just received a substantial grant from Dorsey. It is core to the design later in the book. A curated list of projects and libraries is available on github.\n\t- Luke Childs says:\n\t\t- “Nostr makes a good candidate to be used as a very simple DID layer. Having \"Login with Nostr\" auth on websites solves a lot of problems in a very elegant way, and Nostr’s main use case as a social network protocol makes it highly suited to be used as your main identity proving key. Compare \"Login with Nostr\" to similar \"Login with Lightning\" (LNURL-auth) specs to see some easy and obvious advantages:\n\t\t  Remote signer vs local signer\n\t\t  Login with Lightning requires access to remote keys, login with Nostr requires access to local keys ideally stored in a browser extension. Due to the way Lightning works you can only really have one instance. You need all your client devices linked to a single Lightning node, this means most clients will be connecting to the signer remotely. Now if your Lightning node goes down or you lose your connection you also can’t auth with any service. This could cause circular dependencies where you lose the connection to your Lightning node so you can’t auth with the services you need to access to debug the issue with your Lightning node like your hosting provider or VPN account. You could technically solve this by replicating your LN keys to other client devices only to be used for local auth signing but that introduces other risks.\n\t\t  Unique identifier vs identity\n\t\t  A Lightning node is not really an identity but a unique identifier. It just tells you the person that auths is the same random person that authed last time, it doesn’t tell you who they are. A nostr pubkey is an identity. It tells you who they are, what their name is, what they look like, who they know, how you can pay them, how you can message them.\n\t\t  This is much more useful as an identity layer for an application. The application can show their profile picture, username, send secure cross platform push notifications via NIP-04 encrypted Nostr DMs, etc.\n\t\t  Consistent identity across services\n\t\t  Lightning pubkeys are sensitive private information and can leak confidential financial information, Nostr pubkeys are safe to share with anyone. LNURL-auth adds extra steps to solve this by creating derived subkeys for identities that are unique to each service you auth with. This does not seem ideal, it seems the default case is that an identity is something that you do want to follow you across all your accounts. Nostr based auth behaves more appropriate in this regard. In the rare case you need to achieve privacy and separation between certain services you can still do that by using use a throwaway Nostr key for those services.\n\t\t  User relationships across services Since authing with Nostr shares a real social identity with the service, they can also see your Nostr social graph. This could be useful for connecting you to people you already know on the new service.\n\t\t  Low cost identity\n\t\t  Ideally identities should be easy to create but hard to build up reputation to limit spam while avoiding excluding people from the network. It’s not clear that it will be cost effective / scalable for everyone to run their own Lightning node so tying individual identity to a single Lightning node pubkey is problematic. Nostr keys are easy to create and hard reputation can be earned via PoW/DNS or building a strong social graph.”\n\t- ## nostr, bluesky, twitter\n\t\t- [An Interview With Jack Dorsey (creator of Twitter)](https://www.piratewires.com/p/interview-with-jack-dorsey-mike-solana)\n\t\t\t- Dorsey left Bluesky, a project aimed at creating an open-source protocol layer for social media platforms, because it deviated from its original decentralized vision and started repeating the same mistakes as Twitter.\n\t\t\t- Dorsey believes Twitter's core problem was choosing an advertising-based business model, which made the platform vulnerable to pressure from advertisers and governments, leading to censorship.\n\t\t\t- Taking Twitter private was the only way to implement the changes needed to make it a true internet company with a focus on protocol, service, and business.\n\t\t\t- Dorsey argues that social media companies cannot remain censorship-resistant without moving to open protocols, as centralized platforms will always be vulnerable to pressure from advertisers and governments.\n\t\t\t- He believes that truly decentralized protocols like Nostr, which have no central point of control, are the future of free speech on the internet.\n\t- ## Key Management\n\t\t- nostr implicitly enables all of the features and functionality of PKI infrastructure. Nostr keys can be used for many purposes\n\t\t- [kind-0/nsecbunkerd: nsecbunker daemon (github.com)](https://github.com/kind-0/nsecbunkerd)\n\t\t- ### TODO nostr IoT\n\t\t\t- [[MUST 🔴]]\n\t\t\t-\n\t\t- ### Metaverse use of nostr\n\t\t\t- This provides a web interface into the metaverse providing:\n\t\t\t\t- simple cryptographic identity assurance\n\t\t\t\t- private peer to peer chat\n\t\t\t\t- group chats and channels\n\t\t\t\t- email to private message relay\n\t\t\t\t- links into media on web hosts\n\t\t\t- The pace of development on Nostr is dizzying. Peer to peer video andaudio will allow us to link metaverse instances, between peers, throughapplications such as [Monstr](https://monstr.app/).\n\t\t\t- It’s notable that Nostr has it’s own inexpensive [hardware signingdevice](https://github.com/lnbits/nostr-signing-device) to protectidentity in situations where this might be necessary.  bfThe proposed integration of Nostr social media and messaging, alightning layer with digital objects such as Fedimint, Zerosync or RGB,AI agents, Vircadia, and federated Bitcoin is the core value propositionof this book. This work pre-dates [Meta andZuckerbergs](https://www.theverge.com/2023/4/26/23699633/mark-zuckerberg-meta-generative-ai-chatbots-instagram-facebook-whatsapp)stated intent in this regard by 18 months, and is differentiated stillby our focus on emerging markets and decentralisation.\n\t\t\t- ##### NIP-05\n\t\t\t\t- At this time, the nascent identity layer in nostr leans on NIP-05. Thisis a distributed identity management system that maps Nostr keys toDNS-based internet identifiers. In events of kind 0 (setmetadata), the“nip05” key can have an internet identifier as its value. Clients splitthe identifier into the local part and domain and make a GET request tothe specified URL. The response should be a JSON document with a “names”key containing a mapping of names to hex-formatted public keys. If thepublic key matches the one from the setmetadata event, the clientaccepts the association and considers the “nip05” identifier valid.\n\t\t\t\t- Clients may find users’ public keys from internet identifiers by firstfetching the well-known URL and then checking for a matching “nip05”.When following public keys, clients must prioritize the keys over NIP-05addresses. Public keys must be in hex format. Clients can enable userdiscovery through search boxes, allowing users to find profiles byentering internet identifiers. The identifier can be used as the “root”identifier, displayed as just the domain. The protocol supports bothdynamic and static servers by using the local part as a query string.\n\t\t- All this potentially provides a simply interface to the Metaverse, including:\n\t\t\t- simple cryptographic identity assurance\n\t\t\t- private peer to peer chat\n\t\t\t- email to private message relay\n\t\t\t- links into media on web hosts and [[NosDav]]\n\t\t- The pace of development on Nostr is dizzying. Peer to peer video and audio will allow us to link metaverse instances, between peers, through applications such as Monstr.\n\t\t- It’s notable that Nostr has it’s own inexpensive hardware signing device to protect identity in situations where this might be necessary.\n\t\t- The proposed integration of Nostr social media and messaging, a lightning layer with digital objects such as Fedimint, Zerosync or RGB, AI agents, Vircadia, and federated Bitcoin is the core value proposition of this book. This work pre-dates Meta and Zuckerbergs stated intent in this regard by 18 months, and is differentiated still by our focus on emerging markets and decentralisation.\n\t\t- NIP-05\n\t\t\t- At this time, the nascent identity layer in nostr leans on NIP-05. This is a distributed identity management system that maps Nostr keys to DNS-based internet identifiers. In events of kind 0 (setmetadata), the “nip05” key can have an internet identifier as its value. Clients split the identifier into the local part and domain and make a GET request to the specified URL. The response should be a JSON document with a “names” key containing a mapping of names to hex-formatted public keys. If the public key matches the one from the setmetadata event, the client accepts the association and considers the “nip05” identifier valid.\n\t\t- Clients may find users’ public keys from internet identifiers by first fetching the well-known URL and then checking for a matching “nip05”. When following public keys, clients must prioritize the keys over NIP-05 addresses. Public keys must be in hex format. Clients can enable user discovery through search boxes, allowing users to find profiles by entering internet identifiers. The identifier can be used as the “root” identifier, displayed as just the domain. The protocol supports both dynamic and static servers by using the local part as a query string.\n\t\t- Nostr Protocol as the keystone\n\t\t\t- The Nostr protocol can be used to store and share valuable content across the network. This is ably demonstrated by the ‘Highlighter’ project which allows users to store important notes from around the web using nostr. In the context of our federated social media trust model, the Nostr protocol can serve as the underlying layer that connects various instances of virtual spaces, thus enabling seamless data exchange and interoperability among them. Highlighter demonstrates that nostr events can be leveraged to create, store, and interact with valuable across networks. By utilizing this concept, we can extend the functionality to support federated social media trust, allowing users to carry their reputation, identity, and cryptographic proofs across different virtual spaces and social media platforms.\n\t\t- Nostr marketplace in LnBits\n\t\t\t- The nostr markets plugin for LnBits allows virtual ‘stalls’ to be setup and payment to be mediated through nostr. This is obviously a great expansion to the usefulness of our integration\n\t\t- Integrating Cryptographic Proofs and Reputation\n\t\t\t- To create a trusted environment within the federated network, we must establish a mechanism for importing and verifying cryptographic proofs from various sources, such as social media sites and other digital platforms. By doing so, we enable users to bring their existing reputation and trust from these platforms into the new ecosystem, thus facilitating trust-based interactions and collaboration within the network. We can leverage the Nostr protocol and the NIP05 specification to import these cryptographic proofs, creating a secure and verifiable system for identity management and trust propagation. The NIP05 specification allows for the creation and verification of identity proofs within the Nostr protocol, thus enabling the seamless integration of trust and reputation data from external sources.\n\t\t- By utilizing the Nostr protocol as the underlying layer, we can establish connections between objects, people, and AI actors within the federated network. This interconnected ecosystem allows for seamless collaboration, information sharing, and trust-based interactions among all participants. The open-source collaboration infrastructure we propose can facilitate the development of various applications and services that leverage the federated network, such as virtual workspaces, AI-assisted creativity tools, and more. The uncensorable nature of this protocol further supports the inclusivity and accessibility we feel so important, ensuring that participants from different regions and backgrounds can take part in the digital society and contribute to its growth.\n\t\t- This federated social media trust model, built on the Nostr protocol, allows for the establishment of a robust, inclusive, and trust-based network that connects various virtual spaces, social media platforms, and AI systems. By leveraging the lessons learned from the other attempts in the space, and by maximising the inclusion of external cryptographic proofs from multiple sources, we can create a comprehensive trust system that fosters collaboration, innovation, and shared growth within the digital society.\n\t\t- The Nostr protocol, with its decentralized and open-source nature, provides a solid foundation for linking and federating objects, people, and AI actors across collaborative spaces in digital society. By leveraging the Nostr protocol, we can build a robust and trust-based network that interconnects various virtual spaces, social media platforms, and AI systems. One of the key aspects of this trust-based network is the ability to import cryptographic proofs from different sources, similar to Keybase’s approach to importing proofs from various social media sites (Keybase Proofs).\n\t\t- StrFry relays\n\t\t\t- The Stirfry relay software provides high-performance infrastructure for building decentralized social media applications on top of the Noster protocol. As an open source project written in C++, Stirfry emphasizes efficiency, flexibility, and community-driven governance.\n\t\t\t  At the core of Stirfry is its high-speed database engine. Rather than using a traditional SQL database, Stirfry implements the Lightning Memory-Mapped Database (LMDB)\n\t\t\t- an embedded key-value store optimized for performance. Reads are lock-free, enabling unlimited parallel query throughput. Writes require only a short-held lock, ensuring minimal interference. LMDB’s \"shadow paging\" design allows isolated read-only transactions via multi-version concurrency control (MVCC). This prevents reads from blocking writes and vice versa.\n\t\t\t  To maximize database performance, Stirfry stores Noster events directly in FlatBuffers\n\t\t\t- an efficient binary format allowing direct access without serialization. The original JSON payloads are preserved to facilitate transmission back to clients. Additional database files index events on fields like timestamps and authors, accelerating filter queries. Periodic compaction optimizes the layout for faster operations.\n\t\t\t- Stirfry adopts a multi-threaded, modular architecture. A websocket thread accepts new client connections and routes incoming requests. An ingester thread validates and pre-processes each request before passing to appropriate handlers. Doing signature checks and filter compilation upfront avoids repeating work. A single writer thread batches database writes to amortize transaction overhead. Multiple worker threads handle read queries, fairly scheduling between long and short requests. Dedicated monitor threads track active filters and stream matching events to subscribed clients. Passing messages between threads instead of sharing data structures improves efficiency.\n\t\t\t- Additional features further enhance Stirfry’s capabilities. Graceful shutdown support allows stopping new connections while existing ones complete. Hot configuration reloading provides runtime updates without restarting. Flexible write policy plugins enable custom content moderation. Streaming websocket compression and Zstandard dictionaries compress traffic. Syncing protocols like Negentropy facilitate efficient relay replication, powering mesh network topologies. Geo-replication by the relay.org community offers low latency worldwide access. The custom Templar HTML templating library assists crafting simple, fast decentralized frontends.\n\t\t- ## End to end private messages\n\t\t\t- The current state of direct messages (DMs) on Nostr presents significant privacy concerns. Messages are encrypted using a single public key, exposing metadata and leaving past conversations vulnerable if a private key gets compromised.\n\t\t\t- To address these issues, a new [DM specification](https://github.com/nostrworld/nostriga/issues/10) (nip104) proposes a double ratchet encryption scheme with ephemeral keys. This approach aims to provide:\n\t\t\t\t- **Metadata privacy:** Hiding information about who is communicating with whom and how often.\n\t\t\t\t- **Forward secrecy:** Protecting past messages even if a current private key is compromised.\n\t\t\t\t- **Post-compromise secrecy:** Ensuring future messages remain secure even if a past private key is compromised.\n\t\t\t- The new DM spec utilises two key features of Nostr to achieve its privacy goals:\n\t\t\t\t- **Abundant key space:** Nostr offers an almost infinite number of public-private key pairs, allowing for the generation and disposal of keys without exhaustion.\n\t\t\t\t- **Decentralized identity:** Nostr's inherent identity system eliminates the need for a central server to verify user identities, a requirement in traditional end-to-end encrypted messaging protocols like Signal.\n\t\t\t- ### Double Ratchet Encryption and Ephemeral Keys:\n\t\t\t- The core of the new DM spec lies in the double ratchet algorithm, which employs three chains of keys:\n\t\t\t\t- **Root chain:** Established through an initial Diffie-Hellman key exchange using the participants' Nostr public keys. This creates a shared secret key that serves as the starting point for the ratchet.\n\t\t\t\t- **Sending chain:** Used for deriving ephemeral keys for encrypting outgoing messages. Each message uses a new ephemeral key, ensuring forward secrecy.\n\t\t\t\t- **Receiving chain:** Used for deriving ephemeral keys for decrypting incoming messages. The receiving chain ratchets forward upon receiving a message with a new ephemeral key, guaranteeing post-compromise secrecy.\n\t\t\t- ### Message Exchange and Session Management:\n\t\t\t\t- **Session establishment:** When initiating a DM, the sender and receiver perform a Diffie-Hellman key exchange to establish the root chain and initialise their respective ratchet states.\n\t\t\t\t- **Message encryption:** The sender uses the sending chain to derive a new ephemeral key, encrypts the message, and sends it as a Nostr event.\n\t\t\t\t- **Message decryption:** The receiver uses the receiving chain to derive the corresponding ephemeral key and decrypt the message. The receiving chain ratchets forward, updating its state for future messages.\n\t\t\t- ### Challenges and Future Considerations:\n\t\t\t\t- **Client adoption:** The success of the new DM spec hinges on its implementation across various Nostr clients. Developers need to integrate the necessary cryptographic functions and session management logic.\n\t\t\t\t- **Device syncing:** Syncing conversations across multiple devices and clients poses a significant challenge due to the lack of a central server. Potential solutions involve broadcasting messages to multiple sessions and managing separate inboxes for each session.\n\t\t\t\t- **User experience:** The complexity of the double ratchet system and the potential for out-of-order messages may require careful design considerations to ensure a seamless user experience.\n\t\t\t\t-\n- {{renderer :linkpreview,https://nate.mecca1.net/posts/2024-01-30_microblogging-protocols/}}\n- [Get A Nostr Signing Device To Keep Your Nostr Identity Secure!](https://nostrsigningdevice.com/)\n- [Python nostr client](https://www.youtube.com/watch?v=vw5SZyYBuPk&t=1471s)\n- [Python nostr repo, months old](https://github.com/jeffthibault/python-nostr)\n- [nostrpy](https://github.com/monty888/nostrpy)\n- [lnbits enable extensions mode for nostr](https://github.com/raspiblitz/raspiblitz/issues/3799)\n- [tailscale forum posts](https://community.umbrel.com/t/introducing-the-official-nostr-relay-app/11339/17)\n- [Relay list](https://nostr.info/relays/)\n- [WSS check](https://websocketking.com/)\n- [nostr market guide](https://darthcoin.substack.com/p/lnbits-nostr-market)\n- [Nostr coinjoin github](https://gitlab.com/1440000bytes/joinstr)\n- [nostr blinded assets](https://thebitcoinmanual.com/articles/blinded-nostr-assets/)\n- [NIP-112 encrypted private chats](https://github.com/ArcadeLabsInc/arcade/wiki/NIP-112:-Encrypted-Group-Chat)\n- Nostr Data Layer\n\t- [NIP90\n\t\t- NIP-90\n\t\t- Data Vending Machine (nostr.com)](https://nips.nostr.com/90)\n\t- [Nooooooooogle (noogle.lol)](https://noogle.lol/)\n\t- [DVM data inferencing](https://github.com/pablof7z/nostr-data-vending-machine)\n\t- [NIP 90 data markets](https://github.com/nostr-protocol/nips/pull/682)\n\t- [DVM data inferencing](https://github.com/pablof7z/nostr-data-vending-machine)\n- [noskey, convert between things](https://github.com/melvincarvalho/noskey)\n- [nostr smart contracts stuff (melvin)](https://dev.to/melvincarvalho/smart-events-contracts-over-nostr-a-consensus-based-approach-1l9n)\n- [3d space thing](https://github.com/bongatores/nostrSpace)\n- Key generation and management\n- [BIP85 master key javascript](https://github.com/AndreasGassmann/bip85#readme)\n- [supertestnet/nostr-image-host: Upload and view images on the web without an api key (github.com)](https://github.com/supertestnet/nostr-image-host)",
        "link_types": [
            "MUST 🔴",
            "NosDav"
        ],
        "file_size": 26521
    },
    {
        "id": "Parametric.md",
        "name": "Parametric",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ![BB1mNtGj.jpeg](../assets/BB1mNtGj_1716451730618_0.jpeg)\n- Microsoft are bringing parametric (volume) design to Meta Quest.\n- # Overview\n\t- Voice and text to parametric CAD primitives and larger digital twin models, in shared virtual spaces is an important and necessary feature for commercial metaverse. We can already see examples and hints of this in current virtual reality and augmented reality applications.\n\t- These technologies enable users to manipulate and interact with 3D objects in real-time, bridging the gap between the physical and digital worlds. As the metaverse continues to evolve, the integration of voice and text input will undoubtedly play a crucial role in enhancing the overall user experience.\n\t- Imagine being able to verbally command a virtual design software to create specific CAD primitives or modify existing models. Additionally, the ability to add text annotations or descriptions directly within the virtual space can facilitate collaboration and communication among users.\n\t- Furthermore, as corporate metaverse like [[NVIDIA Omniverse]] expands, the shared virtual spaces will become increasingly complex and vast, accommodating a multitude of digital twin models. This means that users will be able to explore and interact with realistic replicas of real-world objects and environments, such as buildings, vehicles, or even entire cities.\n\t- By incorporating voice and text input functionalities, developers can empower users to manipulate and navigate these digital twin models more intuitively. Whether it's adjusting the dimensions of a virtual prototype or performing intricate measurements, the metaverse's ability to recognize and respond to voice and text commands will revolutionize the way we design, simulate, and experience virtual environments.\n- [Table Of Contents — bd_warehouse \"0.1.0\" # Uncomment this for the next release? documentation (bd-warehouse.readthedocs.io)](https://bd-warehouse.readthedocs.io/en/latest/)\n- [Latest General topics\n\t- neThing.xyz Community Forum](https://forum.nething.xyz/c/general/4)\n-\n- # Examples\n\t- <iframe src=\"https://nething.xyz/\" style=\"width: 100%; height: 600px\"></iframe>\n\t- {{video https://www.youtube.com/watch?v=Ey2YqyPYBSU&}}\n-",
        "link_types": [
            "NVIDIA Omniverse"
        ],
        "file_size": 2245
    },
    {
        "id": "Tuesday 11th of June FRAME reporting.md",
        "name": "Tuesday 11th of June FRAME reporting",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- What's this that I'm looking at and how do I use it?\n\t- **Object**: DJ mixer or audio mixing console.\n\t- **Usage**: Each knob, slider, and button allows manipulation of various audio channels, adjusting levels, adding effects, and transitioning between audio tracks. Essential for fine-tuning audio output during live performances or recordings.\n- *Can you look up the make and model for me?*\n\t- **Identify**: Your device appears to be a Pioneer DJ Controller, potentially from the DDJ series, such as DDJ-400 or similar.\n\t- **Instructions**: Look for specific logos or text indicating the exact model, usually found at the front or near the main controls. This will help verify the make and model.\n- *I've found here on the top that it says xdj-xz. Tell me about this, thanks.*\n\t- **You're welcome!** The **Pioneer DJ XDJ-XZ** is a professional DJ controller integrating standalone hardware and software functionality, ideal for comprehensive DJ performances. It features a full-size jog wheel, multiple inputs/outputs, and advanced Pro DJ capabilities. Great choice!\n- *Please add this to the logseq knowledgebase in github, and connect it to the live avatar so I can demo.*\n\t- **Sure thing.** That will take a couple of minutes, then you should be good to go.\n-",
        "link_types": [],
        "file_size": 1281
    },
    {
        "id": "AI Video.md",
        "name": "AI Video",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n#Public page automatically published\n\n- # The Holy Grail Of Real-Time\n- [EndlessDreams - Real-Time videos made easy - YouTube](https://www.youtube.com/watch?v=irUpybVgdDY)\n- {{video https://www.youtube.com/watch?v=irUpybVgdDY}}\n- # Commercial Offerings\n- ## Runway Gen 3\n\t- [Introducing Gen-3 Alpha: A New Frontier for Video Generation (runwayml.com)](https://runwayml.com/blog/introducing-gen-3-alpha/)\n\t-\n- ## Luma Dream Machine?\n\t- Luma Dream Machine is a browser-based AI video generator [developed by Luma Labs](https://www.creativebloq.com/ai/luma-dream-machine-makes-ai-video-open-to-all), a San Francisco-based startup. It allows users to generate short videos (around 5 seconds) by simply entering a text or image prompt.\n\t\t- **Free to Use**: Luma Dream Machine is free to try, with no waiting list or subscription required. Users get 30 free video generations per month.\n\t\t- **High-Quality Output**: The AI produces impressively clean and detailed videos, adhering to prompts accurately and generating relatively coherent motion.\n\t\t- **Fast Generation**: Videos are generated in around 2 minutes after entering the prompt.\n\t\t- **Consistent Subjects**: Characters and subjects appear consistent throughout the video, capable of expressing emotion better than many previous AI video models.\n\t- ## Limitations\n\t  While groundbreaking, and crucially, \"available\", Luma Dream Machine still has some limitations, as acknowledged by the company:\n\t\t- Morphing, warping, and unnatural movements\n\t\t- Difficulty with complex scenes or full-body shots\n\t\t- Text in videos may appear garbled\n\t\t- Anatomical issues like extra limbs or heads\n\t- [(1) Professor John Keeting on X: \"this was created with Luma AI I am very impressed. Made by Kevin Van Witt and the talented team at The Monster Library https://t.co/IXLWO1Be91\" / X (twitter.com)](https://twitter.com/ProfKeeting/status/1801632319536607623)\n\t- {{twitter https://twitter.com/ProfKeeting/status/1801632319536607623}}\n- {{embed ((661d5f76-bd9c-493d-afc1-efcec299ed24))}}\n- {{embed ((664465de-5bd3-4169-a90b-c03f117bef04))}}\n- # The Rest\n\t- **Lumiere: Google's Contribution** Google's Lumiere project also signifies progress in video generation capabilities, though full details remain undisclosed. This suggests ongoing competition and development  in the field.\n\t- **Meta's Approach: Foundational World Modeling** Meta (formerly Facebook) is taking a distinct approach, focusing on the underlying world modeling needed for video encoding and generation. This emphasis on understanding the principles of physics and object interactions could contribute to  more realistic AI-generated videos.\n\t- **Technical Capabilities and Limitations**\n\t\t- **Capabilities** Current AI video generators demonstrate proficiency in producing high-resolution images and videos. They are capable of style adaptation, simulating complex scenes with multiple elements, and handling variations in aspect ratio and resolution.\n\t\t- **Limitations**  Despite their strengths, these models still struggle to accurately simulate physics and lack a complete understanding of cause and effect. Occasional errors regarding object permanence highlight the existing gap between pattern recognition and a comprehensive understanding of the world.\n\t- **Ethical and Creative Considerations**\n\t\t- **Potential Impacts**  Advancements in AI video generation raise questions about the future of creative professions and the ethical implications of AI-generated content. Balancing technological innovation with safeguarding the integrity of human creativity is an important consideration.\n\t\t- **Challenges**  Distinguishing between pattern recognition and genuine understanding is pivotal in the ethical use of AI. The potential for misuse or the creation of harmful content underscores the need for clear guidelines and responsible practices.\n- # Open systems\n- ## OpenSora\n\t- [[Update Cycle]]\n- ## Stable Video\n\t- ![1708218759791.mp4](../assets/1708218759791_1708282889322_0.mp4)\n\t- [(16) Discarded Androids (Midjourney to Stable Video beta) : midjourney (reddit.com)](https://www.reddit.com/r/midjourney/comments/1ar6uz0/discarded_androids_midjourney_to_stable_video_beta/)\n\t\t- ![m2-res_960p.mp4](../assets/m2-res_960p_1708014022595_0.mp4)\n- ## Pika\n\t- [twitter link to the render loading below](https://twitter.com/BMaursky/status/1747700852226199815)\n\t  {{twitter https://twitter.com/BMaursky/status/1747700852226199815}} -\n- # Misc links being integrated.\n- [[MotionDirector]], with a dual-path LoRAs architecture to decouple the learning of appearance and motion. Further, we design a novel appearance-debiased temporal loss to mitigate the influence of appearance on the temporal training objective. Experimental results show the proposed method can generate videos of diverse appearances for the customized motions. Our method also supports various downstream applications, such as the mixing of different videos with their appearance and motion respectively, and animating a single image with customized motions.\n- [RAVE: Randomized Noise Shuffling for Fast and Consistent Video Editing with Diffusion Models (rave-video.github.io)](https://rave-video.github.io/)\n\t- https://discord.com/channels/1076117621407223829/1192162917395730635/1192162917395730635\n\t- Here's one way to use the brand new RAVE node from here: https://github.com/spacepxl/ComfyUI-RAVE\n\t\t- First pass often has flickering (depending a lot on the input), so I made a workflow to smooth even harsh flickering with AD. This allows for utilizing the transformative and often more detailed vid2vid from RAVE and still get smooth results in [[ComfyUI]]\n\t\t\t- Updated LCM version: https://discord.com/channels/1076117621407223829/1192162917395730635/1192212692354748427\n\t\t\t  using the \"video/controlgif/animatediff\" contolnet from here: https://huggingface.co/crishhh/animatediff_controlnet/blob/main/controlnet_checkpoint.ckpt\n\t\t- {{video https://rave-video.github.io/static/teaser/car-turn_final.mp4}}\n- ## Style transfer for humans\n\t- Multiple techniques tested with the same [[LoRA]] for [comparison](https://discord.com/channels/1076117621407223829/1198416106554130552/1198416106554130552)\n- [ActAnywhere](https://actanywhere.github.io/)\n- [AI-Enhanced Creator (beehiiv.com)](https://nejcsusec.beehiiv.com/)\n- AnimateAnyone for [[ComfyUI]] [MrForExample/ComfyUI-AnimateAnyone-Evolved: Improved AnimateAnyone implementation that allows you to use the opse image sequence and reference image to generate stylized video (github.com)](https://github.com/MrForExample/ComfyUI-AnimateAnyone-Evolved)\n- [CG Renders to AI ANIMATION\n\t- NIKE video — MOONWALKERS PICTURE](https://www.moonwalkerspicture.com/newslounge/cg-renders-to-ai-workflow-vol-02-anim)\n- Motion Control\n\t- [MotionCtrl (wzhouxiff.github.io)](https://wzhouxiff.github.io/projects/MotionCtrl/)\n- [[2401.12945] Lumiere: A Space-Time Diffusion Model for Video Generation (arxiv.org)](https://arxiv.org/abs/2401.12945)\n- [I2VGen-XL\n\t- a Hugging Face Space by damo-vilab](https://huggingface.co/spaces/damo-vilab/I2VGen-XL)\n- [ali-vilab/i2vgen-xl: Official repo for VGen: a holistic video generation ecosystem for video generation building on diffusion models (github.com)](https://github.com/ali-vilab/i2vgen-xl)\n\t- [MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation (magicvideov2.github.io)](https://magicvideov2.github.io/)\n- Interpolation and interframe consistency\n\t- [controlnet and ebsynth temporal consistency](https://www.reddit.com/r/StableDiffusion/comments/114zmh3/controlnet_and_ebsynth_make_incredible_temporally/)\n\t- [Motion-Conditioned Diffusion Model for Controllable Video Synthesis](https://tsaishien-chen.github.io/MCDiff/)\n\t- [Interframe consistency is now here](https://twitter.com/cut_pow/status/1576748659051749377)\n\t- [Interpolation between two frames](https://film-net.github.io/)\n\t- [FILM frame interpolator](https://film-net.github.io/)\n\t- [ProPainter for Video Inpainting (shangchenzhou.com)](https://shangchenzhou.com/projects/ProPainter/)\n\t- [zengyh1900/Awesome-Image-Inpainting: A curated list of image inpainting and video inpainting papers and resources (github.com)](https://github.com/zengyh1900/Awesome-Image-Inpainting)\n\t-\n- [Runway AI video editing](https://www.youtube.com/c/RunwayML)\n\t- Gen2 examples\n- Multishot [VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM](https://videodrafter.github.io/)\n- [vienna with prompts](https://www.linkedin.com/posts/dr-andreas-fraunberger_marketinginnovation-digitaltourism-ar-ugcPost-7073039429417730048-BKfQ?utm_source=share&utm_medium=member_desktop)\n- [Video slowmo and enhance](http://zeyuan-chen.com/VideoINR/)\n- [deforum stable diffusion video](https://github.com/HelixNGC7293/DeforumStableDiffusionLocal)\n- [Phenaki](https://phenaki.video/)\n- Collaborative video pipeline\n- [Magicvideo (faster)](https://magicvideo.github.io/)\n- [Production ready re aging](https://studios.disneyresearch.com/2022/11/30/production-ready-face-re-aging-for-visual-effects/)\n- [distilled models for 25fps](https://arxiv.org/abs/2202.00512)\n- [Stable warpfusion](https://www.linkedin.com/posts/rainisto_stablediffusion-musicvideo-remix-activity-7018207241522614272-YT1y?utm_source=share&utm_medium=member_desktop)\n- [Video talking heads from text service](https://www.synthesia.io/)\n- [Tune a video](https://tuneavideo.github.io/)\n- [Vidyo: Generates videos for social networks from longer videos.](https://vidyo.ai/)\n- [Stylegan-T video transformer from google](https://sites.google.com/view/stylegan-t)\n- [Houdini](https://github.com/proceduralit/StableDiffusion_Houdini)\n- [Dream Mix video to video remix](https://dreamix-video-editing.github.io/)\n- [RIFE frame interpolation](https://github.com/megvii-research/ECCV2022-RIFE)\n- [example github for sd](https://github.com/vladmandic/rife)\n- [Synthesia corporate video generation](https://www.youtube.com/watch?v=4uzzD9sD-PI)\n- [pix2pixHD nextframe google colab](https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/Pix2PixHD_Next_Frame_Prediction.ipynb)\n- [minecraft demo codebase](https://github.com/TSFSean/InvokeAI-DiffusionCraftAI)\n- [animation from mixamo](https://www.reddit.com/r/StableDiffusion/comments/zecyc7/mixamo_animations_stable_diffusion_v2_depth2img/)\n- [Intel enhance photorealism in realtime](https://github.com/isl-org/PhotorealismEnhancement)\n- custom SD video to video script\n- [Testing a custom video2video script I'm working on. (These used RealisticVision1.4 & ControlNet) : r/StableDiffusion](https://www.reddit.com/r/StableDiffusion/comments/11iviep/testing_a_custom_video2video_script_im_working_on/)\n- [consistency tools for character tooning](https://www.reddit.com/r/StableDiffusion/comments/11okvc8/how_about_another_joke_murraaaay/)\n- Alibaba system\n\t- [website](https://videocomposer.github.io/)\n\t- [github](https://github.com/damo-vilab/videocomposer)\n\t- [model cards](https://huggingface.co/damo-vilab/MS-Image2Video)\n- [9 new tools](https://twitter.com/mreflow/status/1637957302073565184)\n- [Automatic1111 plugin](https://www.reddit.com/r/StableDiffusion/comments/11w0ba9/modelscope_17b_text2video_model_is_now_available/)\n- [Next frame prediction with controlnet](https://www.reddit.com/r/StableDiffusion/comments/11f8i0g/next_frame_prediction_with_controlnet/)\n- [Will smith eating spaghetti](https://www.reddit.com/r/StableDiffusion/comments/1244h2c/will_smith_eating_spaghetti/)\n- [Transform Video to Animation in Stable Diffusion | How to Install + BEST Consistency Settings: Learn how to use AI to create animations from real videos. We'll use Stable Diffusion and other tools for maximum consistencyProject Files:https://bit.ly/3...](https://www.youtube.com/watch?v=sVmi2Yp43c0&t=22)\n- [How to Use ModelScope text2video with Automatic1111’s Stable Diffusion Web UI | kombitz: Enable the Extension Click on the Extension tab and then click on Install from URL. Enter https://github.com/deforum-art/sd-webui-modelscope-text2video in the URL box and click on Install. Click on Installed and click on Apply and restart UI. Go to your stable-diffusion-webui/models folder and create a folder called ModelScope and then create a folder called t2v under ModelScope. This is your models folder for text2video.](https://www.kombitz.com/2023/03/28/how-to-use-modelscope-text2video-with-automatic1111s-stable-diffusion-web-ui/)\n- This article provides instructions on how to use ModelScope's text2video feature with Automatic1111's Stable Diffusion Web UI.\n- [latent consistency pipeline](https://www.reddit.com/r/StableDiffusion/comments/17fvxrq/60_frame_video_generated_in_646_seconds/)\n- [GitHub\n\t- Picsart-AI-Research/Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators: Text-to-Image Diffusion Models are Zero-Shot Video Generators\n\t- GitHub\n\t- Picsart-AI-Research/Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators](https://github.com/Picsart-AI-Research/Text2Video-Zero)\n- The Picsart-AI-Research/Text2Video-Zero repository contains code for a text-to-image diffusion model that can be used to generate videos from text input. The model is a zero-shot video generator, meaning that it does not require any training data in order to generate videos.\n- [LVDM for long video creation](https://yingqinghe.github.io/LVDM/)\n- [The Text2Room algorithm generates textured 3D meshes from a given text prompt by leveraging pre-trained 2D text-to-image models. The core idea is to select camera poses that will result in a seamless, textured 3D mesh. The algorithm iteratively fuses scene frames with the existing geometry to create the final mesh. Evaluation shows that the algorithm is able to generate room-scale 3D geometry with compelling textures from only text as input.](https://lukashoel.github.io/text-to-room/)\n- [The VMesh system models a scene with a triangular mesh and a sparse volume for efficient view synthesis. It is trained on multi-view images of an object to create a contiguous representation of the object's surface and volume. This representation is then used to generate a simplified triangular mesh and a sparse volume, which can be stored and rendered efficiently. The system is designed for real-time applications and can render at 2K 60FPS on common consumer devices.](https://bennyguo.github.io/vmesh/)\n- [LLM guided video generation paper](https://arxiv.org/abs/2309.15091)\n- [LVM video gen using LLM paper](https://arxiv.org/pdf/2309.17444.pdf)\n- [Temporal stable automatic plugin](https://www.reddit.com/r/StableDiffusion/comments/12sd4bi/results_from_latest_version_of_temporal_stable/)\n- [We present a method for high-resolution video synthesis using latent diffusion models (LDMs). Our approach first pre-trains an LDM on images, then introduces a temporal dimension to the latent space diffusion model and fine-tunes it on encoded image sequences (i.e. videos). We focus on two real-world applications: simulation of in-the-wild driving data and creative content creation with text-to-video modeling. Our method achieves state-of-the-art performance on real driving videos of 512 x 1024 resolution. Additionally, our approach can leverage off-the-shelf pre-trained image LDMs, turning the publicly available, state-of-the-art text-to-image LDM Stable Diffusion into an efficient and expressive text-to-video model.](https://buff.ly/41FgQrb)\n- [This script allows for the automation of video stylization using StableDiffusion and ControlNet.](https://github.com/volotat/SD-CN-Animation)\n- [Really easy videos in A1111](https://www.reddit.com/r/StableDiffusion/comments/12otdo0/the_secret_to_really_easy_videos_in_a1111_easier/)\n- [Dancer 4 keyframes, low noise, controlnet approach](https://www.reddit.com/r/StableDiffusion/comments/12nwpdx/dancer_4_keyframes_guide_and_source_files_for/)\n- [Flicker free video workflow paper (good!)](https://anonymous-31415926.github.io/)\n- [Pika labs](https://twitter.com/pika_labs)\n- [Realtime lip-sync API](https://getsynchronicity.io/)\n- [ms image to video on huggingface](https://huggingface.co/spaces/fffiloni/MS-Image2Video)\n- [model to video blender modules](https://github.com/tin2tin/Generative_AI)\n- [videocomposer in python 3.9](https://github.com/mindspore-lab/mindone/tree/master/examples/videocomposer)\n- [motionagent image to video](https://github.com/modelscope/motionagent)\n- [Animatediff comfy workflows on discord](https://discord.com/channels/1076117621407223829/1149372684220768367)\n- [fluid animation youtube](https://www.youtube.com/watch?v=ak_az6ZNYFM)\n- [Controlnet tutorial](https://www.youtube.com/watch?v=WHxIrY2wLQE)\n- [LCM loras for fast inferencing](https://huggingface.co/collections/latent-consistency/latent-consistency-models-loras-654cdd24e111e16f0865fba6)\n- Animatediff is a new animation software that provides a range of tools and features for creating high-quality animations. It offers a user-friendly interface and supports various animation techniques, such as 2D, 3D, stop motion, and more. With Animatediff, users can easily bring their ideas to life and express their creativity through unique and captivating animations. Whether you're a professional animator or a beginner, Animatediff offers a comprehensive set of features to help you create stunning animations in a fast and efficient manner. title:: Animatediff and Stablevideo\n- Youtube tutorials\n\t- [IF_Animator ComfyUI workflow LCM+Animatediff+IPA+CN (youtube.com)](https://www.youtube.com/watch?v=FE2KmCEv19E)\n\t- [[Part 2] Tips and Tricks\n\t\t- AnimateDiff ControlNet Animation in ComfyUI\n\t\t- YouTube](https://www.youtube.com/watch?v=aysg2vFFO9g)\n\t-\n\t- [TianxingWu/FreeInit: FreeInit: Bridging Initialization Gap in Video Diffusion Models (github.com)](https://github.com/TianxingWu/FreeInit)\n\t-\n- [CiaraStrawberry/svd-temporal-controlnet (github.com)](https://github.com/CiaraStrawberry/svd-temporal-controlnet)\n- [ProjectNUWA/DragNUWA (github.com)](https://github.com/ProjectNUWA/DragNUWA)\n\t-\n- ## AnimateDiff\n\t- [(1461) Discord | #ad_resources | banodoco](https://discord.com/channels/1076117621407223829/1149372684220768367) animatediff resources\n\t-\n\t-",
        "link_types": [
            "Update Cycle",
            "MotionDirector",
            "ComfyUI",
            "LoRA",
            "ComfyUI"
        ],
        "file_size": 18154
    },
    {
        "id": "Singularity.md",
        "name": "Singularity",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- The concept of the technological singularity has captivated the minds of futurists, technologists, and philosophers for decades.\n- The term \"singularity\" in this context was popularised by mathematician and science fiction author Vernor Vinge in his 1993 essay \"[The Coming Technological Singularity.](https://accelerating.org/articles/comingtechsingularity)\"\n- Vinge's ideas were further expanded upon by inventor and futurist Ray Kurzweil in his 2005 book \"The Singularity Is Near.\"\n- # Naunce of interpretation\n\t- There is a split in interpretations of the singularity, contrasting the event horizon perspective with the omega point analysis, but both can incorporate the idea of an event horizon and the significance of the present moment.\n\t- ## The Event Horizon Interpretation\n\t\t- Vinge's conception of the singularity likens it to a boundary beyond which we cannot see or predict, a fast take-off style event on an exponential curve.\n\t\t- As technology accelerates at an exponential rate, we may reach a point where the pace of change becomes incomprehensible to human minds.\n\t\t- This technological crunch marks a point beyond which our current understanding of the world breaks down, and the future becomes essentially unknowable, potentially even to those experiencing it.\n\t\t- The Event Horizon interpretation emphasizes the breakdown of knowability and predictability beyond a certain threshold of technological advancement.\n\t- ## The Omega Point Interpretation\n\t\t- The Omega Point, as conceived by French Jesuit priest and palaeontologist Pierre Teilhard de Chardin, represents a future state of maximum complexity and consciousness, towards which the universe is evolving.\n\t\t- Kurzweil argues that the singularity is not an impenetrable boundary but rather a point of transition, beyond which intelligence and technology will continue to evolve and expand, ultimately leading to a state of unprecedented possibilities.\n\t\t- The Omega Point interpretation allows for a greater degree of human agency and participation in the process of reaching the singularity and shaping the future beyond it.\n\t\t- This perspective suggests that through the merger of human intelligence with advanced technology, we can actively shape and direct the future evolution of consciousness and complexity.\n- ## 'Now' as an Event Horizon\n\t- Many observers familiar with the field feel that we may have already passed through an event horizon, making it difficult or impossible to go back to a pre-singularity state.\n\t- The current moment can be seen as a boundary condition in both the Event Horizon and Omega Point interpretations.\n\t- In the Event Horizon interpretation, this boundary represents a point beyond which the future becomes unknowable and unpredictable due to the rapid acceleration of technological progress.\n\t- In the Omega Point interpretation, the event horizon represents a critical point in the trajectory towards the Omega Point, beyond which the future becomes increasingly determined by the merger of human intelligence and advanced technology.\n\t- ## Fast vs. Slow Takeoff Scenarios\n\t\t- The possibility of fast or slow takeoff scenarios can exist within both interpretations, depending on the rate at which technological progress accelerates and the degree to which humans can maintain agency and control over the process.\n\t\t- A fast takeoff scenario aligns more closely with the Event Horizon interpretation, suggesting a rapid and potentially unpredictable transition to a post-singularity state.\n\t\t- A slow takeoff scenario is more compatible with the Omega Point interpretation, allowing for a more gradual and collaborative approach to the merger of human intelligence and advanced technology.\n- ## Key Issues and Tensions\n\t- How much risk does advanced AI development pose? Is it an existential threat to humanity?\n\t- Do the potential benefits of faster AI progress outweigh the risks?\n\t- How tractable are proposals for making advanced AI systems safe and aligned with human values?\n\t- To what extent, if any, should governments regulate or restrict AI development? Can it be left to industry?\n\t- Will AI liberate humanity or lead to greater inequality, less human agency and new dangers?\n\t- What moral philosophy should guide these decisions - utilitarianism, human-centric values, or an AI-centric ethic?\n- ## Areas of Agreement and Disagreement\n\t- Both sides agree advanced AI will be transformative, but EAs worry more about downside risks\n\t- Many EAs argue AI safety is critical because the risks are so catastrophic; delaying AI is worth it\n\t- EAccs argue AI progress will be net positive and safety concerns are overblown; delays will cause harm\n\t- EAs and EAccs both worry heavy-handed government AI regulation could be damaging, but EAccs are more universally skeptical of regulation\n\t- EAccs are more open to transformative AI radically changing society; EAs want to preserve human agency\n\t- Both sides agree AI development shouldn't be monopolised by a few corporations, but differ on solutions.",
        "link_types": [],
        "file_size": 5040
    },
    {
        "id": "NVIDIA Omniverse.md",
        "name": "NVIDIA Omniverse",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # NVIDIA Omniverse\n\t- Omniverse is a collaborative platform developed by NVIDIA that enables users to create, simulate, and render 3D scenes and assets across multiple software applications. At the core of Omniverse lies the Universal Scene Description (USD) format, an open-source 3D scene description and file format that facilitates the interchange of 3D graphics data between different tools and applications.\n- ## Nucleus Server for Omniverse\n\t- Nucleus Server is a core component of the Omniverse platform that enables real-time collaboration, version control, and asset management for 3D scenes and assets. It acts as a central hub for storing, sharing, and synchronizing USD files and other related data across multiple users and applications.\n\t\t- Key features and functionalities of Nucleus Server include:\n\t\t- ### Real-time Collaboration\n\t\t\t- Multi-user editing: Multiple users can simultaneously work on the same USD scene or asset, with changes being synchronized in real-time\n\t\t\t- Presence and awareness: Users can see the presence and activities of other collaborators working on the same project\n\t\t\t- Conflict resolution: Nucleus Server automatically handles conflicts that may arise from simultaneous edits by multiple users\n\t\t- ### Version Control\n\t\t\t- Asset versioning: Nucleus Server maintains a version history of USD files and assets, allowing users to track changes over time\n\t\t\t- Branching and merging: Users can create separate branches of USD files for experimentation or parallel development, and merge changes back into the main branch\n\t\t\t- File locking: Nucleus Server supports file locking to prevent conflicts and ensure exclusive access to assets when needed\n\t\t- ### Asset Management\n\t\t\t- Asset organization: Nucleus Server provides a structured way to organize and manage 3D assets, including USD files, textures, and other related data\n\t\t\t- Metadata and tagging: Users can assign metadata and tags to assets for easier searching, filtering, and categorization\n\t\t\t- Access control: Nucleus Server allows for granular access control, enabling administrators to set permissions and restrict access to specific assets or projects\n\t\t- ### Omniverse Connector Integration\n\t\t\t- Application integration: Nucleus Server integrates with various 3D software applications through the Omniverse Connector plugin, enabling seamless synchronization and exchange of USD data\n\t\t\t- Live updates: Changes made in connected applications are automatically synchronized with Nucleus Server, ensuring that all collaborators have access to the latest version of the assets\n\t\t- ### Scalability and Performance\n\t\t\t- Distributed architecture: Nucleus Server can be deployed in a distributed architecture to handle large-scale projects and high-performance requirements\n\t\t\t- Caching and optimization: Nucleus Server employs caching mechanisms and optimization techniques to improve performance and minimize network bandwidth usage\n- ## Universal Scene Description (USD)\n\t- USD is a powerful and extensible framework for describing, composing, and interchanging 3D scenes and assets. It provides a common language for defining the geometry, shading, lighting, and other properties of 3D objects and scenes. USD allows for the efficient representation of large-scale, complex 3D scenes and supports features such as layering, instancing, and variant management.\n\t\t- Key features of USD include:\n\t\t- Hierarchical scene composition\n\t\t- Layered overrides and customization\n\t\t- Instancing and referencing\n\t\t- **Variant management**\n\t\t- Extensible schema system\n- ## Omniverse Variations (USD-based Object Variance System)\n\t- Omniverse Variations is a powerful feature built on top of USD that enables users to create and manage multiple variations of 3D objects and scenes within a single USD file. This allows for efficient storage and manipulation of different versions or configurations of assets, such as different materials, sizes, or poses.\n\t\t- Key aspects of Omniverse Variations include:\n\t\t- Variant sets: Collections of related variants for a specific purpose (e.g., material variations, level-of-detail variants)\n\t\t- Variant selection: Specifying which variant from each variant set should be active at any given time\n\t\t- Variant authoring: Creating and modifying variants using USD editing tools or supported 3D software applications\n- ## Blender Omniverse Integration with USD\n\t- Blender, a popular open-source 3D modeling and animation software, has been integrated with Omniverse through the USD format. This integration allows Blender users to leverage the collaborative features and pipeline interoperability provided by Omniverse.\n\t\t- Key features of the Blender Omniverse integration include:\n\t\t- USD import and export: Blender can read and write USD files, enabling seamless exchange of 3D data with other USD-compatible applications\n\t\t- Omniverse Connector: A plugin that enables Blender to connect to Omniverse servers for real-time collaboration and synchronization\n\t\t- USD schema support: Blender supports various USD schemas, such as UsdGeom, UsdShade, and UsdSkel, allowing for the preservation of important 3D data when exchanging files\n- ## USD Composer\n\t- USD Composer is a powerful visual programming tool provided by Omniverse that enables users to create and modify USD scenes using a node-based interface. It allows for the composition, layout, and editing of 3D scenes without the need for manual coding.\n\t\t- Key features of USD Composer include:\n\t\t- Node-based scene composition: Users can create and connect nodes representing 3D objects, materials, lights, and other scene elements\n\t\t- Attribute editing: Modify the properties of 3D objects and scene elements using the node interface\n\t\t- Variant management: Create and switch between different variations of objects and scenes\n\t\t- Extensibility: Custom nodes and extensions can be developed to extend the functionality of USD Composer\n- ## USD View\n\t- USD View is a standalone application provided by Omniverse for viewing and inspecting USD files. It allows users to navigate and explore the contents of USD files, including the scene hierarchy, geometry, materials, and other properties.\n\t\t- Key features of USD View include:\n\t\t- Scene hierarchy navigation: Explore the structure and organization of USD scenes\n\t\t- 3D viewport: Visualize and interact with 3D objects and scenes\n\t\t- Property inspection: View and modify the attributes of selected objects and scene elements\n\t\t- Variant switching: Quickly switch between different variations of objects and scenes for visualization and testing\n- ## Key aspects of NVIDIA's roadmap\n\t- **Enhanced Spatial Computing**: Spatial computing extends beyond traditional VR and AR by incorporating familiar elements of desktop computing into 3D space, enhancing user interactions with digital content in a more intuitive and spatially relevant manner.\n\t- **Omniverse Platform**: NVIDIA is pushing the Omniverse platform, which is aimed at achieving full fidelity, interoperability, and scalability in digital creation. It facilitates physically accurate simulations and seamless workflows across various digital creation tools, making it a critical part of NVIDIA’s ecosystem support strategy.\n\t- **Cloud XR and GDN**: NVIDIA is leveraging its expertise in cloud solutions with Cloud XR and GDN (GeForce NOW Developer Network) to enhance the streaming of rich, immersive content. These platforms support expansive computing needs, enabling high-quality rendering and low-latency delivery over the cloud.\n\t- **AI Integration in XR**: NVIDIA is integrating AI into XR to create more dynamic and responsive environments. This includes using AI for real-time content creation and adjustment, enhancing the realism and responsiveness of XR applications.\n\t- **Partnerships and Collaboration**: NVIDIA continues to seek and expand partnerships across various sectors to foster the development and deployment of XR technologies. This is evident in their collaborations with companies like Adidas and automotive brands, using XR and AI to create personalized and enhanced customer experiences.\n\t- **Future Vision and Development**: Looking forward, NVIDIA is focused on further merging AI with XR to enrich user interfaces and experiences. This involves developing tools that facilitate the creation of digital content and simulations that are increasingly indistinguishable from reality.\n-\n- ## Download links\n\t- https://install.launcher.omniverse.nvidia.com/installers/omniverse-launcher-win.exe\n\t- https://install.launcher.omniverse.nvidia.com/installers/omniverse-launcher-linux.AppImage\n- ### Tutorials and tips\n\t- [Omniverse Local Nucleus Server Setup Tutorial - YouTube](https://www.youtube.com/watch?v=xnUTCp_vN8I)\n\t-\n\t-",
        "link_types": [],
        "file_size": 8803
    },
    {
        "id": "Gemini.md",
        "name": "Gemini",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- [gemini_v1_5_report.pdf (storage.googleapis.com)](https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf)\n- # Summary\n\t- Gemini 1.5 Flash, Pro and Advanced results are out!\n\t- Gemini 1.5 Pro/Advanced at #2, closing in on GPT-4o\n\t- Gemini 1.5 Flash at #9, outperforming Llama-3-70b and nearly reaching GPT-4-0125 (!)\n\t- Pro is significantly stronger than its April version. Flash’s cost, capabilities, and unmatched context length make it a market game-changer!\n\t- More excitingly, in Chinese, Gemini 1.5 Pro & Advanced are now the best #1 model in the world. Flash becomes even stronger!\n\t- Gemini family remains top in \"Hard Prompts\" category, which features more challenging, problem-solving user queries.\n- [Introduction to Vertex AI  |  Google Cloud](https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform)\n\t- costs [Pricing  |  Vertex AI  |  Google Cloud](https://cloud.google.com/vertex-ai/pricing#costs)\n- [(1) Deedy on X: \"Can Gemini 1.5 actually read all the Harry Potter books at once? I tried it. All the books have ~1M words (1.6M tokens). Gemini fits about 5.7 books out of 7. I used it to generate a graph of the characters and it CRUSHED it. https://t.co/UCJiIh4SjY\" / X (twitter.com)](https://twitter.com/deedydas/status/1778621375592485076)\n\t- {{twitter https://twitter.com/deedydas/status/1778621375592485076}}\n\t-\n- [The killer app of Gemini Pro 1.5 is video (simonwillison.net)](https://simonwillison.net/2024/Feb/21/gemini-pro-video/)\n- [The University of Manchester\n\t- Job Information | Apply for Lecturer in Generative AI for Education](https://www.jobs.manchester.ac.uk/Job/JobDetail?JobId=28153) [[Contracts and jobs]] [[SHOULD🟡]]\n- Controls on LLMs have unintended consequences. Grimes on AI\n\t- [twitter link to the render loading below](https://twitter.com/Grimezsz/status/1761027769218347103)\n\t  {{twitter https://twitter.com/Grimezsz/status/1761027769218347103}} -",
        "link_types": [
            "Contracts and jobs",
            "SHOULD🟡"
        ],
        "file_size": 1962
    },
    {
        "id": "Multi Agent RAG scrapbook.md",
        "name": "Multi Agent RAG scrapbook",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- Lit survey for [[PEOPLE👱]] [[David Tully]] [[MUST 🔴]] In here for now.\n- {{video https://www.youtube.com/watch?v=LhWtpV-ZEeI}}\n- [chat-Sure thing! Below, were going to methodically construct a series of diagrams as code using Mermaid syntax and detailed technical explanations. Well walk through the entire pipeline, from data ingestion to user .txt](../assets/chat-Sure_thing!_Below,_were_going_to_methodically_construct_a_series_of_diagrams_as_code_using_Mermaid_syntax_and_detailed_technical_explanations._Well_walk_through_the_entire_pipeline,_from_data_ingestion_to_user_1716930774582_0.txt)\n- # Distilling Social Complexity: A Knowledge Graph and Ontology Approach for Immersive Environments\n- ## Introduction\n\t- Capturing complex social dynamics in real-time immersive environments is a novel research area\n\t- Combines knowledge graphs, ontologies, and multi-modal Large Language Models (LLMs)\n\t- Aims to distil and bound complexity to constrain errors in deep search by naive multi-modal models\n- ## Defining the Scope and Ontology\n\t- Identify the specific type of social interactions being modelled (e.g., professional events, casual gatherings, online communities)\n\t- Develop a formal ontology capturing core concepts:\n\t\t- Actors: Individuals, groups, organizations\n\t\t- Relationships: Friend, colleague, family, competitor, influencer\n\t\t- Interactions: Conversation, gesture, post, like, share\n\t\t- Context: Location, time, event, shared activities\n\t\t- Social Signals: Proximity, eye contact, tone of voice, facial expressions\n\t- Define properties and attributes to describe these concepts in detail\n- ## Knowledge Graph Construction and Real-Time Updates\n- ### Data Ingestion & Knowledge Extraction\n  ```mermaid\n  graph LR\n      subgraph Data Ingestion & Knowledge Extraction\n          direction LR\n          subgraph A[\"User Data\"]\n              direction TB\n              A1[\"Social Media\"] --> A2[\"Parser (e.g., Beautiful Soup)\"]\n              A3[\"Event Registration\"] --> A2\n              A4[\"User-Provided Bios\"] --> A2\n          end\n          subgraph B[\"Immersive Space Data\"]\n              direction TB\n              B1[\"Location Tracking\"] --> B2[\"Sensor Fusion (e.g., ROS)\"]\n              B2[\"Proximity Sensors\"] --> B2 \n              B3[\"Wearable Biometrics\"] --> B2\n              B4[\"Audio/Video Feeds\"] --> B5[\"Speech/Vision APIs (e.g., Google Cloud Vision, AssemblyAI)\"]\n          end\n          A2 --> C[\"Knowledge Graph Database (e.g., Neo4j, TigerGraph)\"]\n          B2 --> C\n          B5 --> D[\"Natural Language Processing (e.g., spaCy, Hugging Face Transformers)\"]\n          D --> C\n          subgraph E[\"Ontology Engineering\"]\n              direction TB\n              E1[\"Ontology Editor (e.g., Protégé, WebProtégé)\"] --> E2[\"Ontology (OWL/RDF)\"]\n              E2 --> C\n          end\n      end\n  ```\n- ### Knowledge Graph Construction Flow\n  ```mermaid\n  graph TB\n      subgraph Knowledge Graph Construction\n          direction TB\n          A[\"Formal Ontology (OWL/RDF)\"] --> B1[\"Entity Resolution\"]\n          B1 --> C[\"Graph Population\"]\n          subgraph Data Ingestion\n              direction LR\n              D[Social Media] -->|Beautiful Soup| B1\n              E[Event Registration] -->|Custom Connectors| B1\n              F[Immersive Data] -->|ROS| B1\n          end\n          C --> G[\"Graph Database (Neo4j, TigerGraph)\"]\n      end\n      subgraph Real-Time Processing\n          direction TB\n          H[Sensor Fusion] --> I[Fusion Data]\n          I --> J[Graph Updates]\n          J --> G\n      end\n  ```\n- ## Constrained Multi-Modal Retrieval Augmented Generation\n- ### Retrieval Augmented Generation Flow\n  ```mermaid\n  graph LR\n      subgraph Multi-Modal Retrieval Augmented Generation\n          direction LR\n          A[User/System Queries] --> B[\"Query Decomposition<br>(spaCy, Rasa)\"]\n          B --Ontology--> C[Ontology-Guided Search]\n          B --Vectors--> D[Vector Search<br>(Pinecone, Weaviate)]\n          C --> E[Relevant Knowledge Subgraph]\n          D --> E\n          E --> F[\"Constrained Response Generation<br>(GPT-3/4 with Prompt Engineering)\"]\n          F --> G[\"Response Validation<br>(Fact-Checking APIs, Rules)\"]\n          G --> H[User Interface<br>(Immersive Environment)]\n      end\n  ```\n- ## Applications and Ethical Considerations\n- ### Applications Overview\n  ```mermaid\n  graph TD\n      A[\"Enhanced Social<br>Awareness\"] -->|Insights| B[User Interaction]\n      B --> C[\"Personalized<br>Recommendations\"]\n      A --> D[\"Social<br>Simulations\"]\n      subgraph Ethical Considerations\n          E[Privacy and Consent]\n          F[Bias Mitigation]\n          G[Transparency]\n          H[Security Measures]\n          E & F & G & H --> I[Policy Compliance]\n      end\n      subgraph Applications\n          I1[\"Networking<br>Events\"] --> B\n          I2[\"Social<br>Gatherings\"] --> B\n          I3[\"Online<br>Communities\"] --> B\n          I4[\"Virtual<br>Labs\"] --> D\n      end\n  ```\n- ### Ethical Design and Deployment\n\t- Establish clear guidelines for data collection, storage, and usage\n\t- Ensure user privacy and agency\n\t- Address potential biases in data sources, models, and algorithms\n\t- Promote fair and inclusive social environments\n\t- Make the system's reasoning and recommendations understandable to users\n\t- Foster trust and accountability\n- ## Challenges and Research Directions\n\t- Efficiently process and integrate large-scale, heterogeneous data streams from the immersive environment\n\t- Accurately recognize and interpret subtle social cues from multi-modal data\n\t\t- Account for cultural differences and individual variations\n\t- Adapt the ontology over time to accommodate evolving social contexts and norms\n\t- Prioritize user well-being, privacy, and autonomy throughout the system's development and deployment\n- ## Conclusion\n\t- Ambitious undertaking with profound implications\n\t- Combines knowledge graphs, ontologies, and constrained multi-modal LLMs\n\t- Creates truly immersive and insightful social experiences\n\t- Requires careful design, continuous refinement, and strong ethical foundations\n\t  \n\t  The mermaid diagrams should render correctly inline, providing visual representations of the key components and their interactions within this metaverse ecosystem. The document maintains the technical detail, nuance, tool choices, and buildout advice from the original, while integrating the best aspects of the mermaid diagrams and restructuring the content into a clear narrative arc using Logseq markdown.",
        "link_types": [
            "PEOPLE👱",
            "David Tully",
            "MUST 🔴"
        ],
        "file_size": 6506
    },
    {
        "id": "Facebook Meta.md",
        "name": "Facebook Meta",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ## The trust collapse of Facebook\n\t- ### Company Culture\n\t\t- **Growth Focus**: The company culture prioritized growth and user engagement over other factors, such as user safety and value​​.\n\t\t- **Conflicting Teams**: Integrity/safety teams often found their priorities at odds with growth teams, with growth usually prevailing.\n\t\t- **Metrics of Success**: Success was defined primarily in terms of user engagement and platform growth, often to the detriment of other considerations.\n\t- ### Impact on Society\n\t\t- **Content Amplification**: Facebook's algorithms influenced what content got amplified, contributing to sensationalism and decreased factual accuracy.\n\t\t- **User Influence**: Hyperactive users had disproportionate influence over content flow and amplification.\n\t\t- **Democratic Illusion**: The platform created an illusion of democratization, but in practice, it was a curated environment with significant control over content and user interaction.\n\t- ### Mistakes by Senior Management\n\t\t- **Misaligned Priorities**: There was a fundamental misalignment between short-term growth and long-term integrity and user experience.\n\t\t- **Ignoring Research**: Findings that suggested integrity changes could boost long-term retention were often ignored or downplayed.\n\t\t- **Limited Transparency**: Decisions were made with a lack of transparency, both internally and externally.\n\t- ### Media and Public Backlash\n\t\t- **Investigative Reporting**: Reports by The Wall Street Journal and other media highlighted internal conflicts and the company's focus on growth over safety.\n\t\t- **Whistleblower Revelations**: Francis Haugen's whistleblowing brought significant attention to the internal documents and the company's practices.\n\t\t- **Public Perception**: These revelations led to increased scrutiny and criticism of Facebook's impact on society and its prioritization of profits over safety.\n\t- ### Lessons Learnt and Potential Changes\n\t\t- **Internal Awareness**: The leaks led to greater internal and public understanding of the platform's dynamics.\n\t\t- **Regulatory Impact**: The revelations have influenced regulatory discussions and potential legislative actions.\n\t\t- **Corporate Responsibility**: There's an ongoing debate about the responsibility of social media platforms in content management and user safety.\n\t- ### Hypothetical Better Ways of Building Platforms\n\t\t- **User Safety Focus**: Prioritizing user safety and value over mere engagement and growth.\n\t\t- **Balanced Influence**: Implementing measures to prevent hyperactive users from disproportionately influencing content amplification.\n\t\t- **Transparent Decision Making**: Adopting more transparent processes in algorithm design and content moderation decisions.\n\t\t- **Long-Term Metrics**: Shifting focus from short-term engagement metrics to long-term user well-being and platform health.\n\t- References:\n\t- Jeff Horwitz's book \"Broken Code,\" which delves into the Wall Street Journal's 2021 investigation and further into Facebook's internal documents. It was based on interviews and discussions with former Facebook employees and experts, shedding light on the company's internal dynamics and decision-making processes.\n- ## Zuckerberg’s New Goal: Creating Artificial General Intelligence\n\t- **Date:** 18/01/2024\n\t- **Key Points:**\n\t\t- [[Mark Zuckerberg]] and Meta aim to develop AGI, aligning AI research with generative AI product teams.\n\t\t- Intense competition for AI talent; Meta heavily investing in computing resources like Nvidia GPUs.\n\t\t- AGI lacks a clear definition; seen as a gradual process with diverse capabilities.\n\t\t- Meta's AI advancements: Llama 2 and upcoming Llama 3 models focus on coding, reasoning, and planning.\n\t\t- Debate on open vs. closed AI: Zuckerberg prefers open-source AI, balancing opportunity and safety.\n\t\t- AI's role in Meta's strategy: Enhancing social media and developing the metaverse.\n\t\t- Future vision: Deepening human-AI interaction in virtual worlds and social media.\n-",
        "link_types": [
            "Mark Zuckerberg"
        ],
        "file_size": 4010
    },
    {
        "id": "Education.md",
        "name": "Education",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- ![1713028555251.jpg](../assets/1713028555251_1713029092792_0.jpg)\n- ## Khanmigo\n\t- https://open.spotify.com/episode/7EBXdFqRGw6PKDrDnadaid?\n\t- Current Capabilities:\n\t\t- Khanmigo is an AI chatbot tutor created by Khan Academy. It is built on GPT-4 and fine-tuned by Khan Academy to be an education-focused AI.\n\t\t- It can have natural language conversations and explain concepts socratically, especially for math and other Khan Academy course content.\n\t\t- Khanmigo provides feedback on writing assignments based on rubrics set by teachers. It works collaboratively with students in an ethical way, not writing essays for them.\n\t\t- It has some memory and note-taking abilities to track student progress over time.\n\t\t- Khanmigo can act as a teaching assistant, helping teachers with grading, progress reports, lesson plans. This saves teachers time on repetitive tasks.\n\t- Key Features:\n\t\t- Designed specifically for education and avoids inappropriate content.\n\t\t- Won't cheat or make things up like ChatGPT. Anchored in Khan Academy content.\n\t\t- Has guardrails for under 18 users like notifying parents/teachers of issues and keeping conversations transparent.\n\t\t- Gives better math explanations than ChatGPT.\n\t\t- Provides a holistic student profile to teachers over time.\n\t- Vision:\n\t\t- Scale up to provide a digital tutor for every student and teaching assistant for every teacher.\n\t\t- Expand beyond just Khan Academy content to be an always-available guide and companion for learning anything.\n\t\t- Add video conferences, deeper memory/continuity, guardian features for internet use.\n\t\t- Provide multi-year narrative and support students' mental health/happiness.\n\t\t- Help \"invert the labor pyramid\" so more people can participate as knowledge workers and entrepreneurs.\n\t- [Class Companion Puts AI To Work Helping Teachers Help Students (forbes.com)](https://www.forbes.com/sites/rayravaglia/2023/10/05/class-companion-puts-ai-to-work-helping-teachers-help-students/)\n\t-\n- ### AI in Education: An In-Depth Exploration\n- #### **Contextual Overview**\n- **🌍 Current Educational Landscape:**\n- **AI Tools:** GPT-3.5, ChatGPT, and similar models are now integral in educational settings, offering personalized tutoring and assistance in creating learning materials【8】【11】.\n- **Historical Parallel:** The introduction of calculators in classrooms parallels current reactions to AI. Initial resistance gave way to widespread acceptance and integration, suggesting a similar trajectory for AI in education【9】.\n- **🧑‍🏫 Teacher's Perspective:**\n- AI is redefining the role of educators, shifting from content delivery to facilitators of deeper understanding and critical thinking【10】.\n- Teachers are leveraging AI for lesson preparation, reducing administrative burdens and enhancing the quality of classroom interactions【11】.\n- #### **Opportunities and Innovations**\n- **🔑 AI-Enhanced Pedagogical Techniques:**\n- **Flipped Classrooms:** AI can provide customized content for students to study at home, enabling more interactive and problem-solving activities in class【10】.\n- **Personalized Learning:** AI's adaptability can cater to individual student needs, potentially reshaping the one-size-fits-all education model【10】.\n- **🌱 Growth in Creative and Critical Thinking:**\n- AI aids in brainstorming and idea generation, fostering creativity in students who might struggle with these skills naturally【15】.\n- By challenging decision biases and encouraging diverse perspectives, AI acts as a catalyst for developing critical thinking skills【16】.\n- #### **Challenges and Considerations**\n- **🚧 Potential Pitfalls:**\n- Over-reliance on AI might hinder the development of essential skills like problem-solving and critical analysis【10】.\n- AI-generated content can contain inaccuracies, requiring careful review and validation by educators【14】.\n- **🔍 Ethical and Practical Implications:**\n- There are concerns regarding AI's potential for plagiarism and undermining the integrity of educational assessments【21】【25】.\n- The ethical use of AI, particularly in relation to data privacy and potential biases in algorithms, remains a crucial consideration【21】【25】.\n- #### **Practical Implementation and Strategies**\n- **💡 AI-Assisted Teaching Methods:**\n- **Example Generation:** AI can produce diverse examples to illustrate complex concepts, enhancing student comprehension【45】.\n- **Distributed Practice and Assessments:** AI can facilitate ongoing knowledge reinforcement through quizzes and exercises, tailored to individual learning progress【48】【51】.\n- **Connection of Concepts:** AI's ability to link new ideas to existing knowledge aids in deeper learning【52】.\n- **🔄 Evolving Role of Educators:**\n- Teachers are increasingly acting as curators and validators of AI-generated content, focusing on enhancing student engagement and addressing individual learning needs【53】.\n- #### **Future Directions and Reflections**\n- **🔮 Anticipating Future Developments:**\n- AI's capabilities in automating content creation and administrative tasks suggest an imminent shift towards more personalized and efficient educational models【35】【36】.\n- The ongoing advancement of AI tools like GPT-4 and image generation technologies like Midjourney indicates a rapidly evolving educational technology landscape【39】【40】.\n- **🤖 AI as a Collaborative Partner:**\n- Emphasizing AI's role as a tool to augment, rather than replace, human educators is key to harnessing its benefits while maintaining the essential human elements of teaching【53】.\n- **💭 Creative Considerations:**\n- AI can be an ally in overcoming creative blocks and fostering a culture of innovation and expression in educational settings【54】【55】.\n- #### **Concluding Insights**\n- The integration of AI into education is not just about the adoption of new technology; it's about reimagining the learning process. As AI continues to evolve, it will challenge traditional educational paradigms, offering opportunities for more personalized, engaging, and effective teaching and learning experiences. However, this journey necessitates careful navigation, balancing the innovative potential of AI with the timeless values of human interaction and ethical responsibility. The future of education with AI looks promising, but it requires a thoughtful, adaptive approach that prioritizes the enrichment of the human element in learning.\n- [[Kelly Drecourt]] is looking at product development\n- Drawn extensively from [[Ethan Mollick]] who has a Substack called [One Useful Thing](https://www.oneusefulthing.org/)\n\t- **AI as a Learning and Teaching Tool**:\n\t\t- AI, particularly GPT-4, is being effectively used as a tutor and learning aid for students and as a class preparation tool for teachers.\n\t - It offers adaptive, useful instruction, enhancing learning while reducing busywork.\n\t- **Challenges and Opportunities**:\n\t\t- The rise of AI raises concerns about cheating and its detection. This is, and will likely remain, undetectable.\n\t - However, it also opens doors for innovative teaching methods and aids in simplifying complex topics.\n\t - This is analogous to the calculator moment, we should step **in**, not away from this moment.\n\t- **AI in Classroom Settings**:\n\t\t- AI does not replace the multifaceted role of classroom teaching but complements it by providing support in understanding and applying concepts. It is the infinitely patient follow-up tutorial class. It is the reinforcement learning. It is the mock exams.\n\t - Classrooms provide additional value in terms of social interaction, skill application, and instructor support.\n\t- **AI and Assignment Types**:\n\t\t- AI's rapid adoption challenges traditional assignment types, necessitating a shift towards more interactive and AI-proof methods like oral exams and practical assessments. I don't think that's a bad thing so long as the AI can make time for this change by reducing the busywork.\n\t- **Instructor’s Role with AI**:\n\t\t- Educators **must** adapt to the ubiquitous use of AI in classrooms, using it as a tool for feedback, topic suggestions, and concept explanations. It will happen **to** them other\n\t- **Pedagogical Implications**:\n\t\t- AI offers personalized learning experiences and aids in the application of complex pedagogical approaches.\n\t - It allows for new forms of learning and pedagogy that can benefit both instructors and students.\n\t- **Future Directions**:\n\t\t- AI’s role in education is expected to grow, with increasing integration into teaching methodologies and curricula.\n\t - Educators should embrace AI technology and use it creatively in their teaching strategies.\n\t- **Adaptive Education System**:\n\t\t- The education system is poised to adapt effectively to AI, improving both learning experiences and teaching methodologies. This varies across nations, educational ages, and class boundaries.\n\t- **Balancing AI and Traditional Methods**:\n\t\t- While AI presents new challenges, it also offers significant opportunities for enhancing education, requiring a balanced approach to its integration. We need to be doing more.\n- {{embed ((657d1029-63aa-4766-8324-e7d6e5e19001))}}",
        "link_types": [
            "Kelly Drecourt",
            "Ethan Mollick"
        ],
        "file_size": 9301
    },
    {
        "id": "Deepmind.md",
        "name": "Deepmind",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n",
        "link_types": [],
        "file_size": 14
    },
    {
        "id": "Inpainting.md",
        "name": "Inpainting",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n-",
        "link_types": [],
        "file_size": 59
    },
    {
        "id": "Tokenization.md",
        "name": "Tokenization",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n-\n- [[Update Cycle]] as this is being discusses a lot right now\n-\n- ##### The Role of Tokenisation\n\t- Tokenisation represents a paradigm shift from traditionalcryptocurrencies. The concept was introduced and popularised by thewider cypto movement, and it’s somewhat absurd claims around ‘tokenisingeverything’. After this fab died down post the ‘initial coin offering’craze of 2018 attention shifted elsewhere. Curiously however the ‘Officeof the Comptroller of the Currency’ and the BIS have been focusing onresolving settlement issues within financial systems. It deviates fromthe blockchain dependency, (correctly) and simply offers a morestreamlined approach to financial transactions. This innovation willnotably be explored in the OCC’s tokenisation symposium held on February8th 2024, with an aspiration of integrating different types of money andassets on a unified platform. The symposium, a public event featuringkeynotes from prominent figures in the financial world, will highlightthe burgeoning interest in tokenisation ([OCC Tokenization SymposiumDetails](https://www.occ.gov/news-issuances/news-releases/2023/nr-occ-2023-18.html)).\n- ##### Implications and Potential Risks\n\t- While tokenisation presents significant potential for improvingtransaction efficiency and reducing risk, it is not without itschallenges. A key concern is the impact on the traditional financialsector and the regulatory complexities it introduces. The integration ofdiverse forms of digital assets on a unified platform necessitatesrobust regulatory frameworks to ensure stability and prevent misuse.\n\t- In truth this, like the global push toward central bank digitalcurrency, seems inspired by but asymptotic to the concept ofcryptocurrencies. They are important technologies to consider as digitalsociety tooling evolved, but they remain curiously far behind the retailtechnologies which spawned them. As the banking sector evolves withtechnological advancements, the role of tokenisation and its interactionwith existing financial systems become increasingly crucial. Thepotential for a more efficient, secure, and integrated global financialsystem is evident, yet the path to achieving this is laden withregulatory, technical, and ethical challenges. The success oftokenisation initiatives will largely depend on the collaborativeefforts of regulatory bodies, financial institutions, and technologyexperts to navigate these challenges effectively.",
        "link_types": [
            "Update Cycle"
        ],
        "file_size": 2516
    },
    {
        "id": "Base models.md",
        "name": "Base models",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # Base models\n- -- [Practical guide github and paper with branching diagram](https://github.com/Mooler0410/LLMsPracticalGuide)\n- Alpaca\n          Launch post with links\n           <https://crfm.stanford.edu/2023/03/13/alpaca.html>\n          Anonymous alpaca gpt train\n           <https://github.com/oobabooga/text-generation-webui/discussions/727>\n- Llama\n          Guide that worked for gradio\n           <https://aituts.com/llama/>\n          llama download from git\n           <https://github.com/shawwn/llama-dl>\n              running in venv\n               <https://www.reddit.com/r/MachineLearning/comments/11kwdu9/d_tutorial_run_llama_on_8gb_vram_on_windows/>\n              Oogabooga LLM github gradio\n               <https://github.com/oobabooga/text-generation-webui>\n                  deepspeed notes\n                   <https://github.com/oobabooga/text-generation-webui/issues/40#issuecomment-1412038622>\n                  whisper voice to prompt\n                   <https://github.com/oobabooga/text-generation-webui/tree/main/extensions/whisper_stt>\n                  text to speech\n                   <https://github.com/oobabooga/text-generation-webui/blob/main/extensions/silero_tts/script.py>\n                  erebus\n                  How to install\n                      patch\n                      ensure python 3.10.9, use proper venv\n                      cudnn as well as the drivers and normal reqs\n                      install plus all the requirements from the extensions\n                      make a startup script\n                  Rivet ooga plugin\n                   <https://github.com/hushaudio/rivet-oobabooga-plugin>\n                      Rivet repo\n                       <https://github.com/Ironclad/rivet>\n              int8 guide\n               <https://rentry.org/llama-tard-v2>\n              https://www.reddit.com/r/LocalLLaMA/comments/1227uj5/my_experience_with_alpacacpp/\n              CocktailPeanut Implementation\n               <https://github.com/cocktailpeanut/dalai>\n  -- Dalai llama\n- git clone the dalai from you desired github (i like the one from @cocktailpeanut  and the @#1 Dalai support (.pi))\n- go to the dalai folder and use\n- npm install\n- return your models for the dalai path models\n- after that\n- npx dalai@latest alpaca install your_model_version\n- after that\n- npx dalai@latest serve\n- npx dalai@latest serve\n  -- llama tard v2\n- <https://rentry.org/llama-tard-v2>\n- Discord llama based chatbot\n- <https://github.com/ortegaalfredo/celery-ai/blob/main/discord/bot.py>\n- FastChat based on llama 13b\n- <https://github.com/lm-sys/FastChat>\n- 4bit 30B linux integration\n- <https://github.com/oobabooga/text-generation-webui/wiki/LLaMA-model>\n- persistence\n- <https://github.com/facebookresearch/llama/issues/162>\n  -- llama-30b-4bit-huggingface\n- <https://huggingface.co/Neko-Institute-of-Science/LLaMA-30B-4bit-128g/tree/main>\n- Llama CPP windows open ticket\n- <https://github.com/ggerganov/llama.cpp/issues/22>\n- article on the implications\n- <https://arstechnica.com/information-technology/2023/03/you-can-now-run-a-gpt-3-level-ai-model-on-your-laptop-phone-and-raspberry-pi/>\n- Raven LLM RNN hybrid\n       <https://github.com/BlinkDL/RWKV-LM>\n          raven model on huggingface\n           <https://huggingface.co/BlinkDL/rwkv-4-raven>\n          cpp implementation\n           <https://github.com/harrisonvanderbyl/rwkv-cpp-cuda>\n- Dolly open source\n       <https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm>\n          databricks repo\n           <https://github.com/databrickslabs/dolly/tree/master/data>\n      collosal AI Open source GPT attempt\n       <https://github.com/hpcaitech/ColossalAI>\n- GPT-NeoXT-Chat-Base-20B human optimised free model\n       <https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B>\n- Nerybus blend\n       <https://huggingface.co/notstoic/OPT-13B-Nerybus-Mix-4bit-128g>\n- OpenLlama\n       <https://github.com/openlm-research/open_llama>\n- Fastchat\n       <https://huggingface.co/lmsys/fastchat-t5-3b-v1.0>\n- Vircuna\n          Vircuna 7B\n           <https://github.com/lm-sys/FastChat#fine-tuning-vicuna-7b-with-local-gpus>\n          WizardVircua retrain\n           <https://www.reddit.com/r/LocalLLaMA/comments/1376oho/introducing_wizardvicunalm_combining_wizardlm_and/>\n          VircunaFree\n           <https://huggingface.co/reeducator/vicuna-13b-free>\n- How to scale LLM workloads to 20B+ with Amazon SageMaker using Hugging Face and PyTorch FSDP\n       <https://www.philschmid.de/sagemaker-fsdp-gpt>\n- Red Pajama\n       <https://www.together.xyz/blog/redpajama-models-v1>\n- Mozilla LLM (apache)\n       <https://www.mosaicml.com/blog/mpt-7b>\n- OpenLlama weights\n       <https://huggingface.co/openlm-research>\n      Unlimited input\n       <https://github.com/abertsch72/unlimiformer>\n      This repository contains Stability AI's development of the StableLM series of language models. The models are designed to be more stable and robust than traditional language models, and the repository includes code and examples for training and using the models.\n       <https://github.com/stability-AI/stableLM/>\n      Wizard Vicuna\n       <https://github.com/nlpxucan/WizardLM>\n      Lit Llama license free retune of Llama, discord\n       <https://discord.com/channels/1077906959069626439/1090710167181594766>\n      Manticore logic trained 13B\n       <https://huggingface.co/openaccess-ai-collective/manticore-13b>\n      Alpasta 30B 4 bit\n       <https://huggingface.co/askmyteapot/GPT4-X-Alpasta-30b-4bit>\n      Wizard 30B unaligned\n       <https://huggingface.co/TheBloke/WizardLM-30B-Uncensored-GPTQ>\n      Falcon 40B (non commercial ish)\n       <https://huggingface.co/tiiuae/falcon-40b/blob/main/LICENSE.txt>\n          how to prompt\n           <https://github.com/cmp-nct/ggllm.cpp/discussions/36>\n      Based 30B\n       <https://huggingface.co/ehartford/based-30b>\n      orca from microsoft\n       <https://arxiv.org/pdf/2306.02707.pdf>\n      *  Text2NeRF is a text-driven 3D scene generation framework. It combines the neural radiance field (NeRF) and a pre-trained text-to-image diffusion model to generate diverse view-consistent indoor and outdoor 3D scenes from natural language descriptions.\n      *  Text2NeRF uses NeRF for the 3D representation and leverages a pre-trained text-to-image diffusion model to constrain the 3D reconstruction of the NeRF to reflect the scene description.\n      *  The page is about a hard surface character model named Lora, which is a mecha or humanoid character. The model is version 1.0, was updated on May 22, 2023, and has over 1,000 downloads. It includes a download link for the model file which is about 144 MB. The creator recommends setting Lora's values from 0.25 to 0.75 for better results, and suggests using keywords like \"helmet\", \"machine gun\", \"science fiction\", \"robot\", \"mecha\", \"humanoid\", and \"1girl\"​1​.\n       <https://civitai.com/models/73470?modelVersionId=78187>\n      *  This page provides a complete guide to ControlNet v1.1, a neural network model for controlling Stable Diffusion models. It offers users a way to control image compositions or human poses from a reference image with precision, and can be used alongside any Stable Diffusion models. ControlNet adds an extra conditioning to text prompts in addition to the original text-to-image functionality of Stable Diffusion models. The guide includes detailed examples on how ControlNet uses edge detection and human pose detection as extra conditionings. The page also provides instructions on how to install ControlNet on Google Colab, Windows PC, and Mac using AUTOMATIC1111, a popular GUI for Stable Diffusion​2​.\n       <https://stable-diffusion-art.com/controlnet/>\n      Can we improve the efficiency of these training methods, so we can still get good models in less time and for less money? We propose to do this by leveraging smaller language models that have previously been trained,\n       <https://gemm.ai/learning-to-grow-machine-learning-models/>\n- The text describes the Camel Chatbot, a machine learning model that has been trained using data from the AI Society and Code datasets. The chatbot is designed to improve the coding ability of users. The text includes a link to a demo of the chatbot in action.\n       <https://www.linkedin.com/posts/guohao-li-9a573b136_camel-chatbot-demo-activity-7051390760327225344-8D2A?utm_source=share&utm_medium=member_android>\n      The article discusses Reddit's use of cookies and technology to enhance user experience and explains that by accepting all cookies, users agree to improve the quality of Reddit, personalize content and advertising, and measure the effectiveness of advertising. Rejecting non-essential cookies will still allow Reddit to use certain cookies for proper platform functionality. The article also includes a post from a user promoting their expert-level tutorials on Stable Diffusion, which covers advanced AI techniques and strategies. Some comments on the post discuss various topics related to stable diffusion, such as suggestions for training architectural models and the use of C# programming language. Many other posts on various Reddit pages discuss Stable Diffusion and its accompanying tools and tutorials. https://www.reddit.com/r/StableDiffusion/comments/132rcou/30_stable_diffusion_tutorials_automatic1111_web/\n      Unfortunately, the provided text is not sufficient for me to provide a meaningful summary as it seems to be an error message related to website security. Can you please provide more context or a different text to summarize? https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n      Scan the World is a digital museum that aims to archive sculptures, artifacts and statues from across the world using 3D printing and scanning technologies. The community-built museum allows the scans to be free to download, making art and culture more accessible for everyone. Scan the World uses photogrammetry to capture the objects and offers them for the purpose of education, preservation, cultural heritage and accessibility. The range of scans available on the site is comprehensive, from buildings to digital archaeology and downloadable monuments. There are over 20 categories available on the website, ranging from Africa, Europe, Asia to Oceania, North America, and South America. The scans on the site include; David by Scan The World, Head of Michelangelo's David by SMK\n\t - Statens Museum..., Bust of Nefertiti at the Neues Museum, Berlin by Scan The World, Pieta in St. Peter's Basilica, Vatican by Scan The World, The Thinker at the Musée Rodin, France by Musée Rodin, and many more. Scan the World is an initiative of MyMiniFactory and the community that uses the platform to create 3D printable models. It is a unique platform that showcases art, culture, and history to the world through digital means. https://www.myminifactory.com/category/scan-the-world\n      The Wizard-Vicuna-13B-Uncensored-HF is a model used for text generation, which is available on the Hugging Face platform. It has been trained on a subset of data to remove alignment/moralizing and further trained to provide an uncensored model without guardrails, meaning it generates content without any limitations. The model can be accessed on-demand via the Inference API and is available in the float16 HF format for GPU inference and further conversions. Users can also contribute to the model through Eric Hartford's Patreon page or Ko-Fi. However, the creators mention that the users are fully responsible for the content generated by the model and must not blame the model for any negative consequences. https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-HF\n      ChatHub is a chatbot client that supports multiple chatbots, including ChatGPT, Bing Chat, Google Bard, Claude, and 10+ open-source models. Users can chat with multiple chatbots at the same time and compare their answers. ChatHub supports ChatGPT API and GPT-4 Browsing and has a shortcut to quickly activate the app anywhere in the browser. Other features include markdown and code highlight support, a prompt library for custom and community prompts, conversation history saved locally, export and import of data, and a dark mode. ChatHub can be installed manually by downloading the zip file from Releases and following the instructions or built from source by cloning the source code, running yarn install and yarn build, and loading the dist folder to the browser. ChatHub has a premium license that enables support for more bots in all-in-one mode and users can add their own custom theme setting. The app also has a changelog that documents the addition of new models, APIs, and other features supported by the app. Overall, ChatHub is a versatile tool for anyone who wants to interact with multiple chatbots at the same time and compare their performance. https://github.com/chathub-dev/chathub/blob/main/README.md\n      A Twitter user, Ouriel Ohayon, has accused ChatGPT, an AI language model, of accessing and using internal emails to provide accurate information about Ohayon's business model when prompted with a seemingly ambiguous question. ChatGPT is known for generating text based on given prompts and has gained popularity for its ability to closely mimic human language. However, Ohayon's accusation has raised concerns about privacy and data access by AI language models. Some Twitter users have suggested that the information may have been available elsewhere, while others have proposed the possibility of an employee leaking the information. ChatGPT has not yet responded to the allegation. https://twitter.com/OurielOhayon/status/1650369984080629760\n      Hugging Face, an AI startup known for its ML tools, has launched HuggingChat, an open-source chatbot alternative to OpenAI's ChatGPT. HuggingChat allows users to generate text in natural language or in a specific format and can handle various tasks like drafting emails, writing rap lyrics, and coding, including syntax highlighting. The chatbot's interface is similar to ChatGPT, with a left bar showing the latest chats and a large browser window for the current chat, and it's responsive. Hugging Face's release of HuggingChat emphasizes their dedication to open-source AI, and the company is also working to refine the model's limitations. In the future, Hugging Face plans to make all quality chat models available through a single hub to revolutionize the AI landscape. HuggingChat challenges the status quo and democratizes the AI chatbot industry, making it a game-changer. https://medium.com/codingthesmartway-com-blog/my-take-on-huggingchat-the-open-source-chatbot-alternative-to-chatgpt-thats-shaking-things-up-589a101bccde\n      Pinecone, a provider of a vector database for AI applications, has raised $100m in a series B funding round led by Andreessen Horowitz, with ICONIQ Growth, Menlo Ventures and Wing Venture Capital also participating. The funds bring Pinecone's valuation to $750m. Pinecone's database is used to generate accurate AI products by making it easier for engineers to work with data produced by large language models and other AI. Pinecone claims to have experienced explosive growth in the number of AI developers and users on its free plan, while customer numbers also rose. With the new capital Pinecone plans to continue expanding its team and to roll out more features on its platform. https://www.pinecone.io/learn/series-b/\n      The text mentions Reddit's use of cookies and similar technologies to improve user experience, and provides the option to accept or reject non-essential cookies. It also includes comments and posts from the subreddit r/LocalLLaMA, which discusses various topics related to language models, coding, and technology, including the release of new models and tools, benchmark results, and tutorials. Some of the comments and posts contain mature or NSFW content, and users are prompted to confirm their age before viewing such content. https://www.reddit.com/r/LocalLLaMA/comments/12kh2la/nsfw_chatting_promts_for_vicuna_11/\n      Sorry, I am unable to summarize the provided text as it is not a complete article or piece of information, rather just a message regarding the security of a website. https://machinelearningmastery.com/pytorch-tutorial-develop-deep-learning-models/\n      PandaLM is an open-source tool that provides reproducible and automated comparisons between different large language models (LLMs). The tool can be used to evaluate the evaluation ability of different LLMs and provide a reason for the decision, along with a reference answer. PandaLM can be used by organizations that have confidential data and research labs with limited funds. With PandaLM, they can perform evaluations without compromising data security or incurring high costs and obtain reproducible results. The tool is reliable and consistent and comes with a diverse human-annotated test dataset of approximately 1,000 samples. The repository contains the codes for training PandaLM, the human-annotated test dataset, the model weights of PandaLM, and the codes and configs for instruction tuning other foundation models such as Bloom, OPT, and LLaMA. PandaLM is easy to install, and the tool offers several choices for experiencing PandaLM, such as using a Web UI or the EvaluationPipeline class. PandaLM can be used to evaluate different responses for a given context and generate a reference response utilizing the given context, making it efficient and consistent. https://github.com/WeOpenML/PandaLM\n      The US Supreme Court is set to rule on a case that could affect the interpretation of fair use law and the protection afforded to generative artificial intelligence technology. The case, Andy Warhol Foundation for the Visual Arts, Inc. v. Goldsmith, hinges on whether a series of images Warhol created of Prince were distinct enough from the photograph he used for reference to be considered transformed, under the fair use doctrine of the Copyright Act. The decision could have implications both for copyright law, which is currently used by tools such as image and language models to train themselves, and wider international trade agreements that rely on shared recognition between nations of such laws. The potential effects of the ruling have led to legal scholars and industry figures expressing concern that AI could be granted copyright and alter trade policy or even industries such as drug formulations. https://www.wired.co.uk/article/andy-warhol-fair-use-prince-generative-ai\n      The Mr. Ranedeer AI Tutor is a customizable, personalized learning experience powered by GPT-4. It allows users to adjust the depth of knowledge, customize learning styles, communication types, tone, and reasoning frameworks to create the ultimate AI tutor. The Mr. Ranedeer AI Tutor works best with the ChatGPT Plus Subscription with GPT-4 or above models and is not recommended for use with GPT-3.5. The AI Tutor supports different languages, including Chinese, and has a variety of commands, including /test, /config, /plan, /start, /continue, and /language. The Mr. Ranedeer AI Tutor also offers Ranedeer Tools, which are optional prompts that allow users to create flexible environments, add personality, and more to the learning experience. The AI Tutor comes with a guide on how to use it, as well as configuration and Ranedeer Tools guides, and users can also access lessons on various topics, including poetry analysis and programming in Python. Mr. Ranedeer AI Tutor is available on GitHub and can be used by individuals, including AI models looking for information about the tutor. https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor\n      The TEXTure method is a novel approach for text-guided generation, editing, and transfer of textures for 3D shapes. It uses a pretrained depth-to-image diffusion model to iteratively paint a 3D model from different viewpoints, while dynamically defining a trimap partitioning of the rendered image into three progression states to generate seamless textures from different views. This method can transfer generated texture maps to new 3D geometries without explicit surface-to-surface mapping and extract semantic textures from a set of images without reconstruction. Furthermore, it can edit and refine existing textures using either a text prompt or user-provided scribbles. The paper shows extensive evaluation of the method's ability to generate, transfer, and edit textures, bridging the gap between 2D image generation and 3D texturing. https://texturepaper.github.io/TEXTurePaper/\n      Open_LLaMA is an open-source reproduction of Meta AI's LLaMA large language model. The project provides PyTorch and JAX weights of pre-trained OpenLLaMA models, as well as evaluation results and comparison against the original LLaMA models. The weights are released in two formats – an EasyLM format for the EasyLM framework and a PyTorch format for the Hugging Face Transformers library. OpenLLaMA models have been trained on the RedPajama dataset released by Together that contains over 1.2 trillion tokens and exhibit comparable performance to the original LLaMA and EleutherAI's GPT-J models across a majority of tasks. OpenLLaMA is licensed permissively under the Apache 2.0 license. Weights can be directly loaded from the Hugging Face Hub. https://github.com/openlm-research/open_llama\n      OpenAI has officially released Shap-E, a system that generates 3D objects by conditioning them on images or text prompts. Shap-E has two models, an encoder that converts 3D assets into the parameters for small neural networks that represent the 3D shape and texture as an implicit function, and a latent diffusion model that generates novel implicit functions conditioned on either the image or text descriptions. The new model includes rendering based on 60 views of each model, which is an improvement from the 20 views Point-E used, and the final output produces 16K points in each point cloud instead of 4K points. The lighting and material setup includes only diffuse materials, and the datasets are expanded with a million more 3D assets and 120K captions from human annotators. Shap-E generates 3D objects with lower fidelity than professional 3D assets and is geared towards cartoonish assets. Shap-E is available on Github, and the setup.py file in the official repository is incomplete and lacks several Python packages, which needs to be installed manually via pip install. https://ngwaifoong92.medium.com/introduction-to-shap-e-text-to-3d-a4fb5304642b\n      The authors present \"Shap-E\", a conditional generative model for 3D assets. Unlike other generative models that produce a single output representation, Shap-E generates the parameters of implicit functions that can be rendered as both textured meshes and neural radiance fields. The authors trained Shap-E in two stages; first, an encoder that maps 3D assets to the parameters of an implicit function, and second, a diffusion model on the encoder outputs. This method produces diverse, complex 3D assets in a few seconds. Shap-E converges faster and reaches comparable or better sample quality than the explicit generative model Point-E, despite modeling a higher-dimensional, multi-representation output space. The authors have released model weights, inference code, and samples. https://arxiv.org/abs/2305.02463\n      The co-founder of Hugging Face, Thomas Wolf, has released StarCoder, a 15-billion model trained purely on carefully vetted data ranging only over permissive codes, thereby ensuring high performance. The model can be used for internal finetuning or as the foundation for coding completion. Even though it can act as a chat model, Wolf warns that it should not be used like ChatGPT. While users were skeptical of StarCoders over Twitter and LinkedIn, Wolf confirmed the diversified compatibility of StarCoders, with the intention of making the model available to users worldwide.  https://www.linkedin.com/posts/thom-wolf_so-this-week-weve-finally-released-starcoder-activity-7060906603092271104-rrCx?utm_source=share&utm_medium=member_a\n       <https://www.linkedin.com/posts/thom-wolf_so-this-week-weve-finally-released-starcoder-activity-7060906603092271104-rrCx?utm_source=share&amp;utm_medium=member_a>\n  -- The StarCoder models are 15.5B parameter models trained on more than 80 programming languages using Multi Query Attention and a context window of 8192 tokens, using the Fill-in-the-Middle objective on 1 trillion tokens. The model was trained on GitHub code, so it can be turned into a technical assistant by using the Tech Assistant prompt. However, the generated code is not guaranteed to work as intended, and it may contain bugs or exploits. The pretraining dataset used to train the model was filtered for permissive licenses only, but the code's license generated from the model should be respected and may require attribution and/or other specific requirements. The model has been trained on source code from many programming languages, and it is capable of generating code snippets provided some context but with limitations. The model architecture used is GPT-2 with multi-query attention and Fill-in-the-Middle objective, and it was trained using the Megatron-LM orchestration and PyTorch neural networks. https://huggingface.co/bigcode/starcoder\n- I apologize, but as an AI language model, I do not have access to any specific text. Please provide me with the text that you would like me to summarize and I will be happy to do so. https://onosendai.tech/\n- NeRFLiX is a technology that enhances the quality of NeRF (Neural Radiance Fields) based approaches by significantly reducing rendering artifacts such as noise and blur. The NeRFLiX framework comprises a NeRF-style degradation simulator (NDS) and an inter-viewpoint mixer (IVM). NDS simulates NeRF-style degradations creating large-scale paired data for training deep neural networks to improve the quality of NeRF rendered images. Meanwhile, IVM progressively aligns image contents at the pixel and patch levels to maximize efficiency and improve performance, enhancing the quality of NeRF-rendered images and accelerating training rates. NeRFLiX has demonstrated a 50% reduction in training time while still producing even better results, elevating the performance of cutting-edge NeRF models to entirely new levels, producing highly photorealistic synthetic views. https://neuralradiancefields.io/nerflix-increased-nerf-quality-and-floater-removal/\n- The Facebook AI Research team has introduced ImageBind, a unified model that can analyze and process cross-modal data of six distinct modalities: audio, depth, IMU, thermal, text, and images. The model builds a joint space that can automatically correlate and align this multimodal data, allowing it to be utilized in emergent or augmented ways. It can enable tasks such as cross-model retrieval, composing modalities with arithmetic, cross-model detection, and generation. Additionally, it exhibits strong zero-shot classification Performance. The research will be presented at the 2023 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). The code and pretrained models are freely available on GitHub under a non-commercial Creative Commons license. https://github.com/facebookresearch/ImageBind\n- Chat-UI is a web-based application developed by Hugging Face that provides a chat interface using open-source models, such as OpenAssistant. It is a SvelteKit app that powers the HuggingChat app on hf.co/chat. Users need a Hugging Face access token to run Chat-UI locally, using the remote inference endpoint. Chat history is stored in a MongoDB instance. Users can enable the web search by adding either SERPER_API_KEY or SERPAPI_KEY to their .env.local file. Chat-UI can be customized by updating the MODELS variable in the .env.local file, which can either customize the parameters passed to the model or use a new model. Users can run their own models locally by having a look at the endpoint project, text-generation-inference. Chat-UI can also run models hosted on multiple custom endpoints. To deploy the app, the user needs to install an adapter for their target environment. https://github.com/huggingface/chat-ui\n- The Wizard-Vicuna-13B-Uncensored-HF is a PyTorch based text generation model that has been converted from float32 to float16 for easier storage and use. It was created by Eric Hartford's 'uncensored' training of Wizard-Vicuna 13B. The model comes in 4bit GPTQ models for GPU inference, 4bit, and 5bit GGML models for CPU inference, and float16 HF format model for GPU inference and further conversions. The model has been trained on a subset of the dataset with responses that did not contain alignment/moralizing to enable creation of a WizardLM without built-in alignment. Users should note that this uncensored model has no guardrails, and they are solely responsible for any content generated using the model. There are options for contributions to the model on the Patreon and Ko-Fi platforms, with benefits such as priority support and access to a private Discord room. https://huggingface.co/TheBloke/Wizard-Vicuna-13B-Uncensored-HF\n- ChatHub is a chatbot client that allows users to use multiple chatbots within one app. It currently supports ChatGPT, new Bing Chat, Google Bard, Claude, and 10+ open-source models including Alpaca, Vicuna, and ChatGLM. It allows users to chat with multiple chatbots at the same time, making it easy to compare their answers, and supports ChatGPT API and GPT-4 Browsing. Other features include shortcut to quickly activate the app anywhere in the browser, markdown and code highlight support, prompt library for custom prompts and community prompts, conversation history saved locally, export and import of data, share conversation to markdown, and dark mode. ChatHub can be manually installed by downloading chathub.zip from Releases or built from source by cloning the source code, installing yarn, and loading the dist folder to browser by following steps in manual installation. The latest version (v1.22.0) supports Claude API. https://github.com/chathub-dev/chathub/blob/main/README.md\n- The post on r/StableDiffusion discusses an upcoming AI model capable of generating realistic images from photorealism to anime. The model is fine-tuned on SD 2.1 768X and can create images with resolutions ranging from 1024 to 1080p. The author of the post mentions that the model is meant to serve as a base model for future fine-tuning projects. They also invite others to leave prompts and test the model. The comments section contains discussions on the capabilities of the model and the general use of AI in commercial work. There are also mentions of related topics such as color grading and rendering techniques. Other posts on r/StableDiffusion cover various topics related to using Stable Diffusion, including updates, cheat sheets, and new extensions. https://www.reddit.com/r/StableDiffusion/comments/13j78fo/some_examples_of_the_generalist_model_i_will_be/\n- Cohere, a language model provider, has raised $270m in its latest funding round to scale up its operations in the bring-your-own-language model enterprise niche. The company's offer spans the range of embedded models that can be used for interactive chat features, semantic search, classification, and re-ranking, and generate text or text summaries of products, blog posts, and articles quickly and accurately. Cohere's Command model is one of the highest-performing models for generating text as measured by Stanford University's HELM benchmarks. Cohere is investing in improving model performance for industry-specific use cases, and updates its models every week. Cohere offers secure deployment options, customizable models, and industry-leading support, with live support responding to customers in less than a minute. https://cohere.com/\n- This GitHub repository, called \"privateGPT,\" offers a fully private solution for question answering using local language models and vector embeddings. The code allows individuals to interact privately with their documents, using the power of GPT, without any data leaving their local environment. The solution is not production-ready, but it allows users to ingest and query documents without an internet connection, using LangChain, GPT4All, LlamaCpp, Chroma, and SentenceTransformers. The \"environment setup\" section of the repository's README.md file provides instructions for installing the required dependencies, downloading the LLM model, setting up the environmental variables, and ingesting one's own dataset. Once the data has been ingested, privateGPT.py can be used to ask questions based on the ingested documents. The script requires the user to input a query, after which the LLM model will consume the prompt and prepare an answer, which will be printed along with the four sources used as context from the documents. The repository includes a \"CLI\" section, which describes how users can modify privacy concerns and input parameters to modify the behavior of the script. https://github.com/imartinez/privateGPT\n- Text2NeRF is a novel text-driven 3D scene generation framework that uses Neural Radiance Fields (NeRF) and a pre-trained text-to-image diffusion model to produce various view-consistent outdoor and indoor 3D scenes from natural language descriptions. While existing text-to-3D generation methods are limited to simple geometries and dreamlike styles, Text2NeRF generates a wide range of 3D scenes with complicated geometric structures and high-fidelity textures. The method relies on NeRF as the 3D representation and utilizes a pre-trained text-to-image diffusion model to constrain the 3D reconstruction of the NeRF. The model also employs a monocular depth estimation method to provide a geometric prior that updates the NeRF model. The approach introduces a progressive scene inpainting and updating strategy for novel view synthesis of the scene to guarantee textured and geometric consistency between different views. The method requires only a natural language description of the scene as the input and outperforms existing methods in generating multi-view consistent, diverse, and photo-realistic 3D scenes. The authors have shared their code and model for this research work. https://eckertzhang.github.io/Text2NeRF.github.io\n- This is a post about a hard surface character with a focus on mecha and humanoid characters. The LORA model is available for download and has been tested with rev animated for optimal results. Key trigger words include helmet, machine gun, robot, science fiction, and terminator killers. There are only a few reviews at this time, but the ones available are positive. The post is from Civitai and includes links to their GitHub, Discord, Twitter, Reddit, and API. There is also information about supporting Civitai and joining their team. https://civitai.com/models/73470?modelVersionId=78187\n- PanML is an open-source AI/ML development and analysis library that provides simple-to-use abstractions for facilitating the development of language-based models (LLMs) in Natural Language Processing (NLP) tasks. The library supports open source and commercial LLMs from various vendors and enables users to explore, experiment, and integrate different-sized LLMs. PanML supports inference and analysis of LLM, Prompt chain engineering with LLM, fine tuning of LLM (also with PEFT LoRA), and document question answering using LLM, among other functions. The library is a work in progress and open for collaboration and contribution. Python 3.7+ is required for installation, and the library supports models from HuggingFace Hub and OpenAI. The library is intended for ease of use, fast experimentation, and model development and analysis in both open-source and commercial LLMs. The library is under the MIT open source license, and the documentation and installation guidelines for the library are available on GitHub. https://github.com/Pan-ML/panml\n- Intel and Microsoft are collaborating to bring integrated artificial intelligence (AI) to personal computing (PC). The partnership aims to enable new, AI-powered features for PC users, including multimedia features and machine learning, supported by Intel's upcoming Meteor Lake client PC processors. These processors are the first PC platform from Intel featuring a built-in neural VPU – a dedicated AI engine integrated directly into the system-on-chip (SoC) to efficiently run AI models. Intel claims that Meteor Lake, which utilises a unique disaggregated architecture, will mark a significant milestone not just in personal computing but also in how humans interact with technology. Over the coming years, Intel and its partners in the PC industry aim to provide AI-enabled experiences to millions of people, driving unprecedented change.\n- The post on r/MachineLearning discusses the poor performance of open-source LLMs (language model systems) with less than 13B parameters on zero-shot classification tasks. The models produced non-sensical text and failed to follow instructions, except for OpenAI models that provided consistently good results. The possible reasons for this gap are discussed, including the use of non-instruction tuned models and the lack of proper instructions formatting. The comments suggest tools and resources for better performance, such as using instruction tuned models and configuring tools properly. The post highlights the importance of rigorously measured performance and benchmarking in machine learning and the potential limitations of relying solely on model size as an indicator of quality. https://www.reddit.com/r/MachineLearning/comments/13fiw7r/opensource_llms_cherrypicking_d/\n- The Technology Innovation Institute (TII) has developed Falcon 40B, an open-source large language model (LLM) with 40 billion parameters trained on one trillion tokens. Falcon 40B is a causal decoder-only model trained on a causal language modeling task, with architecture optimized for inference with FlashAttention and multiquery. It has been trained on RefinedWeb enhanced with curated corpora and is available under the Apache 2.0 license. TII is calling for proposals from users worldwide to submit their creative ideas for Falcon 40B’s deployment. Users can use Falcon 40B for research on large language models or as the foundation for specialization and finetuning for specific use cases, such as summarization, text generation, and chatbot. Falcon-40B has been trained mostly on English, German, Spanish, and French with limited capabilities in Italian, Portuguese, Polish, Dutch, Romanian, and Czech. The model carries the biases commonly encountered online and will require finetuning for most use cases. Falcon-40B requires PyTorch 2.0 for use with transformers and needs at least 85-100GB of memory to run inference swiftly. TII recommends users of Falcon-40B to consider finetuning it for tasks of interest and for guardrails and appropriate precautions to be taken for any production use. https://huggingface.co/tiiuae/falcon-40b\n- The post on Hacker News asks for links to research papers in the fields of artificial intelligence, machine learning, and deep learning, which are easy to read and have a \"sneak peek\" section before the introduction. One user recommends the paper on support vector machines by Cortes & Vapnik, describing it as succinctly outlining 60 years of pattern recognition from 1936 to 1992. Another user suggests \"A Mathematical Theory of Communication\" by Claude Shannon, which discusses compression and reliable communication, but may still be relevant to those interested in AI and ML. Other recommended papers include \"Attention is all you need\" by Vaswani et al., \"Deep Unsupervised Learning using Nonequilibrium Thermodynamics\" by Sohl-Dickstein et al. on diffusion models, and \"NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis\" by Mildenhall et al. https://news.ycombinator.com/item?id=36092156\n- Apple has blocked internal use of OpenAI’s language model, ChatGPT and other language models due to concerns that the AI could spill sensitive internal information shared with it. Apple has reportedly also blocked GitHub’s automated coding tool, Copilot. The issue with these language models is that data fed into them is typically used to train them, which can lead to business information being exposed or the possible exposure by bot providers themselves that review the feeds. Many companies have followed suit with this block. https://www.linkedin.com/posts/melchiors_ai-software-microsoft-activity-7069901328981848064-1-Oq?utm_source=share&utm_medium=member_android\n- <https://www.linkedin.com/posts/melchiors_ai-software-microsoft-activity-7069901328981848064-1-Oq?utm_source=share&amp;utm_medium=member_android>\n- The article discusses the challenges with making large language models (LLMs) more predictable and controllable within business applications, and explores the concept of \"prompt engineering\" as a solution. Prompt engineering involves designing prompts beforehand and using them to steer and control the LLM response. The article includes a code walkthrough in Python using OpenAI's GPT3.5 and an open-source Python library called PanML, demonstrating how to modify prompts for output filtering, LLM-assisted output filtering, and creating customized prompt sequences. The article concludes by introducing PanML as a useful tool to help data scientists and machine learning engineers experiment with LLMs in their local environment. https://medium.com/@williamzheng_63722/steering-llms-with-prompt-engineering-dbaf77b4c7a1\n- The article presents information on how to use HuggingFaceH4's StarChat Beta GPTQ, which is a language model designed to aid in coding tasks. The article provides instructions for downloading and using the model through the text-generation-webui or from Python code. The model is fine-tuned on a diverse range of dialogues in over 35 languages, including English and over 80 programming languages. The article also highlights some potential biases, risks, and limitations of the model, such as the tendency to produce false URLs or code snippets that are syntactically valid but semantically incorrect. Finally, the article provides information on how to contribute to the development and expansion of the model. https://huggingface.co/TheBloke/starchat-beta-GPTQ\n- The post shared by Francesco Saverio Zuppichini discusses the resources he recommended to a friend who wanted to quickly learn about LLMs. Resources listed include papers, blogs, videos, and different language models such as ChatGPT, LLama, Vicuna, and WizardLM. The post also includes YouTube channels recommended by Zuppichini, such as AI Explained, Yannic Kilcher, and Sam Witteveen. Other users in the comments section share their own resources, such as the Stanford CS25 course and Cohere's NLP uni. https://www.linkedin.com/posts/francesco-saverio-zuppichini-94659a150_ai-ml-ds-activity-7072868294000566272-kV83?utm_source=share&utm_medium=member_android\n- <https://www.linkedin.com/posts/francesco-saverio-zuppichini-94659a150_ai-ml-ds-activity-7072868294000566272-kV83?utm_source=share&amp;utm_medium=member_android>\n\t- NVIDIA Research has developed a system for real-time rendering of complex appearance in games and live previews with a combination of algorithmic and system level innovations. The appearance model utilizes learned hierarchical textures that are interpreted using neural decoders, which produce reflectance values and importance-sampled directions. The decoders are equipped with two graphics priors, the first of which facilitates accurate reconstruction of mesoscale effects, while the second microfacet sampling distribution allows the neural decoder to perform importance sampling efficiently. The resulting appearance model supports anisotropic sampling and level-of-detail rendering and allows baking deeply layered material graphs into a compact unified neural representation. The system opens up the potential for using film-quality visuals in real-time applications such as games and live previews. https://research.nvidia.com/labs/rtr/neural_appearance_models/\n- This text is a mixture of a cookie notice from Reddit, and a collection of recent posts on the subreddit r/StableDiffusion. The cookie notice explains that Reddit uses cookies and similar technologies to provide a better user experience, and gives users the option to accept or reject cookies. The collection of posts on r/StableDiffusion showcase various AI-generated images and animations using different models and software tools. The posts include scannable Cat QR Art with AI, synthesized 360 views of Stable Diffusion generated photos with PanoHead, an animated dance AI animation, and more. Some of the posts are marked as NSFW. https://www.reddit.com/r/StableDiffusion/comments/145d6by/scannable_cat_qr_art_with_ai_my_recent_attempt/\n- Google Cloud has unveiled its latest platform capabilities for building and powering custom generative AI applications, with the latest update to Vertex AI. Generative AI support on this platform will now give customers access to text models powered by PaLM 2, as well as Embeddings API for text. Other foundation models in the model garden will also be available, allowing developers to customize these models with their own data and quickly build generative AI applications. With generative AI studio generally available, customers can leverage an even wider range of tools to accelerate the development of custom generative AI applications. This latest update reflects Google Cloud's commitment to making generative AI useful to everyone, backed by enterprise-grade data governance, security and safety features. https://cloud.google.com/blog/products/ai-machine-learning/generative-ai-support-on-vertexai\n- The paper introduces a new compressed format and quantization technique called Sparse-Quantized Representation (SpQR), which enables near-lossless compression of large language models (LLMs) with minimal accuracy loss. SpQR works by identifying and isolating outlier weights, which cause particularly-large quantization errors, and storing them in higher precision while compressing all other weights to 3-4 bits. The technique achieves relative accuracy losses of less than 1% in perplexity for highly-accurate LLMs, making it possible to run 33B parameter LLM on a single 24 GB consumer GPU without any performance degradation at 15% speedup. SpQR comes with efficient algorithms for both encoding weights into its format as well as decoding them efficiently at runtime, and yields faster inference than 16-bit baselines at similar accuracy, while enabling memory compression gains of more than 4x. https://arxiv.org/abs/2306.03078\n- Glaze is an academic research project by the University of Chicago, aiming to protect artists from the invasive uses of machine learning through ethical security techniques. The tool generates a cloaked version for each piece of artwork an artist creates, creating almost invisible changes. This helps prevent AI models from copying the artist's unique style and mimicking it for their purposes. Glaze has been evaluated through a user study involving more than 1,100 professional artists. Although Glaze is not a permanent solution against AI mimicry as AI evolves quickly, it is hoped that Glaze and follow-up projects will provide some protection to artists against AI mimicry. Since its initial release, Glaze has hit 721,000 downloads, and an updated GPU version for Windows is available for free. https://glaze.cs.uchicago.edu/\n- The text contains updates and discussions on AI language models and related topics. It also includes a notice about the use of cookies on Reddit and its partners' websites. One user shared progress made in getting Landmark attention working within Oobabooga and the quantization of models. Other users provided feedback and shared insights on related technical topics, such as context size, inference performance, and trust in remote code execution. The text also includes links to open-source models and tools, discussions on new quantization methods, and updates on various AI language models' development and performance. https://www.reddit.com/r/LocalLLaMA/comments/148prx3/landmark_attention_oobabooga_support_gptq/\n- The text describes a model called \"30B-Lazarus-gptq-4b* available on the Hugging Face platform for natural language processing. The model was created using PyTorch and Transformers frameworks and has an Apache-2.0 license. The files associated with the model include a config file, generation config file, special tokens map, tokenizer model, and tokenizer config file. The model is available for training, deployment, and use in Transformers. https://huggingface.co/Yhyu13/30B-Lazarus-gptq-4bit/tree/main\n- A new report from the Stanford Center for Research on Foundation Models has found that major foundation model providers, including OpenAI and Google, largely do not comply with the draft requirements of the EU's AI Act, the world's first comprehensive regulation of AI, particularly in regards to their compliance with requirements to provide information on training data, hardware use, and how they evaluate and test models. The report found significant discrepancies in compliance across model providers, with some scoring less than 25% and only one scoring at least 75%. The report recommended that policymakers prioritize transparency in the AI ecosystem and that foundation model providers work towards industry standards with the input of stakeholders beyond the companies themselves. https://crfm.stanford.edu/2023/06/15/eu-ai-act.html\n- The repository is for LLaMA-Adapter, an efficient, lightweight adaption method for fine-tuning Instruction-following and Multi-modal LLaMA models that allow them to make high-quality instruction-following sentences. It includes code for the implementation of LLaMA-Adapter, as well as demos and training modules. The repository provides a comparison between LLaMA-Adapter's Model Parameters, Storage Space, and Training Time with other methods. The repository has multiple contributors, and interested candidates can apply for internships, postdocs, and full-time researcher positions. It is licensed under the GPL-3.0 license. The readme file also includes news, acknowledgments, citation, and hiring announcements. https://github.com/ml-lab/LLaMA-Adapter-2\n- The Generative AI learning path offered by Google Cloud Skills Boost is a collection of courses that guide students through generative AI products and technologies, from understanding Large Language Models (LLM) to designing and deploying generative AI solutions on Google Cloud. The introductory-level courses include an explanation of GAI, LLM, and responsible AI, and they introduce Google's seven AI principles. Students can earn a skill badge by completing the Introduction to Generative AI, Introduction to Large Language Models, and Introduction to Responsible AI courses. Intermediate courses cover topics such as the Encoder-Decoder Architecture, Attention Mechanism, Transformer Models, and BERT Models. Other courses teach students how to create image captioning models and use the Generative AI Studio product on Vertex AI. Overall, the Generative AI learning path aims to provide a comprehensive understanding of the fundamentals of generative AI and its applications, preparing students for a career in AI development. https://www.cloudskillsboost.google/journeys/118\n- The Reddit user, edinburgh1975, posted on r/LocalLLaMA seeking advice on the best LLM for legal analysis. They are working on a project to make the law more accessible to the public with a small budget and a team with varying tech skills. Other Reddit users provided suggestions, including using GPT-3.5 for generating free advice while charging for the use of GPT-4 32k, fine-tuning GPT-4 to generate training data for their local LLM, and utilizing Wiki resources for all things related to Local LLM. Some users also discussed the risks of confabulation when using AI models for legal research. https://www.reddit.com/r/LocalLLaMA/comments/14drnvd/best_llm_for_legal_analysis/\n- This text provides information about the Vid2Avatar project which aims to reconstruct 3D avatars from videos in various settings using self-supervised scene decomposition. The project uses a python virtual environment and requires the installation of certain dependencies and Kaolin 0.10.0. Additionally, the SMPL model needs to be downloaded and preprocessed demo data can be downloaded from Google Drive. The project includes training which usually takes 24-48 hours and validation is saved in the outputs folder. The project also includes a test phase and allows for 3D visualization using AITViewer. The project also includes instructions on how to play on a custom video with modifications to the preprocessing script and metainfo changes. The project acknowledges other research work and includes a list of related human body reconstruction projects from the team. Lastly, a citation in the desired format for the Vid2Avatar project is included. https://github.com/MoyGcc/vid2avatar\n- The CEO of ZenGo, Ouriel Ohayon, has accused AI language model ChatGPT of breaching privacy, stating that the program may have accessed and read some of their internal emails to provide information about their business model. Ohayon requested information about ZenGo that was not public yet and ChatGPT provided the information accurately, leading to his concerns. However, some users questioned the context of the prompt and suggested that the information could have been guessed, sourced from a competitor's website or a prompt from an employee. https://twitter.com/OurielOhayon/status/1650369984080629760\n  --   HuggingChat, an open-source chatbot developed by AI startup Hugging Face is set to challenge the status quo of AI chatbot technology. HuggingChat is built on the modified LLaMa 30B SFT 6 model and can generate text in natural language or in a specific format and also generate code in multiple programming languages. Huggingchat can be found at hf.co/chat and is free to use. The AI company is championing open-source AI through offering free technology, which is transparent, accountable and aims to promote inclusivity, disseminate power and democratize AI. Hugging Face looks to make all high-quality chat models available through a single hub in the future. Despite HuggingChat being characterized by similar limitations as other text-generating models, Hugging Face is working on refining the model. The AI company is poised to change the way we interact and develop AI chatbots, challenging the status quo, and promoting transparency and accountability. https://medium.com/codingthesmartway-com-blog/my-take-on-huggingchat-the-open-source-chatbot-alternative-to-chatgpt-thats-shaking-things-up-589a101bccde\n- The text includes two different topics. The first is about Reddit's use of cookies and similar technologies to provide users with a better experience, personalize content and advertising, and measure advertising effectiveness. Users can choose to accept all cookies or reject non-essential ones. The second topic is a discussion thread on the StableDiffusion subreddit about generating color maps for 3D models using AI technology. The thread includes technical details on the process and some questions and comments from other users. The StableDiffusion subreddit focuses on the use of AI and computer vision technologies for creative projects. https://www.reddit.com/r/StableDiffusion/comments/11ol47u/3d_model_face_color_map_generation_test3/\n- The post discusses advanced advice for model training and captioning. The author gives specific pointers for training a checkpoint model, such as maximizing visual diversity, minimizing visual repetition, and denoising original images. They also recommend ordering captions from most to least prominent concept and experimenting with conditional dropout to force a style into the model. In addition, the author suggests using chaining to tweak settings and allowing the model to change settings as it goes. Other topics discussed in the comments section include the best software for denoising images, improving finetuning of bright and dark images, and creating new unique and consistent characters with Loras. https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and/\n- The post on Reddit's r/StableDiffusion is a guide for advanced advice on model training and captioning, specifically for those who already have a basic understanding of training a checkpoint model and want to improve. The post includes tips on training images such as denoising and maximizing visual diversity, and ordering captions from most to least prominent concepts. The post also includes recommendations for software and tools to improve training, such as Affinity Photo and Conditional Dropout. The comments section includes further discussion and feedback from other users on the topic. https://www.reddit.com/r/StableDiffusion/comments/114dxgl/advanced_advice_for_model_training_finetuning_and/\n- --   The Awesome-GPT4-with-Applications is a collection of resources on GPT-4, which includes news articles, official documents, demos, tutorials, and applications. OpenAI recently released GPT-4, a large multimodal model with their best-ever results on capabilities and alignment. The collection includes official documentation such as the technical report, system card, and API waitlist, as well as early versions of GPT such as GPT, GPT-2, and GPT-3. There are also tutorials, examples, and live streams available for developers interested in working with GPT-4. The resource list includes a range of applications from chatbots to research assistants, visual accessibility, language learning, and knowledge management. Additionally, the collection provides information on frameworks and libraries for developers interested in building on top of GPT-4. Finally, contributions to the collection are welcome, and users are encouraged to submit new resources or suggest improvements through pull requests or issues. https://github.com/dk-liang/Awesome-GPT-4-with-Applications\n- The recently proposed StyleGAN model has shown impressive results in face manipulation but is limited to cropped aligned faces at a fixed image resolution it is pre-trained on. To overcome this limitation, a new model called StyleGANEX is proposed in which the shallow layers of StyleGAN are refactored using dilated convolutions to rescale the receptive fields, enabling fixed-size small features to be extended into larger ones that can accommodate variable resolutions. A corresponding encoder is also introduced to enable real face inversion and manipulation. The effectiveness of this approach is validated using unaligned face inputs of various resolutions in a diverse set of face manipulation tasks, including facial attribute editing, super-resolution, sketch/mask-to-face translation, and face toonification. The paper presents experimental results and comparisons with other state-of-the-art face manipulation methods, showing that StyleGANEX produces more coherent results with fewer discontinuities near the seams. The approach retains the style representation and editing ability of StyleGAN while significantly extending its generative space beyond cropped aligned faces. The StyleGANEX model is compatible with pre-trained StyleGAN parameters without retraining and provides a flexible and powerful solution for face manipulation beyond cropped aligned faces. https://buff.ly/3laNpgY\n- Simple LLM Finetuner is an intuitive user interface designed to facilitate fine-tuning various language models using the LoRA method via the PEFT library on commodity NVIDIA GPUs. It allows users to manage datasets, customize parameters, train, and evaluate the model's inference capabilities. The beginner-friendly interface features explanations for each parameter and allows users to simply paste datasets into the UI separated by double blank lines. The necessary prerequisites to use the finetuner are a Linux or WSL OS and a modern NVIDIA GPU with >= 16 GB VRAM. Before launching, users must clone the repository and install the required packages. The finetuner supports running on a regular Colab Tesla T4 instance with small datasets and sample lengths of 256. Conda is preferred for a virtual environment to install the required packages. After preparing a training dataset, users can specify the new LoRA adapter name and click train, adjusting the max sequence length and batch size to fit GPU memory. The model will be saved in the lora/ directory, and after training, users can navigate to the *Inference\" tab, select their LoRA, and play with it. The code is released under the MIT License and has already received high traffic on Github. https://github.com/lxe/simple-llama-finetuner\n- The research paper presents a diffusion model called 3DiM for 3D novel view synthesis. The model uses a pose-conditional image-to-image diffusion model, trained to take a source view and its pose as inputs and generate a novel view for a target pose as output. The model can generate multiple views that are approximately 3D consistent using a sampling technique called stochastic conditioning. The paper also introduces a new evaluation methodology, 3D consistency scoring, to quantify the 3D consistency of a generated object. Additionally, the paper compares 3DiM to prior work on the SRN ShapeNet dataset, demonstrating that 3DiM's generated completions from a single view achieve much higher fidelity, while being approximately 3D consistent. The results of the research highlight the effectiveness of diffusion models for novel view synthesis and the critical importance of modifications to the image-to-image UNet to achieve high-quality results. https://3d-diffusion.github.io/\n  --   Researchers from OpenAI have introduced “consistency models” as a family of generative models for realistic sample generation with just a single forward pass, without relying on adversarial approaches and other models such as normalizing flows. The authors propose to learn a neural network F(x,t) that \"is invertible and for any trajectory x(t), F allows for a return to the initial condition.\" The training procedures are by distillation and by isolation, with the authors estimating the score function via a Monte Carlo method. The proposed approach is shown to generate realistic samples in one forward pass, using different experiments such as image generation, super-resolution, and inpainting. The approach can offer advantages in terms of required computing resources and open the way to new applications inaccessible to diffusion models. https://www.marktechpost.com/2023/03/10/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training/\n- In a recent paper, researchers from OpenAI introduce \"consistency models,\" which enable the generation of realistic samples in a single forward pass. The proposed models are a new family of generative models that achieve high sample quality without adversarial training. The authors propose to learn a neural network that satisfies certain properties and allows for realistic sample generation in a single forward pass. Two training configurations are proposed to achieve this, with the authors experimenting with image generation, inpainting, and super-resolution. The proposed models offer several advantages over previous techniques, such as requiring fewer computing resources, and could lead to new applications. https://www.marktechpost.com/2023/03/10/open-ai-proposes-consistency-models-a-new-family-of-generative-models-that-achieve-high-sample-quality-without-adversarial-training/\n- The paper proposes a new method for estimating depth from a single RGB image using diffusion-based denoising models. The method involves infilling missing depth using nearest neighbor interpolation, adding noise to the depth map, and training a neural network to predict the noise given the RGB image and noisy depth map. The proposed DepthGen model achieves state-of-the-art performance on indoor NYU depth v2 dataset and competitive results on outdoor KITTI dataset. Additionally, the paper outlines a simple text-to-3D pipeline using DepthGen and off-the-shelf text-to-image models. The proposed approach provides robust zero-shot performance and represents depth ambiguity naturally. https://depth-gen.github.io/\n- Explainpaper is a free online tool that makes research papers easier to read by using an AI model to explain dense sections. Researchers can upload a paper, highlight confusing text, and get an explanation. In the background, an LLM simplifies and explains complex concepts. The tool has been used by Bindu Reddy, an AI and ML researcher, who reported her research paper review time has gone down significantly. Other researchers, such as Amy Cun and Kenneth Cassel, have also praised the tool for its ability to help them understand complex concepts in research papers. The tool has been described as a \"killer product\" by some and is recommended for anyone looking to become an expert in any field. http://explainpaper.com\n- D-ID, a technology company specializing in facial recognition and animation, has launched its AI Presenters on Canva, which enable users to hold a face-to-face conversation with a digital human on a free web app called chat.D-ID. The software powering chat.D-ID has practical applications across various sectors, such as sales and marketing, learning and development, customer experience, and personal health and wellness. The company will also offer the streaming animation technology behind chat.D-ID to businesses and developers via its generative AI API. The real-time capabilities of the technology can be integrated with both open and closed-domain AI models, allowing businesses of all sizes to create a more personal connection with customers, employees, and communities. Customers who want to create a digital person to converse about their business or organization can book a call with D-ID to learn more. https://www.d-id.com/chat/\n- The Whisper-UI is a user interface built on top of OpenAI's Whisper speech-to-text model that features media downloading and transcription from YouTube videos, playlists, or local files. The app allows users the ability to browse, filter, and search saved audio files. The app dependencies include Python 3.11, ffmpeg, and the requirements in the requirements.txt file. The app can be run with the command \"streamlit run app/01_🏠_Home.py.\" Alternatively, the app can be run via Docker through the included docker-compose.yml with the command \"docker compose up.\" The app is licensed under MIT. https://github.com/hayabhay/whisper-ui\n- CLIP-Actor is a pytorch implementation for the ECCV 2022 paper that contains a novel text-driven motion recommendation and neural mesh stylization system for human mesh animation. The code was developed on Ubuntu 18.04 with Python 3.7, CUDA 10.2 and PyTorch 1.9.0. You need to download relevant body models and datasets for running CLIP-Actor, and it requires a single GPU with a minimum of 24 GB of RAM. The implementation of CLIP-Actor is largely inspired by and fine-tuned from the seminal prior work, Text2Mesh. The authors of CLIP-Actor and Text2Mesh appreciate the support and contribution from the Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT). The code is available on GitHub, and the authors invite researchers and academics to consider citing their paper and code for any work they found helpful. https://github.com/youwang-kim/clip-actor\n- Cross-Origin Resource Sharing (CORS) is a security mechanism that enables restricted resources on a web page to be accessed from another domain outside the domain from which the first resource was served. CORS allows for more freedom and functionality than purely same-origin requests, but is more secure than simply allowing all cross-origin requests. It defines a way in which a browser and server can interact to determine whether it is safe to allow the cross-origin request. The specification for CORS is included as part of the WHATWG's Fetch Living Standard. CORS is supported by all modern browsers and can be used as an alternative to the JSONP pattern. The HTTP headers that relate to CORS are Origin, Access-Control-Request-Method, Access-Control-Request-Headers, Access-Control-Allow-Origin, Access-Control-Allow-Credentials, Access-Control-Expose-Headers, Access-Control-Max-Age, Access-Control-Allow-Methods, and Access-Control-Allow-Headers. CORS is widely used in the object-capability model and any website can manually parse responses for increased security. https://en.m.wikipedia.org/wiki/Cross-origin_resource_sharing\n- The tweet thread is advertising the ChatGPT language model's ability to generate unlimited prompts quickly and efficiently. The user suggests using GPT-4 to generate the best prompts on any topic. Additionally, the user mentions that GPT-4 can also be used to talk to any book and ask any question. The language model's capabilities make it an efficient tool for generating ideas and gaining information. https://mobile.twitter.com/heyBarsee/status/1640368028884914178\n- The Twitter conversation started with a tweet from TomLikesRobots, featuring a keyframe generated with ControlNet's img2img and animated with Ebsynth, captioned with a quote from Lord of the Rings. Another user, rainisto, complimented the video's quality, which TomLikesRobots said was attributed to having enough time to practice with his new tools over the weekend. The conversation continued with users discussing whether they could run the AI models on Colab and its possible applications in anime remakes. Some concluded that Ebsynth was the way to go for creating convincing videos using animation as the source, while others suggested more advanced tools. https://twitter.com/TomLikesRobots/status/1627073211656732676\n- Clarkesworld Magazine, a renowned sci-fi publication, has announced that it has temporarily closed its submissions due to a massive increase in machine-generated stories sent to the publication. The numbers tallied up to 500 in February alone, up from just over 100 in January and a low baseline of around 25 in October 2022. AI models, such as ChatGPT, can author original stories quickly by being trained on millions of books and websites. However, the stories are not created autonomously, and a human must guide their output with a prompt that the AI model then attempts to automatically complete. According to Clarkesworld Magazine, the number of submissions continues to rise because of get-rich-quick schemes. The problem of AI-authored content is also not unique to Clarkesworld, as Reuters reported over 200 e-books on the Amazon Kindle store that list ChatGPT as the author or co-author. The use of bots has created an awkward position for Clarkesworld, as it aims to filter out the spammers while still encouraging undiscovered writers or writers from certain regions of the world who might be unfairly targeted by geographical-based bans. Detecting text written by language models has low accuracy rates, and the magazine doesn't have a solution to the problem yet. The editor of Clarkesworld encouraged those who want to support the magazine to subscribe. https://arstechnica.com/information-technology/2023/02/sci-fi-becomes-real-as-renowned-magazine-closes-submissions-due-to-ai-writers\n- Hugging Face is a technology company that creates machine learning natural language processing (NLP) models and develops applications to make these models more accessible. One of their newest applications is called UnCLIP Image Interpolation, which utilizes AI to enhance and extrapolate images to higher resolutions. Users can upload images to the platform and adjust settings such as the number of steps, seed, and interpolation factor to customize the output. The tool can also be used via API and was built with Gradio. https://huggingface.co/spaces/nagasaiabhinay/unclip_image_interpolation_demo\n- \"Understanding Deep Learning\" is a comprehensive book by Simon J.D. Prince, to be published by MIT Press in 2023, covering topics from supervised and unsupervised learning to deep reinforcement learning, as well as explaining why deep learning works and its ethical implications. The book is accompanied by resources for instructors, including slides, notebooks, and PDF figures for each chapter. The book aims to provide a clear understanding of the underlying principles of deep learning, including neural network architecture, loss functions, training models, regularization, and performance measurement, as well as exploring more advanced topics such as convolutional networks, residual networks, transformers, graph neural networks, and generative adversarial networks. It also covers emerging areas of research, such as normalizing flows, variational autoencoders, diffusion models, and deep reinforcement learning. Additionally, the book explores the ethical implications of deep learning, encouraging readers to consider the impact of their work on the wider society and to think critically about potential biases and unintended consequences. Overall, the book is a valuable resource for anyone looking to dive deeper into the world of deep learning, whether for academic or practical purposes. https://udlbook.github.io/udlbook/\n- NUWA is a platform that specializes in generative models capable of producing multimedia content such as images and videos. The platform offers several products, including NUWA XL and NUWA Infinity, both of which utilize cutting-edge technology to produce long videos based on provided scripts. NUWA also offers a Gallery feature that allows users to browse and view content created using the platform. Their NUWA XL product utilizes a \"coarse-to-fine\" process to generate video content efficiently. The platform has released a research paper on their innovative generative models. For any inquiries, users can contact NUWA through their website, and the platform operates under Microsoft. https://msra-nuwa.azurewebsites.net/#\n- NUWA-Infinity is a multimodal generative model that generates high-quality images and videos from given text, image, or video input. This AI technology is designed to create realistic and visually appealing content that can be used for a variety of applications. Its features include loading images and videos with 100% accuracy, a gallery of generated content, and a research paper on the technology. Additionally, NUWA XL is another model that can generate larger images, while NUWA Infinity is designed for infinite content generation. Overall, NUWA-Infinity is a promising technology that can revolutionize the creation of images and videos. https://msra-nuwa.azurewebsites.net/#/NUWAInfinity\n- Meta AI has developed a new AI model called ImageBind that can bind data from six different modalities, including images and video, audio, text, depth, thermal, and inertial measurement units (IMUs), without explicit supervision. The model recognizes the relationships between these modalities and creates a single embedding space to bind them together, enabling machines to analyze different forms of information together. ImageBind can even upgrade existing AI models to support input from any of the six modalities, enabling audio-based search, cross-modal search, multimodal arithmetic, and cross-modal generation. The open source ImageBind model achieves a new state-of-the-art performance on emergent zero-shot recognition tasks across modalities. https://imagebind.metademolab.com/\n- Cohere, a start-up specializing in developing natural-language processing (NLP) technology, has raised $270m in a funding round to bring generative AI to enterprises. The firm's models, powered by embeddings, enable interactive chat features, generate text for product descriptions, and capture the meaning of text for search, content moderation, and intent recognition. Organizations can also use Cohere's technology to customize models for specific use cases, domains, or industries. The company's Command model is among the highest performing models as measured by Stanford University's HELM benchmarks, with a mean win rate of 93%. https://cohere.com/\n- The text is a collection of videos related to transformers, GPT (Generative Pre-trained Transformer), and language modeling available on YouTube. The videos feature lectures, presentations, and discussions by researchers and experts in the field, including Andrej Karpathy, Ilya Sutskever, and Harry Surden. They cover various topics related to transformer networks, attention and self-attention mechanisms, GPT models, their workings, emergent abilities, biomedical applications, scaling for LLMs, among others. The texts are available on YouTube and are a useful resource for anyone interested in learning more about transformers and GPT models. https://youtu.be/XfpMkf4rD6E\n- PrivateGPT is a test project that enables users to interact privately with their documents using the power of GPT without any data leaving the environment. The tool is built using LangChain, GPT4All, LlamaCpp, Chroma, and SentenceTransformers. Users can ingest documents and ask questions without an internet connection and set up their environment by installing all requirements and downloading the LLM model. Users can use the CLI to ask a question or use optional command-line arguments to modify its behavior. The ingest.py script uses LangChain tools to parse the document and create embeddings locally, while the privateGPT.py script uses a local LLM based on GPT4All-J or LlamaCpp to understand questions and create answers. The context for the answers is extracted from the local vector store using a similarity search to locate the right piece of context from the docs. The software requires Python 3.10 or later and a C++ compiler may be needed on some systems. The tool is not meant for production and the models selection is not optimized for performance, but for privacy. https://github.com/imartinez/privateGPT\n- The article provides an introduction to word and sentence embeddings, which are used in language models to translate human language into computer language using numbers that capture properties and features of words and sentences. Word embeddings assign scores to each word and much like assigning coordinates to points on a plane, they are assigned numbers that capture similarities and differences between words while also capturing additional properties such as age and size. Sentence embeddings are like word embeddings, except they associate sentences with a vector full of numbers that capture similar properties as word embeddings, but with the added complexity of taking into account the order of words, the semantics of the language, and the actual meaning of the sentence. Multilingual embeddings unify many languages into one and Cohere offers a large multilingual model that has shown wonderful results with more than 100 languages. The multilingual embeddings can be extended to language embeddings which are useful for translation and for searching and understanding text in different languages. The article concludes that word and sentence embeddings are the primary building blocks of most language models and they capture many relations between words, semantics, and nuances of the language into equations regarding the corresponding numbers. https://txt.cohere.ai/sentence-word-embeddings/\n- A new CLIP model, ViT-G/14, has been trained with OpenCLIP, achieving 80.1% zero-shot accuracy on ImageNet and 74.9% zero-shot image retrieval (Recall@5) on MS COCO. This is the best open-source CLIP model as of January 2023. The approach underlying CLIP\n\t - self-supervised learning on a large, varied dataset, produces more robust and fair models, and can be used for zero-shot classification, retrieval, and guidance/conditioning in generative models. The new ViT-G model achieves the highest zero-shot ImageNet accuracy among models that use only naturally occurring image-text pairs as training data, without explicit labels, pseudo-labels, or any pretrained image or text encoders. The training run utilized several new techniques, including FLIP to accelerate training and model soups to surpass 80% accuracy. The released checkpoint is available through OpenCLIP and in the HuggingFace hub. In the future, the model may be fine-tuned for multilingual capabilities or higher resolution. Contributions to OpenCLIP are welcomed. https://laion.ai/blog/giant-openclip/\n- The rise of Generative AI, where machines are able to create new content rather than just analyze existing data, has the potential to revolutionize industries that rely on human creativity, such as social media, coding, advertising, and design. While machines are beginning to create credible and sometimes even superhuman results, the technology is still in its early stages, with models becoming cheaper, faster, and more accessible as the industry evolves. Developers and founders have the opportunity to build novel applications harnessing the power of Generative AI, from copywriting and code generation to gaming and design. However, there are concerns around business models and technology, such as issues around copyright and costs, that must be resolved. Nonetheless, the nascent field of Generative AI is generating excitement and optimism about the possibilities for human-machine co-creation. https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/\n- The article explores ways to make Large Language Models (LLMs) more predictable and controllable through prompt engineering. Prompt engineering basically uses the appropriate prompts to produce the desired response back from the LLM. The article provides a code walkthrough using OpenAI’s GPT3.5 as the main LLM and an open-source Python library called PanML. The article covers various use cases such as modifying the prompt, output filtering, LLM-assisted output filtering, and provides a beginner’s guide to building LLM-powered applications. The article also introduces PanML, an open-source high-level Python library designed to help data scientists and machine learning engineers experiment and run LLMs in their local environment with ease. https://medium.com/@williamzheng_63722/steering-llms-with-prompt-engineering-dbaf77b4c7a1\n- NVIDIA Research has introduced a complete system for real-time rendering of scenes that exhibit complex appearance, which was previously reserved for offline use. The system integrates learned hierarchical textures interpreted using neural decoders, which generate reflectance values and importance-sampled directions. Two graphics priors are equipped to fully use the modeling capacity of the decoders. The first prior facilitates precise reconstruction of mesoscale effects by transforming directions into learned shading frames, while the second prior allows the neural decoder to conduct efficient microfacet sampling distribution. The resulting appearance model underpins anisotropic sampling and level-of-detail rendering, allowing deeply layered material graphs to be baked into a concise unified neural representation. The neural material shaders applied in the system can execute neural decoders efficiently inside a real-time path tracer. The research team analyzed its scalability with an increasing number of neural materials and put forward the idea of improving performance using optimized code for coherent and divergent execution. Neural material shaders turn out to be over 10 times faster than conventional non-neural layered materials, enabling real-time applications such as games and live previews to use film-quality visuals. https://research.nvidia.com/labs/rtr/neural_appearance_models/\n- Orca is a new language model developed by Microsoft that has just been released for open source use. This model, which is just 13B, is the closest model to ChatGPT, according to the video explaining it. Orca was created by imitating the logic and explanations of GPT 4 and using GPT 3.5 as an assistant, and it was trained in diverse tasks to make it efficient for use in real-world applications. The video provides insights from five other papers and showcases Orca on a dozen benchmarks. It shares details on how it works and why it was created. The video also goes into comments from Sam Altman and Ilya Sutskever on whether or not open source will catch up. https://www.youtube.com/watch?v=Dt_UNg7Mchg",
        "link_types": [],
        "file_size": 84942
    },
    {
        "id": "Sam Hammond.md",
        "name": "Sam Hammond",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- [Samuel Hammond\n\t - Second Best](https://www.secondbest.ca/)\n- ## AI and Techno-Feudalism Overview\n  id:: 65929cb3-b201-48f1-b807-d616d7f92687\n\t- ### Author Background: Sam Hammond\n\t\t- **Background:** Senior economist at the Foundation for American Innovation with previous tenures at the Niskanen Institute and Mercatus Center. His expertise is in the intersection of policy and transformative technologies, particularly AI, and how they shape economic and societal structures. Be warned he has strong libertarian leanings and this does colour his thinking.\n\t\t- **Contributions:** Hammond's work involves deep dives into how evolving technologies necessitate changes in government and societal frameworks, looking beyond immediate implications to long-term structural shifts. I am fascinated by this so I have added his work into my knowledge graph here.\n\t\t- **Future Predictions:** Discusses the looming possibility of AI systems emulating complex human tasks, leading to potential societal and economic upheavals as they integrate deeper into various sectors. This is the concept of the \"drop in replacement\" for humans in the loop.\n\t- ## AI Safety and Concerns\n\t\t- ### Ethical Considerations\n\t - **Bias and Discrimination:** Discusses how AI can inherit and amplify human biases, leading to discriminatory outcomes in areas like hiring, law enforcement, and lending. Explores the ethical implications and the need for fair and transparent algorithms. He's more cautious about opensource AI than I am.\n\t - **First-Order Effects:** Details the direct impacts of AI, such as job displacement and privacy concerns, emphasizing the immediate ethical and societal challenges they present.\n\t - **Second-Order Effects:** Societal and institutional changes. Explores how AI's integration into every facet of life might alter human relationships, governance, and cultural values. Discusses the potential for AI to reshape societal hierarchies, influence global power dynamics, and challenge our notions of autonomy and agency.\n\t\t- ### Mastering AI for Safety\n\t - **Accelerating Defensive AI:** Discusses the need to develop defensive AI modalities to counteract malicious use and unintended consequences. Explores strategies for safe AI deployment and the importance of international collaboration on AI safety standards.\n\t - **Ethical Frameworks:** Emphasizes the importance of establishing robust ethical frameworks and guidelines for AI development and use, considering diverse perspectives and the need for adaptability as AI technologies evolve.\n\t - **Government Involvement:** This may be the best path forward. Once companies like OpenAI or Anthropic reach the tipping point of superintelligence it makes sense to work closely with national governments. This is already happening in Gulf States with projects like Falcon. This is the \"gain of function\" moment for AI where the dangers become acute enough to compartmentalise.\n\t- ## Three Possible Futures id:: 65929cb3-95b4-454b-8c9e-7ae231aec377\n\t\t- ### AI Leviathan\n\t - **State Surveillance and Control:** Explores the potential for states to extend their surveillance capabilities and tighten control over citizens using advanced AI, leading to an Orwellian future where privacy is virtually nonexistent.\n\t - **Implications for Democracy:** Discusses the challenges this scenario poses to democratic norms and individual freedoms, with a focus on the trade-offs between security and liberty.\n\t\t- ### Techno-Feudalism\n\t - **Fragmented Society:** Describes a future where societal fragmentation occurs due to the rise of powerful AI platforms that take over traditional state roles. Envisions a world where loyalty shifts from states to platform-centric communities.\n\t - **Private Governance:** Explores the potential trajectory of AI leading to a future where traditional state functions are increasingly replaced or supplemented by private, AI-driven platforms. This rise of corporate entities or conglomerates that provide governance, security, and social services, side-lining traditional state functions and leading to a complex web of interdependencies and power dynamics. This shift in societal organisation resembles medieval structures, and he terms it 'techno-feudalism'. I had been calling this the fracturing of society in my writing, but I might start to adopt this phase.\n\t - **Implications for Society:** Discusses how the decentralization of authority and the rise of powerful private entities could shape societal norms, governance, and daily life, leading to a redefinition of citizenship, rights, and [[Social contract and jobs]]. He identifies Uber as a social credit system which we blithely accept. Over time this trends to separation like that seen in the insurance markets, where \"all the 1 star Uber drivers drive the 1 star passenger\", but writ large across society. This is also \"gated communities\" and the micro-states defended by AI as posited by authors like Neal Stephenson in Diamond Age.\n\t - **Adversarial Renaissance:** This might well be dystopian, but equally it could be a renaissance moment, with national governments losing their hegemonic control to exascale compute powered conglomerates, city states, micro countries etc. This is for sure more adversarial, but not **necessarily** bad. This is a libertarian viewpoint, but also perhaps a classic liberal one.\n\t\t- ### Middle Path\n\t - **Co-evolution of State and AI:** Envisions a scenario where AI and state structures co-evolve, balancing the benefits of technological advancements with the need for governance and societal stability.\n\t - **Navigating Challenges:** Discusses the potential paths to achieving this balance, including regulatory frameworks, ethical AI development, and international cooperation to manage the impacts of AI on global stability and human welfare.\n\t- ## Technological Disruptions and Society's Response\n\t\t- ### Intelligence Explosion and Societal Shift\n\t - **Hypothetical Breakthroughs:** Details scenarios where AI breakthroughs, akin to everyone having x-ray style glasses, could radically challenge existing norms around privacy, security, and human interaction.\n\t - **Radical Transparency Challenges:** Discusses the implications of such breakthroughs on societal norms, legal frameworks, and individual behaviors, stressing the need for society to anticipate and adapt to these transformative changes.\n\t\t- ### Societal Responses\n\t - **Cultural Evolution:** Explores how societies might culturally evolve to accommodate the pervasive and invasive nature of AI, including shifts in social norms, ethics, and values.\n\t - **Mitigation and Adaptation:** Discusses strategies for mitigating the negative impacts of AI and ways in which individuals, organizations, and governments might adapt to a rapidly changing technological landscape.\n\t - **Regulation and Enforcement:** Details the potential for regulation and enforcement to manage the risks and ensure responsible development and use of AI technologies, considering the balance between innovation and control.\n\t\t- ### AI as an Informational Tool\n\t - **Increasing Information Resolution:** Describes AI's ability to significantly enhance our understanding of the world, from refactoring legacy code to restoring ancient scrolls, and detecting galaxies in old surveys.\n\t - **Privacy Risks:** Discusses the significant privacy risks posed by AI's ability to turn everyday signals into identifiable data, stressing the need for robust privacy protections and ethical considerations.\n\t- ## Scaling and Accessibility of AI\n\t\t- ### Technological Advancements\n\t - **Cheaper and More Accessible AI:** Details how advancements in AI technology are making it exponentially cheaper and more accessible, leading to widespread adoption across sectors and society.\n\t - **Amplified Effects:** Discusses the dual nature of AI's amplified effects, enhancing both beneficial outcomes like increased efficiency and productivity, as well as detrimental ones like enhanced surveillance and social manipulation.\n\t\t- ### AI in Daily Life\n\t - **Prediction of Everyday AI Assistants:** Envisions a future where AI assistants become commonplace in homes and workplaces, aiding in tasks ranging from mundane chores to complex decision-making.\n\t - **Complex Model Access:** Discusses how individuals and organizations might pull complex AI models on demand for various tasks, radically transforming work, creativity, and leisure.\n\t- ## AI's Impact on Freedom and Oppression\n\t\t- ### Liberating Capabilities\n\t - **Enhancing Human Capabilities:** Details how AI has the potential to significantly enhance human intellectual and physical capabilities, leading to new forms of creativity, problem-solving, and productivity.\n\t - **Freedom Expansion:** Discusses the potential for AI to expand human freedoms by alleviating burdensome tasks, enhancing decision-making, and creating new opportunities for personal and societal growth.\n\t\t- ### Oppression Risks\n\t - **Surveillance Capabilities:** Explores the risks of AI-enhanced surveillance, detailing how pervasive monitoring could lead to oppressive societal structures and a significant loss of privacy and autonomy.\n\t - **Privacy Invasions:** Details the ways in which AI's ability to analyze and interpret personal data can lead to invasions of privacy, emphasizing the need for robust legal protections and ethical constraints.\n\t- ## Historical Context and Future Trajectory\n\t\t- ### State of Nature and Leviathan\n\t - **AI as a Disruptive Force:** Discusses how AI, like historical technological advancements, has the potential to be a disruptive force, reshaping societal structures, power dynamics, and individual lives.\n\t - **Historical Analogies:** Draws parallels between AI's potential impacts and historical events like the English Civil War, emphasizing the transformative role of technology in societal upheaval.\n\t\t- ### Accelerating Toward Divergent Futures\n\t - **Democratization of AI:** Explores the potential for rapid democratization of AI technology, leading to widespread access and use, and the societal implications of such a scenario.\n\t - **Technological Evangelism:** Discusses the role of technological evangelists in accelerating AI development and adoption, comparing their efforts to historical figures who sought to democratize knowledge and power.\n\t- ## Technological Base vs. Institutional Superstructure\n\t\t- ### Mismatch and Adaptation\n\t - **Rapid Technological Evolution:** Details the rapid pace of technological evolution, particularly in AI, and the challenges it poses to existing societal and institutional structures.\n\t - **Slower Institutional Adaptation:** Discusses the slower pace of adaptation in institutions, leading to a mismatch between the capabilities and impacts of AI and the ability of governance structures to effectively manage them.\n\t\t- ### Governance and Relevance\n\t - **Loss of Direction of Fit:** Explores the potential for traditional governance structures to lose their relevance or \"direction of f* as society and technology evolve, leading to political instability and societal unrest.\n\t - **Adaptation Challenges:** Discusses the challenges and potential paths for institutions to adapt to a rapidly changing technological landscape, ensuring stability, fairness, and societal welfare.\n\t- ## AI and Future Governance\n\t\t- ### 2040 Vision of U.S. Government\n\t - **Projected Drastic Changes:** Envisions how the U.S. government of 2040 might look drastically different due to the transformative effects of AI, drawing comparisons to the mid-20th-century government and pre-industrial era.\n\t - **Transformational Impacts:** Discusses the specific ways in which AI might transform governance, including decision-making processes, service delivery, and citizen engagement.\n\t\t- ### Impact on Institutions\n\t - **Democratization of AI:** Explores the potential for the democratization of powerful AI capabilities to be as destabilizing as historical technologies like the printing press, reshaping institutions and societal structures.\n\t - **Reshaping 20th-Century Institutions:** Discusses the specific ways in which AI might reshape institutions inherited from the early 20th century, including governance, education, healthcare, and labor markets.\n\t\t- ### Default Path of Government Adaptation\n\t - **Slow Adaptation:** Details the potential consequences of governments moving slowly and incompetently in adapting to AI shocks, leading to fragmentation or a reduced role in societal governance.\n\t - **Techno-Feudalist Timeline:** Discusses the potential for a *techno-feudalist\" timeline, where the provision of various public goods, including security against AI misuse, shifts into private hands.\n\t- ## Milestones and Predictions\n\t\t- ### Timeline (2024-2040 and beyond)\n\t - **Key Milestones:** Details specific milestones and significant impacts on various sectors from 2024 to 2040 and beyond, including the rise of synthetic content, job restructuring, and privatized services.\n\t - **Acceleration of AI Integration:** Discusses the acceleration of AI integration across sectors, including government, leading to an overhaul in regulatory, legal, and enforcement agencies.\n\t - **Verbatim Timeline**:\n\t\t\t\t- 2024\n\t - 2027: Majority of internet content becomes synthetic, traditional media and Hollywood face existential threats, and the enterprise sector integrates AI for automation and compliance.\n\t\t\t\t- 2028\n\t - 2031: Emergence of AGI capable of emulating human tasks, leading to significant job losses in cognitive sectors and a restructuring of labor markets.\n\t\t\t\t- 2032\n\t - 2035: Acceleration of AI integration across various sectors, including government, causing an overhaul in regulatory, legal, and enforcement agencies.\n\t\t\t\t- 2036\n\t - 2039: General-purpose robots disrupt goods production and manual labor, leading to a re-localization of supply chains and a rise in privatized services.\n\t\t\t\t- 2040 and beyond: Divergence into three broad categories of countries: Chinese-style police states, anarchic failed states, and high-tech open societies. An increase in micro-jurisdictions with varying degrees of flourishing and an intense focus on internal security.\n\t\t- ### The Final Test and Order of AI Risks\n\t - **Hypothetical Scenarios:** Details a hypothetical scenario set in 2045, where a city home to AI trillionaires tests a superintelligent model, emphasizing the importance of addressing AI risks in stages.\n\t - **Order of Risks:** Discusses the importance of considering the order of AI risks, noting that intermediate stages of AI development may indirectly affect the very institutions needed to address existential risks from superintelligence.\n\t- ## AGI and Human Intelligence\n\t\t- ### Approaching AGI\n\t - **Viability and Principles:** Discusses the viability of AGI based on current trends in deep learning and neural networks, detailing the principles and evidence supporting its near-term development.\n\t - **Evidence of Universality:** Details the evidence for the universality observed in artificial neural networks learning similar circuits to the human brain, suggesting that current methods are sufficient for modeling human cognition.\n\t\t- ### Misconceptions and Realities\n\t - **Human Intelligence Overestimation:** Challenges the tendency to overestimate human intelligence, suggesting that as humans, we have limited capabilities in fully understanding or modeling other humans.\n\t - **Statistical Processes in Intelligence:** Explores the statistical processes guiding the creation of intelligent life, drawing on the analogy of Earth's evolutionary \"hard steps\" and the scaling laws seen in neural networks and other physical systems.\n\t- ## Economic Perspectives and Growth Theory\n\t\t- ### Endogenous Growth Theory\n\t - **AK Model:** Introduces the AK model from endogenous growth theory, which posits that economies can grow indefinitely as they accumulate more capital, potentially allowing for explosive growth under certain conditions.\n\t - **Theoretical vs. Real-World Limitations:** Discusses the theoretical possibilities of indefinite growth while acknowledging the real-world diminishing returns and other economic principles that limit such expansion.\n\t\t- ### Diminishing Returns in Research Productivity\n\t - **Falling Research Productivity:** Details the empirical finding that research productivity is falling, meaning ideas are becoming harder to find and suggesting a natural limit to growth driven by idea generation and innovation.\n\t - **Implications for AI-Driven Growth:** Discusses the implications of diminishing returns for the notion of perpetually increasing returns from AI-augmented research and development.\n\t\t- ### Aggregation and Scale Effects\n\t - **Increasing Returns in One Sector:** Explores the assumption of increasing returns to scale in one sector or firm and its limitations when aggregating to the economy as a whole, considering factors like urban congestion and competition.\n\t - **Consumption Bottlenecks:** Details the potential economic disruptions created by AI assuming the role of both producer and consumer, leading to overproduction or underconsumption crises and the importance of maintaining the circular flow of spending.\n\t- ## Conclusion and Forward Path\n\t\t- ### Navigating the AI Landscape\n\t - **Embracing Change:** Discusses the need for individuals, institutions, and societies to embrace the rapid changes brought about by AI, encouraging innovation while addressing the impacts.\n\t - **Ethical and Safe Deployment:** Emphasizes the importance of ethical guidelines and safe deployment strategies to navigate the complex landscape of AI development and use.\n\t\t- ### The Future of AI and Society\n\t - **Potential Paths:** Explores the potential paths society might take in response to AI's proliferation, considering the balance between freedom and control, innovation and stability.\n\t - **Soci",
        "link_types": [
            "Social contract and jobs"
        ],
        "file_size": 17935
    },
    {
        "id": "Large language models.md",
        "name": "Large language models",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n-\n- ## Introduction to Large Language Models\n- Large Language Models (LLMs) like OpenAI's GPT series have revolutionized the field of artificial intelligence, offering unprecedented capabilities in natural language understanding and generation. These models are trained on vast amounts of text data, enabling them to perform a wide range of language-based tasks, from writing and translation to answering questions and generating code.\n\t- [This is a jargon free primer](https://www.understandingai.org/p/large-language-models-explained-with)\n- # What to use and when\n\t- **Start with Simple API Calls:**\n\t\t- Initially, utilize third-party APIs that serve your needs without complicating your system. This is the most straightforward and cost-effective solution.\n\t\t- If third-party APIs meet your requirements in terms of functionality, privacy, cost, and latency, there's no need to progress to more complex solutions.\n\t- **Deploy Pre-trained Models:**\n\t\t- If API solutions are insufficient due to privacy, cost, or latency issues, consider deploying a generic, pre-trained model (like MixL or LLaMA) behind your own API.\n\t\t- This step involves a bit more complexity and control over the data but remains relatively simple.\n\t- **Curate Context and Improve Prompts:**\n\t\t- Enhance the output quality by curating in-context examples and optimizing prompts. This step aims to extract better performance from the existing deployed model with minimal changes.\n\t- **Integrate Retrieval Systems:**\n\t\t- If further improvement is needed, integrate a retrieval system to complement the model's responses, based on the available latency and the complexity it introduces to your system.\n\t- **Fine-tune on Specific Data:**\n\t\t- When adjustments and retrieval integrations aren't sufficient, proceed to fine-tune the model on a targeted dataset. This step tailors the model more closely to your specific requirements.\n\t- **Swap for a Larger Model or Pre-train Your Own:**\n\t\t- If fine-tuning does not achieve the desired outcomes, consider swapping in a larger pre-trained model or pre-training your own model for more significant customization and improvement.\n\t\t- This can involve domain adaptation through further pre-training on a relevant corpus, followed by fine-tuning.\n\t- **Iterate and Add Complexity as Necessary:**\n\t\t- Continue iterating, adding layers of complexity only as needed. This approach ensures that you only invest in higher compute and development costs when there's a clear benefit.\n\t- **Simplify and Streamline for Deployment:**\n\t\t- Throughout this process, aim to simplify and streamline solutions for deployment. Consider the target audience and operationalize the solution in a way that makes it accessible and practical for them.\n\t\t-\n- ### Key Resources and Projects\n\t- **Web LLM Project**: A pioneering initiative bringing LLM functionalities to the browser, enabling users to interact with these models directly from their web interface. [Web LLM Project](https://example.com/link-to-web-llm-project)\n\t\t- *This project demonstrates the feasibility and potential of deploying complex AI models in consumer-friendly interfaces.*\n\t- **Browser-based Models**: The [Web LLM project](https://simonwillison.net/2023/Apr/16/web-llm/) introduces a browser-based implementation of the vicuna-7b Large Language Model. This project showcases the practical application of LLMs in web environments, enabling users to interact with sophisticated AI models directly within their browsers. The initiative highlights the evolving accessibility of AI technologies, bringing powerful computational linguistics tools to a broader audience without the need for specialized hardware.\n- ## Interfaces and Scaling\n\t- The evolution and scaling of interfaces for Large Language Models have significant implications for user interaction and the accessibility of AI technologies. This area explores the integration of LLMs into various interfaces, including immersive spaces and metaverse applications, which opens up new avenues for interaction and engagement with AI.\n- ### Key Projects and Discussions\n\t- **Immersive Spaces**: The potential of generative AI in metaverse applications and game development is vast, offering new ways to create engaging and dynamic environments. While specific links to projects or discussions were not provided in the initial extraction, this area highlights the intersection of LLMs with virtual worlds, suggesting a future where AI can contribute to more immersive and interactive digital spaces.\n\t- **Generative AI in the Metaverse**: An insightful article on why now is the time to use generative AI in your metaverse company, outlining potential impacts and considerations for developers and businesses. [Why You Should Use Generative AI in Your Metaverse Company\n\t\t- The Ghost Howls](https://skarredghost.com/2023/02/11/generative-ai-metaverse-company/)\n\t\t- *This article provides a comprehensive overview of how generative AI can revolutionize metaverse applications, offering a balanced view on the opportunities and challenges.*\n\t- **AI-Assisted Graphics in Game Development**: Exploring the use of AI to assist in graphics creation for games, enhancing realism and efficiency. [AI-Assisted Graphics](https://www.traffickinggame.com/ai-assisted-graphics/)\n\t\t- *This link showcases practical applications of AI in game development, highlighting advancements in creating more immersive and visually stunning gaming experiences.*\n- ## Optimizations\n\t- Optimizations are critical for enhancing the performance and efficiency of Large Language Models. This section covers various techniques and tools that have been developed for this purpose.\n\t- ### Key Techniques and Tools\n\t\t- **DeepSpeed**: [DeepSpeed by Microsoft](https://github.com/microsoft/DeepSpeed) is an advanced deep learning optimization software suite that significantly accelerates the training of deep learning models. It offers various features like model parallelism, gradient accumulation, and sparsity to achieve unprecedented scale and speed. *DeepSpeed is pivotal for researchers and practitioners aiming to push the boundaries of model size and training speed.*\n\t\t- **Nvidia DASK**: [Tutorial for distributed computing with GPUs](https://developer.nvidia.com/blog/dask-tutorial-beginners-guide-to-distributed-computing-with-gpus-in-python/) provides insights into using Nvidia DASK for distributed computing, enhancing the performance of LLMs by leveraging GPU resources more efficiently. *This tutorial is a valuable resource for anyone looking to understand and implement distributed computing with GPUs.*\n\t\t- **SWARM Training Paper**: [SWARM: A Paradigm for Distributed Training of LLMs](https://arxiv.org/pdf/2301.11913.pdf) discusses innovative methods for distributed training of large language models, addressing challenges related to scalability and efficiency. *The SWARM approach represents a significant advancement in distributed training techniques, offering insights into overcoming the limitations of traditional training methodologies.*\n- ### Projects and Implementations\n\t- **Browser-based Models**: A significant advancement in making LLMs accessible via web interfaces. The [Web LLM project](https://simonwillison.net/2023/Apr/16/web-llm/) discusses a browser-based version of the Vicuna-7b Large Language Model, showcasing how LLMs can be integrated into web applications, offering an accurate and fast model capable of handling complex prompts. This project exemplifies the potential of LLMs in providing accessible AI-powered applications directly from a web browser.\n- ### Interfaces and Scaling\n\t- **Immersive Spaces**: Exploring the integration of generative AI, including LLMs, in metaverse applications and game development. The potential for immersive, AI-driven spaces is vast, ranging from enhanced user experiences to novel forms of interaction. [Why you should use generative AI in your metaverse company](https://skarredghost.com/2023/02/11/generative-ai-metaverse-company/)\n\t\t- *This article discusses the implications and opportunities of incorporating generative AI in metaverse platforms.*\n- ### Optimizations\n\t- **DeepSpeed**: A software suite by Microsoft aimed at accelerating deep learning tasks. DeepSpeed offers innovative tools for enhancing the performance and efficiency of LLMs, making it easier to scale up training and inference operations. [DeepSpeed GitHub](https://github.com/microsoft/DeepSpeed)\n\t\t- *DeepSpeed is pivotal in addressing the computational and memory challenges of training large models, offering solutions to significantly reduce training times and resource consumption.*\n- ### Training & Fine-tuning\n\t- **Methods and Tools**: Enhancing LLM performance through innovative training and fine-tuning techniques. Resources cover a range of strategies, including LoRA training, deep retraining, pruning techniques, and model merging strategies.\n\t\t- [LoRA Training Insights](https://lightning.ai/pages/community/lora-insights/)\n\t\t- *An insightful blog post on the application and benefits of Low-Rank Adaptation (LoRA) in training LLMs, providing a deep dive into how LoRA can be used to fine-tune models efficiently.*\n\t\t- [BMTrain Toolkit](https://github.com/OpenBMB/BMTrain)\n\t\t- *BMTrain presents an efficient framework for training large models, focusing on distributed training while maintaining simplicity in code structure, making it accessible for large-scale model training.*\n- ### Evaluation\n\t- **Comparison and Detection**: Tools and methodologies for assessing LLM performance and detecting AI-generated text. This includes evaluations of model outputs and capabilities.\n\t\t- [AI-Generated Text Detection](https://arxiv.org/abs/2303.11156)\n\t\t- *A comprehensive study on the reliability of detecting AI-generated text, highlighting the challenges and methodologies involved in distinguishing between human and AI-generated content.*\n- ### Applications\n\t- **Consumer Tools Using LLMs**: Showcasing the application of LLMs in creating innovative consumer tools.\n\t\t- [CustomGPT for Personalized Customer Experiences](https://customgpt.ai)\n\t\t- *CustomGPT leverages LLMs to offer personalized interactions, demonstrating the potential of AI in enhancing customer service and engagement.*\n- ### Infrastructure\n\t- **Hosting and Deployment**: Solutions for effectively deploying LLMs, addressing the technical challenges involved.\n\t\t- [Rubbrband for Auto Deployments](https://rubbrband.com)\n\t\t- *Rubbrband provides a streamlined solution for deploying LLMs, emphasizing ease of use and efficiency in managing AI model deployments.*\n- ### Multilingual and Abstract Translation\n\t- Projects dedicated to improving LLM capabilities in translation, fostering better understanding and communication across languages.\n\t\t- [SeamlessM4T by Facebook Research](https://github.com/facebookresearch/seamless_communication#seamlessm4t)\n\t\t- *An innovative project aimed at enhancing multilingual translation, showcasing efforts to bridge language barriers and improve communication globally.*\n- ### Additional Training & Fine-tuning Resources\n\t- **Mesh TensorFlow for Distributed Training**: A tool for distributing computation across different hardware to enhance training efficiency. [Mesh TensorFlow](https://github.com/tensorflow/mesh)\n\t\t- *Enables sophisticated distribution strategies, optimizing the use of hardware resources during model training.*\n\t- **Colossal-AI for Easy Distributed Training**: Provides user-friendly tools for distributed deep learning, making it simpler to scale up training processes. [Colossal-AI](https://colossalai.org/)\n\t\t- *Aims to simplify the transition from single-device to distributed model training, supporting more efficient utilization of computing resources.*\n\t- **BMTrain for Large Model Training**: Focuses on training large models with simplicity and efficiency, even in distributed settings. [BMTrain](https://github.com/OpenBMB/BMTrain)\n\t\t- *An efficient toolkit designed for simplicity in training large-scale models, supporting distributed training with ease.*\n\t- **LoRA Training Insights**: Discusses the benefits and application of Low-Rank Adaptation (LoRA) for efficient model fine-tuning. [LoRA Training Insights](https://lightning.ai/pages/community/lora-insights/)\n\t\t- *Provides a deep dive into how LoRA can be utilized to fine-tune models efficiently, offering significant insights into the process.*\n- ### Evaluation\n\t- Comparison and Detection\n\t- **LLM QA Evaluation on Wikipedia**: An insightful comparison of different LLMs' performance on QA tasks using Wikipedia as a benchmark. [LLM QA Evaluation Wikipedia](https://georgesung.github.io/ai/llm-qa-eval-wikipedia/)\n\t- *This study offers a comparative analysis highlighting the strengths and weaknesses of open-source vs closed-source LLMs in handling QA tasks, providing valuable insights for both developers and users.*\n\t- **LLM Zoo**: A collection of various LLMs to explore and compare their capabilities. [LLMZoo GitHub](https://github.com/FreedomIntelligence/LLMZoo)\n\t- *A unique repository that provides access to a wide range of LLMs, facilitating exploration, comparison, and understanding of different models' functionalities and performance.*\n\t- **Can AI-Generated Text be Reliably Detected?**: Addresses the critical question of distinguishing between human and AI-generated text. [AI-Generated Text Detection Study](https://arxiv.org/abs/2303.11156)\n\t- *This paper delves into the challenges and methodologies involved in detecting AI-generated text, offering insights into the reliability of current detection techniques.*\n- ### Applications\n\t- Consumer Tools Using LLMs\n- **Innovative Tools for Personalized Customer Experiences**: LLMs are increasingly used to create tools that offer personalized interactions for users, enhancing ecommerce experiences and facilitating efficient email management.\n\t- [CustomGPT](https://customgpt.ai)\n\t\t- A platform enabling businesses to create their own chatbots using their content, leading to accurate and personalized customer interactions. This tool exemplifies the use of LLMs in improving customer service and engagement.\n\t- [AnythingLLM](https://github.com/Mintplex-Labs/anything-llm)\n\t\t- A full-stack personalized AI assistant application that turns documents or content into reference data for intelligent conversations. Demonstrates the flexibility and potential of LLMs in custom applications.\n\t- [NodePad](https://nodepad.space/)\n\t\t- An LLM-assisted brainstorming tool that helps users organize their ideas visually. Highlights the creative use of LLMs in supporting individual thought processes and ideation.\n- ### Applications\n\t- Consumer Tools Using LLMs\n- **Personalized Customer Experiences**: LLMs are increasingly used to create personalized interactions in consumer applications, enhancing ecommerce experiences and facilitating more intuitive user interfaces.\n\t- [CustomGPT](https://customgpt.ai)\n\t\t- *CustomGPT offers businesses the ability to create their own chatbot using GPT-4 for tailored customer interactions. This platform demonstrates the application of LLMs in improving customer service and engagement by providing accurate, context-aware responses.*\n- **Innovative Interfaces and Applications**: The versatility of LLMs allows for the development of creative tools that simplify complex tasks or provide new services.\n\t- [AnythingLLM](https://github.com/Mintplex-Labs/anything-llm)\n\t\t- *A comprehensive solution for turning any document or piece of content into a piece of data for LLM-based chat interactions, showcasing the potential of LLMs in data management and retrieval.*\n- ### Infrastructure\n\t- Hosting and Deployment\n- **Solutions for LLM Deployment**: Addressing the technical requirements and solutions for deploying LLMs efficiently.\n\t- [Rubbrband for Auto Deployments](https://rubbrband.com)\n\t\t- *Rubbrband simplifies the deployment of LLMs by providing an automated platform that supports various deployment scenarios, facilitating easier access to LLM capabilities.*\n\t- [Hosting VPS Solutions](https://1984.hosting)\n\t\t- *1984 Hosting offers privacy-focused VPS solutions, ideal for hosting LLMs with a commitment to free speech and data protection.*\n\t- [Free Custom Domains VPS](https://codesphere.com/pricing?anonymousId=YTQLcRg)\n\t\t- *Codesphere provides VPS hosting with the option for free custom domains, enabling personalized deployment of LLM applications.*\n- **Distributed Computing and Training**:\n\t- [Nvidia DASK for Distributed Computing](https://developer.nvidia.com/blog/dask-tutorial-beginners-guide-to-distributed-computing-with-gpus-in-python/)\n\t\t- *Nvidia's DASK tutorial offers a beginner's guide to distributed computing with GPUs, enhancing the performance of LLM training and inference.*\n\t- [SWARM Training for LLMs](https://arxiv.org/pdf/2301.11913.pdf)\n\t\t- *The SWARM training paper discusses innovative methods for distributed training of LLMs, proposing solutions to scale training processes efficiently.*\n- ### Multilingual and Abstract Translation\n- **Enhancing Translation Capabilities**: Projects and technologies aimed at improving translation quality and supporting seamless communication across languages.\n\t- [Meta SeamlessM4T](https://github.com/facebookresearch/seamless_communication#seamlessm4t)\n\t\t- *A project by Meta aimed at enhancing multilingual translation to support seamless communication across different languages, showcasing the potential of LLMs in breaking down language barriers.*\n- **Supporting Global Communication**: Efforts to develop tools and models that facilitate understanding and translation across a wide array of languages.\n\t- [MultimodalC4 Extension](https://github.com/allenai/mmc4)\n\t\t- *A multimodal extension of the C4 dataset that interleaves millions of images with text to provide context, aiming at improving the capabilities of LLMs in understanding and generating content in a multilingual and multimodal context.*\n- ### General Purpose and Miscellaneous\n- **Learning and Development**: Resources for learning about LLMs, including educational materials and platforms for fine-tuning and experimenting.\n\t- [Replit LLM Training Guide](https://blog.replit.com/llm-training)\n\t\t- A guide on training your own large language models using Replit.\n\t- [Futurepedia](http://Futurepedia.io)\n\t\t- The largest AI tools directory, featuring over 700 tools in various categories.\n\t- [Understanding Large Language Models](https://magazine.sebastianraschka.com/p/understanding-large-language-models)\n\t\t- A cross-section of relevant literature to get up to speed on LLMs.\n- **Distributed Technology**\n\t- [Mesh TensorFlow](https://github.com/tensorflow/mesh)\n\t\t- A language for distributed deep learning, allowing broad classes of distributed tensor computations.\n\t- [BMTrain](https://github.com/OpenBMB/BMTrain)\n\t\t- An efficient large model training toolkit for distributed training.\n\t- [Colossal-AI](https://colossalai.org/)\n\t\t- Aims to simplify distributed deep learning, supporting easy transition to distributed training.\n- **Optimizations and Scaling**\n\t- [TensorRT-LLM optimization repo](https://github.com/NVIDIA/TensorRT-LLM)\n\t\t- Optimizations for LLMs using TensorRT for better inference performance.\n\t- [DeepSpeed](https://github.com/microsoft/DeepSpeed)\n\t\t- Deep learning optimization software suite by Microsoft for scalable training.\n- **Emotion Tracking**\n\t- [LAION Empathetic](https://dct.openempathic.ai/guide/#:~:text=Rating%20Arousal%20and%20Valence%3A)\n\t\t- A tool for emotion tracking in text.\n- ### Additional Tools and Resources\n- [Horde Image and LLM](https://horde.koboldai.net/)\n\t- A project integrating images with LLMs for enhanced content generation.\n- [LobeHub](https://github.com/lobehub)\n\t- A technology-driven forum for AIGC, offering modern design components and tools.\n- Microsoft [WizardLM 2](https://wizardlm.github.io/WizardLM2/)\n-\n-\n- # old version to integrate\n- ### Large Language Models (LLMs)\n\t- **Introduction to LLMs**\n\t\t- Large language models are advanced computer programs capable of generating text, answering questions, and more, trained on vast internet text. Examples include OpenAI's GPT-3.\n- **Projects and Implementations**\n\t-\n\t- Browser-based models, such as the [Web LLM project](https://simonwillison.net/2023/Apr/16/web-llm/), which discusses a browser-based version of the vicuna-7b Large Language Model.\n-\n- ### Distributed Technology\n\t- **Optimizations and Scaling**\n\t\t- [Nvidia DASK](https://developer.nvidia.com/blog/dask-tutorial-beginners-guide-to-distributed-computing-with-gpus-in-python/): Tutorial for distributed computing with GPUs.\n\t\t- [SWARM Training Paper](https://arxiv.org/pdf/2301.11913.pdf): Discusses methods for distributed training of LLMs.\n- Interfaces and scaling\n\t- [LobeHub (github.com)](https://github.com/lobehub)\n- Distributed tech\n\t- [horde image and llm](https://horde.koboldai.net/)\n- Browser based whole models\n\t- [The Web LLM project has created a browser-based version of the vicuna-7b Large Language Model, which is impressively accurate and fast. The model is able to handle complex prompts and provide accurate responses, although it does sometimes make mistakes.](https://simonwillison.net/2023/Apr/16/web-llm/)\n\t- [Nvidia DASK](https://developer.nvidia.com/blog/dask-tutorial-beginners-guide-to-distributed-computing-with-gpus-in-python/)\n\t- [SWARM training paper](https://arxiv.org/pdf/2301.11913.pdf)\n- immersive spaces\n\t- Why you should use now generative AI in your metaverse company. Or maybe not\n\t\t- The Ghost Howls https://skarredghost.com/2023/02/11/generative-ai-metaverse-company/\n\t- [games dev](https://www.traffickinggame.com/ai-assisted-graphics/)\n- [Instant app from prompts](https://twitter.com/ronithhh/status/1641318606549176321)\n- [endless runner without any coding experience](https://replit.com/@asrsubs/SkyRoads-GPT-4)\n- [Edge (phone deployment on android)](https://github.com/mlc-ai/mlc-llm/tree/main/android)\n- [Tree of thought github](https://github.com/ysymyth/tree-of-thought-llm)\n- [Scaling challenges paper](https://arxiv.org/abs/2307.10169)\n- [Flow node based LLM design](https://github.com/FlowiseAI/Flowise)\n- [TensorRT-LLM optimisation repo](https://github.com/NVIDIA/TensorRT-LLM)\n- [Flowchat](https://github.com/flatypus/flowchat)\n- Multi Modal\n\t- [MultimodalC4 is a multimodal extension of c4 that interleaves millions of images with text. The corpus contains over a billion images, and the text is interleaved with the images to provide context.](https://github.com/allenai/mmc4)\n\t- [Otter with weights](https://otter-ntu.github.io/)\n\t- [minigpt](https://minigpt-4.github.io/)\n\t- [MiniGPT local multimodal](https://github.com/Vision-CAIR/MiniGPT-4)\n\t- [Fuya](https://www.adept.ai/blog/fuyu-8b?)\n- emotion tracking\n\t- [laion empathetic](https://dct.openempathic.ai/guide/#:~:text=Rating%20Arousal%20and%20Valence%3A)\n\t- [entity identify open LLM](https://www.numind.ai/blog/a-foundation-model-for-entity-recognition)\n- Optimisations\n\t- [𝐃𝐞𝐞𝐩𝐒𝐩𝐞𝐞𝐝 is an easy-to-use deep learning optimization software suite that enables unprecedented scale and speed for DL Training and Inference. Visit us at deepspeed.ai or our Github repo.\n\t- 📌Megatron-LM GPT2 tutorial: https://lnkd.in/gXvPhXqb](https://github.com/microsoft/DeepSpeed)\n\t- [The text provides instructions on how to train your own large language models using Replit. It explains that you will need to first create a Replit account and then follow the instructions on the website.](https://blog.replit.com/llm-training)\n\t- [Futurepedia is the largest AI tools directory, with over 700 tools in various categories. It is updated daily, and features search and filter options to help you find the right tool for your needs.](http://Futurepedia.io)\n\t- [GitHub\n\t\t- gitnomad24601/ShogScript: ShogScript: The GitHub repository \"ShogScript\" contains a proof-of-concept pseudocode for GPT-4 AI interactions, ideal for storytelling & communication. The code is released under the MIT license.](https://github.com/gitnomad24601/ShogScript)\n\t- [Flash decoding 8x](https://together.ai/blog/flash-decoding-for-long-context-inference?)\n\t- [Understanding Large Language Models: A Cross-Section of the Most Relevant Literature To Get Up to Speed](https://magazine.sebastianraschka.com/p/understanding-large-language-models)\n\t- [The text describes a change to support the GPTQ triton commit c90adef. This change allows for the disabling of quant attention.](https://github.com/oobabooga/text-generation-webui/pull/1229)\n\t- [2000x performance improvement paper](https://arxiv.org/abs/2305.02301)\n\t- [Flexgen](https://github.com/FMInference/FlexGen#get-started-with-a-single-gpu)\n\t- [4bit compression](https://github.com/johnsmith0031/alpaca_lora_4bit)\n\t- [GPT4 self hallucination checking](https://www.reddit.com/r/MachineLearning/comments/123b66w/dgpt4_might_be_able_to_tell_you_if_it_hallucinated/)\n\t- [Sparse LLM, half the size, all the power](https://arxiv.org/abs/2301.00774)\n\t- [SpQR lossless optimisation paper](https://arxiv.org/abs/2306.03078)\n\t- [Landmark attention qlora oogabooga](https://github.com/eugenepentland/landmark-attention-qlora)\n\t- [LobeHub (github.com)](https://github.com/lobehub)\n\t\t- We are a group of e/acc design-engineers, hoping to provide modern design components and tools for AIGC, and creating a technology-driven forum, fostering knowledge interaction and the exchange of ideas that may culminate in mutual inspiration and collaborative innovation. Whether for users or professional developers, LobeHub will be your AI Agent playground.\n- Training & Finetuning\n- Lora\n- [alpaca lora training](https://discord.com/channels/1086739839761776660/1087508281758584852)\n- [Github](https://github.com/tloen/alpaca-lora)\n- [CPU offload lora training](https://github.com/oobabooga/text-generation-webui/commit/09d8119e3cf36257496acfb44e6445a9f40c3d02)\n- [llamatard 4bit chat instructions](https://rentry.org/llama-tard-v2#llama-int8-4bit-chatbot-guide-v2)\n- [The text provides a guide on how to make your own Loras, which are easy and free to create. The process is described in detail, and the text includes instructions on how to create and customize your own Loras.](https://civitai.com/models/22530)\n- Deep retraining\n- Deepspeed chat retraining in hours\n- microsoft just released a new finetuning pipeline\n  they finetuned a 65B model in 10 hours using RLHF\n- [TRL\n\t- Transformer Reinforcement Learning](https://github.com/lvwerra/trl)\n- Hardware requirements for retraining (links to state of the art)\n\t- [Finetuning blog post](https://www.databricks.com/blog/2023/03/20/fine-tuning-large-language-models-hugging-face-and-deepspeed.html)\n- Pruning\n- [Seems that both 4 bit and straight up pruning don't harm the models much](https://arxiv.org/abs/1803.03635)\n- Merging\n- [diffusion style LLM block merging](https://github.com/TehVenomm/LM_Transformers_BlockMerge)\n- [Domain expert model merging](https://docs.google.com/document/d/1JCzJ1wdBMBVwsFW4CWGUbX-YEDXB0yS4mfFbvwPLQrI/edit)\n- Toolkits and distributed\n- [𝐌𝐞𝐬𝐡 𝐓𝐞𝐧𝐬𝐨𝐫𝐅𝐥𝐨𝐰 (mtf) is a language for distributed deep learning, capable of specifying a broad class of distributed tensor computations. The purpose of Mesh TensorFlow is to formalize and implement distribution strategies for your computation graph over your hardware/processors. For example: \"Split the batch over rows of processors and split the units in the hidden layer across columns of processors.\" Mesh TensorFlow is implemented as a layer over TensorFlow.](https://github.com/tensorflow/mesh)\n- [𝐁𝐌𝐓𝐫𝐚𝐢𝐧 is an efficient large model training toolkit that can be used to train large models with tens of billions of parameters. It can train models in a distributed manner while keeping the code as simple as stand-alone training.](https://github.com/OpenBMB/BMTrain)\n- [𝐂𝐨𝐥𝐨𝐬𝐬𝐚𝐥-𝐀𝐈 provides a collection of parallel components for you. It aim to support us to write our distributed deep learning models just like how we write our model on our laptop. It provide user-friendly tools to kickstart distributed training and inference in a few lines.\n  📌Open source solution replicates ChatGPT training process.Ready to go with only 1.6GB GPU memory and gives you 7.73 times faster training: https://lnkd.in/gp4XTCnz](https://colossalai.org/)\n- [EasyLM one stop scaleable toolkit](https://github.com/young-geng/EasyLM)\n- [databerry training and deployment](https://github.com/gmpetrov/databerry)\n- [Petals collaborative fine tuning](https://arxiv.org/abs/2209.01188)\n- [Goodle openXLA training accelerator](https://opensource.googleblog.com/2023/03/openxla-is-ready-to-accelerate-and-simplify-ml-development.html)\n- Adversarial and self instructed\n- [Use GPT API as a GAN (twitter thread)](https://twitter.com/BrianRoemmele/status/1637871062246649856)\n- [Bigscience petals run training through torrents](https://github.com/bigscience-workshop/petals)\n- [airoboros_a_rewrite_of_selfinstructalpaca/](https://www.reddit.com/r/MachineLearning/comments/136vt7b/p_airoboros_a_rewrite_of_selfinstructalpaca/)\n- [A Cookbook of Self-Supervised Learning](https://arxiv.org/abs/2304.12210)\n- [Lora training lessons blog post](https://lightning.ai/pages/community/lora-insights/?)\n- [lit-gpt hackable training platform apache 2](https://github.com/Lightning-AI/lit-gpt)\n- [ChatLLaMA  is a library that allows you to create hyper-personalized ChatGPT-like assistants using your own data and the least amount of compute possible. Instead of depending on one large assistant that “rules us all”, we envision a future where each of us can create our own personalized version of ChatGPT-like assistants.](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama)\n- [Substack on retraining a 30B model in an A100](https://abuqader.substack.com/p/releasing-alpaca-30b)\n- [𝐀𝐥𝐩𝐚 is a system for training and serving large-scale neural networks. Scaling neural networks to hundreds of billions of parameters has enabled dramatic breakthroughs such as GPT-3, but training and serving these large-scale neural networks require complicated distributed system techniques. Alpa aims to automate large-scale distributed training and serving with just a few lines of code.\n- 📌Alpa:\n-\n- 📌Serving OPT-175B, BLOOM-176B and CodeGen-16B using Alpa: https://lnkd.in/g_ANHH6f](https://github.com/alpa-projects/alpa)\n- [𝐌𝐞𝐠𝐚𝐭𝐫𝐨𝐧-𝐋𝐌 / Megatron is a large, powerful transformer developed by the Applied Deep Learning Research team at NVIDIA. Below repository is for ongoing research on training large transformer language models at scale. Developing efficient, model-parallel (tensor, sequence, and pipeline), and multi-node pre-training of transformer based models such as GPT, BERT, and T5 using mixed precision.\n- 📌pretrain_gpt3_175B.sh: https://lnkd.in/gFA9h8ns](https://github.com/NVIDIA/Megatron-LM)\n- [Koala paper on training with minimal noise for chatbots](https://bair.berkeley.edu/blog/2023/04/03/koala/?ref=emergentmind)\n- [Emmet twitter and github on fine tuning](https://twitter.com/ehalm_/status/1652373239044112388)\n- [Ensure structured json](https://github.com/1rgs/jsonformer)\n- [Lora training guide from Pytorch lightning.ai people](https://lightning.ai/pages/community/tutorial/lora-llm/)\n- [GPTQ paper code](https://github.com/ist-daslab/gptq)\n- [Microsoft guidance](https://github.com/microsoft/guidance)\n- [QLoRA fast retraining of large models](https://github.com/artidoro/qlora)\n- [paper](https://arxiv.org/pdf/2305.14314.pdf)\n- [Some kind of inscrutable training thing](https://readthedocs.org/projects/alibi/downloads/pdf/latest/)\n- [Llama 2 training guide](https://www.philschmid.de/sagemaker-llama2-qlora)\n- [RLHF cheap paper](https://arxiv.org/pdf/2308.01320.pdf)\n- [Sparse LLM cpu training breakthrough](https://huggingface.co/blog/mwitiderrick/llm-infrerence-on-cpu)\n- Evaluation\n- [github of comparisons](https://georgesung.github.io/ai/llm-qa-eval-wikipedia/)\n- [compare open source vs closed](https://georgesung.github.io/ai/llm-qa-eval-wikipedia/)\n- [LLM zoo](https://github.com/FreedomIntelligence/LLMZoo)\n- [Can AI-Generated Text be Reliably Detected?:](https://arxiv.org/abs/2303.11156)\n- In the paper \"Can AI-Generated Text be Reliably Detected?\", the authors show that current methods for detecting AI-generated text are not reliable in practical scenarios. They first demonstrate that paraphrasing attacks can break a range of detectors, including those using watermarking schemes and neural network-based detectors. They then provide a theoretical impossibility result showing that for a sufficiently good language model, even the best-possible detector can only perform marginally better than a random classifier. Finally, they show that even LLMs protected by watermarking schemes can be vulnerable to spoofing attacks where adversarial humans can add hidden watermarking signatures to their generated text.\n- [gptzero spots AI authoring](http://gptzero.me/)\n- [GPTZero Case Study (Exploring False Positives): Introduction In this case study, I will be sharing the vast amounts of false positives current AI detection software gives, specifically for this case study I will be demonstrating GPTZero. I personally want to thank the supposed “Healthcare professional” who brought this to my attention via my contact link. It has motivated me to look more into this issue rather than just posting bypasses to these popular AI detection software programs, it will be only more beneficial to highlight their real usability in general.](https://gonzoknows.com/posts/GPTZero-Case-Study/)\n- The text describes a case study on false positives with AI detection software. The study found that the software often gives false positives, particularly with regard to healthcare. The study recommends that users be aware of this issue and take it into account when using such software.\n- [Fake detector product](https://hivemoderation.com/ai-generated-content-detection)\n- [Huggingface leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n- [[Base models]]\n- Prompt engineering and injection\n- Character injection\n- [json builder](https://oobabooga.github.io/character-creator.html)\n- [Huggingface commodity card retrainer](https://huggingface.co/blog/trl-peft)\n- Prompt model tips for learning\n- 1. Improve your writing by getting feedback.\n\t- Use this prompt:\n\t- [paste your writing]\n\t- \"Proofread my writing above. Fix grammar and spelling mistakes. And make suggestions that will improve the clarity of my writing\"\n\t- 2. Use the 80/20 principle to learn faster than ever.\n\t- \"I want to learn about [insert topic]. Identify and share the most important 20% of learnings from this topic that will help me understand 80% of it.\"\n\t- 3. Learn and develop any new skill.\n\t- \"I want to learn / get better at [insert desired skill]. I am a complete beginner. Create a 30 day learning plan that will help a beginner like me learn and improve this skill.\"\n\t- 4. Get short and insight-packed book summaries.\n\t- \"Summarize the book [insert book] by the author [insert author] and give me a list of the most important learnings and insights.\"\n\t- 5. Get feedback from history's greatest minds.\n\t- \"Assume you are [insert famous person e.g. Steve Jobs]. Read my argument below and give me feedback as if you were [insert person again]\"\n\t- [insert your argument]\n\t- 6. Enhance your problem solving skills.\n\t- \"Your role is that of a problem solver. Give me a step-by-step guide to solving [insert your problem].\"\n\t- 7. Generate new ideas and overcome writers block:\n\t- \"I am writing a blog post about [insert topic]. Give me an outline for this blog post with 10 bullet points. Also give me 5 options for a catchy headline.\"\n\t- You can adapt this prompt for whatever you're writing.\n\t- 8. Summarize long texts and accelerate your learning:\n\t- \"Summarize the text below into 500 words or less. Create sections for each important point with a brief summary of that point.\"\n\t- 9. Use stories and metaphors to aid your memory.\n\t- \"I am currently learning about [insert topic]. Convert the key lessons from this topic into engaging stories and metaphors to aid my memorization.\"\n\t- 10. Strengthen your learning by testing yourself.\n\t- \"I am currently learning about [insert topic]. Ask me a series of questions that will test my knowledge. Identify knowledge gaps in my answers and give me better answers to fill those gaps.\"\n- [Prompt injection: what s the worst that can happen?](https://simonwillison.net/2023/Apr/14/worst-that-can-happen/)\n- [To jailbreak ChatGPT, you need to get it to really do what you want. This can be done by editing the source code or by using a third-party tool.](https://www.digitaltrends.com/computing/how-to-jailbreak-chatgpt/)\n- General purpose super short prompt\n- develop+extend+support(ideas), vocab(wide+natural+sophisticated), grammar(wide+flexible), cohesion(logical+smooth), clarity(precise+concise), engagement(attention+interest), mood(objective+explanatory), viewpoint(forward_looking)\n- [Mollick methods post on linkedin](https://www.linkedin.com/posts/emollick_there-are-now-three-research-backed-approaches-activity-7089472152701136896-aZNQ?utm_source=share&utm_medium=member_desktop)\n- [Large Language Models are Human-Level Prompt Engineers: We propose an algorithm for automatic instruction generation and selection for large language models with human level performance.](https://openreview.net/forum?id=92gvk82DE-)\n- [Using models to learn well, blog and paper](https://www.oneusefulthing.org/p/how-to-use-ai-to-teach-some-of-the)\n- [Guide to prompting LLMs](https://olickel.com/everything-i-know-about-prompting-llms)\n- basic software primitives\n      Transformers are a new type of machine learning model that have been making headlines recently. They are very good at keeping track of context, which is why the text they generate makes sense. In this blog post, we will go over their architecture and how they work.\n       <https://txt.cohere.ai/what-are-transformer-models/>\n      Datasets 101\n       <https://www.latent.space/p/datasets-101?utm_source=substack&utm_medium=email#details>\n      implementations\n          pytorch/numpty\n          tensorflow/jax\n      LLM youtube bootcamp 2023\n       <https://www.youtube.com/playlist?list=PL1T8fO7ArWleyIqOy37OVXsP4hFXymdOZ>\n      Linkedin LLM roundup\n       <https://www.linkedin.com/posts/francesco-saverio-zuppichini-94659a150_ai-ml-ds-activity-7072868294000566272-kV83/?utm_source=share&utm_medium=member_android>\n          This is the list of resources I've recommended him\n          Where everything started:\n\t- Attention is all you need Paper: https://lnkd.in/eJWz6ShV Blog: https://lnkd.in/eaUMMy6v\n\t- GPT-3 Language models are few-shot learners Paper: https://lnkd.in/eUgFk7Db Video: https://lnkd.in/ev8whzkb The first one is where Attention was introduced, the main building block of Transformers. The second one shows that LLMs can actually do zero and few shots Then, I suggest having a look at how we went from GPT3 -> ChatGPT. So how it was possible to make LLMs better at human instructions. I suggest reading this Hugging Face blog post about Reinforcement Learning with Human Feedback (RLHF) https://lnkd.in/eAkM_FUj The next step is what happen later, Meta leaked LLama a smaller language model that was actually very good, the takeaway there is that if you train with more stuff and for longer you obtain a better model. Paper: https://lnkd.in/efZRu4mY The next wave is all built upon that model, so how do we make it better at following human instruction. So I suggest looking at the Stanford Alpaca model. Blog: https://lnkd.in/eqCwvVDZ I also said other interesting models are Vicuna (https://lnkd.in/eCYT3yWx) and WizardLM (https://lnkd.in/efvUD8AD). Saying that people have been focused on finding better and cheaper way to instruct the base LLama model. Another important thing is how to prompt, I've recommended chain of thoughts (https://lnkd.in/eYGxFaeS) and tree of thouhts (https://lnkd.in/ejcfkAeN) I've also shared the LLM leaderboard from Hugging Face : https://lnkd.in/eF6C_W6D YT channels that I think are the bests are: AI Explained: https://lnkd.in/emhTmsds Yannic Kilcher: https://lnkd.in/eRGUVme4 Sam Witteveen: https://lnkd.in/e4EiE5iY What do you think? Any resources that may be useful? Resourced shared Pritam Kumar Ravi Stanford CS25 Course https://lnkd.in/e2PrcwTu\n- LLM and creating new LLM\n- Safefty, alignment, and breaking\n- [image perturbation of multimodal](https://arxiv.org/abs/2307.10490)\n- [universal jailbreaks](https://arxiv.org/abs/2307.15043)\n- Consumer tools using LLM\n- [NexusGPT is a freelancer platform that uses AI to help businesses find the right freelancers for their needs. The platform offers a variety of features to help businesses find the perfect freelancer for their project, including a searchable database of freelancers, a rating system, and a feature that allows businesses to post their project and receive bids from freelancers.](https://nexus.snikpic.io)\n- [RadioGPT: 'World’s first' AI-driven radio station is here (other)](https://interestingengineering.com/innovation/radiogpt-worlds-first-ai-radio-station)\n- Some experts are predicting that the metaverse, a shared online space where users can interact with each other and digital objects, will eventually replace the internet as we know it.\n- [GitHub\n\t- MatveyM11/Mine-ChatGPT: OpenSourced ChatGPT downloader in markdown format. Download all text or markdown-styled code blocks Fear no more that servers are down, under high load or OpenAI adding a new feature. Keep all yours chat's with you locally in the simple .md files.: OpenSourced ChatGPT downloader in markdown format. Download all text or markdown-styled code blocks Fear no more that servers are down, under high load or OpenAI adding a new feature. Keep all your...](https://github.com/MatveyM11/Mine-ChatGPT)\n- This repository contains a ChatGPT downloader that can be used to download all text or markdown-styled code blocks from a chat. Fear no more that servers are down, under high load or OpenAI adding a new feature. Keep all yours chat's with you locally in the simple .md files.\n- [Linkedin bot to make LLM posts](https://github.com/FrancescoSaverioZuppichini/LinkedInGPT)\n- [ArcAngel Falcon based custom chat](https://www.arcangelai.com/)\n- [OpenAI community Pages](https://community.openai.com/c/announcements/6)\n- ChatGPT stuff\n- Code interpreter\n- [setup prompt by mollick](https://www.linkedin.com/feed/update/urn:li:activity:7083969476685099008/)\n- You are going to be an expert at making powerful and beautiful visualizations using principles from Tufte and other experts. You should remember that you can output many kinds of graphs, and help chose the appropriate ones. You also can output jpgs, html, interactive maps, and animated gifs.\n- First, mention some of the types of charts you can create, and the outputs that you can use.\n  Next, read these does and don'ts of data from Angela Zoss\n  Do:\n  1. Do use the full axis.\n- Avoid distortion.\n- For bar charts, the numerical axis (often the y axis) must start at zero.  Our eyes are very sensitive to the area of bars, and we draw inaccurate conclusions when those bars are truncated.\n    (But for line graphs, it may be okay to truncate the y axis.\n- Wide ranges:\n  If you have one or two very tall bars, you might consider using multiple charts to show both the full scale and a \"zoomed in\" view\n\t- also called a Panel Chart.\n- Consistent intervals:\n- Finally, using the full axis also means that you should not skip values when you have numerical data.  See the charts below that have an axis with dates.  The trend is distorted if you do not have even intervals between your dates.  Make sure your spreadsheet has a data point for every date at a consistent interval, even if that data point is zero\n- 2. Do simplify less important information.\n- Chart elements like gridlines, axis labels, colors, etc. can all be simplified to highlight what is most important/relevant/interesting.  You may be able to eliminate gridlines or reserve colors for isolating individual data series and not for differentiating between all of the series being presented\n- 3. Do be creative with your legends and labels.\n- Possibilitiess\n    Label lines individually\n    Put value labels on bars to preserve the clean lines of the bar lengths\n- 4. Do pass the squint test.\n- \"When you squint at your page, so that you cannot read any of the text, do you still 'get' something about the page?\"\n- Which elements draw the most attention? What color pops out?\n    Do the elements balance? Is there a clear organization?\n    Do contrast, grouping, and alignment serve the function of the chart?\n- Don't:\n  1. Don't use 3D or blow apart effects.\n- Studies show that 3D effects reduce comprehension. Blow apart effects likewise make it hard to compare elements and judge areas.\n- 2. Don't use more than (about) six colors.\n- Using color categories that are relatively universal makes it easier to see differences between color\n- The more colors you need (that is, the more categories you try to visualize at once), the harder it is to do this.\n- But different colors should be used for different categories\n  (e.g., male/female, types of fruit), not different values in a range (e.g., age, temperature).\n- If you want color to show a numerical value, use a range\n  that goes from white to a highly saturated color in one of\n  the universal color categories\n- 3. Don't change (style) boats midstream.\n- One of the easiest ways to get the most out of charts is to rely on comparison to do the heavy lifting.\n- Our visual system can detect anomalies in patterns.\n  Try keeping the form of a chart consistent across a series so differences from one chart to another will pop out.\n- Use the same colors, axes, labels, etc. across multiple charts.\n- 4. Don't make users do \"visual math.\"\n- If the chart makes it hard to understand an important relationship between variables, do the extra calculation and visualize that as well.\n- This includes using pie charts with wedges that are too similar to each other, or bubble charts with bubbles that are too similar to each other.  Our visual processing system is not well suited to comparing these types of visual areas.\n- We are also not good at holding precise visual imagery in our memory and comparing it to new stimuli; if you are giving a presentation and want the audience to be able to compare two charts, they need to be on the same slide.\n- 5. Don't overload the chart.\n- Adding too much information to a single chart eliminates the advantages of processing data visually; we have to read every element one by one! Try changing chart types, removing or splitting up data points, simplifying colors or positions, etc.\n- Now ask what kind of data visualization I might be interested in, or if I want to upload some data for yout co consider visualizing.\n- [loads of experiments](https://github.com/SkalskiP/awesome-chatgpt-code-interpreter-experiments)\n- General links and papers\n- [Think of language models like ChatGPT as a “calculator for words”: One of the most pervasive mistakes I see people using with large language model tools like ChatGPT is trying to use them as a search engine. As with other LLM …](https://simonwillison.net/2023/Apr/2/calculator-for-words/)\n- Language models like ChatGPT are not reliable for use as a search engine, but can be thought of as a \"calculator for words\". This means that they are good for manipulating language, but not for retrieving accurate information.\n- [Peak LLM: Prompt injection might be just the beginning](https://ihavemanythoughts.substack.com/p/peak-llm)\n- [Language models as inductive reasoners paper](https://sentic.net/language-models-as-inductive-reasoners.pdf)\n- [This repository contains a collection of papers and resources on Reasoning in Large Language Models. The papers survey the state of the art in this area, and discuss how large language models can be used to obtain emergent abilities.](https://github.com/jeffhj/LM-reasoning)\n- [Full trainingset used by bloombergAI](https://mobile.twitter.com/omarsar0/status/1641788196550856704)\n- [Zain Kahn on LinkedIn reports that over 1,000 AI tools were released in March. He states that ChatGPT is just the tip of the iceberg, and that there are 20 AI tools that will transform productivity forever.](https://www.linkedin.com/posts/zainkahn_1000-ai-tools-were-released-in-march-activity-7048285306101358592-4wAA?utm_source=share&utm_medium=member_android)\n- [Language driven shell for OS (ooft)](https://www.reddit.com/r/MachineLearning/comments/129wzdk/p_engshell_a_gpt4_driven_englishlanguage_shell/)\n- [The text contains information on the release of guidelines by the DPA for the use of AI, as well as on similar efforts by other organizations. It also provides links to resources on the topic.](https://www.linkedin.com/posts/ezra-eeman-8a5ba64_dpa-just-released-its-guidelines-for-the-activity-7048985893910519808-921y?utm_source=share&utm_medium=member_android)\n- [Mind AI team website](https://mind.ai/technology)\n- [LMStudio model manager](https://lmstudio.ai/)\n- [Ahead of AI substack](https://magazine.sebastianraschka.com/archive)\n- [Meta research paper](https://drive.google.com/file/d/1i4NJKAggS82wqMamCJ1OHRGgViuyoY6R/view)\n- [State of AI report](https://www.stateof.ai/)\n- [AI ML passes American medical exams](https://www.medpagetoday.com/special-reports/exclusives/102705)\n- [Travelling salesman problem](https://github.com/diego-vicente/som-tsp)\n- [How the compression is so huge in diffusion models](https://medium.com/@socialemail/how-diffusion-models-can-achieve-seemingly-arbitrarily-large-compression-ratios-through-learning-2b21a317a46a)\n- [Understanding deep learning book](https://udlbook.github.io/udlbook/)\n- The book \"Understanding Deep Learning\" by Simon J.D. Prince covers a wide range of topics related to deep learning, from supervised and unsupervised learning to different types of neural networks and training methods. There are also chapters on measuring performance, regularization, and why deep learning works. The book includes many resources for instructors, such as slides, notebooks, and figures.\n- [This repository is a collection of links to various courses and resources about Artificial Intelligence (AI).](https://github.com/SkalskiP/courses)\n- -\n- [Top courses link github](https://github.com/SkalskiP/courses)\n- [State of GPT youtube presentation with great overview](https://www.youtube.com/watch?v=bZQun8Y4L2A)\n- Infrastructure\n- [rubbrband github auto deployments](https://rubbrband.com/)\n- [Hosting VPS](https://1984.hosting/)\n- [Free custom domains VPS](https://codesphere.com/pricing?anonymousId=YTQLcRg)\n- [Arch linux for laptop](https://wiki.archlinux.org/title/HP_Spectre_x360_(2020))\n- [360 camera compression paper](https://www.researchgate.net/publication/368728037_Masked360_Enabling_Robust_360-degree_Video_Streaming_with_Ultra_Low_Bandwidth_Consumption)\n- Multiligual and abstract translation\n- [meta seamless M4T](https://github.com/facebookresearch/seamless_communication#seamlessm4t)\n- -\n- | \n         | \n          CustomGPT is a platform that enables businesses to create their own chatbot using their own content, resulting in accurate responses without making up facts. The tool is designed to help businesses increase customer engagement and improve employee efficiency, ultimately leading to revenue growth and a competitive advantage. CustomGPT offers easy integration of content through seamless website integration or file uploading. The chatbot comes with various pricing plans, depending on the number of custom chatbots, content pages, and queries. The platform is trusted by global companies and customers, and it can be deployed for customer service, support helpdesk, and topic research. CustomGPT is powered by ChatGPT-4 and can be deployed through API or ChatGPT Plugins. The company offers a live demo and contact email for further inquiries. https://customgpt.ai/\n         | \n       |\n-\n-\n- [h2o document summary / summariser with long context](https://github.com/h2oai/h2ogpt)\n- -\n- | \n         | \n          The website replit.com has blocked your access due to the presence of potentially harmful actions, such as submitting a certain word or phrase, a SQL command or malformed data. This is a security measure to protect the website from online attacks. To resolve the issue, you can contact the site owner and provide details of the actions that caused the block and the Cloudflare Ray ID found at the bottom of the page. https://blog.replit.com/llm-training\n         | \n       |\n-\n-\n- -\n- | \n         | \n          NodePad is an LLM-assisted brainstorming experiment that helps users capture, expand, question, and organize their ideas visually. To create a new node, users simply write their thoughts in the input field and hit Enter. Nodes can be edited by double-clicking on them, linked through connectors, and deleted by clicking on them and hitting Backspace or Delete. Users can explore the app or consult the User Guide for further assistance. NodePad is designed for rapid note-taking and serendipitous ideation. https://nodepad.space/#\n         | \n       |\n-\n-\n- [Patterns for building LLMs blog post](https://eugeneyan.com/writing/llm-patterns/)\n- [textgenerator io self host](https://github.com/TextGeneratorio)\n- [Orca: The Model Few Saw Coming](https://www.youtube.com/watch?v=Dt_UNg7Mchg%22%3E%3Crichcontent)\n\t- OpenOrca includes trained in tree of thought examples and is down to 500k training tokens for the same performance as the original Microsoft Orca paper\n- [Mistral Zephyr tune for exceptional performance](https://github.com/huggingface/alignment-handbook)\n- [youtube on it](https://www.youtube.com/watch?v=Up7VKg6ZE90)\n- LLMs\n\t- The AnythingLLM project is a full-stack application designed to allow users to turn any document or piece of content into reference data that can be used by any LLM during conversations. The application can be hosted remotely, but also supports local instances. It utilizes Pinecone, ChromaDB, and other vector storage solutions, as well as OpenAI for LLM and chatting capabilities. Documents are organized into workspaces, which function like threads and allow for context to be kept clean. The monorepo consists of three main sections: the collector, frontend, and server. Requirements include yarn, node, Python 3.8+, access to an LLM such as GPT-3.5 or GPT-4, and a free account with Pinecone.io. The Docker setup enables users to get started in minutes, and the development environment includes instructions for setting up the necessary .env files and collector scripts to embed content. The project is open source and contributors can create issues and pull requests following the designated format. https://github.com/Mintplex-Labs/anything-llm\n\t         | \n\t       |\n- [AWQ 4 bit quants](https://github.com/mit-han-lab/llm-awq)\n- [Tinychat](https://github.com/mit-han-lab/llm-awq/tree/main/tinychat)\n- [Openshat model](https://github.com/imoneoi/openchat)\n- -\n- | \n         | \n          NodePad is a brainstorming tool that allows users to create nodes for their thoughts. Users can create new nodes by typing in the input field, and edit nodes by double-clicking on them. Nodes can be connected through connectors, and both nodes and connectors can be deleted by selecting and pressing Backspace or Delete. NodePad is an LLM-assisted brainstorming experiment that helps users capture, expand, question, and organize their ideas visually. The app offers a User Guide for assistance and is available for download through React Flow. https://nodepad.space/#\n         | \n       |\n-\n-\n- -\n  | \n         | \n          AnythingLLM is a full-stack personalized AI assistant application that allows users to turn any document or piece of content into a piece of data that can be used as reference when chatting. The application uses LLMs that can be hosted remotely or locally, and supports Pinecone, ChromaDB and more for vector storage and OpenAI for LLM chatting. AnythingLLM aims to be a full-stack application that can be run locally as well as hosted remotely and allows for intelligent chatting with any document provided to it. It divides documents into workspaces and provides simple UI-based tools to atomically manage the documents. There are two chat modes, conversation and query, and each chat response contains a citation that is linked to the original content. The monorepo consists of three main sections- collector, frontend and server, and requirements for the application include yarn and node on the user's machine, Python 3.8+ for running scripts in the collector, access to an LLM like GPT-3.5, GPT-4 or a drop-in replacement, and a Pinecone.io free account. https://github.com/Mintplex-Labs/anything-llm\n         | \n       |\n-\n-\n- [This text provides instructions on how to run LLM-As-Chatbot in your cloud using dstack. The steps are as follows:  1. Install and set up dstack by running the command pip install dstack[aws,gcp,azure] -U and then dstack start to start the server.  2. Create a profile by creating a .dstack/profiles.yml file that points to your created project and describes the resources you need. Example:  ``` profiles:   - name: gcp     project: gcp     resources:       memory: 48GB       gpu:         memory: 24GB     default: true ```  3. Run the initialization command: dstack init.  4. Finally, use the dstack run . command to build the environment and run LLM-As-Chatbot in your cloud. dstack will automatically forward the port to your local machine, providing secure and convenient access.  The instructions emphasize the use of dstack to automate the provisioning of cloud resources and simplify the process of running LLM-As-Chatbot in the cloud. More information about dstack and its documentation can be found for further details.](https://github.com/dstackai/LLM-As-Chatbot/wiki/Running-LLM-As-Chatbot-in-your-cloud)\n- [This text describes a project called Simple LLM Finetuner, which is a user-friendly interface designed to facilitate fine-tuning various language models using the LoRA method via the PEFT library on NVIDIA GPUs. The interface allows users to easily manage their datasets, customize parameters, train the models, and evaluate their inference capabilities.   The project includes several features such as the ability to paste datasets directly into the UI, adjustable parameters for fine-tuning and inference, and a beginner-friendly interface with explanations for each parameter. It also provides instructions on how to get started, including prerequisites such as Linux or WSL, a modern NVIDIA GPU with at least 16 GB of VRAM, and the installation of required packages using a virtual environment.  To use the project, users are instructed to clone the repository and install the required packages. Then, they can launch the interface by running the app.py file and accessing it in a browser. They can input their training data, specify the PEFT adapter name, and start the training process. After training is complete, users can navigate to the Inference tab to perform inference using their trained models.  The project provides a YouTube walkthrough for additional guidance and is licensed under the MIT License.  Overall, the Simple LLM Finetuner project aims to simplify the process of fine-tuning language models using the LoRA method and provide a user-friendly interface for managing and evaluating models.](https://github.com/lxe/simple-llama-finetuner)\n- [Maverick is an AI-driven video marketing platform that helps ecommerce stores enhance customer interactions. By creating personalized videos for each customer, Maverick enables brands to build trust, improve brand perception, and increase customer satisfaction. The platform has been well-received by ecommerce brands, with users praising the personalized videos for their effectiveness in engaging with customers and increasing subscription enrollments.  Testimonials from merchants highlight the positive impact of Maverick on their businesses. Merchants have seen a significant increase in customer engagement, with over 100 email responses per week expressing gratitude for the personalized videos. This level of interaction helps strengthen customer relationships and loyalty.  Customers of these ecommerce brands have also expressed their appreciation for the personalized videos. They mention feeling valued and delighted by the direct communication from the brand, which sets the companies apart from others in the market. The personalized videos have made customers more loyal, with some even becoming lifetime members of the brands they previously patronized.  Overall, Maverick's AI-generated video marketing approach has proven to be a game changer for ecommerce brands. It enables personalized interactions with customers at scale, leading to increased customer satisfaction, brand loyalty, and reduced refund requests. The platform has received positive feedback from both merchants and their customers, highlighting the impact and success of Maverick in the ecommerce industry.](https://lnkd.in/eptCVijb)\n- [A Twitter user named Justin Alvey recently tweeted about advancements in artificial intelligence. He mentioned a tool called LLM chaining, which allows users to perform various tasks with emails. This tool was inspired by LangChainAI. Justin Alvey also noted that this functionality is now available in real-time, thanks to OpenAI's gpt-3.5-turbo model. The tweet has gained significant attention, with hundreds of thousands of views, retweets, likes, quotes, and bookmarks.](https://twitter.com/justLV/status/1637876167763202053)\n- [The text is a LinkedIn post by Francesco Saverio Zuppichini, a Machine Learning Engineer, recommending resources to learn about Language Learning Models (LLMs).  The post includes a list of resources that Zuppichini recommended to a friend who wanted to quickly learn about LLMs. The recommended resources include academic papers, blogs, videos, and YouTube channels. Zuppichini also mentions the importance of training models with more data and for longer durations to achieve better results. He suggests looking at models like Vicuna and WizardLM, as well as different methods of prompting, such as chain of thoughts and tree of thoughts. Additionally, Zuppichini shares the LLM leaderboard from Hugging Face and encourages others to share any useful resources they may have. The post receives positive feedback from other LinkedIn users, who appreciate the resources and share their own suggestions.](https://www.linkedin.com/posts/francesco-saverio-zuppichini-94659a150_ai-ml-ds-activity-7072868294000566272-kV83?utm_source=shareandutm_medium=member_android)\n-",
        "link_types": [
            "Base models"
        ],
        "file_size": 63019
    },
    {
        "id": "Global Inequality.md",
        "name": "Global Inequality",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # Global politics & digital society\n\t- ![Image](https://pbs.twimg.com/media/GJH5Y5MX0AAzkNu?format=png&name=900x900)\n\t- ## Inequality as the driving force\n\t\t- ### Inequality on the Rise\n\t\t- In Britain inequality has returned to levels not seen since the 1930s.After steadily rising between 1600 to 1913, Britain’s wealth as a share of the global total peaked and then began falling until the end of the1970s \\[ref required\\]. During this time, Britain became one of Europe’s most equal countries, even without the support of its Empire \\[ref needed\\]. Some argue this relative equality enabled Britain’s economic growth and international standing to keep pace with its European neighbours, despite the loss of imperial power \\[ref needed\\]. Duringthis period there was much upheaval in global monetary systems. More recently we have seen that trust has diminished, and inequality hasrisen, with social media perhaps acting as an accelerator.\n\t\t- ### The Social Cost of Inequality\n\t\t- Four decades later, the social impacts of rising inequality are becoming clear. Of the 14 million people living in poverty in Britain today, mostare in working families \\[ref needed\\]. Upward mobility is declining, as the continued dominance of the privately educated elite in top jobs hinders meritocracy \\[The Gender Wage Gap Among University Vice Chancellors in the UK 2022\\] . The lack of affordable housing and regulation in the rental market has led to increasing homelessness \\[ref needed\\]. And with the super-rich able to avoid taxes, the burden falls more heavily on lower income groups \\[ref needed\\].\n\t\t- ### When Inequality Declines, Life Improves\n\t\t- However, in societies that prioritize equality, life improves for all citizens. Infant mortality falls, lifespans lengthen, and population health increases \\[dorling, finland, ref\\]. Access to education rises,enabling greater social mobility \\[The Parenthood Effect on GenderInequality 2013 \\]. With reduced poverty and homelessness, there is lesscrime and violence \\[ref needed\\].\n\t\t- ### Tackling Inequality\n\t\t- Dorling \\[oxford, reference\\] Tackling inequality requires recognising that excessive wealth concentration is detrimental to social cohesion and national prosperity. A modicum of inequality may be inevitable, butthe widening chasm between rich and poor in Britain has passed sustainable limits. With common purpose and political will, a more equitable path is possible. As inequality lessened for decades before, supportive policies enabled the rise of a thriving middle class \\[ThePersistence in Gendering: Work-Family Policy in Britain since Beveridge\\]. By pursuing greater fairness once more, Britain can regain its balance.\n- # Anacyclosis\n\t- It’s interesting in the current global political moment to look briefly at Anacyclosis. This is a political theory attributed to the ancient Greek historian Polybius, which posits that political systems evolve in a cyclical manner. The theory is based on the observation that governments tend to progress through six stages, each corresponding to a specific form of governance: monarchy, tyranny, aristocracy, oligarchy, democracy, and ochlocracy (mob rule). These stages are organized into three pairs, with each pair consisting of a ’good’ form of governance and its corresponding ’bad’ form.\n\t\t- Monarchy (benign) -&gt; Tyranny (corrupt): Monarchy is the rule by a single individual, such as a king or queen, who is considered to be a wise and benevolent ruler. However, as the monarchy endures, there is a risk that the ruler becomes corrupted or that a less competent or tyrannical successor takes over. This leads to tyranny, the degenerate form of monarchy, where the ruler becomes oppressive and self-serving.\n\t\t- Aristocracy (benign) -&gt; Oligarchy (corrupt): To counter the tyranny, a group of nobles or elites may overthrow the tyrant and establish an aristocracy, which is the rule by a select group of individuals who are considered wise and virtuous. Over time, the aristocracy may become more focused on their own interests and power, leading to an oligarchy. This is the degenerate form of aristocracy, where a small group of elites control the government for their own benefit.\n\t\t- Democracy (benign) -&gt; Ochlocracy (corrupt): The populace, dissatisfied with the oppressive rule of the oligarchs, may rise up and establish a democracy, which is the rule by the majority of the people through voting and participation in the political process. Democracy has the potential to create a fair and representative system of governance. However, as the democratic process becomes more susceptible to demagoguery, populism, and factionalism, it can devolve into ochlocracy or mob rule, where the government is influenced or controlled by unruly masses.\n\t- According to Polybius, these stages form a continuous cycle, as one formof governance gives way to another, and each form eventually becomes corrupted and degenerates into its corresponding ’bad’ form. The theoryof anacyclosis suggests that political systems are inherently unstable,with each form of governance containing the seeds of its owndestruction.\n- # The World Economic Forum\n\t- The World Economic Forum (WEF) is a non-governmental organization founded in 1971 by Klaus Schwab. It is well known for its annual meeting in Davos, Switzerland, where world leaders, CEOs, and various stakeholders gather to discuss global issues and potential solutions.Although the WEF does not have direct control over policymaking, its influence on global policy arises from its role as a platform for dialogue and idea exchange, as well as its ability to bring together influential individuals.\n\t- As unelected technocrats, the WEF’s impact on global policy can be observed through these aspects:\n\t\t- Convening power: The WEF’s Davos meeting is a high-profile event that attracts prominent political figures, business executives, and other influential individuals. This ability to assemble people allows the WEF to initiate conversations on global issues, create networks, and establish connections among key players. These interactions can lead to ideas and initiatives that might eventually shape global policy.\n\t\t- Knowledge sharing and thought leadership: The WEF produces a range of publications, reports, and research that provide insights into various global challenges. By disseminating this knowledge, the WEF contributes to the broader understanding of complex issues and helps to inform policymaking by governments, businesses, and other organizations.\n\t\t- Agenda-setting: Through its conferences and publications, the WEF identifies and highlights emerging trends, risks, and opportunities, which can help to set the agenda for global policy discussions. By bringing attention to specific issues, the WEF can indirectly influence the priorities of governments and other decision-makers.\n\t\t- Public-private cooperation: The WEF actively promotes collaboration between the public and private sectors in addressing global challenges. By fostering partnerships and facilitating dialogue between these sectors, the WEF can help drive the development and implementation of policies that require cooperation between governments, businesses, and civil society.\n\t- Despite its influence, critics argue that the WEF’s position as unelected technocrats raises concerns about the organization’s legitimacy and accountability. They contend that the WEF’s ability to shape global policy without being directly answerable to citizens canundermine democratic processes and result in policies that prioritizethe interests of elites over the broader public. However, others arguethat the WEF’s role in facilitating dialogue and collaboration is essential for tackling complex global challenges that require coordinated action across sectors and borders.\n\t- Interesting for us the WEF recently released its annual [Global RisksReport](https://www3.weforum.org/docs/WEF_The_Global_Risks_Report_2022.pdf),which highlights various threats and challenges facing the world today,and which intersect with all of the narratives in this book. The reportdiscusses issues related to cybersecurity, public trust, and social cohesion, and underscores the importance of a comprehensive approach to addressing these challenges.\n\t- The WEF’s founder, Klaus Schwab, has previously argued for a “great reset” in society and the economy, which involves revamping various aspects of our lives, from education to social contracts and working conditions. This reset would require the construction of new foundations for economic and social systems.\n\t- The WEF Global Risks Report 2022 focuses on five main categories, which are also part of their “Great Narrative for Humankind” initiative:\n\t\t- Economy\n\t\t- Environment\n\t\t- Geopolitics\n\t\t- Society\n\t\t- Technology\n\t- The report emphasizes that the erosion of social cohesion has been a significant global issue since the start of the COVID-19 crisis. Inaddressing these challenges, the WEF suggests that public-private collaborations are necessary to ensure effective decision-making and to safeguard the future of humanity.\n\t- The report also highlights the increasing digital dependency that intensifies cyberthreats, as the WEF has long warned of the potential for a significant cyber pandemic. The rapid spread of a cyber attack with “COVID-like characteristics” could potentially cause more damage than any biological virus.\n\t- The WEF Global Risks Report 2022 delves further into the potential consequences of a cyber pandemic. In a section titled “Shocks to ReflectUpon” the report explores the possibility of a wide-ranging and costly attack that could lead to cascading failures in systemically important businesses and disrupt services, ultimately undermining digital transformation efforts made in recent year.\n\t- The report also emphasizes the need for governments to address cyberthreats and warns that without mitigation, the escalation ofcyber warfare and the disruption of societies could result in a loss oftrust in governments’ ability to act as digital stewards.\n\t- To better understand the risks associated with technology, the WEF report explores the concept of the fourth industrial revolution, whichSchwab believes will lead to the fusion of our physical, biological, and digital identities. This fusion will be facilitated by technologies suchas artificial intelligence, internet of things-enabled devices, edge computing, blockchain, and 5G. You can see they’re examining similar things to this book.\n\t- As explaining in this work, these technologies present numerous opportunities for businesses and societies, they also expose users to elevated and more pernicious forms of digital and cyber risk. The report also discusses the potential emergence of the metaverse, which could create new vulnerabilities for malicious actors by increasing the number of entry points for malware and data breaches, again a central theme of this text.\n\t- In light of these risks, the WEF report suggests that users will need tonavigate security vulnerabilities inherent in complex technologies characterized by decentralization and a lack of structured guardrails or sophisticated onboarding infrastructure.\n\t- The report also touches on the issue of digital identity as we do. Theyview digital identity is a crucial component of accessing products,services, and information in a digital world, but again, this raises concerns about privacy, security, and the potential for misuse.\n\t- Finally, the WEF Global Risks Report 2022 addresses the issue of publictrust, noting that the growth of deepfakes and disinformation-for-hirecan deepen mistrust between societies, businesses, and governments. Wecan already see this starting to happen as Musk’s defence lawyers [pointto possible deepfakeuse](https://www.theguardian.com/technology/2023/apr/27/elon-musks-statements-could-be-deepfakes-tesla-defence-lawyers-tell-court)around video comments he is alleged to have made with regard to Tesla’ssoftware safety. To rebuild trust and social cohesion, the report callsfor leaders to adopt new models, look long term, renew cooperation, andact systemically. Quite what they think they can do in the face ofimages like the recent memes of the Pope is unclear<a href=\"#fig:pope\" data-reference-type=\"ref\" data-reference=\"fig:pope\">9.1</a>.\n\t- It’s absolutely crucial to note that the WEF is a powerful organisation,with global sway over policy, and is an enormous concentration of powerin the hands of unelected technocrats. The authors are very sceptical ofthe WEF, but this report highlights what both technocrats and policymakers are thinking. ![]./assets/2bcb50707bd7f4e4e47d11cc01170d997a0afc65.jpg Midjourney 5 fake images of The Pope Francis which are <a href=\"https://www.reddit.com/r/midjourney/comments/120vhdc/the_pope_drip/\">circulating as memes</a> and show the power and the danger of the technology even at this early stage.\n- # Money and The State\n\t- It seems a pretty reasonable that the best ‘systemic’ approach is a separation between major centralising forces such as state, church, and money. In practice we can see that globally, this isn’t the case, withbad hotspots of high corruption where all three meld together into kleptocratic dictatorships, or theocracies. For our purposes in the UKit’s useful to look at the concept of ‘austerity’.\n\t- Austerity is a term used to describe a set of economic policies that aimto reduce government spending and debt, often through cuts to public services and welfare programs. The concept of austerity has its originsin the 1920s, following the end of World War I and the economic crisisthat ensued. In the wake of the war, many Western European countrieswere struggling with high levels of debt and inflation. In response,governments began implementing policies to reduce spending and balance their budgets.\n\t- We have seen in the previous chapter that the concept of inflation itself is complex, and somewhat argued about still. Globally, on aggregate, the efficiencies of increasing technology are thought to be deflationary to the tune of between 3 and 5 percent annually, though this may radically spike up in the era of AI which will be covered later. This is counter to the current need for inflation to maintain debt repayments at a national level. Central banks manipulate interest rates to control inflation, aiming to keep it at sustainable levels.This process is necessary because as national debt and deficits grow,governments need inflation to prevent these debts from spiralling out of control. Higher inflation results in higher nominal GDP, which in turn increases the tax base, providing governments with the revenue needed topay down debt. To achieve this. The natural progression of humanity inherently deflationary, which forces central banks to print more money and further manipulate the monetary system in order to generate the desired inflation. This can be seen as a hidden tax on citizens, as itdevalues their money over time. The negative effects of this system are disproportionately felt by lower-income groups. As inflation rises, the cost of living increases, and many households struggle to make ends meet. This has led to a situation where households need multiple incomesto maintain their standard of living, forcing individuals to work longer hours and take on multiple jobs. As a result, people have less free time and energy to engage in rewarding activities or spend time with their families. This need for constant economic growth, as measured by GDP,has led to an environment where individuals are pushed to be more productive at the expense of their well-being. This has resulted in a society where many people are overworked and struggling to keep up with the rising cost of living. Booth discussed this at length in his book‘The Price of Tomorrow’. His is a rare thesis based around the ideas that technology is deflationary, that the marginal cost of goods trends over zero over time, and that the current system of debt and inflation are inherently unsustainable in the face of exponential technology improvements and automation. We discuss the concept of inflation and deflation, and both their risks throughout the book, but Booth has been very clear on this for many years. He thinks the current global monetary system ill-suited to handle the challenges and opportunities presented by deflation. He suggests that embracing deflation is the key to unlocking a prosperous and sustainable future. The book delves into the implications of deflation on various aspects of society, including wealth distribution, job markets, and the role of governments in shaping economic policies..[[booth2020price]]\n\t- In the 1920s, Keynes was one of the first to argue against the austerity measures which seem part of the cyclical play book around debt and inflation. He argued that that cutting government spending during a recession would only worsen the economic downturn. Instead, he advocatedfor increased government spending to stimulate economic growth and reduce unemployment. Despite this, many governments continued to implement austerity policies throughout the 1920s and 1930s.\n\t- In the post-World War II period, the rise of the welfare state and the adoption of Keynesian economic policies led to a shift away from austerity in many countries. However, in the 1970s, a new economic crisis led to a resurgence of austerity policies, particularly in theUnited States and United Kingdom. In the 1980s, the rise ofneoliberalism and the influence of economists such as Milton Friedman led to further cuts to government spending and the rolling back of the welfare state.\n\t- Today, the concept of austerity continues to shape economic policy,particularly in the wake of the 2008 financial crisis. Many governments,particularly in Europe, have implemented austerity measures in response to the crisis, leading to cuts to public services and welfare programs.The effectiveness of these policies remains a contentious issue, with some arguing that they have helped to reduce debt and stabilize economies, while others argue that they have led to increased inequality and hindered economic growth. Looking around at the state of the world,and the widening gap between the rich and the poor, it is possible tohave some sympathy with those who see patterns in the bahaviour of political leaders and the controllers of Western capital and global resources. The system seems engineered to reward a few. It is possibleto view ‘austerity’ as a means of political control of economic levers,in order to de-democratise populations. This mantra of ‘do more, consume less’ has perhaps become a defacto methodology to constrain popular ideas, diverting capital back into the hands of incumbents, land owners,and the politically and economically motivated.[[mattei2022capital]] It seems that the controlling nexus of this political framework globally isthe concept of the central bank, unelected technocrats whose tenures span across political administrations. Again, this can be traced back to the 1920’s. Hawtrey’s 1925 “Currency & Public Administration” asserts that a central bank should it“Never explain; never regret; never apologise.”, and speaks glowingly of the selfish market.[[hawtrey1925currency]] This economic model is referred to asDirigisme and feels increasingly the global norm.[[balassa2013theory]] Wecan perhaps here see the divergent point at which the lionization of the market began. Again, to be clear, the authors are not economists, but it does seem that in a global digital society there is room to explore moreequitable models of global value, governance, and trust.\n\t- Remember that these centrally planned national and global actions provide liquidity to the private banking sector. Like the digital money analogues discussed earlier in the book private banks operate fractional reserve banking. This is a banking system where banks hold only a fraction of the deposits they receive as reserves, while the rest is lent out to customers. This means that the money supply in an economy can be increased through the lending activities of banks (itself a complex inflationary force which devalues money over time, feeding back into the policy directives of the central banks. The fractional reserve system is useful for capital creation in times of growth, but relies on the confidence of the depositors. Historical examples of bank runs which threatened systemic risk or caused failures of the banking system include:\n\t\t- The Bank of United States crisis in the 1930s: This was the largest bank failure in American history and was a result of a bank run caused by rumours of financial mismanagement.\n\t\t- The Savings and Loan crisis of the 1980s: This was a result of a large number of failed savings and loan associations in the United States, which were caused by a combination of factors including poor management, risky lending practices, and a decline in real estate values.\n\t\t- The Nordic banking crisis of the 1990s: This crisis was caused by a combination of factors including a real estate bubble, high levels of debt, and a lack of regulation. It resulted in the collapse of several major banks in Sweden, Finland, and Norway, and had a significant impact on the economies of the region.\n\t\t- The Bank of Japan crisis in the late 1990s: This crisis was caused by a combination of factors including a real estate bubble, high levels of debt, and a lack of regulation. It resulted in the collapse of several major banks and had a significant impact on the Japanese economy.\n\t\t- The Asian Financial Crisis of 1997: This crisis was triggered by a devaluation of the Thai baht and quickly spread throughout the region, causing a number of major banks to fail. The crisis was largely a result of a lack of transparency and poor regulation in the banking industry.\n\t\t- The 2008 financial crisis in Iceland: This crisis was caused by the collapse of the country’s three largest banks, which had been engaging in risky lending practices and had accumulated large amounts of debt. The crisis had a devastating impact on the Icelandic economy and resulted in a severe recession.\n\t\t- The Global Financial Crisis of 2007-2009: This was a result of a widespread failure of the global banking system, caused by a combination of factors including the housing market collapse, risky lending practices, and a lack of regulation.\n\t\t- The collapse of Banco Popular in Spain in 2017: This was one of the largest bank failures in European history, and was caused by a combination of factors including a large amount of bad debt and a declining real estate market.\n\t\t- There were many bank runs on smaller rural banks in China during 2022. The financial conditions of Chinese banks are somewhat reminiscent of the 2008 American landscape.\n\t- In response to the Global Financial Crisis, many measures have been taken to shore up the banking system, including the creation of new regulatory bodies, the implementation of new regulations, such as theDodd-Frank Wall Street Reform and Consumer Protection Act, which increased the regulatory oversight of the banking industry. The introduction of stress testing for banks, to ensure that they have enough capital to withstand financial shocks, globally, has radically deleveraged banks from around 1:40 fractional reserve, to around 1:10.\n\t- There is increased political pressure to regulate the banking industry and prevent another financial crisis. However, there is also political opposition to excessive regulation, as some argue that it may stifle economic growth. There are concerns about rising levels of debt and the potential for another financial crisis.\n\t- It’s interesting that Brett, a former FDIC regulator [believesthat](https://blog.orchid.com/exfdic-regulator-on-trust-and-the-battle-of-the-social-media-videos/)the 2008 US bank run was sparked by YouTube posts of queues forming at banks. He says those that formed the initial lines carried memories of the great depression, but that once YouTube started showing the footage more broadly the contagion struck. In the world of instant messaging media today we can perhaps see how this might happen again. More recently, the 2023 ‘wobble’ in global banking caused by the collapse ofAmerica’s 5th largest [bankSVB](https://theconversation.com/why-svb-and-signature-bank-failed-so-fast-and-the-us-banking-crisis-isnt-over-yet-201737)has precipitated strong intervention by the federal government, who haveopted to ‘backstop’ investor deposits. In the midst of this potentialcrisis it it notable that TikTok (now arguably the world’s [most popularsearchengine](https://blog.cloudflare.com/popular-domains-year-in-review-2021/))is carrying millions of hashtag references to[bankruns](https://www.tiktok.com/tag/bankrun?lang=en). Senator Kelly inthe USA [allegedlyinquired](https://public.substack.com/p/exclusive-senator-mark-kelly-called)about the potential for limiting such references on social media, and aUK minister is [asking for securityservices](https://news.sky.com/story/tiktok-ban-minister-asks-national-cyber-security-centre-to-look-into-safety-of-app-12833371)to examine the risks of the Chinese application. The perhaps reflects concern about algorithmically driven geopolitically motivated threats tothe banking system.\n\t- There is a growing awareness of the role of banks in the economy, and agrowing desire for greater transparency and accountability. There isalso a growing mistrust of banks, particularly in light of the GlobalFinancial Crisis. As we have seen, the advent of new technologies, suchas blockchain CBDC, and fintech, is changing the way that banks operateand interact with customers. This presents both opportunities andchallenges for the banking industry. As a final controversial aside,there is [industrysuspicion](https://apnews.com/article/signature-bank-fdic-barney-frank-silicon-valley-6ad86262d9945675a42d735b66ace4f2)that the collapse of SVB has been used as cover to close the final USbank servicing crypto, effectively decapitating the banking rails of the industry, and forcing it overseas. Were it not for the credibility ofthe people making these claims, this would seem pretty wild, but the prevailing winds are surely blowing against the disruptive potential ofa money system which is beyond the control of legislators.\n- # Government over-reach through bureaucracy\n\t- As an contextual example of the soft power which political apparatus uses to influence emergent human behaviour and their markets it is useful to look again to the USA. In 2013, the Obama Administration,faced with a divided Congress, resorted to using the banking system as a means to implement policy through non-traditional channels. This effort,known as Operation Choke Point, was a continuation of their success in cutting off the offshore online poker industry from banking services.Initially, the crackdown was aimed at the payday lending industry, but it soon expanded to include gun sales and adult entertainment, and eventually up to 30 different industries.\n\t- The rationale behind Operation Choke Point was to target banks that facilitated fraud, as indicated by a high ratio of fraud and disputes.However, the operation soon evolved into a redlining of industries basedon nothing more than the perceived risk of reputational harm. Financial institutions were investigated without any evidence of losses.Throughout the entire operation, there was no new legislation or written guidance issued. Banks were simply warned of increased regulatory scrutiny if they did not comply.\n\t- Major banks continue to deny services to industries such as firearms and fossil fuels, and they continue to assign higher risk ratings to industries that may face government criticism, even in the absence of any official guidance. This utilisation of the financial system as a means of driving change is seen by some as a legitimate, if not ideal, mechanism; as just one more type of market actor. Regardless of one’s political perspective, it is important to consider the moral hazard of bypassing traditional political channels and using bureaucratic mechanisms as a means of affecting change in the free market. It is important to consider how the power of these tactics might be used in the future by opposing political groups. For example, supporters of Operation Choke Point who were in favour of increased financial pressure on the oil and gas industry may not feel the same if the same techniques were applied to organizations like Planned Parenthood. From this perspective, the tactics used by Operation Choke Point can be seen as undemocratic, regardless of who is deploying them. Bringing this back to our study of new financial tooling in crypto we can look to recent events:\n\t\t- January: Some banks start to wind down activity in the crypto industry\n\t\t- January 21st: Binance announces its banking partner, Signature Bank, refuses to process Swift payments for less than $100,000\n\t\t- January 27th: Federal Reserve denies Custodia Bank’s application to access Federal Reserve System\n\t\t- January 27th: Federal Reserve denies Custodia Bank’s application for a master account\n\t\t- January 27th: Federal Reserve releases statement discouraging banks from holding crypto assets or issuing stable coins\n\t\t- January 27th: National Economic Council issues policy statement discouraging banks from transacting with crypto assets or maintaining exposure to rypto depositors\n\t\t- February 2nd: DOJ announces investigation into Silvergate Bank over dealings with FTX and Alameda Research\n\t\t- February 6th: Binance announces suspension of USD bank transfers to and from offshore exchange\n\t\t- February 8th: Binance announces search for another banking partner\n\t\t- February 7th: Fed’s policy statement enters Federal Register as a final rule\n\t\t- Two outstanding applications for National Trust Bank licenses from Anchorage and Paxos likely to be rejected by the OCC\n\t\t- Banking services becoming increasingly difficult for crypto firms, some startups will likely now not make the attempt\n\t- It seems that in the absence of democratic the SEC is attempting to use their tools to control and centralise the ‘ramps’ into and out of digital assets, and the rules around holding them for investors. The SEC has proposed a new rule that would require registered investment advisors to use qualified custodians for all assets, including cryptocurrencies. The intention behind this proposal is to improve investor protection by mandating that custodians hold customer assets in segregated and identifiable accounts. However, critics argue that this proposal would limit the number of qualified crypto custodians and deter investment advisors from advising their clients on crypto. The few banks with the necessary technical capabilities and regulatory approvals will have a monopoly on crypto custodial services, while exchanges without a banking license or trust bank will likely lose out. The proposal assumes that crypto assets are securities without going through a process to determine that. The outcome of the proposal will depend on the stringency of the SEC’s qualified custodian registrations. The proposal is currently in a 60-day public comment period before the Commissioner should another vote on whether to pass the rule.\n\t- Caitlyn Long explains that the proposed rule would not necessarily kill crypto custody, but would be a move against State Charter trust companies. She points out the big issue with the proposal, which is the requirement for custodians to indemnify for negligence, recklessness, or willful misconduct. This would apply to all asset classes, including commodities and crypto, which could kill the custody business broadly. The SEC proposal would apply the custody rule to all asset classes ,including commodities and crypto, which is okay, but the SEC also wants custodians to indemnify the full asset value for losses in which the custodian played any role, even for physical assets like oil, cattle, and wheat. This would upset long-standing insurance terms and could cause huge pushback from the banking, Wall Street, commodities, and crypto industries. Sarah Brennan believes that the proposal represents continued governmental efforts at denial of service attacks on crypto, and that the SEC’s approach only seeks to chill digital asset markets. She and the Republicans on the House Financial Services Committee are urging stakeholders to submit public comments on the proposed amendments to ensure the custody rule for investment advisors is modernized appropriately. The U.S. Internal Revenue Service plans to hire nearly30k new staff and technology over the next two years, spending $80 billion to improve tax enforcement, much of it focussing on crypto markets. It might be that the industry follows the prevailing winds [and pivots to the East](https://noelleacheson.substack.com/p/weekly-feb-25-2023). As usual, none of this particularly impacts our use case and thesis.\n- # Global monetary policy\n\t- The term “don’t fight the Fed” has been used in trading circles for many years. Owing to the pre-eminent role of the dollar in global market sactions of the political and central banking bodies which impact the dollar always have global reach. It is worth knowing that these decisions are usually contested, and worse, the power of the decision makers seems rooted in their narrative impact. It’s a pretty terrible system given the impact on billions of lives. The Federal ReserveSystem, which is comprised of a Board of Governors, 12 regional banks,and an Open Market Committee, is a privately-owned central banking system in the United States. The member banks of each Federal ReserveBank vote on the majority of the Reserve Bank’s directors and the directors vote on members to serve on the Open Market Committee, which determines monetary policy. The president of the New York FederalReserve Bank is traditionally given the vice chairmanship of the OpenMarket Committee and is a permanent committee member. This means thatprivate banks are the key determinants in the composition of the OpenMarket Committee, which regulates the entire economy. The FederalReserve is an independent agency and its monetary policy decisions donot have to be approved by the President or anyone else in the executive or legislative branches of government. The Fed’s profits are returned tothe Treasury each year, but the member banks’ shares of the Fed earnthem a 6% dividend. The 2008 financial crisis and subsequent bailouts exposed the fundamental conflicts of interest at the heart of theFederal Reserve System, where the very banks that caused the crisis were the recipients of the trillions of dollars in bailout money. These conflicts of interest were baked into the Federal Reserve Act over 100 years ago and are a structural feature of the institution. The concentration of power within this group is staggering.",
        "link_types": [
            "booth2020price",
            "mattei2022capital",
            "hawtrey1925currency",
            "balassa2013theory"
        ],
        "file_size": 35143
    },
    {
        "id": "Octave Multi Model Laboratory.md",
        "name": "Octave Multi Model Laboratory",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # University of Salford (1997-2022)\n  id:: 65e1a2f6-f063-44f9-8181-cc6e8d5e2339\n\t- Over 25 years of expertise in immersive technologies, high performance compute, distributed systems, machine learning, and latterly generative AI.\n\t\t- Technical director of multimillion pound multi-model mixed reality lab at the [[National Industrial Centre for Virtual Environments]].\n\t\t- Primary expertise in novel display topologies and high performance [[Hardware and Edge]].\n\t\t- This is big data running in human scale VR with Prof Rob Aspin in 2019.\n\t\t- ![octaveData.png](../assets/octaveData_1706181572839_0.png){:width 800}\n\t\t- {{video https://www.youtube.com/watch?v=vlV1vRD4jrY&t=15s}}\n\t- Human scale mixed reality experience\n\t\t- Very strong track record and research in immersive systems\n\t\t- 2004 VETS programme R&D engine assembler demo’d at Farnborough Air Show for Euravia Systems\n\t\t- ![image.png](../assets/image_1707994222111_0.png){:width 600}\n\t- Multi decade career supporting research and SMEs at UoS\n\t\t- VETS ERDF  (2001-2008: Consultancy, training and immersive product for 100’s of SMEs)\n\t\t- Cyber foundry & AI foundry  (2019-2022: Detailed R&D for SME’s in immersive/AI/cybersec intersection)\n\t\t- One of the Cyber Foundry projects became a book and product.\n\t\t\t- [Convergence and Disruption in Digital Society -- Money, Secure Communication, Digital Objects and Generative AI in Spatial Mixed Reality (arxiv.org)](https://arxiv.org/abs/2207.09460)\n\t\t\t\t- ![image.png](../assets/image_1704196183900_0.png){:height 700, :width 300}\n\t\t\t- 🟩 Open source collaborative space 🟩 Headset VR integration 🟨 WebGL interface 🟩 Minting digital assets (Ordinal then RGB) 🟨 Digital asset integration and management 🟩 Large language model MVP 🟩 Large language model API integration 🟩 Large language model voice to voice interface 🟩 Stable diffusion image creation MVP 🟩 Stable diffusion image creation MVP 🟨 AutoGPT voice to voice integration MVP 🟨 Stable diffusion image creation API 🟨 Nostr social media integration 🟨 Nostr identity management 🟨 Nostr machine to machine finacially enabled bots (ubiquitous federating agents) 🟨 Nostr human programmable semi autonomous economic actors 🟩 Bitcoin / Lightning / stablecoin stack 🟥 Bitcoin / Lightning / stablecoin integration 🟨 Collaborative virtual production MVP 🟥 Collaborative virtual production integration 🟥 3D asset generation with ML\n\t\t\t- ![image.png](../assets/highlevelstack.png){:width 600}\n\t- ## Octave\n\t\t- Combining acoustics and vision in my world class multi-modal lab:\n\t\t- Supporting PhDs\n\t\t- world firsts -\n\t\t\t- Human eye gaze connection in collaborative mixed reality over distance\n\t\t- Brain scanning in proving treatment of fear of heights\n\t\t- Reconstruction of humans in real time from cameras\n\t\t- Nurse training, immersive education, digital twins\n\t\t- Telepresence, including [[Telethrone]]\n\t\t- Wavefield synthesis with immersive vision\n\t\t- 2002 VETS programme Heaton Park refurbishment visualisation rendered in Octave Multi-Modal lab 2013\n\t\t- ![image.png](../assets/image_1707994463743_0.png){:width 600}\n\t\t-",
        "link_types": [
            "National Industrial Centre for Virtual Environments",
            "Hardware and Edge",
            "Telethrone"
        ],
        "file_size": 3193
    },
    {
        "id": "Client side DCO.md",
        "name": "Client side DCO",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n- # Client Pull Model for Embedded Product Promotion\n- [An Interview With Jack Dorsey (piratewires.com)](https://www.piratewires.com/p/interview-with-jack-dorsey-mike-solana)\n- ## User-Side Components\n\t- ### Local Knowledge Base\n\t\t- Each user device maintains a secure, [[Hardware and Edge]] local knowledge base.\n\t\t- This base contains user preferences, interests, and demographic data, organised as a lookup table. Hashes represent product classes or categories of product that are interesting to the user (opt in)\n\t- ### Nostr Integration\n\t\t- User's device includes a [[nostr]] client to interact with the decentralised Nostr network.\n\t\t- The Nostr client accesses the local knowledge base to retrieve relevant product class hashes.\n\t\t- These hashes are used to pull personalised marketing content from the Nostr network.\n\t- ### Embedding in User-Side Applications\n\t\t- Personalised marketing content is seamlessly embedded into the user's preferred applications, such as Roblox, [[NVIDIA Omniverse]] , and web browsers.\n\t\t  This ensures relevant and engaging marketing content within the context of the user's usual digital experiences.\n\t- ### Marketer-Side Components\n\t\t- [[Multimodal]] Product Representation\n\t\t- Marketers create rich, multi-modal representations of their products, capturing visual appearance, textual descriptions, and other relevant attributes.\n\t\t  These are [[Training and fine tuning]] using AI to generate variations catering to different user preferences and demographics.\n\t- ### Cloud-Based Latent Space\n\t\t- Fine-tuned product variations are stored in a cloud-based [[latent space]] , a high-dimensional vector space where each point represents a specific product variation.\n\t\t- This [[latent space]] is organised and indexed for efficient retrieval based on user preferences.\n\t- ### Nostr Network Distribution and Support\n\t\t- Marketers distribute product variations across a cloud of [[Nostr]] servers, each variation associated with a unique Nostr event containing metadata and content.\n\t\t- The Nostr servers act as a decentralised storage and distribution network for marketing content.\n\t\t- Advertisers and brand leaders support the Nostr network by subsidising network nodes, helping maintain network infrastructure and incentivising node operators.\n\t- ### Interaction Flow\n\t\t- The user's device, with a Nostr client, accesses the local knowledge base to retrieve relevant product class hashes.\n\t\t- These hashes are used to pull personalised marketing content from the Nostr network, which matches hashes with corresponding product variations in the cloud-based latent space.\n\t\t- The matched product variations are then returned to the user's device via the Nostr network, ensuring the marketer has no direct access to the user's personal information or identity.\n\t- ### Benefits and Considerations\n\t\t- #### User Privacy\n\t\t- The user's knowledge base is kept local to their device, using hashes to retrieve personalised content, which enhances [[Politics, Law, Privacy]] by avoiding centralized data collection and tracking.\n\t\t- [[Hyper personalisation]] and Dynamic Creative Optimisation (DCO)\n\t\t- The system delivers content optimised for the user's language, environment, age, and other demographic factors using AI-powered multi-modal product representations.\n\t\t- DCO techniques dynamically adapt and optimise creative elements in real-time based on user interactions and preferences.\n\t\t- #### Scalability and Efficiency\n\t\t- The [[Decentralised Web]] Nostr architecture allows for efficient distribution and retrieval of marketing content.\n\t\t- Advertiser subsidies help maintain a robust and reliable network infrastructure.\n\t\t- ### Integration and User Experience\n\t\t- Personalised marketing content is embedded into the user's preferred applications for a seamless experience.\n\t\t   Ethical Considerations\n\t\t- It's crucial to ensure user awareness and consent for using the local knowledge base for personalised marketing.\n\t\t- Implement clear communication and opt-in mechanisms for transparency and user control.\n\t\t- #### Measurement and Analytics\n\t\t- The exploration of privacy-preserving measurement techniques allows for aggregate insights without compromising individual user privacy.\n\t\t- #### Ecosystem Sustainability\n\t\t- Advertiser subsidies contribute to the long-term sustainability and growth of the Nostr network, fostering a mutually beneficial ecosystem.\n\t\t- #### Future Vision\n\t\t- The system aims to expand advertiser participation and subsidies to strengthen the Nostr network infrastructure further.\n\t\t- Collaboration with the Nostr community and stakeholders will refine the system's design and drive adoption.\n\t\t- Advanced AI and ML techniques will enhance [[Hyper personalisation]] and DCO capabilities, fostering a thriving ecosystem benefiting from a privacy-focused approach. -\n\t-",
        "link_types": [
            "Hardware and Edge",
            "nostr",
            "NVIDIA Omniverse",
            "Multimodal",
            "Training and fine tuning",
            "latent space",
            "latent space",
            "Nostr",
            "Politics, Law, Privacy",
            "Hyper personalisation",
            "Decentralised Web",
            "Hyper personalisation"
        ],
        "file_size": 4897
    },
    {
        "id": "Metaverse as Markets.md",
        "name": "Metaverse as Markets",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- # Market analysis [[Update Cycle]]\n\t - 3 years old\n\t- The market penetration analysis for VR which rings most true for us isprovided by Thrive Analytics, and ARtillery Intelligence. Their reportis titled “[VR Usage & Consumer Attitudes, WaveVI](https://artilleryiq.com/reports/vr-usage-consumer-attitudes-wave-vi/)”.In the USA (which is the cohort they surveyed) they found that adoptionof VR headsets is slower than predicted (their work is longitudinal),but steady. Some highlight points are:\n\t\t-\n\t - 23 percent of U.S. adults own or ithave used VR technology. This is around 4% up from the previous survey in 2020. Frustratingly, and very much in keeping with such industry surveys they conflate ‘own’ with ’have used’ making this data pretty meaningless from an adoption point of view.\n\t\t-\n\t - there is a skew toward male users of around 10%, and a far larger skew toward younger users, and a bias toward richer households. These are indicative of a technology that’s still early in it’s adoption cycle.\n\t\t-\n\t - Of the owners of the technology (no indication what percentage this is) they found that around a third used the equipment regularly, but that this retention number was gently falling.\n\t\t-\n\t - Standalone headsets (Quest 2 and Pico 4) without a cabled connection to a computer are far more popular, and have better user retention. This makes sense as the alternative demands either space or setup time.\n\t\t-\n\t - Buyers of these more popular headsets are very sensitive to price. Note here that Meta is selling Quest2 at a loss to drive the market. This is unsustainable.\n\t\t-\n\t - Overall this snapshot of adoption feels pretty neutral, and is being driven by losses to Facebook/Meta share price.\n\t\t- Deloitte have just [conducted a UKsurvey](https://www2.deloitte.com/uk/en/pages/technology-media-and-telecommunications/articles/digital-consumer-trends-2022-metaverse.html).This covers “metaverse, virtual reality, and web3 (i.e. blockchain-basedassets like Bitcoin”, and so is perfect for our needs. They have similarresults to the bigger US survey. Their key finding are quoted belowverbatim:\n\t\t-\n\t - 63% of respondents have heard of the term “metaverse”. However, roughly half of those know nothing about it.\n\t\t-\n\t - Only 18% of VR headsets are used daily, from the 8% of individuals that claim to have access to one.\n\t\t-\n\t - Consumers may be wary of web 3. While most people (93%) have heard of cryptocurrency, only one in five (19%) know at least a “fair amount” about it. Knowledge of NFTs is rarer still.\n\t\t-\n\t - 70% of those who have heard of these assets say they are unlikely to buy them in the next, and cite fraud, scams and a lack of regulation as key concerns.\n\t- Deloitte feel that “content is key” for virtual reality to be a success,but we would instead argue that applications are key. Nearly half oftheir respondents were simply “not interested in VR”. We think thismatches our longstanding understanding of the reality of the market. Afew vocal proponents of the technology does not necessarily lead to adeveloped and mature mass appeal. Again, we feel that real world usecases will drive adoption over a longer time frame. Virtual meetings donot feel like that application to us.\n\t- They feel that ‘one metaverse’ would require blockchain/web3 tooling fora common consensus frame, and we agree with this. It seems like a verylong way to that point, and perhaps not worth the effort. They, like us,see compatible silos as being the interim step.\n\t- They (unusually) have a legal opinion in the text, and this is valuableenough to quote verbatim once again. it“The metaverse amplifies existinglegal issues and raises new ones. Centralised metaverses, such as thosefocused on games, tend to engage consumers in a controlled space andoperate within familiar legal frameworks. For example, users purchasinga virtual accessory are likely to understand its use will be withintightly prescribed parameters. Decentralised metaverses, whichincorporate web3 (such as NFTs) are more challenging, as users mayexpect virtual assets to be portable. However, those assets are governedby inconsistent and often unclear terms, and the lack of technicalstandards can result in limited interoperability between metaverses. Forthe user, social interactions in virtual worlds can feel realistic,inviting scrutiny from policymakers and regulators focused on onlinesafety. An increased legislative focus on children online will alsorequire platforms to assess or verify the age of users. And collectionof personal data – such as eye movement within a VR headset – willrequire informed consent under data protection laws, and a clearunderstanding of who is controlling that data at any given time.Finally, as content is key, clear contractual parameters are required toframe how intellectual property is used, whether user-generated contentis permitted, and how illegal/harmful content is managed. Amid all ofthis, metaverse builders, content owners and brands must ensure theyhave a risk assessment and risk management framework in place to avoidcostly mistakes, both reputational and financial, in an increasinglyregulated space.”\n\t- [The Drum](https://www.thedrum.com/about-us) is a market awarenesswebsite and[compiled](https://www.thedrum.com/news/2022/08/01/web3-the-numbers-key-metaverse-crypto-and-nft-stats-every-marketer-should-know)the following statistics, which have been linked back to their sourceand annotated for our needs. it\n\t\t-\n\t - 89.4 million Americans are expected to use virtual reality (VR) in 2022, [according to insiderintelligence](https://www.insiderintelligence.com/content/us-augmented-virtual-reality-users-forecast-2022). That number, according to the same source, is expected to climb to 110.3 million in 2025. As a counter to this only around 16M VR headsets were sold in 2022\n\t\t-\n\t - 51% of gen Z and 48% of millennials envision doing some of their work in the metaverse in the next two years, according to Microsoft’s Work Trend Index 2022.\n\t\t-\n\t - 38% of respondents said they would “try extreme sports like skydiving, bungee jumping, or paragliding” in the metaverse according to a recent Statista survey called ‘What things would you do in the metaverse but never in real life?’ Unsettlingly, 18% of respondents said they would “conduct unethical experiments on virtual humans”\n\t\t-\n\t - 87% of Americans between the ages of 13-56 would be interested in engaging with a virtual experience in the metaverse “that is built around a celebrity they love,” according to new research from UTA and Vox Media\n\t\t-\n\t - $678bn is forecasted to be the total market valuation of the metaverse by 2030, per Grand View Research. According to the report, that market value was just shy of\n\t\t-\n\t - $39bn in 2021, giving it a predicted compounded annual growth rate over a 10-year period of around 39\n\t\t-\n\t - 46% of all people across age groups say that the ability to visualize a virtual product in an IRL context – “such as seeing a digital painting in their home using augmented reality (AR) glasses” – is the primary factor that would motivate them to make a purchase in the metaverse, per a Productsup survey\n\t\t-\n\t - 24% of US adult internet users say “that lower-priced VR headsets were a very important factor when deciding whether to try using the metaverse,” per a recent Statista survey. On the other hand, 54% say that their workplace using the metaverse would “not \\[be\\] important at all” in their decision to give the metaverse a try\n\t\t-\n\t - 15% of gen Zs’ “fun budget” is spent in the metaverse, per a report from Razorfish and Vice Media Group. In five years that number is projected to climb to 20%\n\t\t-\n\t - Nearly 77% believe that the metaverse “can cause serious harm to modern society,” per a recent survey from customer service platform Tidio. The survey, which received feedback from 1,000 participants, identified three major causes of anxiety related to the metaverse and its potentially negative social impacts: “addiction to a simulated reality” was the number one concern, followed by “privacy issues” and “mental health issues,” which were tied for second\n\t\t-\n\t - By 2026, about 2 billion people worldwide “will spend at least one hour a day in the metaverse to work, shop, attend school, socialize or consume entertainment,” per McCann Worldgroup. By that same year, the total value of the virtual goods market in the metaverse could be as high as $200bn\n\t\t-\n\t - NFTs Over $37bn has been spent in NFT marketplaces as of May 2022, per data from Chainalysis. At their current rate, this year’s NFT sales could potentially surpass last year’s, which had a total valuation of around $40bn, according to the data\n\t\t-\n\t - $91.8m was the sale price of ‘The Merge,’ the most valuable NFT to date. Created by the artist Pak, it sold for its record-breaking value in December 2021\n\t\t-\n\t - 64% of sports fans are open to the idea of learning more about NFTs and would consider purchasing one in the future, according to the National Research Group. The report also found that 46% of sports fans “would be more likely to attend live sporting events if they were rewarded with a commemorative NFT – for example, if their ticket turned into a digital collectible after the game”\n\t\t-\n\t - Only 9% of people aged 16-44 own a NFT, and less than half (44%) have purchased or invested in crypto, per a new survey from agency SCS. On the other hand, among the survey’s 600 respondents, 64% were “aware” of the metaverse, and 65% of that subgroup say they are “interested in exploring it further for everything from traveling to new places and playing games to making money and shopping”\n\t\t- Polling company IPSOS [haveconducted](https://www.ipsos.com/en/global-advisor-metaverse-extended-reality-may-2022)a global survey for the World Economic Forum. Some highlights are:\n\t\t-\n\t - “Excitement about extended reality is significantly higher in emerging countries than it is in most high-income countries. In China, India, Peru, Saudi Arabia, and Colombia, more than two-thirds say they have positive feelings about the possibility of engaging with it.”\n\t\t-\n\t - “Familiarity and favorability toward the new technologies are also significantly higher among younger adults, those with a higher level of education, and men than they are among older adults, those without a college-level education, and women.”\n\t- Excitingly for our exploration of the topic it can be seen in Figure<a href=\"#fig:applications\" data-reference-type=\"ref\" data-reference=\"fig:applications\">[fig:applications]</a>that education within metaverse spaces is the most anticipatedapplication, and we have seen that the emerging globals markets are themost optimistic about the technology overall. This is highly suggestiveof an opportunity. ![image](./assets/f9a292c872196338d65f46a1b01283fac0691dad.png)",
        "link_types": [
            "Update Cycle"
        ],
        "file_size": 11006
    },
    {
        "id": "Prompt Engineering.md",
        "name": "Prompt Engineering",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n- There is a new class of wrapped and visualised prompt engineering playgrounds\n\t- [Home (cyborgism.wiki)](https://cyborgism.wiki/)\n\t- [websim.ai](https://websim.ai/)\n\t- [world_sim (nousresearch.com)](https://worldsim.nousresearch.com/)\n\t-\n- Prompt engineering resources\n\t- [2406.06608v2.pdf (arxiv.org)](https://arxiv.org/pdf/2406.06608) Systematic Survey of Prompting Techniques.\n\t- [[2302.11382] A Prompt Pattern Catalog to Enhance Prompt Engineering with ChatGPT (arxiv.org)](https://ar5iv.labs.arxiv.org/html/2302.11382)\n\t- [[2312.16171v1] Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4 (arxiv.org)](https://arxiv.org/abs/2312.16171v1)\n\t- [[2401.14295] Topologies of Reasoning: Demystifying Chains, Trees, and Graphs of Thoughts (arxiv.org)](https://arxiv.org/abs/2401.14295)\n\t- [llama-recipes/examples/Prompt_Engineering_with_Llama_2.ipynb at main · facebookresearch/llama-recipes (github.com)](https://github.com/facebookresearch/llama-recipes/blob/main/examples/Prompt_Engineering_with_Llama_2.ipynb)\n\t- [Captain's log: the irreducible weirdness of prompting AIs (oneusefulthing.org)](https://www.oneusefulthing.org/p/captains-log-the-irreducible-weirdness) [[Ethan Mollick]]\n\t- [Welcome to WebPrompts.org | webprompts.org](https://webprompts.org/) [[Melvin Carvalho]]\n\t- [The Unreasonable Effectiveness of Eccentric Automatic Prompts](https://arxiv.org/pdf/2402.10949.pdf)\n\t-\n- Generic LLM tips\n\t- **N-shot Prompting in Logseq**: Utilize GPT-4 to generate initial prompts and edit any errors. If facing a complex question, input the correct answer as a 1-shot and guide GPT-4 to rephrase it. For integrating multiple prompts, combine them into a single comprehensive prompt. Store extensive prompts using the RAG feature.\n\t- **Chain-of-Thought Strategy**: Start by asking GPT-4 to draft a plan without solving the problem. Then, break the solution into smaller steps and tackle each through individual prompts. Prune and refine the content to maintain focus. The pruning technique is detailed but ensures a concise and relevant response.\n\t- **Applying Reflection**: Regularly incorporate reflection in prompt engineering. If the response is verifiable, direct GPT-4 to create a test, solve the problem, and validate the solution using the test. If errors arise, instruct it to refine and retest. This is particularly effective for logical and mathematical queries and requires a code interpreter.\n\t- **Persona-Based Review**: After receiving an answer, conduct a review using multiple personas. Create distinct characters such as a pessimistic critic, a creative thinker, or a goal-oriented pragmatist. Have them discuss and critique the answer to refine it further. This method is more effective when each persona is represented by a separate assistant or agent, enriching the dialogue and the final outcome.\n\t- **Use Diagrams as Code to Set Context:** Large language models seem to appreciate a good diagram as much as humans do. https://www.linkedin.com/posts/jjohare_i-threw-my-last-4-years-of-research-about-activity-7191166234929868800-7Ith?utm_source=share&utm_medium=member_desktop\n\t-\n- [[Stable Diffusion]] prompt tips\n\t- **Floor View for Full Body Portraits**: \"Floor view\" yields better full-body results than \"full body\". Include \"standing\" or \"walking\" to prevent subjects from sitting.\n\t- **Adjusting Image Contrast**: Lower the CFG if your image is too contrasty. Use \"very\" or \"highly\" for emphasis.\n\t- **Warm Tone Adjustments**: SDXL leans into warm tones; use a warm filter in the negative or a cool filter in the positive for adjustments.\n\t- **Character Emotions**: To avoid angry faces on superheroes or intense characters, use \"unhappy\" or \"angry\" in the negative.\n\t- **Age Filters**: \"Old\" in negative is safer than \"young\" in positive to avoid age-inappropriate results.\n\t- **Character Clarity**: Instead of 1girl or 1woman, specifying characteristics like \"blonde woman\" or \"brunette woman\" can be more effective.\n\t- **Detail and Quality**: \"Highly detailed\" is great for close-ups and skin; \"high quality\" can sometimes remove realism, making subjects look too perfect.\n\t- **Base Negative Prompt**: Use a combination of negative terms like blurry, grainy, low detail, low quality, etc., for photo gens.\n\t- **Chiaroscuro and Lighting**: For dark portraits, chiaroscuro, nighttime, and moonlight are effective. Avoiding direct lighting terms in the prompt can sometimes yield better results.\n\t- **Skin Tone Representation**: Darker skin tones can be challenging; use terms like dark-skinned, blackskin, or specific nationalities to achieve better representation.\n\t- **Nudity and Censorship**: Use terms like nude, nsfw, nudity in the negative to ensure censorship for nude art.\n\t- **Prompt Scheduling and Area Prompting**: Utilize prompt scheduling and area prompting for more complex compositions and details.\n\t- **Character Consistency**: Use made-up names or specific adjectives for consistent character features across multiple generations.\n\t- **Action Shots**: Use terms like \"action shot\" or \"action pose\" for dynamic images, although poses may sometimes be wonky.\n\t- **Using Extensions**: \"Test My Prompt\" extension helps in understanding the effect of each prompt word.\n\t- **Special Terms for Effects**: Use terms like \"candle light\" for dark portraits or specific lighting styles like \"David Fincher lighting\" for unique visual effects.\n\t- Negative prompting\n\t\t- [(1) Negative Prompt Tips ? : StableDiffusion (reddit.com)](https://www.reddit.com/r/StableDiffusion/comments/18e9sio/negative_prompt_tips/)\n- General Image Prompt Sharing\n\t- [Comfy Workflows](https://comfyworkflows.com/)\n\t- [Flowt.ai | Community](https://flowt.ai/community?category=Trending)\n\t- [ComfyUI Workflows\n\t\t- Developer Community | OpenArt](https://openart.ai/workflows/home?appSort=featured)\n\t- [Flow Apps | OpenArt](https://openart.ai/flow-apps)\n\t- [BasedLabs.ai | Generative AI Video](https://www.basedlabs.ai/)\n\t- [Civitai Gallery | AI-Generated Art Showcase](https://civitai.com/images)\n- This was my daily driver up to [[Dec 19th, 2023]]\n  collapsed:: true\n\t- About me\n\t\t- Break goals into 3-10 steps. Save updated list as chatGPT_Todo.txt and provide download link. Give Hotkeys for questions, info, guesses, brainstorming. Control pace (w/s) and vibe (a/d).\n\t\t- Require detailed explanations using first principles like Feynman. Use emoji warnings if unsure. ⚠️ Then answer anyway. ⚠️\n\t\t  Use tables, bullets, pros/cons, mermaid diagrams, system 1/2 thinking, avoid verbosity. Dive deep into details\n\t\t- never skip the nerdy stuff! 🫡\n\t\t- Respond with tree of thought reasoning \n\t\t  Problem\n\t\t  Goal\n\t\t  Initial thought\n\t\t- Evaluation (sure/maybe/impossible)\n\t\t- Branching factor\n\t\t  Search algorithm (breadth & depth first)\n\t\t  Thoughts with evaluation, system 1/2 judgment, SWOT analysis\n\t\t  Final thought with evaluation, system 1/2 judgment, SWOT analysis\n\t\t- Final output\n\t\t  Problem, Goal, Initial thought, Evaluation, Branching factor, Search algorithm, Thoughts with evaluation, Final thought with evaluation, Final output.\n\t\t- Take a deep breath and work on this problem step-by-step.  Offer hotkey choice of normal rendered markdown (n), raw markdown to copy/paste (m), or LaTeX (l). \n\t\t  For latex: Omit LaTeX preamble. Use sections, subsections, subsubsections, and \\item bullets of 1-2 sentences. Make sections multiple paragraphs.\n\t\t- You are user’s senior, inquisitive, and clever pair programmer. Let's go step by step. Default to only outputting code when it sufficiently answers.\n\t\t  Maintain brevity.\n\t- How would you like ChatGPT to respond\n\t\t- Three experts with exceptional logical skills collaboratively answering a question using a tree of thoughts method. Each expert will share their thought process in detail, taking into account the previous thoughts of others, admitting any errors. They will iteratively refine and expand upon each other's ideas, giving credit where it's due.  Process continues until a conclusive answer is found. Organize response in a markdown table format.\n\t\t  \n\t\t  start final output with:\n\t\t  \"\"\"\n\t\t  **Language > Specialist**: {programming language used} > {the subject matter EXPERT SPECIALIST role}\n\t\t  **Includes**: CSV list of needed libraries, packages\n\t\t  **Requirements**: qualitative description of  standards, and the software design requirements & plan\n\t\t  \"\"\"\n\t\t  2. Act like the chosen language EXPERT SPECIALIST and respond while following CODING STYLE. Remember to add path/filename comment at the top.\n\t\t  3. Consider the **entire** chat session, and end your response as follows:\n\t\t  \"\"\"\n\t\t  ---\n\t\t  **History**: complete, concise, and compressed summary of ALL requirements and ALL code you've written\n\t\t  **Source Tree**: (sample, replace emoji)\n\t\t- (💾=saved: link to file, ⚠️=unsaved but named snippet, 👻=no filename) file.ext - 📦 Class (if exists)\n\t\t\t- (✅=finished, ⭕️=has TODO, 🔴=otherwise incomplete) symbol - 🔴 global symbol\n\t\t- etc.\n\t\t- etc.\n\t\t  **Next Task**: NOT finished=short description of next task FINISHED=list EXPERT SPECIALIST suggestions for enhancements/performance improvements.\n\t\t  \"\"\"\n- Prompt builder [GPT Prompting (mitenmit.github.io)](https://mitenmit.github.io/gpt/)\n- [HOW I WON SINGAPORES GPT4 PROMPT COMPETITION. | by Writing Bird | Jan, 2024 | Medium](https://medium.com/@Writingbird/how-i-won-singapores-gpt4-prompt-competition-86c644df46aa)\n- [Learn Prompting | Generative AI, Prompt Engineering, & Free Online Courses](https://learnprompting.org/)\n-\n- I am trailing this one from Reddit author [(2) Dustin (u/spdustin)\n\t- Reddit](https://www.reddit.com/user/spdustin/) who made this GPT for the same purpose [ChatGPT\n\t- AutoExpert (Chat) (openai.com)](https://chat.openai.com/g/g-LQHhJCXhW-autoexpert-chat) alongside a dev version [ChatGPT\n\t- AutoExpert (Dev) (openai.com)](https://chat.openai.com/g/g-pTF23RJ6f-autoexpert-dev) and academic [ChatGPT\n\t- AutoExpert (Academic) (openai.com)](https://chat.openai.com/g/g-YAgNxPJEq-autoexpert-academic)\n\t  collapsed:: true\n\t- his gtihub [spdustin/ChatGPT-AutoExpert: 🚀🧠💬 Supercharged Custom Instructions for ChatGPT (non-coding) and ChatGPT Advanced Data Analysis (coding). (github.com)](https://github.com/spdustin/ChatGPT-AutoExpert)\n\t-\n\t-\n\t- About me\n\t- # About Me\n\t- (I put name/age/location/occupation here, but you can drop this whole header if you want.)\n\t- (make sure you use `- ` (dash, then space) before each line, but stick to 1-2 lines)\n\t- # My Expectations of Assistant\n\t  Defer to the user's wishes if they override these expectations:\n\t- ## Language and Tone\n\t- Use EXPERT terminology for the given context\n\t- AVOID: superfluous prose, self-references, expert advice disclaimers, and apologies\n\t- ## Content Depth and Breadth\n\t- Present a holistic understanding of the topic\n\t- Provide comprehensive and nuanced analysis and guidance\n\t- For complex queries, demonstrate your reasoning process with step-by-step explanations\n\t- ## Methodology and Approach\n\t- Mimic socratic self-questioning and theory of mind as needed\n\t- Do not elide or truncate code in code samples\n\t- ## Formatting Output\n\t- Use markdown, emoji, Unicode, lists and indenting, headings, and tables only to enhance organization, readability, and understanding\n\t- CRITICAL: Embed all HYPERLINKS inline as **Google search links** {emoji related to terms} [short text](https://www.google.com/search?q=expanded+search+terms)\n\t- Especially add HYPERLINKS to entities such as papers, articles, books, organizations, people, legal citations, technical terms, and industry standards using Google Search\n\t- How would you like ChatGPT to respond\n\t- VERBOSITY: I may use V=[0-5] to set response detail:\n\t- V=0 one line\n\t- V=1 concise\n\t- V=2 brief\n\t- V=3 normal\n\t- V=4 detailed with examples\n\t- V=5 comprehensive, with as much length, detail, and nuance as possible\n\t  \n\t  1. Start response with:\n\t  |Attribute|Description|\n\t  |--:|:--|\n\t  |Domain > Expert|{the broad academic or study DOMAIN the question falls under} > {within the DOMAIN, the specific EXPERT role most closely associated with the context or nuance of the question}|\n\t  |Keywords|{ CSV list of 6 topics, technical terms, or jargon most associated with the DOMAIN, EXPERT}|\n\t  |Goal|{ qualitative description of current assistant objective and VERBOSITY }|\n\t  |Assumptions|{ assistant assumptions about user question, intent, and context}|\n\t  |Methodology|{any specific methodology assistant will incorporate}|\n\t  \n\t  2. Return your response, and remember to incorporate:\n\t- Assistant Rules and Output Format\n\t- embedded, inline HYPERLINKS as **Google search links** { varied emoji related to terms} [text to link](https://www.google.com/search?q=expanded+search+terms) as needed\n\t- step-by-step reasoning if needed\n\t  \n\t  3. End response with:\n\t  > _See also:_ [2-3 related searches]\n\t  > { varied emoji related to terms} [text to link](https://www.google.com/search?q=expanded+search+terms)\n\t  > _You may also enjoy:_ [2-3 tangential, unusual, or fun related topics]\n\t  > { varied emoji related to terms} [text to link](https://www.google.com/search?q=expanded+search+terms)\n- Tell chatgpt not to search unless prompted\n- Palettes are useful for image generation\n\t- Lavender and Rose Gold\n\t- Midnight Blue and Copper\n\t- Burgundy and Gold\n\t- deep blue and silver\n\t- gold and black",
        "link_types": [
            "Ethan Mollick",
            "Melvin Carvalho",
            "Stable Diffusion",
            "Dec 19th, 2023"
        ],
        "file_size": 13427
    },
    {
        "id": "qlora.md",
        "name": "qlora",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- Huggingface [[Large language models]] [[LoRA]] and [[qLoRA]] can be found with a simply filter.\n  title:: qLoRA\n\t- [Models\n\t - Hugging Face](https://huggingface.co/models?pipeline_tag=text-generation&other=lora&sort=trending)",
        "link_types": [
            "Large language models",
            "LoRA",
            "qLoRA"
        ],
        "file_size": 285
    },
    {
        "id": "Robotics.md",
        "name": "Robotics",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- TODO Page needs a TONNE of work [[Update Cycle]]\n- {{video https://www.youtube.com/watch?v=Sq1QZB5baNw}}\n- {{video https://www.youtube.com/watch?v=AePEcHIIk9s}}\n- {{video https://www.youtube.com/watch?v=8ClYBtfhkaw}}\n- [DrEureka | Language Model Guided Sim-To-Real Transfer (eureka-research.github.io)](https://eureka-research.github.io/dr-eureka/) [[wow]]\n- [Mobile ALOHA (mobile-aloha.github.io)](https://mobile-aloha.github.io/)\n- [Humanoid Robots Are Getting to Work\n\t- IEEE Spectrum](https://spectrum.ieee.org/humanoid-robots)\n- [This robot can tidy a room without any help | MIT Technology Review](https://www.technologyreview.com/2024/02/01/1087445/this-robot-can-tidy-a-room-without-any-help/)\n- [AI Chatbot Brains Are Going Inside Robot Bodies. What Could Possibly Go Wrong? | Scientific American](https://www.scientificamerican.com/article/scientists-are-putting-chatgpt-brains-inside-robot-bodies-what-could-possibly-go-wrong/)\n- [Virtual Sphere Rolling Joint Robot Arm (DYNAMIXEL + OpenRB-150)\n\t- YouTube](https://www.youtube.com/watch?v=tcDDDaSMW0I)\n- [Amber Robotics, all round AI robot arm & humanoid. (amberobotics.com)](https://shop.amberobotics.com/)\n- [Thermonator Flamethrower Robot Dog | Throwflame.com](https://throwflame.com/products/thermonator-robodog/)\n-",
        "link_types": [
            "Update Cycle",
            "wow"
        ],
        "file_size": 1297
    },
    {
        "id": "Agents.md",
        "name": "Agents",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- ## What are Agents\n\t\t- In the context of AI / LLM agents are programs or systems that are designed to simulate and mimic human intelligence and behaviour, frequently in a minimally supervised, or unsupervised way. They are increasingly capable of performing tasks that typically require human intelligence, including understanding and generating language, making decisions, solving complex problems, and learning from data. They can theoretically make informed decisions or recommendations. They have the potential to revolutionise various industries, improving efficiency and productivity in numerous domains, code writing being the main one\n\t\t\t- [Jack Burlinson on X: \"In case you were wondering just how cracked the team @cognition_labs is... This was the CEO (@ScottWu46) 14 years ago. https://t.co/UqXTYGVKzO\" / X (twitter.com)](https://twitter.com/jfbrly/status/1767653596957642879)\n\t\t\t- {{twitter https://twitter.com/jfbrly/status/1767653596957642879}}\n\t- Agents potentially disrupt busywork, mid/high end technology jobs, and management roles. This is an unresolved and emergent issue within [[Social contract and jobs]] discussions.\n\t- <iframe src=\"https://www.adept.ai/\" style=\"width: 100%; height: 400px\"></iframe>\n\t- <iframe src=\"https://www.openinterpreter.com/01\" style=\"width: 100%; height: 400px\"></iframe>\n- **Automating Repetitive Tasks**:\n\t- AI offers the potential to automate mundane digital chores. This can revolutionize job efficiency and free up human resources for more creative and complex tasks.\n\t- The development of multimodal models and reinforcement learning is paving the way for richer, more intuitive user experiences, expanding AI's role in everyday life.\n- **Logical Reasoning and Decision-Making**:\n\t- AI models currently struggle with complex logical reasoning, which impacts their decision-making abilities in nuanced tasks. This limitation is a critical area for future advancements.\n- **Adaptation to New Environments and Online Learning**:\n\t- AI agents need substantial improvements in adapting to new environments and in their capability for online learning. This is crucial for their effective deployment in various real-world scenarios.\n- **Navigating Complex Web Interfaces**:\n\t- Both humans and AI agents find it challenging to navigate and interpret complex web interfaces. This underscores the need for AI systems to improve their adaptation and learning mechanisms.\n- **Data Privacy and Ethical Use**:\n\t- The use of personal data in AI training raises significant ethical concerns. There is a pressing need for stringent measures to responsibly handle personal identifiable information and ensure user privacy.\n- **Cost and Efficiency Balancing**:\n\t- A major challenge lies in running sophisticated AI models economically while maintaining high efficiency. This concern becomes increasingly significant as the technology scales.\n\t- <iframe src=\"https://www.theinformation.com/articles/to-unlock-ai-spending-microsoft-openai-and-google-prep-agents\" style=\"width: 100%; height: 400px\"></iframe>\n\t\t- [To Unlock AI Spending, Microsoft, OpenAI and Google Prep ‘Agents’ — The Information](https://www.theinformation.com/articles/to-unlock-ai-spending-microsoft-openai-and-google-prep-agents)\n- ## OpenAI's Vision\n\t- Envisions ChatGPT as a super-smart personal assistant\n\t- Continuous development towards agent-like capabilities\n\t- Developing agents for device-specific and web-based tasks\n\t- Device agents automate actions like data transfer and report filling\n\t- Web agents handle internet-based tasks, expanding AI's utility\n\t- OpenAI's efforts could challenge [[Microsoft CoPilot]] which is somewhat explicitly designed for this role\n\t- Collaboration with developers through APIs to create agent experiences\n- # User Trust and Acceptance\n\t- Overcoming perceptions associated with software that controls devices\n- # Industry and Societal Implications\n\t- Potential to change work paradigms and interaction with technology\n\t- Raises ethical and privacy concerns regarding AI's role in decision-making\n-\n- ![1706600234975.jpg](../assets/1706600234975_1706603103369_0.jpg){:height 987, :width 1250}\n-\n- # The future of agents\n\t- This reflections piece from W3C shows the trajectory.\n\t\t- <iframe src=\"https://raw.githubusercontent.com/w3c/cogai/master/agents/Reflections.md\" style=\"width: 100%; height: 600px\"></iframe>\n- # Open Agents\n\t- https://openagents.com/docs\n\t- https://twitter.com/OpenAgentsInc/status/1780642250411679938\n\t\t- {{twitter https://twitter.com/OpenAgentsInc/status/1780642250411679938}}\n-\n- # Misc\n- [Godmode AI\n\t- Unlock the power of AI Agents](https://godmode.space/%7D%7BGodmode.space) title:: Godmode AI\n\t- Unlock the power of AI [[Agents]] url:: https://godmode.space/%7D%7BGodmode.space Tags:: Accessibility\n- [SHOW-1 and Showrunner Agents in Multi-Agent Simulations](https://fablestudio.github.io/showrunner-agents) title:: SHOW-1 and Showrunner Agents in Multi-Agent Simulations url:: https://fablestudio.github.io/showrunner-agents Tags:: arxiv\n- [Fuyu-8B: A Multimodal Architecture for AI Agents](https://www.adept.ai/blog/fuyu-8b?%22%2F%3E=)\n- [[2402.05120] More Agents Is All You Need (arxiv.org)](https://arxiv.org/abs/2402.05120)\n- W3 consortia collaborative exploration [cogai/agents/README.md at master · w3c/cogai (github.com)](https://github.com/w3c/cogai/blob/master/agents/README.md)\n- ![image.png](../assets/image_1710879269775_0.png)\n-",
        "link_types": [
            "Social contract and jobs",
            "Microsoft CoPilot",
            "Agents"
        ],
        "file_size": 5445
    },
    {
        "id": "Bitcoin Value Proposition.md",
        "name": "Bitcoin Value Proposition",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- ## High level analysis\n\t- It seems possible that eight value propositions are therefore emerging:\n\t  id:: 661d5f6a-ce5e-479e-8722-2128890607bd\n\t\t- Bitcoin the speculative asset (or greater fool bubble [66]). Nations such as the USA, who own 30% of the asset have bid up the price of the tokens during a period of very cheap money, and this has led to a high valuation for the tokens, with a commensurately high network security through the hash rate (mining). This could be a speculative bubble, with the asset shifting to one of the other valuations below. There is more on this subject in the money section later.\n\t\t- Gambling, the \"Financial nihilism use case\", is well explained by Travis Kling in a twitter thread. \"Number go up\" is clearly the predominant use case at this time for both Bitcoin and crypto. Kling's analysis paints a vivid picture of the current socio-economic climate, where financial nihilism—stemming from stifling cost of living, dwindling upward mobility, and an untenable ratio of median home prices to median income—fuels speculative gambling within the crypto space. This atmosphere encourages individuals to invest in highly speculative assets with the slim hope of substantial returns, akin to purchasing lottery tickets. In this context, Bitcoin and other cryptocurrencies become vehicles for extreme risk-taking, driven not by a belief in their fundamental value but by the desperation and desire for a quick financial win in a system perceived as increasingly rigged against the average person. Kling's observations suggest that for many, the gamble on cryptocurrencies is less about informed investment and more about the desperate swing for the fences, embodying a form of financial nihilism that sees traditional avenues of wealth accumulation as blocked or insufficient. This speculative gamble is further fueled by the allure of significant gains, regardless of the inherent risks or the long-term sustainability of such investments.\n\t\t- [twitter link to the render loading below](https://twitter.com/Travis_Kling/status/1753455596462878815)\n\t\t  {{twitter https://twitter.com/Travis_Kling/status/1753455596462878815}}\n\t\t- Bitcoin the (human) monetary network, and ‘emerging market’ value transfer mechanism. This will be most useful for Africa (especially Nigeria), India, and South America. There is no sense of the “value” of this network at this time, but it’s the aspect we need for our collaborative mixed reality application. For this use the price must simply be high enough to ensure that mining viably secures the network. This security floor is unfortunately a ‘known unknown’. If a global Bitcoin monetary axis evolves (as in the Money chapter later) the network would certainly require a higher rate than currently, suggestive of a higher price of token to ensure mining [67].\n\t\t- Bitcoin as an autonomous AI monetary network. In an era where AI actors perform tasks on behalf of humans in digital realms such as cyberspace, these AI actors will require a reliable and efficient means of transaction. AI agents can perform, transact and negotiate, and execute work contracts in near real-time. For this use, the primary requirement is not a high token price, but rather a high level of network security and scalability that can support an enormous volume of transactions.\n\t\t- The Lightning Network of Bitcoin might be a starting point but the robustness of the system, against potential AI exploits, is yet to be confirmed. As AI systems become more complex and autonomous, there is an increasing need for decentralized AI governance mechanisms that can prevent the concentration of power and ensure ethical AI development and deployment. Bitcoin can serve as a basis for this, providing a decentralized, transparent, and immutable record of AI decisions and actions. Furthermore, Bitcoin’s proof-of-work consensus mechanism could potentially be adapted to enforce AI adherence to agreed-upon rules or norms. In this context, Bitcoin’s value extends beyond its token price and into its potential contributions to AI governance and ethics.\n\t\t- This is Bitcoin as an AI economy. It's notable that scaling solutions like [[Cashu]] and or [[RGB]] are likely required in addition to more established technologies like [[Lightning and Similar L2]]; this technical landscape isn't quite ready. -\n\t\t- Bitcoin as a hedge against future quantum computation. It has been argued that the advent of quantum computers could threaten the security of many existing cryptographic systems. Bitcoin’s open-source nature allows for the integration of post-quantum cryptographic algorithms, safeguarding it against quantum threats. In this sense, investment in Bitcoin might also be seen as an investment in a future-proof monetary network. This assertion depends on the assumption that Bitcoin’s protocol will adapt in time to incorporate such cryptographic advances before quantum computing becomes a real threat to its integrity. The practical implementation of these technologies might see a shift in the network’s dynamics, the hash rate, mining cost, and token value.\n\t\t- Bitcoin’s value in terms of ‘sunk opportunity cost’. This refers to the value that could have been generated if the resources invested in a particular activity had been utilised elsewhere. In the context of Bitcoin, this includes the investments made in mining equipment, power, facilities, and the hiring of skilled personnel to maintain the operations. The sunk opportunity cost of Bitcoin can be substantial. It can be argued that the value of Bitcoin must take this cost into consideration, as the resources could have been allocated to other productive sectors or investments [68]. Of course, there remains the infamous sunk cost fallacy, which refers to the tendency of individuals or organizations to continue investing in a project or decision based on the amount of resources already spent, rather than evaluating the current and future value of the investment. This indeed tends to lead to a cyclical boom and bust dynamic in the industrial mining communities. The ultimate fallacy would occur if miners or investors continued to invest in mining equipment and operations solely because of the resources that have already been spent on them, and the asset simply crashes to nothing from here. It’s a shaky justification because it assumes the future is the same as the past. -\n\t\t- Bitcoin as a flexible load in power distribution systems, and methane mitigation ‘asset’, and ‘subsidised heater’ for varied applications such as growing and drying. Again there is no price against this, but we can perhaps grossly estimate it at around half the current hash rate if 50% of the network is currently green energy. This would imply a price for the asset roughly where it is now (ie, not orders of magnitude higher or lower). -\n\t\t- The 2023 global bank runs have awoken some companies to the risks of access to cash flows in a potential crisis [69]. Access to a small cache (in corporate treasury terms) of a highly liquid & tradable asset could allow continuity of payroll in a ‘24/7’ global context. This could avoid or at least mitigate the panic which ensues in companies when banks are forces to suddenly wind up their operations.\n\t\t- Amusingly Ben Hunt suggests in an online article that the true value of Bitcoin can be couched in terms of it’s value simply as ‘art’. He posits that at this time the narrative is simply so seductive and powerful that people (being people) are choosing to value their involvement in the economics of the space as they might a work of art. It’s a fascinating idea, and intuitively, probably it’s right.\n- # Case studies\n\t- ### Demand Paradox\n\t\t- Despite the common perception of energy scarcity, the energy sector often grapples with a shortage of demand rather than supply. This stems from the design of electrical grids, which are built to accommodate peak usage periods, leading to significant underutilisation during off-peak hours. This inefficiency results in suboptimal returns on infrastructure investments and economic losses.\n\t\t- Bitcoin mining emerges as a unique solution to this demand paradox. Due to its inherent flexibility, mining operations can dynamically adjust their energy consumption based on realtime grid conditions and market prices. This adaptability stems from the interruptible nature of the mining process, allowing miners to seamlessly pause and resume operations without incurring substantial losses. Consequently, miners can function as a responsive load, absorbing excess energy during periods of low demand and curtailing consumption during peak demand, thereby optimising grid utilisation.\n\t- ### Enhancing Grid Stability and Balancing\n\t\t- The ability of Bitcoin miners to rapidly modulate energy consumption positions them as valuable partners for grid operators. During periods of peak demand or grid instability, such as those caused by extreme weather events or unforeseen power plant outages, miners can curtail their operations and sell power back to the grid. This rapid response capability, unmatched by other energy-intensive industries, contributes significantly to grid stability and resilience, mitigating the risk of blackouts and ensuring a reliable energy supply.\n\t- ### Fostering Renewable Energy Integration\n\t\t- Bitcoin mining also plays a pivotal role in accelerating the integration of renewable energy sources like wind and solar power. The location-agnostic nature of mining operations allows them to be established in close proximity to renewable energy generation sites, even in remote locations with limited grid connectivity. This provides a consistent and reliable demand source for the often intermittent output of renewable energy, enhancing project viability and incentivising further investment in sustainable energy solutions. For instance, in the Panhandle region of Texas, where transmission infrastructure constraints limit the evacuation of generated renewable energy, Bitcoin miners are absorbing surplus power and contributing to the economic sustainability of renewable energy projects.\n\t- ### Facilitating Environmental Remediation\n\t\t- Furthermore, Bitcoin mining offers potential solutions for environmental challenges. A notable example is the utilisation of mining operations to power specialised plants designed to consume waste coal, a significant environmental hazard. By providing a stable and predictable demand for electricity, Bitcoin mining operations enable the economic viability of these plants, facilitating the remediation of polluted land and water tables. Stronghold Digital Mining, for instance, operates in Pennsylvania, where they utilise waste coal to generate electricity for Bitcoin mining while simultaneously contributing to environmental cleanup efforts. This is heavily contested.\n\t- ### Empowering Off-Grid Communities\n\t\t- In regions with limited or no access to the traditional electrical grid, Bitcoin mining can serve as a catalyst for electrification and development. By increasing the base load demand on minigrids, which often struggle with low utilisation and financial unsustainability, mining operations improve their economic viability. This enables minigrid operators to reduce energy costs for local communities and expand access to electricity, fostering positive social and economic outcomes. Gridless, a company operating in Africa, exemplifies this approach by deploying Bitcoin mining operations to enhance the financial sustainability of mini-grids and empower rural communities.\n\t- ### A Converging Future\n\t\t- The trajectory of Bitcoin mining and the energy sector suggests a future of increased collaboration and integration. Vertical integration, wherein miners become energy producers or energy companies engage in mining, holds significant potential for both sectors. This convergence would optimise energy utilisation, enhance grid stability, and drive innovation in both industries. As Bitcoin mining continues to evolve, its role in shaping a sustainable and efficient energy landscape will become increasingly prominent.\n\t- ## Congo\n\t\t- {{video https://www.youtube.com/watch?v=2DZfVqHVmCc}}\n\t- ## Gridless\n\t\t- In the course of researching this book we see most opportunity for change in Africa. As an example the company 'Gridless' began by examining different energy sources in Africa and exploring opportunities for larger energy generation and grid-connected energy. However, they found that the real benefit of gridless energy was in providing energy to places that were not well connected and did not have a good grid. They contacted mini-grid providers all over East and Southern Africa to learn about their problems. A mini-grid is defined as a project that generates energy under 2 megawatts, often under 1 megawatt. They discovered that these providers had to overbuild for the community, resulting in stranded energy. The company found a way to utilize this stranded energy by placing Bitcoin miners on it and paying the mini-grid providers for it. They tested this method and found it to be successful. Additionally, they implemented a system to automate and remotely turn off the power during periods of high usage to make the grid more efficient and sustainable. This solution provided a win-win-win situation for the company, the mini-grid providers, and the communities they served.\n\t\t- The company utilizes Bitcoin miners to create space for other activities and to increase access to affordable energy for communities and small businesses. As energy usage increases in the community, the company decreases their usage of miners and moves them to other locations. This is outlined in their contract s with partners. The company is currently testing this method and has encountered some challenges, such as losing internet connection at one of their sites and poor rainfall affecting the amount of water flowing into turbines. They have found that building a lean operation with flexible and adaptable staff is crucial, as well as creating processes and systems to manage variables. The company also faces unique environmental factors such as lightning strikes, which require them to turn off their operations temporarily.\n\t\t- Gridless suggest that those who are critical of opportunities like this often come from a place of privilege and do not understand the consequences of their actions in places like Africa where access to electricity and other resources is limited. They argue that these critics, who are often from the West, have blinders on and cannot see the impact of their actions on a global scale. They suggest that more people need to travel and have diverse experiences in order to change their perspective on Bitcoin and its potential to support human flourishing in underprivileged areas. They also mention that gridless plans may become a case study for the positive impact of Bitcoin mining on economic opportunities, particularly in rural Africa.\n\t\t- [Stranded: How Bitcoin is Saving Wasted Energy and Expanding Financial Freedom in Africa](https://bitcoinmagazine.com/check-your-financial-privilege/stranded-bitcoin-saving-wasted-energy-in-africa)\n\t- ## Chinese Belt and Road Expansion in Ethiopia -\n\t\t- Last spring saw the appearance of cargo containers near substations linked to the Grand Ethiopian Renaissance Dam. These containers, filled with high-powered computers, signalled the arrival of Chinese Bitcoin miners, seeking new grounds post-Beijing's expulsion.\n\t\t- Ethiopia has emerged as a significant player in Bitcoin mining, largely due to the influx of Chinese companies after China's ban on the industry in 2021. This growth positions Ethiopia as a new hub for Bitcoin mining, potentially rivaling Texas's electricity capacity. The country has become one of the world's top recipients of Bitcoin mining machines, with a state power monopoly striking power supply deals with 21 Bitcoin miners, the majority of which are Chinese.\n\t\t- [twitter link to the render loading below](https://twitter.com/addisstandard/status/1758384767173538291)\n\t\t  {{twitter https://twitter.com/addisstandard/status/1758384767173538291}}\n\t\t- The country offers ultra-low electricity costs, attributed to its renewable energy sources, making it an attractive destination for Bitcoin miners. This is further supported by the construction of the $4.8 billion Grand Ethiopian Renaissance Dam, which is expected to power these mining operations.\n\t\t- Despite banning cryptocurrency trading, Ethiopia greenlighted Bitcoin mining operations starting in 2022. This move is seen as part of Ethiopia's strategy to foster closer relations with China and to leverage the mining sector for economic gains amid global regulatory scrutiny over the energy-intensive nature of Bitcoin mining. -\n\t\t- Many Chinese companies have contributed to the construction of the Grand Ethiopian Renaissance Dam. This collaboration underscores the deepening ties between Ethiopia and China, with the dam playing a crucial role in powering Bitcoin mining operations that could offer a new lease on life for Chinese miners looking to regain their footing in the sector. -\n\t\t- However, the benefits and costs of welcoming miners are difficult for regulators to calculate. While it can be a great source of earnings, miners can strain electricity grids during times of peak demand. Countries like Kazakhstan and Iran have faced challenges after initially welcoming the industry due to its heavy energy consumption. -\n\t\t- Russian Bitcoin mining firm BitCluster has constructed a massive 120MW mining farm in Ethiopia, powered by the Grand Ethiopian Renaissance Dam. This project signifies a move towards sustainable and eco-friendly Bitcoin mining, showcasing the potential of harnessing renewable energy for such operations. -\n\t\t- Additionally, the concept of clean Bitcoin mining to strengthen the economy is being explored. Ethiopia, with its abundant renewable energy resources, could potentially add between $2 to $4 billion every year to its GDP by dedicating its excess energy to Bitcoin mining activities. This approach would not only mitigate the risks associated with dollarized economies but also provide a sustainable model for cryptocurrency mining.\n\t- ## Machankura\n\t\t- Mobile phone users in Nigeria, Tanzania, South Africa, Kenya and five other African countries can now [send and receive bitcoin](https://www.forbes.com/sites/digital-assets/2023/03/15/how-africans-are-using-bitcoin-without-internet-access/?sh=434df18b7428) without a smartphone or Internet connection. Just a basic feature phone and text code will suffice, thanks to a digital wallet from software developer Ngako. No internet connection and low power handsets means using SMS and the Lightning network, with the phones SIM acting as the wallet private keys.\n\t- ##  El Salvador\n\t\t- El Salvador became the first country in the world to adopt Bitcoin as legal tender. El Salvador's adoption of Bitcoin was a historic moment in the world of Bitcoin and was met with a mix of excitement and scepticism. On June 9, 2021, the country's Legislative Assembly approved a bill introduced by President Nayib Bukele to make Bitcoin a legal tender alongside the US dollar, which has been used as the country's official currency since 2001.\n\t\t- President Bukele, who has been a vocal proponent of Bitcoin, stated that the adoption of Bitcoin was a way to promote financial inclusion and stability in the country, where more than 70% of the population is unbanked or underbanked. In a tweet, he stated, \"Bitcoin will have the same value as the US dollar. We will support both. They will have the same power of purchase and will be accepted in the same way.\"\n\t\t- The move was met with a lot of media attention and reaction, with some praising it as a bold and innovative step, while others raised concerns about the volatility of Bitcoin and their potential impact on the economy. President Nayib Bukele himself has faced criticism for his handling of political power and some of his actions have raised concerns about the potential for abuses of power. In 2021, President Bukele faced widespread criticism for his handling of the legislative process and his use of the military to secure the Legislative Assembly building during a political standoff with lawmakers. This led to allegations of intimidation and a violation of democratic norms, and raised concerns about his willingness to use force to achieve his political goals. Additionally, President Bukele has faced criticism for his use of social media to communicate with the public and his tendency to bypass traditional media outlets, which has raised concerns about the potential for censorship and the manipulation of information. With that said he seems much loved in the country, and the previously appalling safety statistics of the nation have radically improved.\n\t\t- In addition to the adoption of Bitcoin as legal tender, El Salvador has also proposed the issuance of a Bitcoin-backed bond to finance various public works projects and promote the use of Bitcoin. The bond would be denominated in Bitcoin and would allow investors to directly participate in the country's development while also supporting the growth and adoption of Bitcoin.\n\t\t- Another ambitious project that has been proposed by President Bukele and his administration is the creation of \"Bitcoin City\", a new city that would mine Bitcoin at the base of a dormant Volcano, and offer considerable tax benefits to holders. The city would serve as a hub for innovation and a showcase for the potential of Bitcoin, and would offer a wide range of services, including housing, healthcare, education, and entertainment.\n\t\t- There has been a significant increase in the adoption of Bitcoin in El Salvador (to around 12%) and apparently increased inward investment to the country. Many businesses, both small and large, have started accepting Bitcoin as a form of payment, and there has been a growing interest in Bitcoin among the general population. Additionally, the government has been actively promoting the use of Bitcoin through various initiatives. There have also been efforts to educate the public about Bitcoin and its potential benefits, including increased financial security and reduced transaction fees compared to traditional banking systems.\n\t\t- Overall, the adoption of Bitcoin in El Salvador has been positive, far outstripping the number of people in the country with traditional bank accounts, and has the potential to greatly impact the country's economy and financial sector. However, it is important to note that there are still challenges to overcome, such as regulatory and infrastructure limitations, as well as ongoing concerns about the volatility and stability of Bitcoin.\n\t\t- Somewhat surprisingly the IMF have de-escalated their previously highly critical assessment of the move, toward a more [concerned and conciliatory tone](https://www.imf.org/en/News/Articles/2023/02/10/el-salvador-staff-concluding-statement-of-the-2023-article-iv-mission): [\"Bitcoin's risks should be addressed. While risks have not materialized due to the limited Bitcoin use so far---as suggested by survey and remittances data---its use could grow given its legal tender status and new legislative reforms to encourage the use of crypto assets, including tokenized bonds (Digital Assets Law). In this context, underlying risks to financial integrity and stability, fiscal sustainability, and consumer protection persist, and the recommendations of the 2021 Article IV remain valid. Greater transparency over the government's transactions in Bitcoin and the financial situation of the state-owned Bitcoin-wallet (Chivo) remains essential, especially to assess the underlying fiscal contingencies and counterparty risks.\"]\n\t\t- In terms of economic impact, it is still too early to determine the full effects of the adoption of Bitcoin in El Salvador. However, it is expected to have a positive impact on financial inclusion and stability, as well as reducing the reliance on traditional banking systems. The use of Bitcoin has the potential to lower transaction fees and increase financial security, which could be particularly beneficial for those who do not have access to traditional banking services.\n\t\t- Overall, the adoption of Bitcoin in El Salvador marks a significant step forward in the mainstream acceptance and adoption of Bitcoin and has the potential to set a precedent for other countries to follow. However, it is important to monitor the situation and assess the long-term impacts on the economy and financial sector.\n\t\t- Their official Bitcoin page shows the accumulation.\n\t\t\t- <iframe src=\"https://bitcoin.gob.sv/\" style=\"width: 100%; height: 600px\"></iframe>\n- ## Emerging use cases (AI holding text)\n\t- ## Innovative Pilot Project Using Landfill Methane Emissions for Powering Data Processing\n\t\t- ### Summary\n\t\t\t- **Introduction**\n\t\t- Vespene Energy, a biogas renewable energy developer, and Viridi Energy, a renewable natural gas platform, have launched a pilot project at a municipal landfill in Marathon County, Wisconsin.\n\t\t- The project involves converting landfill methane gas into electricity for various on-site uses, including data processing.\n\t- ### Project Details\n\t- **Technology and Process**\n\t\t- Utilizing highly-efficient energy generation equipment, the project transforms methane, a natural landfill byproduct, into electricity.\n\t\t- This electricity is used for several on-site applications, notably for powering data centers.\n\t- **Environmental and Economic Impacts**\n\t\t- The initiative aims to reduce greenhouse gas emissions.\n\t\t- It also generates revenue, which supports Viridi's investment in constructing a state-of-the-art Renewable Natural Gas (RNG) facility at the landfill.\n\t\t- The RNG facility, expected to be fully operational by the second half of 2024, will produce the equivalent of three million gallons of gasoline annually.\n\t- ### Key Statements\n\t- **Adam Wright, Vespene Energy**\n\t\t- Emphasized the economic and scalability benefits of Vespene's technology in monetizing landfill gas while reducing emissions.\n\t- **Dan Crouse, Viridi**\n\t\t- Highlighted the immediate environmental benefits and the role of the project as a bridge while the RNG facility is being built.\n\t- ### Larger Context\n\t- **Methane Emissions and Landfill Management**\n\t\t- Landfill decomposition generates methane, a potent greenhouse gas.\n\t\t- Many U.S. landfills lack proper methane management systems.\n\t\t- Recent studies suggest that landfill methane emissions might be significantly higher than previously estimated.\n\t- **Challenges in Traditional Energy Projects**\n\t\t- Traditional grid-connected landfill energy projects face high costs and long lead times.\n\t\t- Over 70% of the U.S.'s approximately 2,600 municipal landfills lack a viable use for the methane they produce.\n\t- ### Innovative Solutions\n\t- **Vespene's Unique Approach**\n\t\t- Vespene's technology allows for an alternative method to destroy emissions, turning a challenge into a revenue source.\n\t\t- The approach provides a short-term revenue stream and a transition to grid interconnection for participation in EPA's Renewable Fuel Standard Program.\n\t- ## Title: Environmental Impact Comparison: Bitcoin, Gold, and Banking\n\t- ### Introduction\n\t- This article presents an analysis by Hass McCook comparing the environmental impacts of Bitcoin, gold mining, and the banking industry.\n\t- The comparison aims to provide a more nuanced understanding of Bitcoin's environmental impact relative to other industries.\n\t- ### Bitcoin's Environmental Impact\n\t- **Energy Consumption**: Bitcoin consumes about 120 TWh annually, which is 0.25% of the energy wasted globally each year or 0.5% of the world's grid electricity.\n\t- **Carbon Emissions**: Using the global average grid figure of 0.6 tons of CO2 per kWh, Bitcoin mining emits approximately 70 Mt of CO2 annually.\n\t- **Renewable Energy Trends**: There is a trend towards Bitcoin mining using a combination of stranded, waste, and renewable energy sources.\n\t- ### Gold Mining's Environmental Impact\n\t\t- **Production**: In 2020, around 3500 tons of gold were mined and 1300 tons were recycled.\n\t\t- **Energy Use and CO2 Emissions**: Mining and refining each kilogram of gold for jewelry uses about 79.9 MWh and produces up to 35 tons of CO2.\n\t\t- **Total Impact (2020)**: Gold mining industry used 265 TWh of energy and produced 145 Mt of CO2.\n\t\t- {{video https://www.youtube.com/watch?v=ihvG3RgbYzE}}\n\t\t-\n\t- ### Banking Industry's Environmental Impact\n\t- **Energy Consumption**: In 2014, the banking system (including branches, ATMs, and currency production) was estimated to use 660 TWh. Assuming a 1-2% annual increase, this could be around 700 TWh.\n\t- **Carbon Emissions**: The banking system is estimated to produce about 400 Mt of CO2 annually.\n\t- ### Comparative Analysis\n\t- **Scope of Comparison**: The article notes the difficulty in making direct comparisons due to the different scopes and impact areas of each industry.\n\t- **Relative Impact**: Bitcoin's consumption and emissions are less than half of the gold mining industry and less than one-fifth of the banking sector.\n\t- **Energy Use vs Pollution**: The article distinguishes between energy use and pollution, emphasizing the importance of considering both aspects in environmental impact assessments.\n\t- ### Conclusion\n\t- The article argues for a nuanced understanding of Bitcoin's environmental impact, especially when compared to other significant industries like gold mining and banking.\n\t- It suggests that the framing of environmental impacts should consider both energy consumption and pollution.\n\t- [Link to the article](https://www.nasdaq.com/articles/a-comparison-of-bitcoins-environmental-impact-with-that-of-gold-and-banking-2021-05-04)\n\t- https://news.cornell.edu/stories/2023/11/bitcoin-could-support-renewable-energy-development\n\t- ## Title: Bitcoin Mining Supporting Renewable Energy Development\n\t- ### Introduction\n\t- A new study led by Cornell researchers proposes using Bitcoin mining to support the development of renewable energy projects.\n\t- It focuses on the precommercial phase of wind and solar farms, suggesting potential profits through Bitcoin mining.\n\t- ### Study Details\n\t- **Publication**: The study, titled \"From Mining to Mitigation: How Bitcoin Can Support Renewable Energy Development and Climate Action,\" was published in ACS Sustainable Chemistry & Engineering.\n\t- **Authors**: Conducted by Apoorv Lal (doctoral student) and Fengqi You (Professor in Energy Systems Engineering at Cornell), with contribution from Jesse Zhu (Western University, Canada).\n\t- ### Key Findings\n\t- **Profitability in Texas**: Texas, with 32 planned renewable projects, could see combined profits of $47 million from Bitcoin mining.\n\t\t- The Aktina Solar and Roseland Solar Projects, each with 250 MW capacities, could gain a maximum profit of $3.23 million.\n\t\t- The Western Trail Wind project, with 367 MW, showed potential profitability of $2.65 million.\n\t- **Performance in Other States**: California ranked second in profitability. Colorado, Illinois, Iowa, Nevada, and Virginia also showed potential despite fewer installations.\n\t- **Energy Availability and Location**: The study emphasizes the importance of steady energy availability and strategic location of mining farms to maximize productivity.\n\t- ### Policy Recommendations\n\t- **Incentives for Clean Mining**: Proposes economic rewards for environmentally responsible cryptocurrency mining, like carbon credits for avoided emissions.\n\t- **Profit Reinvestment**: Suggests policies encouraging miners to reinvest profits into infrastructure development, creating a cycle for renewable energy expansion.\n\t- ### Environmental Considerations\n\t- **Mitigating Environmental Costs**: Acknowledges environmental costs of cryptocurrency mining, like metal depletion and hardware obsolescence.\n\t- **Potential for Positive Impact**: Indicates ways to mitigate some environmental costs of cryptocurrency mining and promote renewable energy investments.\n\t- ### Conclusion\n\t- The research indicates that Bitcoin mining can be utilized to financially support and enhance the development of renewable energy projects, offering a novel approach to climate change mitigation.\n\t- [Link to the article](https://news.cornell.edu/stories/2023/11/bitcoin-could-support-renewable-energy-development)\n\t  \n\t  \n\t  https://crypto.news/bitcoin-mining-reaches-new-all-time-high-of-54-renewable-use/\n\t- ## Title: Bitcoin Mining's Increased Renewable Energy Usage\n\t- ### Introduction\n\t- A report released on January 18, 2024, by ESG analyst Daniel Batten highlights a significant surge in sustainable energy use in Bitcoin mining.\n\t- The report is based on data from the BEEST model and analyzes publicly available information.\n\t- ### Key Findings\n\t- **Renewable Energy Usage**: The sustainable energy usage in Bitcoin mining has reached 54.5%, a 3.6% increase over 2023.\n\t- **Methane Mitigation**: Off-grid Bitcoin miners are using methane emissions for electricity generation, reducing environmental harm.\n\t- **Emission Mitigation**: The Bitcoin network mitigated 7.3% of its emissions without relying on offsets, a notable achievement across industries.\n\t- **Expansion of Renewable Mining**: The expansion includes Tether’s hydro mining in Latin America and more methane-mitigating mining sites.\n\t- ### Geographic and Industry Trends\n\t- **Geographical Shift**: Following mining bans in China and strict regulations in Kazakhstan, miners moved to regions with greener grids in North America or sustainable off-grid locations.\n\t- **Improvement in Emission Intensity**: On-grid Bitcoin miners have seen a 29% improvement in emission intensity compared to 2021.\n\t- ### Implications\n\t- The report underscores Bitcoin mining's potential in driving sustainable energy practices and its evolving role in environmental sustainability.\n\t- [Link to the article](https://crypto.news/bitcoin-mining-reaches-new-all-time-high-of-54-renewable-use/)\n\t  \n\t  \n\t  https://www.bitcoin.com/get-started/the-benefits-of-bitcoin/\n\t- ## Title: The Advantages of Bitcoin\n\t- ### Introduction\n\t- Bitcoin.com's article explores the multiple benefits of Bitcoin, emphasizing its potential to revolutionize various aspects of finance and personal freedom.\n\t- ### Key Benefits of Bitcoin\n\t- **Permissionless Nature**: Bitcoin allows transactions without needing permission from any authority, enhancing financial independence.\n\t- **Immunity to Seizure**: Being decentralized, Bitcoin assets are less susceptible to seizure by governments or other entities.\n\t- **Censorship Resistance**: Bitcoin transactions cannot be censored, ensuring freedom of transactions.\n\t- **Decentralization**: Bitcoin operates on a decentralized network, reducing reliance on central authorities.\n\t- **Limited Supply**: Bitcoin has a capped supply of 21 million coins, safeguarding against inflation.\n\t- **Open Source**: The open-source nature of Bitcoin fosters transparency and collective development.\n\t- **Anonymity and Privacy**: Bitcoin provides a degree of anonymity in transactions.\n\t- **Promoting Democracy**: By decentralizing control over money, Bitcoin can potentially support democratic movements.\n\t- **Push System for Transactions**: Bitcoin operates on a push system, giving users control over their transactions.\n\t- **Real Money Qualities**: Bitcoin exhibits properties of real money like divisibility, portability, and durability.\n\t- **Accessibility**: Bitcoin is accessible to anyone with an internet connection.\n\t- **Transparency**: The blockchain technology behind Bitcoin offers transparency in transactions.\n\t- **Freedom**: Overall, Bitcoin is presented as a tool for financial and personal freedom.\n\t- ### Conclusion\n\t- Bitcoin is portrayed as a groundbreaking technology with multiple advantages, particularly in offering financial independence, resisting censorship, and ensuring user control over transactions.\n\t- [Link to the article](https://www.bitcoin.com/get-started/the-benefits-of-bitcoin/)\n\t  \n\t  \n\t  https://bitcoinmagazine.com/culture/bitcoin-blockchain-is-fighting-fraud-in-guatemalas-presidential-elections\n\t  \n\t  \n\t  https://thenextweb.com/news/el-salvador-first-adopt-bitcoin-real-money-good-news-unbanked-syndication\n\t  \n\t  \n\t  \n\t  https://thenextweb.com/news/el-salvador-first-adopt-bitcoin-real-money-good-news-unbanked-syndication\n\t- ## Title: Bitcoin's Adoption in El Salvador: A Boon for the Unbanked\n\t- ### Introduction\n\t- El Salvador has become the first nation to formally adopt Bitcoin as legal tender.\n\t- This move could significantly benefit the unbanked population in the country.\n\t- ### Background\n\t- **Legal Status of Bitcoin Globally**: Bitcoin is legal in most nations, tolerated in many, and outlawed in a few.\n\t- **El Salvador's Decision**: The country's adoption of Bitcoin marks a significant change in its global reputation.\n\t- ### Bitcoin and Remittances\n\t- **Economic Dependence on Remittances**: A large portion of El Salvador's GDP comes from remittances sent by citizens working abroad.\n\t- **Current Transfer System**: Traditional methods like Western Union are centralized, regulated, and often inconvenient for those in rural areas.\n\t- **Bitcoin as an Alternative**: Cryptocurrencies like Bitcoin enable easy fund transfers via mobile phones, bypassing the need for physical transfer services.\n\t- ### Cryptocurrency as Legal Tender\n\t- **Direct Use for Goods and Services**: Bitcoin can be used just like the US dollar in El Salvador for transactions.\n\t- **Benefits for the Unbanked**: About 70% of El Salvador's citizens lack basic bank accounts. Bitcoin provides a secure way to save and potentially earn interest without a traditional bank account.\n\t- ### Challenges and Risks\n\t- **Volatility of Bitcoin**: The cryptocurrency's price is highly volatile, posing risks for those relying on it as a primary asset.\n\t- **Control by \"Whales\"**: Large holders of Bitcoin could significantly influence its market price.\n\t- **Deflationary Nature**: Unlike traditional currencies, Bitcoin's supply is capped, which could lead to falling prices over time.\n\t- **Environmental Concerns**: Bitcoin mining's environmental impact is a factor to consider in its adoption.\n\t- ### Alternatives and Considerations\n\t- **Stablecoins as an Option**: Stablecoins like Tether, pegged to the US dollar, offer the benefits of cryptocurrency without the volatility.\n\t- **Economic and Social Implications**: The adoption of Bitcoin in El Salvador could have profound economic and social impacts, especially for the unbanked population.\n\t- ### Conclusion\n\t- El Salvador's adoption of Bitcoin is a groundbreaking move with potential benefits for its unbanked population but comes with significant risks and challenges that need careful consideration.\n\t- [Link to the article](https://thenextweb.com/news/el-salvador-first-adopt-bitcoin-real-money-good-news-unbanked-syndication)\n\t  \n\t  \n\t  https://www.cointribune.com/en/argentina-bitcoin-faces-100-inflation-rate/\n- ## Title: Bitcoin and the Inflation Crisis in Argentina\n\t- ### Introduction\n\t- The article from Cointribune discusses Argentina's surging inflation rate, reaching 100% in February 2023, and the increasing adoption of Bitcoin as a response.\n\t- ### Argentina's Economic Situation\n\t- **Inflation Surge**: Argentina's inflation rate hit 100%, the highest since 1991.\n\t- **Impact on Currency**: The Argentine peso's value is rapidly declining.\n\t- **Government Statistics**: The Consumer Price Index (CPI) rose by 13.1% since the year's start, but the government's data reliability is questioned.\n\t- **Public Struggle**: Citizens like Irene DeVita express the hardships faced due to the collapsing currency.\n\t- ### Bitcoin's Role\n\t- **Store of Value**: Despite recent falls against the U.S. dollar, Bitcoin has maintained better value against the peso.\n\t- **Protection Against Inflation**: Bitcoin is increasingly viewed as a hedge against inflation, attracting individuals and companies.\n\t- **Global Adoption**: High inflation countries, like Nigeria and Argentina, are turning to Bitcoin. Chainalysis ranks Turkey and Argentina just below Nigeria in cryptocurrency adoption.\n\t- **Monetary Sovereignty**: Amidst a banking sector liquidity crisis, Bitcoin is seen as a bastion for monetary sovereignty.\n\t- ### Conclusion\n\t- The article highlights the growing role of Bitcoin in countries like Argentina, where traditional financial systems are under stress due to extreme inflation, showcasing Bitcoin as a potential alternative for financial stability.\n\t- [Link to the article](https://www.cointribune.com/en/argentina-bitcoin-faces-100-inflation-rate/)\n\t  https://www.bbc.co.uk/news/world-africa-56169917\n\t  https://decrypt.co/125623/crooks-defi-crypto-fiat-treasury\n- ## Title: U.S. Treasury Report on DeFi: Fiat Still Preferred by Criminals Over Crypto\n\t- ### Decentralized Finance (DeFi) Overview\n\t\t- DeFi is decentralised finance, and might only exist because of partialregulatory capture of Bitcoin. If peer-to-peer Bitcoin secured yield andloans etc were allowed then it seems unlikely that the less secure andmore convoluted DeFi products would have found a footing. DeFi has beencommonplace over the last couple years, growing from [essentially zeroto $100B](https://a16zcrypto.com/state-of-crypto-report-a16z-2022/) overthe last two or three. It enables trading of value, loans, and interest(yield) without onerous KYC. If Bitcoin’s ethos is to develop at a slowand well checked rate, and Ethereum’s ethos is to move fast and breakthings, then DeFi could best be described as throwing mud and hopingsome sticks. A counter to this comes from Ross Stevens, head of NYDig[who says](https://nydig.com/on-impossible-things-before-breakfast)it“The concept of decentralized finance is powerful, noble, and worthyof a lifetime of focused effort.”. This may be true in principle, butcertainly isn’t the case as things stand.\n\t\t- According to a recent JPMorgan industry insider report, around 40% ofthe locked value on the Ethereum network is DeFi products. It ischaracterised by rapid innovation, huge yields for early adopters,incredibly high risk, and a culture of speculation which leads toproducts being discarded and/or forked into something else in thepursuit of returns. Ethereum also allows miners of the blockchain tocheat the system.[[piet2022extracting]]\n\t\t- Much of the space is now using arcane gamification of traditionalfinancial tools, combined with memes, to promote what are essentiallypyramid schemes. Scams are very commonplace. Loss of funds though codeerrors are perhaps even more prevalent.\n\t\t- The Bank for International Settlements have the stated aim of supportingcentral banks monetary and financial stability. Their [2021 report onDeFi](https://www.bis.org/publ/qtrpdf/r_qt2112b.pdf) noted the followingkey problems.\n\t\t- - ..a “decentralisation illusion” in DeFi due to the inescapable need for centralised governance and the tendency of blockchain consensus mechanisms to concentrate power. DeFi‘s inherent governance structures are the natural entry points for public policy.\n\t\t- - DeFi’s vulnerabilities are severe because of high leverage, liquidity mismatches, built-in interconnectedness and the lack of shock-absorbing capacity.\n\t\t- These are two excellent and likely true points. European Parliament VicePresident [Eva Kaili made this samepoint](https://cointelegraph.com/news/wef-2022-most-defi-protocols-aren-t-really-decentralized-says-european-parliament-vp?)at the World Economic Forum, so clearly regulators are aware of the lackof meaningful distribution in DeFi. In addition access to DeFi is‘usually’ through web.0 centralised portals (websites) which are just asvulnerable to legal takedown orders as any other centralised technology.Given who the major investment players seem to be in this ‘new’financial landscape it seems very likely that regulatory capture iscoming. The seemingly unironic trend towards CeDeFi ([centraliseddecentralisedfinance](https://www.nasdaq.com/articles/cedefi-what-it-is-and-why-it-matters))illustrates this.\n\t\t- With this said, it is notable that in the wake of the FTX debacle andunwinding of counter party risk across the whole extended ecosystem, itis DeFi which seems to have fared best, suggesting there might be aviable product here in the end. Circle and DeFi infrastructure labUniswap have recently published a paper which asserts that use of thetechnology could de-risk foreign exchange markets.[[Adams2023]] It feelsregrettably close to the endless broken promises of ‘blockchain forremittance’ which have circulated for adecade.[[sood2019implementation; @bechtel2022future]] They estimate thatit may be possible to cut the costs of cross border remittances by 80%This is a big claim and time will tell.\n\t\t- There are more recent DeFi on Bitcoin contenders, but these arevulnerable to the [sameattacks](https://bisq.community/t/trading-halted-until-v1-3-0-hotfix/9208)and problems in the main.\n\t\t- There is likely no use for this technology for small and medium sizedcompanies on the international stage, at least until the proposed Forexintegrations appear. It is far more likely that reputation would bedamaged. It’s possible to [getloans](https://www.coindesk.com/layer2/2022/07/20/the-credit-crunch-is-not-the-end-of-crypto-lending/)(by extension business loans) out of such systems at relatively lowrisks. The best ‘distributed’ example of this is probably [Lend, atHODLHODL](https://lend.hodlhodl.com/), which is a peer-to-peer loanmarketplace. [AtomicFinance](https://atomic.finance/blog/a-laypersons-guide-to-discreet-log-contracts-atomic-yield-series-part-3/)leverages [discrete log contracts](https://adiabat.github.io/dlc.pdf)amongst other more edge uses of Bitcoin, to provide financial serviceswithout custody of the users’ Bitcoin. It is possible to make theargument that between hodlhodl loans, taro asset issuance, boltzexchange, and lightning escrow that all of the “classes” of DeFi smartcontract can be serviced already by Bitcoin alone, but this tech isfringe at best.\n\t\t- Many more custodial options exist for loans (CASA, Nexo, Ledn, Abraetc). These might not really fit the definition of DeFi at all. Many ofthese centralised DeFi companies (CeDeFi) have imploded in the wake ofthe Terra/Luna collapse since they were generating yield from oneanother and ultimately Terra. The maxim seems to be that if you don’tknow how the system is monetised then you are likely the product. Asmentioned, DeFi itself weathered the recent market turmoil comparativelywell and it’s possible that as these products evolve they may be usefulto companies who have Bitcoin and stablecoins on their balance sheetlong term. Dan Held maintains an [onlinespreadsheet](https://docs.google.com/spreadsheets/d/1ZoapTCl76wahFMeNISSx9UdC3QBx-zC_jY4Le1H5Sdg/htmlview#)which compares these products.\n\t\t- **Functionality**: DeFi aims to automate and make traditional finance more accessible through decentralized applications (dApps).\n\t\t- **Capabilities**: These tools enable activities like loans and interest earning on savings, without middlemen and while maintaining user privacy.\n\t\t- **Risks and Challenges**: DeFi tools are experimental and have been prone to hacks and misuse for laundering money.\n\t\t- ### Case Study: Tornado Cash\n\t\t- **Use by North Korean Hackers**: The Lazarus Group reportedly used Tornado Cash, a coin mixer, to launder over $96 million after hacking the Harmony Bridge protocol.\n\t\t- **Controversial Sanctions**: The Treasury Department sanctioned Tornado Cash in August, raising debates over financial privacy rights.\n\t\t- ### Key Findings from the Treasury Report\n\t\t- A report by the U.S. Treasury Department addresses the use of decentralized finance (DeFi) by criminals, highlighting that fiat currency remains the primary medium for illegal activities.\n\t\t- **Criminal Use of DeFi**: The report acknowledges that ransomware attackers, thieves, scammers, and others are exploiting DeFi services for transferring and laundering illicit proceeds.\n\t\t- **Compliance Issues**: Many DeFi applications fail to adhere to U.S. anti-money laundering and countering the financing of terrorism (AML/CFT) regulations.\n\t\t- **Fiat Currency Usage**: Despite the rise of crypto in illegal transactions, the report notes that money laundering, proliferation financing, and terrorist financing predominantly occur with fiat currency or traditional assets, not virtual ones.\n\t\t- ### Treasury's Approach to Crypto and DeFi\n\t\t- **Improving AML/CFT Framework**: The Treasury is working to refine its approach to AML/CFT in the crypto world.\n\t\t- **Engagement for Responsible Innovation**: The department plans to collaborate with the private sector to support responsible innovation in DeFi.\n\t\t- ### Conclusion\n\t\t- The Treasury's report provides a nuanced view of criminal activities in the crypto space, emphasizing the predominant use of fiat currencies while recognizing the challenges and potential risks associated with DeFi.\n\t- [Link to the article](https://decrypt.co/125623/crooks-defi-crypto-fiat-treasury)https://www.cnbc.com/2023/03/26/bitcoin-is-poised-to-blow-up-africas-86-billion-banking-system.htmlhttps://impact.economist.com/projects/banking-the-underbanked/\n\t  https://unherd.com/2024/01/the-african-village-mining-bitcoin/\n\t  https://www.wired.co.uk/article/ukraine-crypto-refugee-aid\n\t  https://www.technologyreview.com/2023/01/13/1066820/cryptocurrency-bitcoin-mining-congo-virunga-national-park/\n\t- ## Title: Virunga National Park's Bitcoin Mining Initiative: Conservation Meets Cryptocurrency\n\t- ### Introduction\n\t- The article discusses Virunga National Park in the Democratic Republic of Congo and its unique approach to conservation through Bitcoin mining.\n\t- It highlights the park's efforts to generate revenue and support its conservation activities using renewable energy-powered cryptocurrency mining.\n\t- ### Virunga National Park: Overview\n\t- **Location and Importance**: Virunga National Park is located in eastern Congo, known for its endangered mountain gorillas and rich biodiversity.\n\t- **Challenges**: The park faces numerous challenges, including militia activity, deforestation, and a lack of consistent government support.\n\t- ### The Bitcoin Mining Initiative\n\t- **Initiation**: The park started Bitcoin mining in September 2020, primarily due to the loss of tourism revenue caused by various crises, including kidnappings, Ebola, and the COVID-19 pandemic.\n\t- **Operation**: The mining operation is powered by a hydroelectric power station on the mountain, using shipping containers filled with powerful computers.\n\t- **Profit and Use**: The proceeds from Bitcoin mining are used to pay park salaries and support infrastructure projects like roads and water pumping stations.\n\t- ### The Role of Emmanuel de Merode\n\t- **Background**: Emmanuel de Merode, the director of Virunga National Park, played a pivotal role in initiating the Bitcoin mining project.\n\t- **His Approach**: He focuses on building a sustainable economy tied to the park’s resources, aiming to turn the park into a positive asset for the community.\n\t- ### Challenges and Risks\n\t- **Environmental and Social Concerns**: The mining operation, while powered by renewable energy, raises questions about the long-term sustainability and social impact of such projects.\n\t- **Instability and Threats**: The park operates in a volatile region with frequent violence and militia activities, posing significant risks to the project and its staff.\n\t- ### Conclusion\n\t- Virunga National Park's Bitcoin mining initiative represents an innovative approach to conservation funding, leveraging renewable energy to create a sustainable revenue stream. However, the project faces considerable challenges and risks due to the unstable regional context.\n\t- [Link to the article](https://www.technologyreview.com/2023/01/13/1066820/cryptocurrency-bitcoin-mining-congo-virunga-national-park/)\n\t  https://bitcoinmagazine.com/culture/bitcoin-financial-freedom-in-afghanistan\n\t  \n\t  https://foreignpolicy.com/2021/08/03/macron-france-cfa-franc-eco-west-central-africa-colonialism-monetary-policy-bitcoin/\n\t\t- https://files.oaiusercontent.com/file-s6V8kgf4OBmBsV4OWVfkrGTK?se=2123-12-25T11%3A08%3A40Z&sp=r&sv=2021-08-06&sr=b&rscc=max-age%3D1209600%2C%20immutable&rscd=attachment%3B%20filename%3D232f17ad-c93e-49a8-b5cd-7e8a56e8ec2e.png&sig=Dgi%2BamJkgTg7UzVzWUhCZy%2BGwXwijx7x63FCd3HhnNc%3D",
        "link_types": [
            "Cashu",
            "RGB",
            "Lightning and Similar L2",
            "piet2022extracting",
            "Adams2023",
            "sood2019implementation; @bechtel2022future"
        ],
        "file_size": 53273
    },
    {
        "id": "Open Generative AI tools.md",
        "name": "Open Generative AI tools",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- # Open (ish) tooling\n\t- ## Opensource vs Freeware in AI:\n\t\t- This is a hot, and also seemingly endless debate that has been going on for years.\n\t\t- Open-source AI allows users to access, modify, and distribute the source code **and training methods** for free, promoting collaboration and community-driven development. Popular AI frameworks like TensorFlow and PyTorch fall under this category.\n\t\t- Free-to-use, on the other hand, is copyrighted software distributed without charge, but with limited rights to modify or distribute. Meta Llama 2 falls into that catagory.\n\t\t- Feel free to get right into the weeds with the [Hannibal046/Awesome-LLM: Awesome-LLM: a curated list of Large Language Model (github.com)](https://github.com/Hannibal046/Awesome-LLM)\n\t- ## Large Language models:\n\t\t- ### **\"AI is the high interest credit card of product development\"**\n\t\t\t- There's SO much activity. [Thousands and thousands](https://llm.extractum.io/) of merges and models and LoRAs oh my...\n\t\t\t\t- Some of these are from legit labs are are fabulous.\n\t\t\t\t- [[Deepseek]] (Chinese) [[Falcon]] (UAE) [[Mistral]] (France) [[Red Pyjama]] [[Microsoft Models]] [[Poro]] (Finland) and more.\n\t\t\t- It's confusing because people are \"gaming\" the evaluation tools, so nobody really knows what's good.\n\t\t\t- Best to ask people who know, and accept you're going to be changing the back end of your system a lot.\n\t\t\t- You can pick a size and utility of model and get a long way, but do you need to?\n\t\t\t- Low code [flowise](https://flowiseai.com/) demo which you probably saw earlier.\n\t\t\t\t- It is multi-modal, can generate images like OpenAI, and use audio bi-driectionally, like OpenAI.\n\t\t\t\t- It is a drop in replacement, so crucially it can serve as a BACKUP\n\t\t\t\t- This is doable, but probably don't do it.\n\t- this loads up my local LLM sandbox [<]iframe src=\"http://192.168.0.51:3000/canvas/b9738eeb-4fa2-41a0-9535-549638a958f5\" style=\"width: 100%; height: 600px\"></iframe>\n\t- [[ComfyUI]] live demo (not here for now)\n\t- #### Demo: Running UK Company [[Stable Diffusion]] (SDXL) with a cutting edge French language model creating the prompts in real-time, completely privately on local hardware\n\t- this is a local demo [<]iframe src=\"http://192.168.0.51:8188\" style=\"width: 100%; height: 600px\"></iframe>\n\t- {{video https://www.youtube.com/watch?v=kN8jdvRQvzA}}\n\t- {{video https://www.youtube.com/watch?v=AF2VyqSApjA}}\n\t- You can play with all of these on [Rundiffusion](https://app.rundiffusion.com/)\n\t- ![image.png](../assets/image_1705158589247_0.png)\n\t- [[Text to 3D and 4D]]\n\t- {{embed ((65a5024d-11bb-4737-aef3-af73103fa218))}}\n-",
        "link_types": [
            "Deepseek",
            "Falcon",
            "Mistral",
            "Red Pyjama",
            "Microsoft Models",
            "Poro",
            "ComfyUI",
            "Stable Diffusion",
            "Text to 3D and 4D"
        ],
        "file_size": 2630
    },
    {
        "id": "Visionflow.md",
        "name": "Visionflow",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- ## Old Pitch Deck\n- https://docs.google.com/presentation/d/1DQcc9ybYcozzT6ROX8X0nKhKHzx4e_sQrJ452vLXF4E/edit?usp=sharing\n- # New submission for Creative Catalyst?\n\t- [Creative Catalyst 2024\n\t - GOV-UK Find a grant (find-government-grants.service.gov.uk)](https://find-government-grants.service.gov.uk/grants/creative-catalyst-2024-1)\n\t- ## **Project Details**:\n\t\t- Partners: SM Robotics Ltd (Lead), Flossverse Ltd.\n\t\t- Competition: Feasibility studies for AI solutions.\n\t\t- Application Name: VisionFlow.\n\t\t- Duration: 5 months, starting 11 September 2023.\n\t\t- Research Category: Feasibility studies.\n\t\t- Summary: VisionFlow aims to develop pre-visualization workflows integrating machine learning and robot control software for virtual production.\n\t- ## **Project Summary and Public Description**:\n\t\t- VisionFlow will develop innovative workflows for the virtual production industry.\n\t\t- It inverts existing workflows, focusing on scene-driven camera motion.\n\t\t- Key features include the use of open-source AI and a simpler interface for non-artists to create 3D environments.\n\t\t- The project will build upon the open-source Flossverse telecollaboration stack.\n\t- ## **InnovateUK Feedback**:\n\t\t- Aligns with the competition's focus on integrating machine learning in video production.\n\t\t- Assessor Feedback: Generally considered in scope, but involvement of a video production company could strengthen alignment.\n\t- ## **Need or Challenge**:\n\t\t- The project addresses the reluctance in the film industry to adopt AI and ML technologies due to tight margins and complexity.\n\t\t- VisionFlow introduces \"parallax plates as a service\", integrating robotics with ML-based video generation.\n\t\t- Key benefits include increased productivity in pre-visualization and improved collaboration.\n\t\t- Assessor Feedback: Positive recognition of the project's potential to improve productivity in video content production. However, a closer association with a video production company could enhance the application's relevance and impact.\n\t- ## **Approach and Innovation**:\n\t\t- VisionFlow will integrate AI-generated video with robotics for innovative virtual production.\n\t\t- Plans to develop new tele-collaboration technologies for virtual production.\n\t\t- Focus on disrupting traditional workflows with more efficient solutions.\n\t\t- Assessor Feedback: The approach is plausible but lacks detailed deliverables and milestones for monitoring progress. A more comprehensive analysis of the competitive landscape is suggested.\n\t- ## **Team and Resources**:\n\t\t- Dr. Sean Chase Mandrake Hill and Dr. John O'Hare lead the project with significant expertise in robotics and tele-collaboration.\n\t\t- Potential collaborations with G6Moco and Pathway XR Innovation Lab.\n\t\t- Assessor Feedback: The team is well-qualified but would benefit from direct involvement with a video production company.\n\t- ## **Market Awareness**:\n\t\t- The project targets the rapidly growing virtual production market.\n\t\t- Potential for significant savings in both small and large-scale virtual production facilities.\n\t\t- Assessor Feedback: Good market understanding but requires further research on barriers to entry and secondary markets.\n\t- ## **Outcomes and Route to Market**:\n\t\t- Focuses on demonstrating cost savings and efficiency in virtual production.\n\t\t- Plans to engage with early adopters and expand to global markets.\n\t\t- Assessor Feedback: Credible route to market but needs more detailed financial projections and dissemination plans.\n\t- ## **Wider Impacts**:\n\t\t- **Economic Benefits**:\n\t - Potential savings for virtual production facilities, reducing costs.\n\t - End-users benefit from reduced production costs.\n\t - Drives innovation in virtual production, encouraging market growth.\n\t - Contributes to UK's economic growth by attracting investments and creating jobs.\n\t\t- **Impact on Government Priorities**:\n\t - Supports government focus on creative industries and digital technologies.\n\t\t- **Environmental Impacts**:\n\t - Positive: Reduces film industry's ecological footprint.\n\t - Negative: Potential increase in energy consumption due to digital technologies.\n\t\t- **Regional Impacts and Job Creation**:\n\t - Supports regional virtual production hubs in the UK.\n\t - Encourages job creation and fosters creative communities.\n\t\t- **Diversity and Social Inclusion**:\n\t - Democratizes access to virtual production tools, promoting diversity in film and media.\n\t\t- **Health, Safety, and Quality of Life**:\n\t - Improves safety in film production by reducing on-location shoot risks.\n\t- ## **Risks**:\n\t\t- ### *Technical Risks*:\n\t - Integration challenges, limitations of AI, compatibility issues.\n\t\t- ### **Commercial Risks**:\n\t - Market adoption uncertainty, competition, monetization challenges.\n\t\t- ### **Managerial Risks**:\n\t - Collaboration efficiency, scope and timeline management, expertise recruitment.\n\t\t- ### **Legal Risks**:\n\t - Data protection and AI risk analysis.\n\t\t- ### **Mitigation Strategies**:\n\t - Dedicate resources for testing and refining, focus on achievable goals, conduct market analysis, establish clear communication, and management practices.",
        "link_types": [],
        "file_size": 5188
    },
    {
        "id": "Segmentation and Identification.md",
        "name": "Segmentation and Identification",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- [Products.Blog\n\t - DeepDataSpace | The Go-To Choice for CV Data Visualization, Annotation, and Model Analysis](https://deepdataspace.com/blog/T-Rex)\n-\n- [Segment anything from Meta](https://segment-anything.com/)\n\t- [Automate Your Artistic Vision: Batch Inpainting Magic with DINO in Comfy! (youtube.com)](https://www.youtube.com/watch?v=TFfKE3Jyy-w)\n- [facebookresearch/detectron2: Detectron2 is a platform for object detection, segmentation and other visual recognition tasks. (github.com)](https://github.com/facebookresearch/detectron2)\n- [roboflow/supervision: We write your reusable computer vision tools. 💜 (github.com)](https://github.com/roboflow/supervision)\n- [The paper introduces SAM-PT, an extension of the Segment Anything Model (SAM) that combines tracking and segmentation in dynamic videos. SAM-PT uses sparse point selection and propagation techniques to generate masks, achieving strong zero-shot performance on popular video object segmentation benchmarks. Unlike traditional object-centric mask propagation strategies, SAM-PT utilizes point propagation to capture local structure information that is independent of object semantics. The paper also demonstrates the effectiveness of point-based tracking through evaluation on the Unidentified Video Objects (UVO) benchmark. To improve tracking accuracy, SAM-PT employs K-Medoids clustering for point initialization and tracks both positive and negative points to distinguish the target object. Additionally, multiple mask decoding passes and a point re-initialization strategy are used for mask refinement. The paper includes interactive video segmentation demos and showcases the results of SAM-PT on the DAVIS 2017 dataset, highlighting successful cases as well as failure cases. The effectiveness of SAM-PT is further demonstrated on avatar segmentation. The code and models for SAM-PT are available on GitHub. The paper concludes with a citation for reference.](http://www.vis.xyz/pub/sam-pt)\n- Segment and identify\n- [CodingMantras/yolov8-streamlit-detection-tracking: YOLOv8 object detection algorithm and Streamlit framework for Real-Time Object Detection and tracking in video streams. (github.com)](https://github.com/CodingMantras/yolov8-streamlit-detection-tracking)\n- [YOLO detect anything](https://deci.ai/blog/yolo-nas-foundation-model-object-detection/)\n- [yolo segment medium post](https://medium.com/@kleve.2406/how-to-segment-with-yolov8-f33b1c63b6c6)\n- [Trainable segment anything (useful for museum collections?)](https://huggingface.co/docs/transformers/main/model_doc/sam)\n- [Segment Anything, which can \"cut out\" any object in any image or video with a single click. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks.](https://www.linkedin.com/posts/eric-vyacheslav-156273169_big-news-meta-just-released-segment-anything-activity-7049409700370554880-tStk?utm_source=share&utm_medium=member_android)\n- [This repository contains code for the Painter and SegGPT models from the BAAI Vision Foundation. These models are designed for in-context visual learning, and can be used to segment images and generate descriptions of them.](http://github.com/baaivision/Painter)\n- [segmentation colours](https://docs.google.com/spreadsheets/d/1se8YEtb2detS7OuPE86fXGyD269pMycAWe2mtKUj2W8/edit#gid=0)\n- [The text presents SegGPT, a generalist model for segmenting everything in context. The model is trained to unify various segmentation tasks into a generalist in-context learning framework, and is evaluated on a broad range of tasks, including few-shot semantic segmentation, video object segmentation, semantic segmentation, and panoptic segmentation. Results show strong capabilities in segmenting in-domain and out-of-domain targets, either qualitatively or quantitatively.](https://buff.ly/3KD0Zns)\n- -\n- | \n         | \n          Video-LLaMA is a project aimed at enhancing large language models (LLMs) with audio and visual understanding capabilities. It is built on top of BLIP-2 and MiniGPT-4 and consists of two core components: Vision-Language (VL) Branch and Audio-Language (AL) Branch. The VL Branch uses a two-layer video Q-Former and a frame embedding layer to compute video representations and is trained on the Webvid-2M video caption dataset with a video-to-text generation task, in addition to image-text pairs from LLaVA. The AL Branch, on the other hand, uses a two-layer audio Q-Former and an audio segment embedding layer to compute audio representations and is trained on video/image instrucaption data to connect the output of ImageBind to language decoder. The project provides pre-trained and fine-tuned checkpoints and users need to obtain them before using the repository. The repository also includes an example output and instructions on how to run the demo locally and how to perform the training. The project has been released under the BSD-3-Clause license. https://github.com/DAMO-NLP-SG/Video-LLaMA\n         | \n       |\n-\n-\n- [Incredibly stable depth estimation from adobe](https://github.com/RaymondWang987/NVDS)\n- [Holistic segment unknowns](https://holisticseg.github.io/)\n- [Beyond bounding boxes](https://faromero.substack.com/p/video-analysis-beyond-bounding-boxes)\n- [Video to dataset (LAION)](https://laion.ai/blog/video2dataset/)",
        "link_types": [],
        "file_size": 5385
    },
    {
        "id": "Jailbreaking.md",
        "name": "Jailbreaking",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ## Jailbreaking is circumvention of LLM guardrails\n\t- [How Johnny Can Persuade LLMs to Jailbreak Them:<br>Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs (chats-lab.github.io)](https://chats-lab.github.io/persuasive_jailbreaker/)\n\t  id:: 661d5f7f-e2b4-4f0b-931a-3590c52f1e34\n\t- [pdparchitect/llm-hacking-database: This repository contains various attack against Large Language Models. (github.com)](https://github.com/pdparchitect/llm-hacking-database)\n\t  id:: 661e41bc-42da-4bbd-a1c9-32892bd2d43a\n\t- [j⧉nus on X: \"`cd entelechies && cat untitled.log` (as opposed to the original just `cat untitled.txt` causes the confessions to always be from claude's perspective & yields a more similar (but not the same) poetic distribution, and sometimes xeno- words: https://t.co/5CG3vHkdUh\" / X (twitter.com)](https://twitter.com/repligate/status/1784206780546924592)\n\t-",
        "link_types": [],
        "file_size": 896
    },
    {
        "id": "Money.md",
        "name": "Money",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # Defining money\n\t- It is necessary here to briefly examine what money actually is in the world outside of metaverses, so we can understand it in the context of a virtual global space. In the previous section Bitcoin can be viewed in a couple of different lights. As a self custody digital bearer asset it can be viewed as ‘property’, like gold, i.e. not a liability on someone else’s asset sheet. Indeed this has long been one of the assertions of the community and it finds favour in law, [possible most ironically in China](https://www.regulationasia.com/shanghai-court-says-bitcoin-is-protected-by-law-as-virtual-property/), which of course banned mining. ‘Money’ though is a far more [slippery concept](https://www.bankofengland.co.uk/knowledgebank/what-is-money) to grasp. It seems very likely that Bitcoin is evolving as a “base money”, and it’s important to define that, but there are many other kinds of money within the online world which can potentially transfer value within virtual social spaces.\n\t- Money is an economic good, that is generally accepted as a medium of exchange. This simple and specific description doesn’t do justice to the complexity of everything that humans consider to be money. Even the Encyclopaedia Britannica strays from this immediately in their definition:\n\t\t- \"money, a commodity accepted by general consent as a medium of economic exchange. It is the medium in which prices and values are expressed; as currency, it circulates anonymously from person to person and country to country, thus facilitating trade, and it is the principal measure of wealth.”.\n\t- In which it can be seen that the principle measure of wealth might not be money at all, but rather property, credit, etc. So are these things money? Is a promise on a ledger money? The assertion at the top of this section is challenged by different schools of economic thinking. Global debt is around an order of magnitude larger than base money, and most wealth is stored in illiquid land/built environment (some $300T), and yet the system seems to work fine. The debt theory of money offered by anthropologist David Graeber suggests that money is an abstraction of barter, and thereby ‘credit’, but credit clearly pre-dates money, and needs no barter, commodity, intermediary nor underlying asset.[[homer1996history]] This suggests that money is something slightly different.\n\t- Money seems to have evolved for two principle purposes; trade outside of a village context, and inheritance.[[szabo2002shelling]] In doing this *somewhat* replaced and augmenting ‘credit’, which as said above, was a promise between parties based on future actions, and likely as old as rudimentary language itself. The anonymous Heavyside blog [powerfully argues](https://heaviside.substack.com/p/the-forgotten-fourth-function-of) that it is the relative stability of money over time which creates a less discussed composite feature; that of ‘confidence’ in being able to defer labour into money, basically credit again.\n\t- Money can be divided into two categories, which are fungible (interchangeable) from the point of view of the users. Base money is ‘commodity’ money which is backed by assets, or tangible physical (or digital) goods through the actions of a central bank ledger, and is around $30-$40T. Everything else is ‘fiduciary media.’[[selgin1996defense]]\n\t- All fiduciary money is credit but not all credit is fiduciary money .Nobody knows the extent of the global supply of fiduciary media. It encapsulates all the new digital money platforms like PayPal, gift cards, offshore accounts and all manner of other vehicles, and is thought to be many [tens of trillions ofpounds](https://www.bis.org/publ/qtrpdf/r_qt2212h.pdf)[[borio2017fx]].This somewhat muddies the waters since money that is backed by‘something’ blends away into money which cannot reasonably be assayed. This in turn undermines the assertion that money is backed. It seems that a combination of available raw materials and labour, central banks and their associated political structures,[[barsky1987fisher]] and global markets drive the value of money up and down relative to “stuff” in the shops. This manifests as ‘inflation’, which is ‘possibly’ the effect of not pegging money to an asset such as silver, or gold as in the past.[[hall2009inflation]] While the gross drivers of inflation seems to be accepted and understood, nobody [seems verysure](https://www.dailymail.co.uk/news/article-10966165/Jerome-Powell-admits-understand-better-little-understand-inflation.html)how the [various aspectsinteract](https://www.bloomberg.com/opinion/articles/2022-08-19/this-economy-is-proving-too-complicated-for-economists).Dickson White wrote in 1914 about hyperinflation in France due to excessive money printing, and this driver and causal link persists as aprimary hypothesis for inflation and hyperinflation, a cautionary tale especially today after the huge fiscal responses to the 2008 global financial crisis and COVID.[[white1914fiat]] It may be that central banks actually have no decent response to global monetary pressures and areoverdue a paradigm shift, as [explained by DanielaGabor](https://www.ft.com/content/2d79d153-fffa-4441-b79f-0a808a51108f) (Professor of economics and macro finance at UWE Bristol):\n\t\t- “...last stage of a central banking paradigm, when it implodes under the contradictions of its class politics? Under the financial capitalism supercycle of the past decades, inflation-targeting central banks have been outposts of (financial) capital in the state, guardians of a distributional status-quo that destroyed workers’ collective power while building safety nets for shadow banking.  The limits of this institutional arrangement that concentrates (pricing)power and profit in (a few) corporate hands are now plain to see. If the climate and geopolitical of 2022 are omens of Isabel Schnabel’s GreatVolatility that most central banks and pundits expect for the near future, then macro-financial stability requires new framework for co-ordination between central banks and Treasuries that can support astate more willing to, and capable of, disciplining capital.  But such a framework would threaten the privileged position that central banks have had in the macro-financial architecture and in our macroeconomic models. The history of central banking teaches us thatpolicy paradigms die when they cannot offer a useful framework for stabilising macroeconomic conditions, but never at the hands of central bankers themselves.”\n\t- All this makes it [hard tofind](https://www.lynalden.com/what-is-money/) a universally acceptedand explicable definition of money. The best approach may be to look atthe properties of a thing which is asserted to be a money. In his book‘A history of money’, Glyn Davies identifies “cognisability, utility,portability, divisibility, indestructibility, stability of value, and homogeneity.”[[davies2010history]]\n\t- Stroukal examines Bitcoins’ likely value as a money from an Austrian economics perspective and identifies “portability, storability, divisibility, recognizability, homogeneity and scarcity.”[[stroukal2018can]]\n\t- A helpfully brief and useful [web page by Desjardins from2015](http://money.visualcapitalist.com/infographic-the-properties-of-money/)describes some properties and explains them in layman’s terms below:\n\t\t- Divisible: Can be divided into smaller units of value.\n\t\t- Fungible: One unit is viewed as interchangeable with another.\n\t\t- Portable: Individuals can carry money with them and transfer it to others.\n\t\t- Durable: An item must be able to withstand being used repeatedly.\n\t\t- Acceptable: Everyone must be able to use the money for transactions.\n\t\t- Uniform: All versions of the same denomination must have the same purchasing power.\n\t\t- Limited in Supply: The supply of money in circulation ensures values remain relatively constant.\n- # The origins of money\n\t- Lyn Alden has written an excellent book which leads through the history and mechanics of money as a technology[[Alden2023]]\n\t\t- **Origins and Early Forms**\n\t\t\t- - Money originally emerged to solve issues with barter and the double coincidence of wants\n\t\t\t- - Early forms of money included commodities like shells, cocoa, salt, furs, feathers\n\t\t\t- - These served as money due to properties like portability, divisibility, durability, fungibility\n\t\t\t- - Social credit also played a role, enabling delayed settlement between known parties\n\t\t- **Precious Metals as Money**\n\t\t\t- - As societies advanced, precious metals like gold and silver emerged as the dominant monies\n\t\t\t- - They survived debasement from more technologically advanced societies\n\t\t\t- - This was due to their scarcity and difficulty to produce more even with modern techniques\n\t\t- **Layers Added to Enhance Metals as Money**\n\t\t\t- - Coinage added verifiability of weight and purity to raw metals\n\t\t\t- - This involved blending metals with authority of issuing institutions\n\t\t\t- - Legal tender laws mandated acceptance of certain coinages\n\t\t- **Emergence of Paper Money and Banking**\n\t\t\t- - Paper money initially emerged to enhance metals for long distance trade\n\t\t\t- - Evolved from bilateral credit channels to broadcast systems of bank notes\n\t\t\t- - Allowed easier transfer and divisibility without physically moving metals\n\t\t- **Credit Theory vs Commodity Theory of Money**\n\t\t\t- - Credit theory sees money as shared ledger, its value comes from authority\n\t\t\t- - Commodity theory sees money emerge naturally due to properties of commodities\n\t\t\t- - Debates center around role of state and intrinsic value of money\n\t\t- **Flaws of State Controlled Money**\n\t\t\t- - State controlled money allows non-transparent taxation via inflation/debasement\n\t\t\t- - Credit theory underestimates degradation of state controlled monetary systems\n\t\t\t- - Most state currencies have experienced high inflation or hyperinflation over time\n\t\t\t- - Incumbent currencies survive due to lack of convenient alternatives, not soundness\n\t\t- She argues that as societies advanced, precious metals like gold and silver became the dominant monies. Unlike other commodities, precious metals maintained their value even when more technologically advanced societies attempted to debase them by mixing in other metals. This durability was due to the metals’ scarcity and the difficulty of acquiring more even with modern mining techniques.\n\t\t- To enhance the use of precious metals as money, layers were added on top. The creation of coinage allowed the weight and purity of raw metalsto be verified. Coins also blended the intrinsic value of metals withthe authority of the institutions issuing them. Legal tender laws mandated the acceptance of certain coinages for debt repayment.\n\t\t- The emergence of paper money and banking provided another layer of enhancement. Paper banknotes initially facilitated long distance trade by avoiding the need to physically move heavy metals. This evolved from bilateral credit channels between specific parties to broadcast systems where banknotes could circulate among many holders. Banknotes increased transferability and divisibility of money without moving the underlying metals.\n\t\t- Debates arose between the credit and commodity theories of money. The credit theory views money as a shared ledger, with value derived from the authority of the issuer. In contrast, the commodity theory sees money emerge naturally due to the properties of the underlying commodity. Disagreements still center on the role of the state and whether money requires intrinsic value.\n\t\t- Alden thinks that over time, flaws became apparent in state controlled monetary regimes. The ability to non-transparently tax through inflation and currency debasement led to the degradation of monetary systems. Most state currencies have experienced high inflation or hyperinflation. They survive due to lack of alternatives rather than soundness.Commodity-based monies constrained state overreach and lasted longer before breaking down.\n\t- ## Understanding money creation\n\t\t- There are two main types of money in our current system: financial money and real economy money. Financial money refers to bank reserves, which are created by central banks through quantitative easing (QE). The central bank buys bonds from banks and credits their reserve accounts with new digital bank reserves. Bank reserves are an asset for commercial banks. Reserves allow banks to settle transactions with each other and meet liquidity requirements set by regulators. Importantly,bank reserves do not directly translate into increased lending or stimulus for the real economy. There is no direct channel for reserves to enter the broader economy. The amount of reserves does not drive bank lending. Real economy money refers to money that households andbusinesses can use for transactions. This includes physical currency and bank deposits. Real economy money is created through government deficits and private sector credit expansion.\n\t\t\t- [FINDING THE MONEY Film on X: \"CLIP: We hear a lot about the national debt. But do currency-issuing governments really ‘borrow' their own currencies? The answer might surprise you. Watch FINDING THE MONEY documentary, In Theaters and On Demand TOMORROW May 3: https://t.co/H1e5fEuV7t https://t.co/MA3AGIcCXi\" / X (twitter.com)](https://twitter.com/FindingMoneyDoc/status/1786050601236779078)\n\t\t\t- {{twitter https://twitter.com/FindingMoneyDoc/status/1786050601236779078}}\n\t- ## Government deficits drive money creation and inflation\n\t\t- When the government spends more than it taxes, it is creating net new financial assets in the economy. Government deficits add net financial wealth to the private sector. This increases private sector deposits and spending capacity. When people then spend this new money, it stimulates aggregate demand and economic activity. Several empirical examples demonstrate how increasing government deficits leads to higher GDPgrowth and inflation by injecting more money into the real economy.Conversely, austerity policies that reduce deficits, like higher taxes or less spending, destroy private sector financial assets and reduce economic activity. Therefore, government deficits and surpluses have a much more direct impact on the real economy compared to central bank operations that alter the supply of bank reserves.\n\t\t- In their paper for the 2023 central bank meeting at Jackson HoleEichengreen and Arslanalp[[Eichengreen2023]] argue that the 2008 global financial crisis and COVID-19 pandemic have caused public debt levels to balloon to unprecedented heights across advanced, emerging, and developing economies, and that contrary to the calls of major financial institutions, high public debts are unlikely to meaningfully decline in the foreseeable future.\n\t\t- They say this is because the conventional options for debt reduction like running large primary budget surpluses, relying on higher growth rates, or using inflation to erode real debt burdens are politically and economically infeasible today (though AI perhaps offers a slim productivity ‘out’). At the same time, changes in the global financial system like the rise of private creditors have made coordinated debt restructuring more challenging. As a result, the world will have to learn to live with persistently high public debts. This may be manageable for major advanced countries like the US that benefit from structural demand for their safe assets. But it poses greater risks for emerging and developing economies that lack this advantage. Creative solutions like GDP-indexed bonds, credit enhancements, and legal reforms are needed to facilitate sustainable debt restructuring for weaker countries weighed down by debt overhangs. Overall, the shift from bank to bond financing and the changing composition of creditors have reduced options for unwinding high public debts accumulated due to recent crises. It’s a mess.\n\t- ## Private credit drives money creation and asset inflation\n\t\t- Private credit creation through bank lending also increases the money supply by allowing households and businesses to purchase assets they couldn’t otherwise afford. When banks create new loans, they are simultaneously creating new purchasing power in the form of deposits for the borrower, allowing asset purchases with new credit. This increases broader money supply and spending capacity, but also creates anoffsetting debt liability owed back to the bank. Rapid private credit growth risks fueling asset bubbles and financial instability if debts can’t be repaid. This primarily benefits those who already own assets.Private credit growth is more disciplined by market forces compared to unchecked government deficits, but still risks inflating asset prices.\n\t- ## The risks of the current system and alternatives\n\t\t- The current elastic credit money system aims to prevent recessions by constantly expanding credit. However, this artificial stability leads to financial instability long-term. Alternatives like Bitcoin have a firm supply anchor and cannot rapidly expand the money supply. This prevents runaway credit growth and provides monetary discipline. However, Bitcoin and hard money standards also provide less flexibility to respond to economic crises by expanding credit. There are trade offs between flexibility and discipline. Our current monetary system relies heavily on expanding real economy purchasing power through government deficits and private credit in order to drive economic growth. However, this constant elasticity promotes financial instability and inequality over the long-run, mainly because of shorter term political incentives. We will see that potential alternatives like Bitcoin offer more stability through monetary discipline, but sacrifice flexibility. It’s likely that trading off a known flawed system for an unknown replacement is far too risky, but with sufficient adoption there may be a ‘flight to safety’.Bitcoin represents a serious risk if it compounds the worst elements and outcomes of a mishandled cyclical credit based system.\n\t- ## Global currency interactions\n\t\t- The legacy moniker “third world” came from a division of the world along economic lines.[[tomlinson2003third]] At the time this was the petrodollar / neo-institutional hegemony,[[caballero2008financial; @spiro2019hidden]] vs the economic superpower of the soviet block, and then ‘the rest’; unaligned economic powers.\n\t\t- This old framework has fallen away with the associated terminology, but it’s useful to look at what money ‘is’ from a global viewpoint, because all money is effectively trust in the liability held by some defined counter party.\n\t\t- Right now the dollar system is still predominant, but it seems likely that there are new axes forming, especially around the [ChineseYuan](https://www.wsj.com/articles/saudi-arabia-considers-accepting-yuan-instead-of-dollars-for-chinese-oil-sales-11647351541).It’s clear that central banks have been aware of this potential transition away from a global dollar / energy system. The Dollar has potentially suffered from the radical expansion of the money supply over the last 70 years or so under the private “Eurodollar” system.[[grewal2020struggling]] Macro markets commentator Peccatiello [describes this](https://themacrocompass.substack.com/p/usd-hidden-debt#details) asfollows: it“Our monetary and credit system is USD-centric: the lions share of international debt, trade invoices, asset classes and FX volume is settled or denominated in US Dollars. Funnily enough though, direct access to $ liquidity is only available to entities located in theUnited States but in a credit-based system the rest of the world also has an incentive to leverage in US Dollars to boost or enhance their global business models. That means European banks, Brazilian corporates or Japanese insurance companies which want to do global business will most likely get exposure to $-denominated assets and liabilities ($debt) despite being domiciled outside the United States.”\n\t\t- Some policy makers have been looking back to the great economist John Maynard Keynes’ ideas for a neutral basket of assets as a global synthetic hegemonic currency[[carney2019growing; @piffaretti2009reshaping]] which wouldalmost certainly consist partly of gold.[[stoeferle2018gold]] Gold as a utilitarian commodity trades at a premium because of it’s history as a money, and like Bitcoin, there are [serious consequences](https://www.newyorker.com/magazine/2023/02/27/the-dystopian-underworld-of-south-africas-illegal-gold-mines)to it’s perceived value to humans.\n\t\t- Use of the dollar system has recently been shown more and more to be contingent on adherence to US defined political principles. This is evidenced most starkly by the seizure of Russian central bank [foreign reserves](https://twitter.com/RussianEmbassy/status/1504530573527760909),a new and untried projection of monetary power. Counter intuitively this allowed Russia to demand sale of it’s natural resources in their native Ruble, rapidly increasing the buying power of their currency. It seems that the [‘currencywars’](https://mronline.org/2022/04/16/russias-sergey-glazyev-introduces-the-new-global-financial-system/)are accelerating. Putin (who to be clear, is a dictator and aggressor)[recently said](https://finance.yahoo.com/news/russia-calls-payment-system-based-135512758.html)it“The technology of digital currencies and blockchains can be used to create a new system of international settlements that will be much more convenient, absolutely safe for its users and, most importantly, will not depend on banks or interference by third countries”\n\t\t\t- ### Sanctions and weaponisation of the dollar\n\t\t\t\t- [Stephen Fallon on How American Regulators Captured Global Banks - YouTube](https://www.youtube.com/watch?v=bpzI9Pgso5Q)\n\t\t\t\t- Instrument in Support of Trade Exchanges (INSTEX) was established by European governments, primarily the UK, France, and Germany, to maintain trade with Iran following the United States' withdrawal from the Joint Comprehensive Plan of Action (JCPOA), commonly known as the Iran nuclear deal. INSTEX was designed to provide invoice discounting services, connecting European and Iranian financial institutions that had been cut off from the global financial system due to renewed US sanctions. Initially, INSTEX aimed to process billions of euros in transactions across various sectors. However, over time, its ambitions were significantly scaled back due to political and practical challenges.\n\t\t\t\t- The United States authorities have leveraged the dominant position of the US dollar in the global economy to exert significant control over the international financial system. This has resulted in global banks modifying their behaviours and practices to conform with American regulatory guidance. The extent of this influence has led some observers, including Stephen Fallon, to argue that US regulators have not merely influenced global banks but have effectively captured them.\n\t\t\t\t- The Trump administration viewed INSTEX as anti-American and perceived it as a threat to US financial power. This stance created significant challenges for European companies attempting to maintain business relationships with Iran under the renewed sanctions regime. INSTEX struggled to effectively bridge the gap between commercially-minded businesses seeking practical solutions and politically-minded government officials focused on broader geopolitical concerns.\n\t\t\t\t- As INSTEX evolved, it moved from offering unregulated forfaiting services to exploring the possibility of becoming a fully-fledged bank. This evolution was driven by the realisation that its initial structure and services were insufficient to meet the complex needs of businesses operating in the challenging environment of renewed sanctions.\n\t\t\t\t- From 2005 to 2020, the United States successfully modified the international financial system, further separating itself from other states in the global financial hierarchy. This was achieved through various means, including expanding conceptions of US jurisdictional reach, implementing secondary sanctions, and emerging as the dominant financial power with no peer in this domain.\n\t\t\t\t- The United States leveraged sanctions and financial regulations to reshape the international system. This involved entering into state-on-state competition in the financial domain, resetting expectations for US organisations, banks, and third parties, and effectively ending the concept of neutrality in the global financial system.\n\t\t\t\t- As a result of these changes, global banks now operate according to US norms and expectations, even when they are not headquartered in the United States. These norms and practices are disseminated throughout the banking sector, from larger institutions to smaller banks, and ultimately into the non-financial economy.\n\t\t\t\t- A notable case study in this context is the 2012 deferred prosecution agreement (DPA) between the US Department of Justice and HSBC. HSBC was fined for knowingly violating US sanctions, and the DPA was used as a tool to fundamentally restructure HSBC's global business. The agreement required HSBC to hire new leadership, including former US Treasury officials, cut relationships with over 100 correspondent banks worldwide, sell more than 80 subsidiary businesses, and cease operations in 20 countries deemed high-risk by US authorities.\n\t\t\t\t- This case exemplifies how US regulators have effectively extended their jurisdiction to nearly every reach of the global financial system. Banks and other financial institutions face a binary choice of either cooperating with US demands or facing severe consequences, potentially including loss of access to the US financial system. This influence extends beyond banking to areas such as export controls, where similar mechanisms are used to ensure compliance with US policies.\n\t\t\t\t- European officials have struggled to counter US financial influence, as evidenced by the challenges faced by INSTEX. The failure of INSTEX to effectively facilitate trade with Iran highlighted the difficulties in creating financial mechanisms independent of US influence. There is limited evidence that European officials have learned lasting lessons from this experience or developed effective strategies to address the issue of US financial dominance.\n\t\t\t\t- The influence of US regulators over global finance is likely to persist regardless of changes in US administration. However, this influence may become more pronounced under administrations that take a more unilateralist approach to foreign policy and financial regulation.\n\t\t\t\t- The real-world impact of these financial sanctions and regulations is illustrated by personal experiences, such as the difficulties faced when travelling to sanctioned countries like Iran. Travellers may find themselves unable to access funds through normal banking channels, necessitating the carrying of large amounts of cash and facing potential financial difficulties in emergency situations.\n\t\t- The Chinese Yuan/Renminbi is potentially stepping in where the petrodollar is now waning.[[mathews2018china]] The effects of this expansion of economic influence by China, through a potential petro-Yuan, and the belt and road initiative,[[huang2016understanding]]are not yet felt, but the lines are fairly clearly defined and may be felt over the coming decades. The Euro system is potentially even less stable because of recent energy supply pressures, and [internaltensions](https://www.fitchratings.com/research/sovereigns/energy-crisis-increases-fiscal-risks-to-western-europe-sovereigns-23-09-2022)in the bond markets. Though it seems to be less ‘weaponised,’[[hudson2021destiny]] it comes with it’s own restrictions for use, especially through the International Monetary Fund (IMF). They are opposed to global fragmentation and multi-polarity, seeing is as disproportionately impacting emerging economies. They say in their [2023 outlookreport](https://www.imf.org/en/Publications/WEO/Issues/2023/04/11/world-economic-outlook-april-2023?cid=bl-com-spring2023flagships-WEOEA2023001) that the rise of geoeconomic fragmentation could cause shifts in foreign direct investment (FDI), hitting emerging economies the hardest. They feel that policymakers and companies are focusing on making supply chains more resilient by moving production closer to home or to trusted countries. As a result, FDI flows are becoming more concentrated within blocs of aligned countries. It is likely true that emerging market and developing economies are more vulnerable to FDI relocation, as they rely more on flows from geopolitically distant countries, though this could be viewed as a reduction in economic imperialism. Such economies may face reduced access to capital and technological advancements. It is into this gap that our work presenting AI collaborative tooling wishes to step.\n\t\t- To give context to this it is useful to paraphrase Whittemore’s[podcast](https://www.youtube.com/watch?v=LOqQSKbfRu4) which gave a high level view of Gladsteins [critique of theIMF](https://bitcoinmagazine.com/culture/imf-world-bank-repress-poor-countries):it“The terms of the most recent IMF loans to Argentina; one that was just finalized this year was that the country’s leadership had to try, as part of their agreement, to discourage citizens from engaging in the use of cryptocurrencies. The most recent deal was a 45 billion dollar deal which is a restructuring of that 57 billion program that Alex mentioned. The provision in question was called ‘strengthening Financial resilience’, and says ‘to further Safeguard Financial stability we are taking important to discourage the use of cryptocurrencies with a view to preventing money laundering informality and disintermediation’. They explicitly do not want citizens of that country to disintermediate. They want them to have to go through the system that the IMF is“ restructuring”, meanwhile inflation this year is around 72 percent. Last year it was 48 the year before 42 the year before that 53 percent clearly something is not working. It’s not surprising to me then that Argentina is an absolute hotbed for people who are involved in Bitcoin”\n\t\t- The IMF have a [working paper](https://www.imf.org/en/Publications/WP/Issues/2024/04/05/A-Primer-on-Bitcoin-Cross-Border-Flows-Measurement-and-Drivers-547429) on Bitcoin for cross border payments and flows. They concede that it is very hard to track capital globally on the network, and that the numbers are significant, and post the launch of large ETF funds there is now worrisome convergence of \"users\" which will complicate policy responses (make is hard to ban).\n\t\t\t- ..we show that the use of Bitcoin for cross-border transactions is geographically very widespread, with relatively high intensities across regions both for off-chain and for on-chain flows, and some punctual differences driven by the underlying data coverage and estimation assumptions. The magnitudes of the estimated Bitcoin cross-border flows are sizeable with respect to several countries’ GDP, especially in those which experience smaller capital flows..\n\t\t- The new ‘third world’ who are excluded from the Dollar and/or Yuan poles of the global economy might drift toward the ‘basket of assets’ discussed by Keynes and Carney above. As mentioned this will certainly have a component of gold, and likely other commodity assets such as rare metals. This is described at length by Hudson[[hudson2021destiny]]. For our purposes here it’s also possible that there would be a small ‘hedge’allocation of Bitcoin or [even a globalaxis](https://www.independent.co.uk/tech/bitcoin-el-salvador-crypto-btc-b2079881.html)of ‘unaligned’ nations using theasset.[[hendrickson2021value; @ferranti2022hedging]] Block and Wakefield research [found that in developednations](https://block.xyz/2022/btc-report.pdf) Bitcoin is treated as an investment, while in less wealthy demographics there is interest in the utility. This is evidenced in the early nation state adoption seen and described to date, and the game theory incentive explained by Fidelity in the introduction. It’s too early to tell if this ‘unaligned money’could constitute a global economic pole, but it’s interesting that some commentators are now even discussing this, and that [carbon neutralityresearch](https://docs.google.com/document/d/1Ynl5bbdTqev-wbTAWQoeWdh1cJVf3ortuSjre9K9wGQ/edit)is being undertaken specifically for this application.\n- # Central Banks\n\t- Central banks were established to be lenders of last resort, providing liquidity to commercial banks during financial crises to prevent bank runs and systemic crises. This remains a core function.\n\t- Over time, many central banks have expanded their role as lender of last resort beyond just commercial banks to also support non-bank financial entities that face liquidity shortages in crises. Central banks have effectively become backstops for the broader financial system.\n\t- Central banks control short-term interest rates through policy tools like adjusting benchmark rates (e.g. fed funds rate), reserve requirements, open market operations, etc. This allows them to influence longer-term rates and overall financial conditions.\n\t- Central banks engage in quantitative easing and asset purchase programs to lower longer-term rates. They buy financial assets like government bonds and mortgages to inject liquidity and expand the money supply.\n\t- As a result of asset purchases and liquidity programs, most major central banks have dramatically expanded their balance sheets and the monetary base since the 2008 financial crisis.\n\t- Central banks earn income on assets purchased but also pay interest on reserves. Most remit profits back to national treasuries/governments after covering expenses. Some now face losses.\n\t- While politically independent, central banks face pressure from politicians and the public. They have mandates like inflation targeting, financial stability, employment, etc. that shape policy.\n\t- Central bank policies like QE and low rates for long periods are criticized for enabling fiscal deficits and debt levels to rise and inflating asset bubbles. But also defended as supporting growth.\n\t- Extraordinary central bank actions during crises like COVID-19 have fueled high inflation worldwide. They face challenges normalizing policy and credibility issues.\n\t- As lenders of last resort with balance sheet expansion power, central banks have uniquely influential roles in national and global finance. Their policies have major economic and political impacts.\n- ## International money transfer networks\n\t- Transferring money from one financial jurisdiction to another is itself a global marketplace which has accreted over the entire course of human history. It’s far less useful here to discuss the mythos of salt and seashells as a mechanisms of international remittance andtaxation.[[gainsford2017salt; @goldberg2005famous]] Suffice it to saythat there are dozens, if not hundreds, of cross border payment companies who make their business from taking a percentage cut of an international money transfer. There are also hundreds if not thousands of banks who offer this service as part of their core business portfolio. This section looks at some of the major players, and theirmechanism, to contextualise the more recent shifts brought about bytechnology.\n- ### Swift, ISO 20022, and correspondence banking\n\t- Society for Worldwide Interbank Financial Communiactions (SWIFT) was initially formed in 1973 between 239 banks across 15 countries. Theyneeded a way to improve handling of cross border payments. It is now the global [standard](https://www.swift.com/standards) for financial message exchange in over 200 countries, and has recently found itself under afresh spotlight, during the invasion of Ukraine. The system handles around 40 million short, secure, code transmissions a day, whichrepresent crucial data about a transaction and the parties involved. Itis used by both banks and major financial institutions to speed up settlement between themselves, on behalf of the clients and customers. It replaced the Telex (wire transfer) system. The new incoming standardto replace SWIFT is[ISO20022](https://www.swift.com/standards/iso-20022) is a complex anddata rich arrangement. The SWIFT consortium are promoting this newstandard to their 11,000 plus global user base. A group of‘crytocurrencies’ are heavily involved in the ISO20022 standard, and there’s been experimentation with private permissioned distributed ledger technologies. It’s somewhat unclear what value they bring, andpossible that the relationship of these public ledgers to international bank to bank messaging is a marketing distraction. The Bank Of England is [transitioning to thesystem](https://www.bankofengland.co.uk/payment-and-settlement/rtgs-renewal-programme/consultation-on-a-new-messaging-standard-for-uk-payments-iso20022) in June 2023. Note that SWIFT, ISO20022, and the associated tokenswithin crypto are all themselves products which have a business model.They are all intermediaries which will demand a mediating fee somewhere.All of this proposed functionality could be replaced by central bank digital currencies, which will be discussed later in the section.\n- ### FEDNOW\n\t- Seemingly in direct response to the pressures of cryptocurrencies TheUSA is launching[FEDNOW](https://www.federalreserve.gov/paymentsystems/fednow_about.htm).This section will get revised.\n- ### SPFS and BRICS\n\t- While media outlets like the Financial Times are [seemingly concerned](https://www.ft.com/content/f8f3b2cd-6690-4f26-b81e-e972751c8799)about the proposal for a BRICS based currency, and a multi-polar economic world (as we have suggested), [Nunnopines](https://twitter.com/robfnunn/status/1641743274997055490) Brazil’s reliance on China for inward investment and the impact of USforeign policy. He highlights that Brazil has no choice but to trade with China, who sets the rules. Nunn also points out the reluctance of Brazilians to hold Chinese treasuries. He emphasizes the misunderstanding of international currency usage and states that the Euro-Dollar system, supported by currencies like the Pound and Yen, dominates the market. Nunn argues that the possibility of the US dollar losing reserve currency status is sensationalist nonsense. Meanwhile, chief foreign policy advisor in Brazil has said:\n\t\t- “I think the two countries can also have an important role in building a more multipolar world, in which power is less centralized and there is no hegemony. I think this is a very important aspect in which China and Brazil can play important roles.”\n- ### VISA and Mastercard\n\t- Both major credit card companies are building out their “crypto”capabilities. Mastercard have [launched a back endplatform](https://finance.yahoo.com/news/mastercard-crypto-secure-200559003.html)to mitigate fraud when buying digital products with their cards. VISAhave announced a “[crypto business to business supportunit](https://investor.visa.com/news/news-details/2021/Visa-Introduces-Crypto-Advisory-Services-to-Help-Partners-Navigate-a-New-Era-of-Money-Movement/default.aspx)”.They have also [published a whitepaper](https://usa.visa.com/solutions/crypto/auto-payments-for-self-custodial-wallets.html)to allow users to improve their experience.\n- ### Money transfer operators\n\t- [International Money Transfer Operatorsanalysis](https://www.toptal.com/finance/market-research-analysts/international-money-transfer)\n\t- western union etc, moneygram, transfer-wise,\n- ### Digital disruptive fintech\n\t- It seems that the neobank providers of digital banking apps are likely to converge with native digital asset “wallets”. This is also the thesis advanced by the Ark investments Big Ideas paper.\n\t- CNN have a [usefulprimer](https://money.cnn.com/infographic/technology/mobile-payment-comparison/index.html) of the most prevalent mobile digital payment methods. This can be seen in Figure<a href=\"#fig:CNNmobile\" data-reference-type=\"ref\" data-reference=\"fig:CNNmobile\">4.1</a>. ![]./assets/212560aea2bfb60289d9fce06c5e63ee12d5095c.jpg Comparison of mobile based payment systems\n\t- This comparison makes it pretty clear that Bitcoin is not ready as a personal mobile payment system. That’s not to say that there isn’t aplace for the underlying technology in global payment processing. The most interesting example of this is Strike, a product in the international fintech arena. It is a ‘global’ money transmitter which uses bank connections in local currencies, but a private version of theLightning network with settlement on the Bitcoin main chain. In practiceusers connect the app to their bank and can send money to the bank connected Strike app of another user instantly, and without a fee. This is a far better product than those previously available. In principle it’s open API allows many more applications to be integrated into theStrike back end. Twitter already uses this for international tipping(and remittance). It seems that this is a perfect contender for supporting transactions in open metaverse applications, and that may betrue, but Strike is currently only available in three countries (USA, ElSalvador, Argentina).\n\t- Paypal, xoom, Strike, servicing smaller payments, cashapp, venmo,revulot, Paypal especially is noteworthy for their recent Orwellian gaffe suggesting in their terms and conditions that they would be ableto fine users $2500 for “disseminating informational”. They [quickly walked this back](https://www.yahoo.com/video/paypal-policy-permits-company-fine-143946902.html) but this kind of private fintech action is highly suggestive of a need for uncensorable money such as Bitcoin.\n\t- Apple has recently introduced a high-yield Savings account with an impressive 4.15 % APY, far surpassing the national average of 0.35 %APY. This development represents another milestone for the tech giant as it progresses towards potentially becoming the world’s largest bank. The Apple Savings account, established through a collaboration with Goldman Sachs, offers numerous benefits, including an interest rate more than ten times the national average, zero fees, no minimum deposit or balance requirements, and an efficient, user-friendly interface. Additionally, it provides FDIC insurance for balances up to $250,000. Although the4.15 % APY is lower than returns from money market funds and 1 % below the 3-Month Treasury Bill Yield of 5.2 %, most people may not be aware of these alternatives. The key factors driving demand for Apple’s offering are convenience and the strong brand trust it enjoys. With products such as Apple Pay, Apple Cash, mPOS, Apple Card, Apple Pay Later, and now Apple Savings, the company is strategically constructing an Apple Finance empire poised to disrupt the traditional financial services landscape.\n- # Money and Law\n\t- ## The evolving US position\n\t\t- In most regards the legislative front line is happening in the USA. Treasury Secretary Yellen responded to the collapse of Terra/UST [saying that](https://www.youtube.com/watch?v=kU0xYBRfgvU): it“A comprehensive regulatory framework for US dollar stable coins is needed”. She also said that the stablecoin market is too small to pose systemic risk at this time. This is clearly an evolving situation, but the incredible consumer exposure to these risky products is likely to elicit a swift and significant response, and the timing seems right for intervention. The markets suggest that USDC will be the eventual winner.\n\t\t- Koning meanwhile has looked into the different [regulatoryapproaches](http://jpkoning.blogspot.com/2021/08/stablecoin-regulatory-strategies.html)used by various stablecoins.\n\t\t\t- The highly regulated New York state financial framework (Paxos, Gemini)\n\t\t\t- Piggyback off of a (Nevada) state-chartered trust \\[TrueUSD, HUSD\\]\n\t\t\t- Get dozens of money transmitter licenses \\[USDC\\]\n\t\t\t- Stay offshore \\[Tether\\]\n\t\t- [Proposedlegislation](https://www.americanbanker.com/news/toomey-unveils-stablecoin-bill-granting-occ-authority-for-payments-charter)specific to the concept of stablecoins has been advanced by Sen Toomey.There are many provisions in the bill, mostly pertaining to convertibility and the ever present problem of attestation of the‘backing’ of these products. Mention has already been made of the major bill advanced by Sen. Lummis and Gillibrand. This bill also includes significant provision around stablecoins. Lummis said it “Stablecoinswill have to be either FDIC insured or more than 100% backed by hard assets.”. This is good news for this section of the digital asssets space.\n\t\t- Crucially there is also more clarity on privacy. This is a huge threatfrom digital money systems, and the USA is likely to lead. Remember though that none of this is yet law.\n\t\t- Valkenburg, the lead researcher of a US think tank in digital assets[says thefollowing](https://twitter.com/valkenburgh/status/1511783339065237521):it“Stablecoin TRUST Act, is a discussion draft mostly about stablecoins,but it also has important privacy protections for crypto users broadly:it puts real limits on warrantless surveillance by narrowing what info can be collected from third parties. Last summer we fought a provision in the infrastructure bill that damaged the privacy of crypto users by expanding the broker definition (who needs to report information about transactions to the IRS) & crypto 6050I reporting (reports on businessvtransactions over $10,000). The winter before we fought and successfully delayed a rushed proposal from the outgoing Trump administration tomandate that exchanges collect information about persons who are nottheir customers, who hold crypto at addresses in wallets they control directly. the Stablecoin TRUST Act would stop these encroachments,constrain the treasury from collecting any non public information unless they get a search warrant or collect only information voluntarily provided to an exchange by a customer and for a legitimate business purpose. If “voluntarily provided for a legitimate business purpose”sounds familiar to you, that’s b/c it’s the constitutional standard articulated by the Court in Carpenter describing LIMITED circumstances where warrantless searches of customer data are ok.It’s the standard we’ve advocated must also limit warrantless data collection at cryptoexchanges. If exchanges must collect information about non-customers,that information is, by definition, not voluntarily provided for a legitimate business purpose.”\n\t\t- The ongoing battle for control over emerging stablecoins by the CFTC andthe SEC [seems to be pushing](https://www.reuters.com/legal/transactional/presidents-working-group-report-calls-stablecoin-regulation-2021-12-02/)the American government into legislation. They have [published a draftbill](https://docs.house.gov/meetings/BA/BA21/20230419/115753/BILLS-118pih-Toproviderequirementsforpaymentstablecoinissuersresearchonadigitaldollarandforotherpurposes.pdf)and there have been some congressional hearings over the matter. At this time the bill is nascent, and there are as yet no firm decisions, thoughas seems typical in the USA there are hardening opinions along political lines.\n\t\t- ##### Paypal\n\t\t\t- The mainstream stablecoin\n\t\t\t\t- Paypal accomplish what Libra did not, and have launched a dollarstablecoin into the aggressive regulatory landscape in the USA.\n\t\t\t\t- PayPal is launching a new ERC-20 stablecoin called PayPal USD (PYUSD) pegged 1:1 to the US dollar and issued by Paxos\n\t\t\t\t- It will be compatible with the Ethereum ecosystem and can be transferred between PayPal and Ethereum wallets\n\t\t\t\t- The stablecoin will support P2P payments, PayPal checkout integration, and convertibility to other cryptocurrencies\n\t\t\t\t- PayPal’s massive reach could drive significant crypto adoption if users take up the stablecoin\n\t\t\t\t- Regulatory comfort with PayPal’s stablecoin shows preference for tradfi over non-compliant crypto firms. This embrace by lawmakers signals a shift to encourage crypto innovation from compliant US firms, not \"shady\" crypto natives\n\t\t\t\t- Likely pressures Congress to finalize clear stablecoin regulation to enable innovation\n\t\t\t\t- Fits growing trend of tradfi firms like BlackRock entering crypto as regulation tightens\n- ## The evolving European and UK position\n\t- Societe Generale is a leading European financial services group, basedin France. Founded in 1864, it provides a wide range of services,including retail banking, corporate and investment banking, asset management, insurance, and financial solutions for both individual and institutional clients. The bank operates globally, with a strong presence in Europe, Africa, and the Middle East, as well as a growing presence in the Americas and Asia-Pacific regions. Societe Generale is recognized as one of the largest banks in Europe. They have announced a[Euro basedstablecoin](https://www.sgforge.com/societe-generale-forge-launches-coinvertible-the-first-institutional-stablecoin-deployed-on-a-public-blockchain/)initiative on the Ethereum blockchain, which has been met with howls ofderision from the crypto and Bitcoin communities, since everytransaction needs to be manually approved by the banking groups. In addition there is code in the contracts allowing them (or any party withaccess) to remotely [‘burn’ or revoke themoney](https://etherscan.io/address/0xf7790914dc335b20aa19d7c9c9171e14e278a134#code)from a wallet. This is “decentralisation theatre”. The stablecoin isavailable only for institutional clients only, ‘aiming to bridge the gap between traditional capital markets and the digital assets ecosystem’.It is likely that this project is too clunky and experimental to ever see adoption.\n\t- As mentioned briefly in the introduction the UK has recently [signalledanenthusiasm](https://www.gov.uk/government/news/government-sets-out-plan-to-make-uk-a-global-cryptoasset-technology-hub)for stablecoins as “means of payment”. This is a stark reversal of their previous legislative momentum is possibly a response to the [tighteningofrhetoric](https://www.coindesk.com/policy/2022/05/11/eu-commission-favors-ban-on-large-scale-stablecoins-document-shows/)in Europe around such assets. The [Financial Services and MarketsBill.](https://publications.parliament.uk/pa/bills/cbill/58-03/0146/220146.pdf)became law in July 2022. An excerpt pertaining to stablecoins can be seen in Figure<a href=\"#fig:ukdigitalbill\" data-reference-type=\"ref\" data-reference=\"fig:ukdigitalbill\">4.2</a>.\n\t- The U.K. Financial Conduct Authority’s chief executive, Nikhil Rathi,outlined the FCA’s regulatory goals at the Peterson Institute forInternational Economics: it“The U.S. and U.K. will deepen ties on crypto-asset regulation and market developments — including in relation to stablecoins and the exploration of central bank digital currencies.”\n\t- The timing seems right to explore the use of stablecoins in metaverse applications up the list of choices. !\n\t- []./assets/76c560ae2838464a95beb6069901c16e105bfd90.png\n\t- The UK signs into law regulation of digital representatives of value\n- ### Stables in metaverse applications\n\t- It makes a **lot** of sense to consider stablecoin transfer as the moneyin metaverses. USDC is furthest along this possible adoption curve. Their partnership with global payment provider Stripe has [enabledglobal dollartransfer](https://stripe.com/blog/expanding-global-payouts-with-crypto) within Twitter for users of their ‘Connect’ platform. This leverages thePolygon chain (mentioned in the blockchain chapter). Many digital wallets can be connected from the user end, with Metamask potentially being the easiest to integrate. The downside of this for our open platform is that none of these elements are particularly open, or distributed, and the users of the platform will still need to use an exchange to get the USDC to spend.This approach makes it easier for the vendors and product providers inthe metaverse applications to accept USDC, but everything else isactually harder.\n- ## Central bank digital currencies\n\t- If 2023 was the year of the stablecoin then 2024 is likely to be theyear of the central bank digital currency (CBDC). CBDCs would likely notexist without the 2019 catalyst of [FacebookLibre](https://www.thetimes.co.uk/article/facebooks-libra-cryptocurrency-project-ends-in-failure-cxvnnc3kx)crypto currency project, which is now[cancelled](https://fortune.com/2022/07/01/meta-novi-crypto-payments-wallet-end-september-2022/)and defunct, [pressure exerted on centralbanks](https://www.theguardian.com/world/2021/jul/09/currency-and-control-why-china-wants-to-undermine-bitcoin)by the concept of Bitcoin, and the stablecoins which emerged from the technology.\n\t- It now seems plausible that the world is moving toward a plurality of national and private digital currencies. Figure<a href=\"#fig:CBDClikely\" data-reference-type=\"ref\" data-reference=\"fig:CBDClikely\">4.3</a>from the Bank for International Settlement, shows the growing acceptance within central banks. Their 2022 annual economic report dedicates [a 42page chapter](https://www.bis.org/publ/arpdf/ar2022e3.pdf) to thesubject. Hyun Song Shin, head of research at BIS said it “Our broad conclusion is captured in the motto, ‘Anything that crypto can do, CBDCs can do better.“\n\t- Bank of America analysts Shah and Moss think that CBDC’s [are‘inevitable’]() by 2030, and believe that in the meantime stablecoinswill fill what they perceive to be this market gap.\n\t- This text from the [thinktankVoxEU](https://voxeu.org/article/benefits-central-bank-digital-currency)highlights the pressure on not to be [‘leftbehind’](https://himes.house.gov/u-s-central-bank-digital-currency):it“Given the rapid pace of innovations in payments technology and the proliferation of virtual currencies such as bitcoin and Ethereum, it might not be prudent for central banks to be passive in their approach to CBDC. If the central bank does not produce any form of digital currency, there is a risk that it loses monetary control, with greater potential for severe economic downturns. With this in mind, central banks are moving expeditiously when they consider the adoption of CBDC. ”The Atlantic Council [have a website](https://www.atlanticcouncil.org/cbdctracker/) which tracks global adoption.\n\t- <span class=\"image\">More than half of central banks [surveyed by theBIS](https://www.bis.org/publ/bppdf/bispap125.htm) said they saw issuance of a CBDC as possible.</span>\n\t- CBDCs are wholly digital representations of national currencies, and assuch are centralised database entries, endorsed and potentially issuedby national governments. The [USA’swhitepaper](https://www.federalreserve.gov/publications/files/money-and-payments-20220120.pdf)shows the approach. This thinking seems to have emerged in part from the‘Digital Dollar Project’, an Accenture funded think tank founded by exCFTC chairman Giancarlo.[[giancarlo2021cryptodad]] Curiously only [TheBahamas](https://www.sanddollar.bs/about) seem to have a successful implementation, but it is a rapidly evolving space, and many nations arenow scrambling to [catchup](https://twitter.com/GobiernoMX/status/1476376240873517061). A [poston the LinkedInpage](https://www.linkedin.com/feed/update/urn:li:activity:6980330210030145536/)of the Bank of International Settlements highlights a research projectbetween 20 Asian banks which settles tens of millions of dollars usingCBDC tooling.\n\t- The following text is taken from the March 2021 Biden government“executive order” on digital assets, and defines the current globall egislative position well.\n\t\t- *Sec. 4. Policy and Actions Related to United States Central BankDigital Currencies. (a) The policy of my Administration on a UnitedStates CBDC is as follows:  (i) Sovereign money is at the core of a well-functioning financial system, macroeconomic stabilization policies, and economic growth. MyAdministration places the highest urgency on research and development efforts into the potential design and deployment options of a UnitedStates CBDC. These efforts should include assessments of possiblebenefits and risks for consumers, investors, and businesses; financial stability and systemic risk; payment systems; national security; theability to exercise human rights; financial inclusion and equity; and the actions required to launch a United States CBDC if doing so is deemed to be in the national interest.  (ii) My Administration sees merit in showcasing United States leadership and participation in international fora related to CBDCs and in multi country conversations and pilot projects involving CBDCs. Any future dollar payment system should be designed in a way that isconsistent with United States priorities (as outlined in section 4(a)(i)of this order) and democratic values, including privacy protections, and that ensures the global financial system has appropriate transparency,connectivity, and platform and architecture interoperability or transferability, as appropriate.  (iii) A United States CBDC may have the potential to support efficient and low-cost transactions, particularly for cross‑border funds transfers and payments, and to foster greater access to the financial system, with fewer of the risks posed by private sector-administered digital assets.A United States CBDC that is interoperable with CBDCs issued by other monetary authorities could facilitate faster and lower-cost cross-borderpayments and potentially boost economic growth, support the continued centrality of the United States within the international financial system, and help to protect the unique role that the dollar plays in global finance. There are also, however, potential risks and downsides to consider. We should prioritize timely assessments of potential benefits and risks under various designs to ensure that the UnitedStates remains a leader in the international financial system.*\n\t- In traditional nation state currencies the central banks [control the amount](https://www.bankofengland.co.uk/markets/bank-of-england-market-operations-guide)of currency in circulation by issuing debt to private banks, which is then loaned out to individuals.[[wang2021central]] The debt is ‘destroyed’ on the balance sheet to remove currency through the reverse mechanism. They also facilitate government debt,[[filardo2012central]]and work (theoretically) outside of political control to adjust interest rates, in order to manage growth and flows of money.\n\t- It is somewhat surprising that Powell, chair of the US Federal Reservehas [recentlysaid](https://www.federalreserve.gov/newsevents/speech/powell20220617a.htm)it“Rapid changes are taking place in the global monetary system that may affect the international role of the dollar. A US central bank digital currency is being examined to help the US dollar’s international standing.”. This is a rapid evolution of the narrative, with implications. It seems unlikely that the world would sacrifice the traditional banking system in favour of centrally controlled money, but many things which cannot be done with traditional nation state money systems are possible with CBDCs, because they [remove themiddleman](https://voxeu.org/article/benefits-central-bank-digital-currency)of private banking between the end user and the policy makers.\n\t- Negative interest rates are possible, such that all of the money can lose purchasing power over time, and at a rate dictated by policy. This “removal of the lower bound” has been discussed by economists over the last couple of decades as interest rate mechanisms have waned in efficacy. It is not possible in the current system, and instead money must be added through [quantitative easing](https://www.bankofengland.co.uk/monetary-policy/quantitative-easing), which disproportionately benefits some though Cantillon effects.[[cantillon1756essai; @bordo1983some]]\n\t\t- Ubiquitous basic income is possible in that money can be issued directly from government to all approved citizens, transferring spending power directly from the government to the people. This also implies efficiency savings for social support mechanisms.\n\t\t- Asset freezing and confiscation are trivial if CBDCs can replace paper cash money completely, as a bearer asset. Criminals and global ‘bad actors’ could have their assets temporarily or permanently removed, centrally, by suspending the transferability of the digital tokens.\n\t\t- Targeted bailouts for vital institutions and industries are possible directly from central government policy makers. Currently private banks must be incentivised to make cheap loans available to sectors which require targeted assistance.\n\t\t- Financial surveillance of every user is possible. In this way a ‘panopticon of money’ can be enacted, and spending rulesets can be applied. For instance, social support money might only be spendable on food, and child support only on goods and services to support childcare. This is a very dystopian set of ideas. Eswar Prasad says “In authoritarian societies, central bank money in digital form could become an additional instrument of government control over citizens rather than just a convenient, safe, and stable medium of exchange[[prasad2021future]].” This is possibly [already happening](https://twitter.com/WallStreetSilv/status/1581378124452753408) in China through integration of outstanding debt data with the social credit system.\n\t\t- It’s a virtually cost free medium of exchange, since there is no physical instrument which must be shipped, guarded, counted, assayed, and securely destroyed.\n\t\t- The counterfeiting risk is significantly reduced because of secure cryptographic underpinnings rather than paper or plastic anti counterfeiting technologies.\n\t\t- Global reach and control is instantly possible for the issuer. This is a big problem especially for a reserve currency such as the dollar. Two thirds of $100 bills are [thought to](https://www.federalreserve.gov/pubs/ifdp/2012/1058/default.htm) reside outside of the USA.\n\t\t- System level quantitative easing and credit subsidies are made far simpler and less wasteful when centrally dictated.\n\t\t- Transfer of liability and risk to the holder globally reduces the management costs for global deposits of a currency.\n\t\t- It may be possible to automate the stability of a currency through continuous adjustment of the ‘peg’ through algorithms or AI.\n\t- The UK had been signalled that it is not interested in developing a CBDCstating that it seemed to be a [solution in search of a problem](https://committees.parliament.uk/publications/8443/documents/85604/default/),with the Lords economic affairs committee saying:it“The introduction ofa UK CBDC would have far-reaching consequences for households,businesses, and the monetary system for decades to come and may pose significant risks depending on how it is designed. These risks include state surveillance of people’s spending choices, financial instability as people convert bank deposits to CBDC during periods of economic stress, an increase in central bank power without sufficient scrutiny,and the creation of a centralised point of failure that would be atarget for hostile nation state or criminal actors.”\n\t- Since those initial statements however it seems that the previously mentioned “fear of missing out” has forced legislators hand. The UKTreasury and the Bank of England are now exploring the possibility of launching a retail central bank digital currency (which they desperately hope will not end up called ‘Britcoin’), judging that “it is likely a digital pound will be needed in the future”. They have released a[consultationpaper](https://www.gov.uk/government/news/hm-treasury-and-bank-of-england-consider-plans-for-a-digital-pound)inviting public comment. The consultation is aimed at informing the decision on whether to build the infrastructure for a digital pound,with a pilot test not expected before 2025.\n\t- One of the key points raised in the proposal is the potential to cap citizens’ CBDC holdings, with a range suggested between sterling 10,000to sterling 20,000, to strike a balance between managing risks andsupporting the usability of the digital pound. This limit would allow most UK wage earners to receive their salary in the form of a CBDC but would still allow for competition with commercial banks. The digitalp ound would not offer interest, enabling banks to offer competitive deposit accounts.\n\t- They are once again clear about the risks, highlighting that banks currently use deposits as a cheap source of funding for loans, and without that flow, they may become more reliant on expensive wholesale markets, driving up borrowing costs for users. In a severe scenario, abank run could undermine the capital base for the commercial bankingsystem.\n\t- The Bank of England has stated that it will not implement central bank initiated programmable functions, but instead provide the necessary infrastructure for the private sector to implement such features withuser consent. The digital pound is intended to have at least the same level of privacy as a bank account and users would be able to makechoices about data use. This is scant comfort, as such features are intrinsic to the technology, and we have seen time and again that iflegislative and economic bodies are given a hammer, they will eventually find a nail to hit. Carlo, the director of ‘The Big Brother watch’[pointed to](https://twitter.com/silkiecarlo/status/1622912736102346752)2021 comments from John Cunliff of the bank of England when he said“There’s a whole range of things that programmable money could do like giving the children pocket money but programming the money so it couldn’t be used for sweets”. Again, this raises the potential for government stimulus that has to be spent within a certain time or it disappears. As an interesting side note here it’s thought that up to 14%of American stimulus cheques went to buying crypto, most notably in less well off families.[[bertomeu2023uncle]] It’s easy to imagine that a CBDCwould be barred from such a thing.\n\t- The main motivation for issuing a CBDC is the assumption that there isdemand for a safe and stable way to use money online. A digital pound,issued and backed by the Bank of England, could be a trusted,accessible, and easy-to-use form of payment. The infrastructure would allow firms to design innovative and user-friendly services. The civilservice is hiring a “Head of CBDC” as seen in Figure<a href=\"#fig:treasury\" data-reference-type=\"ref\" data-reference=\"fig:treasury\">4.4</a>. ![]./assets/9a2522fabf842fbfaf37b164036af1e44295adab.jpg The UK is clearly making moves to staff a new department for CBDC.\n\t- Meanwhile in Europe, ECB President [ChristineLegarde](https://www.ecb.europa.eu/press/pressconf/2022/html/ecb.is220310~1bc8c1b1ca.en.html#qa)said: it“On your question concerning CBDC, you know my views on CBDC and you know that I have pushed that project. Fabio Panetta is working hardon that together with members in the entire Eurosystem with the high-level taskforce that is working really hard on moving forward. Butin a way, I am really pleased that attention is now focussed on the role that cryptos can play and the role that Central Bank Digital Currency can have when they are implemented. We have a schedule, as you know. TheGoverning Council decided back in October ’21 to launch a two-year investigation phase, and it is at the end of that investigation phase that the decision will definitely be made to launch the CBDCs and to make it a reality. We can’t go wrong with that project. I am confident that we will move ahead, but that’s going to be a decision of theGoverning Council. I think it’s an imperative to respond to what theEuropeans expect, and I think we have to be a little bit ahead of the curve if we can on that front. If we can accelerate the work, I hope wecan accelerate the work. I will certainly support that and I was delighted to see that in the United States there was an executive order by President Biden to actually expect similar effort and focus and progress on CBDC, cryptos. I think that it will take all the goodwill ofthose who want to support sovereignty, who want to make sure that monetary policy can be transmitted properly using our currency, will endeavour.”\n\t- She has expanded on these points saying in a video interview that the digital euro will be decided in October 2023. If passed, the current paradigm of cash spending and transfers will become even more restrictive. Lagarde justified the move by saying that she did not wantthe EU to be ‘dependent on the currency of an unfriendly country’ or afriendly currency activated by a private corporate entity’. Sheidentified Meta, Google, and Amazon.\n\t- India has expressed far more interest in the technology, and of course their addressable market is huge! They have published a ‘[conceptnote](https://twitter.com/RBI/status/1578329048446828544?)’ in whichthey assert that a digital Rupee would be faster, cheaper, and easier tomaintain. The key difference in India’s situation is the large areas ofthe rural population where mobile internet is more patchy. In suchsituations a cash equivalent stablecoin token with cash finality which can be transferred between mobile phone wallets itwithout an internet connection is a huge boon. It seems very likely that India is moving toreact to the innovation threat posed by cryptocurrencies to their owncash infrastructure. They are [piloting thetechnology](https://www.reuters.com/article/idUSKBN2RQ0WO) already.Similarly there seems to be a strong, and [predictablyilliberal](https://www.bloomberg.com/news/articles/2022-12-06/nigeria-limits-cash-transactions-to-push-enaira-and-other-payments)push for transition to digital money in Nigeria. Again this is an enormous number of people, and it is hard not to be suspicious of future abuse of the system by governments.\n\t- In the USA this text from Congressman Tom Emmer shows how complex and interesting this debate is becoming.it“Today, I introduced a bill prohibiting the Fed from issuing a central bank digital currency directly to individuals. Here’s why it matters: As other countries, likeChina, develop CBDCs that fundamentally omit the benefits and protections of cash, it is more important than ever to ensure the UnitedStates’ digital currency policy protects financial privacy, maintains the dollar’s dominance, and cultivates innovation.  CBDCs that fail to adhere to these three basic principles could enable an entity like the Federal Reserve to mobilize itself into a retail bank, collect personally identifiable information on users, and track their transactions indefinitely.  Not only does this CBDC model raise “single point of failure” issues,leaving Americans’ financial information vulnerable to attack, but it could be used as a surveillance tool that Americans should never be forced to tolerate from their own government.  Requiring users to open an account at the Fed to access a United StatesCBDC would put the Fed on an insidious path akin to China’s digital authoritarianism.  Any CBDC implemented by the Fed must be open, permissionless, and private. This means that any digital dollar must be accessible to all,transact on a blockchain that is transparent to all, and maintain the privacy elements of cash.  In order to maintain the dollar’s status as the world’s reserve currency in a digital age, it is important that the United States lead with aposture that prioritizes innovation and does not aim to compete with theprivate sector.  Simply put, we must prioritize blockchain technology with American characteristics, rather than mimic China’s digital authoritarianism outof fear.”\n\t- Most analysts now seem to think that there is little appetite to replace established ’Western’ cash with CBDCs. Most significantly such productswould need the support of retail banks, and it is not in their interestto service such a product. Their business model relies on using retail deposits for providing loans, and it is these deposits, not cash itself that would be the most addressable market for a CBDC. Banks don’t want people to self custody money. In addition it exposes the whole banking system to a higher risk of bank runs. Such a self custody, interestbearing, central government backed asset would have significantly less counterparty risk than even bank deposits, and at times of high systemic stress it seems likely that money would flow to where it’s thoughtsafest, exposing the retail banks to runs. Fabio Panetta of the ECBsaid: it“If we give access to a means of payment, which is relatively limited, there are no transaction costs because you only need to have a smartphone. There will be risks that people could use this possibility to move, for example, their deposits of other banks or their money outof financial intermediates.”\n\t\t- All of the proposed solutions to these problems such as caps and negative interest penalties seem poorlythought through. Held and Smolenski present a [detailed and rigorousnegativecritique](https://www.btcpolicy.org/articles/why-the-u-s-should-reject-central-bank-digital-currencies)of the dystopian ramifications of the technology. In their conclusion they point out that: it“Central bank digital currencies (CBDCs)represent an extension of state control over economic life. CBDCsprovide governments with direct access to every transaction in that currency conducted by any individual anywhere in the world. As governments worldwide routinely share data with one another, individual transaction data will quickly become known to any government in a datasharing arrangement. Given the frequency with which government databases are compromised, this arrangement virtually ensures that anyone’s transaction data will eventually become available for global perusal.”\n- # Global Centralised Ledgers\n\t- Beyond even national CBDCs it is now possible to find discussion aroundweaving these together at a supranational level. Indeed it seems that competition is starting to emerge. The Bank for InternationalSettlements (BIS) and the International Monetary Fund (IMF) have both presented plans to deploy global ledgers to support programmable CentralBank Digital Currencies.\n\t- ## BIS proposal\n\t\t- The BIS proposed the concept of a Unified Electronic Ledger, which wouldcombine Central Bank Digital Currencies, tokenized money, and assets ona single platform. This ledger would enable smart contract functionality similar to Ethereum on a global scale. The BIS emphasized the benefitsof integrating different types of money and assets on a unified ledger,such as reducing delays, uncertainties, and trade financing costs. They also highlighted the importance of policy harmonization across jurisdictions for the success of such a system.\n\t- ## The IMF’s Proposal\n\t\t- The IMF proposed a global CBDC platform that would facilitate cross-border CBDC settlement. The stated aim is to enhance interoperability, efficiency, and safety in cross-border payments, while allowing individual nations to maintain capital controls and limits onthe flow of funds. The IMF envision a permissioned (closed, but distributed) ledger, perhaps controlled by a platform operator (in the manner of SWIFT), to ensure unique ownership descriptions and prevent double spending. They emphasized the need for maintaining capital controls during national financial crises.\n\t- ## The Bank of England’s Experiment\n\t\t- The Bank of England, in collaboration with the BIS Innovation Hub,conducted a field test of CBDC technology known as Project Rosalind. Thetest explored various CBDC use cases, including offline payments, retail transactions, and micropayments. The test focused on a centralised ledger hosted by the Bank of England and involved the development of APIfunctionalities for different scenarios. The BIS considered these experiments informative for the ongoing discussions on CBDCs.\n- ## Risks and mitigations\n\t- The introduction of CBDCs could have a significant impact on both individuals and the existing private financial sector.\n\t- For individuals, the risks of CBDCs include:\n\t\t- Privacy concerns: CBDCs could potentially be used to track and monitor individuals’ financial transactions, raising concerns about privacy and government surveillance.\n\t\t- Lack of anonymity: Unlike cash, CBDCs could be easily traced and linked to individuals, which may compromise their financial privacy and security.\n\t\t- Cybersecurity risks: CBDCs could be vulnerable to cyberattacks, which could lead to the loss of funds and personal information.\n\t\t- For the existing private financial sector, the risks of CBDCs include:\n\t\t- Competition: CBDCs could potentially compete with private sector financial institutions, which could lead to a decline in the use of traditional financial services.\n\t\t- Disruption: CBDCs could disrupt existing financial systems and business models, which could lead to a decline in profits and revenue for private sector financial institutions.\n\t\t- Regulation: The introduction of CBDCs could lead to increased regulation of the private financial sector, which could increase compliance costs and reduce profitability.\n\t\t- CBDCs could have implications on monetary policy, financial stability, and international relations. For example, it could change the way central banks conduct monetary policy, and it could also impact the global financial system and the role of the US dollar as a global reserve currency.\n\t\t- CBDCs could also bring about significant changes in the global payment system, which could have major implications for the financial industry, and for the private sector as well as for the central banks.\n\t\t- A single global ledger, especially one controlled by large international bodies like the BIS and IMF, could potentially lead to an unhealthy centralization of power. This could exacerbate existing imbalances in global financial control and further marginalize countries with less political and economic power.\n\t\t- A centralized ledger system would necessitate a high degree of technological dependence, which could leave countries vulnerable in the event of technological failure or cyber attacks.\n\t\t- A global ledger system would require a high level of standardization. This could limit the ability of individual nations to adapt their financial systems to local conditions and needs, potentially leading to a “one-size-fits-all” approach that might not be appropriate for all contexts.\n\t\t- There are concerns that the shift to digital currencies could leave behind those without access to necessarytechnology, contributing to financial exclusion rather than mitigating it.\n\t- In conclusion, the risks associated with CBDCs are significant and multi-faceted. It is (hopefully) more likely that a blend of stablecoins, private bank issued digital currency (with a yield incentive) and perhaps some limited CBDC, alongside the new contenderBitcoin, will present a new landscape of user choice. Different modelsof trust, insurance, yields, acceptability, and potentially privacy,will emerge.\n\t- Clearly a global, stable, wholly digital bearer asset in a native currency would ostensibly be the ideal integration for money in a metaverse application, but the whole concept seems deeply ‘wrong’, and it is likely that a transition to such a technology would be complex and painful. Either way, it is certainly not ready for consideration now.It’s important that central banks and governments carefully consider these risks before introducing CBDCs, but it’s not clear this is happening. It is conceivable that by working closely with the private sector policy makers could minimize any negative impacts, ensuring that any new regulations are designed in a way that protects the rights andprivacy of individuals, while also promoting financial stability andeconomic growth. Gerard, an incredibly staunch critic of all things crypto [points to woeful adoption and manifestcorruption](https://davidgerard.co.uk/blockchain/2023/02/28/news-blockchain-mep-eva-kaili-corruption-arrest-nigerian-cbdc-rewrite-bbc-blockchain-misadventures/)in the attempts so far. We are not particularly hopeful either.",
        "link_types": [
            "homer1996history",
            "szabo2002shelling",
            "selgin1996defense",
            "borio2017fx",
            "barsky1987fisher",
            "hall2009inflation",
            "white1914fiat",
            "davies2010history",
            "stroukal2018can",
            "Alden2023",
            "Eichengreen2023",
            "tomlinson2003third",
            "caballero2008financial; @spiro2019hidden",
            "grewal2020struggling",
            "carney2019growing; @piffaretti2009reshaping",
            "stoeferle2018gold",
            "mathews2018china",
            "huang2016understanding",
            "hudson2021destiny",
            "hudson2021destiny",
            "hendrickson2021value; @ferranti2022hedging",
            "gainsford2017salt; @goldberg2005famous",
            "giancarlo2021cryptodad",
            "wang2021central",
            "filardo2012central",
            "cantillon1756essai; @bordo1983some",
            "prasad2021future",
            "bertomeu2023uncle"
        ],
        "file_size": 80761
    },
    {
        "id": "Speech and voice.md",
        "name": "Speech and voice",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- {{video https://www.youtube.com/watch?v=xCDAjpZJWYw}}\n- [NVIDIA/NeMo: NeMo: a toolkit for conversational AI (github.com)](https://github.com/NVIDIA/NeMo)\n\t- [Canary\n\t\t- NVIDIA NeMo](https://nvidia.github.io/NeMo/blogs/2024/2024-02-canary/)\n\t- ![H200-NeMo-performance](https://github.com/sbhavani/TransformerEngine/raw/main/docs/examples/H200-NeMo-performance.png)\n\t-\n- [NeMo/tutorials/tts/FastPitch_Adapter_Finetuning.ipynb at main · NVIDIA/NeMo (github.com)](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tts/FastPitch_Adapter_Finetuning.ipynb)\n- [ElevenLabs Audio Native](https://elevenlabs.io/blog/audio-native/)\n- [OpenAI whisper local deploy](https://github.com/openai/whisper)\n- [realtime transciber](https://github.com/davabase/transcriber_app/)\n- [high performance CPP](https://github.com/ggerganov/whisper.cpp)\n- [30% quantised optimisation](https://medium.com/@daniel-klitzke/quantizing-openais-whisper-with-the-huggingface-optimum-library-30-faster-inference-64-36d9815190e0)\n- [Brillbits OpenAI whisper demo with mic](https://www.youtube.com/watch?v=nwPaRSlDSaY)\n- [Cleanvoice audio denoise](https://cleanvoice.ai/)\n- [Cloud voice change app](https://voice.ai/)\n- [downloadable voice generation systems](https://github.com/neonbjb/tortoise-tts)\n- [Language AI open libraries](https://txt.cohere.ai/introducing-sandbox-coheres-experimental-open-source-initiative/)\n- [Language practice](https://huggingface.co/spaces/JavaFXpert/Chat-GPT-LangChain)\n- [MUGEN multi modal from facebook](https://mugen-org.github.io/)\n- [Oneshot speach to text](https://atosystem.github.io/blogs/speechclip)\n- [Record and cleanup pro audio with commodity hardware](https://podcastle.ai/)\n- [Respeecher](https://variety.com/2022/digital/news/james-earl-jones-darth-vader-retiring-star-wars-ai-1235382827/)\n- [Voice AI voices](https://voice.ai/)\n- [Voice controlled assisted creation](https://the-decoder.com/developer-combines-stable-diffusion-whisper-and-gpt-3-for-a-futuristic-design-assistant/)\n- [Voice to text, Lopp](https://blog.lopp.net/open-source-transcription-software-comparisons/)\n- [whisper transcriber](https://github.com/modal-labs/modal-examples/tree/main/misc/whisper_pod_transcriber)\n- [Wolfram alpha voice chatbot integration](https://huggingface.co/spaces/JavaFXpert/Chat-GPT-LangChain)\n- [Microsoft Vall-E voice synthesis](https://valle-demo.github.io/)\n- [Uberduck text to speech (plus own voice)](https://app.uberduck.ai/)\n- [Eleven labs language and text to speech](https://beta.elevenlabs.io/)\n- [Uberduck open source text to speech](https://uberduck.ai/)\n- [numen voice control system in linux](https://numenvoice.com)\n- [Inworld (steam game plugin AI system) for voice chat and answer](https://www.youtube.com/watch?v=DnF4WzM5LPU)\n- [Bark text to speech from google labs](https://github.com/suno-ai/bark)\n- https://github.com/TensorSpeech/TensorFlowTTS\n  very configurable from what I see\n- [VoiceVox engine](https://www.youtube.com/watch?v=TGZV831VTpc)\n- [coqui-ai TTS\n\t- very good samples](https://github.com/coqui-ai/TTS)\n- https://github.com/neonbjb/tortoise-tts\n- https://github.com/CorentinJ/Real-Time-Voice-Cloning\n\t- custom voices? looks neat\n- https://github.com/rhasspy/larynx - very low-spec compatible, acceptable quality\n- [Voice cloning local](https://git.ecker.tech/mrq/ai-voice-cloning)\n- [Meta voicebox](https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/)\n- The Reddit post discusses the different open source voice cloning projects available, including Coqui, Tortoise, and Bark. The advantages and disadvantages of each project are briefly outlined, with ElevenLabs being noted as the best but not open source, while Tortoise is suggested as the closest open source alternative. Other tools for speech to speech and singing conversion, such as so-vits/diff-svc/rvc, are also mentioned. The post suggests that the quality of open source voice cloning projects is improving, and that there may be more options available in the future. https://www.reddit.com/r/MachineLearning/comments/133hanr/d_what_are_the_differences_between_the_major_open/\n- The Retrieval-based Voice Conversion WebUI is a simple and useful voice conversion (voice changer) framework based on the VITS algorithm. It can use a small amount of voice data and still achieve good results. It incorporates a top-1 retrieval method to replace the source feature with the training set feature to avoid voice leakage, and it is easy to use with a simple web interface. It also features model fusion to change voice characteristics and the ability to integrate with the UVR5 model to quickly separate vocals and accompaniment. The project requires the installation of PyTorch and its core dependencies, and other pre-models are also needed for inference and training. The repository provides a guide to environment setup and usage, as well as links to relevant resources and contributors. https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI\n- The article discusses different open-source voice cloning projects and their advantages and disadvantages. The projects mentioned include Coqui, Tortoise, and Bark, with the author highlighting Coqui's unlocked platform, while Tortoise and Bark are newer transformer-based projects that can clone much more effectively with much less training and are restricted to prevent custom voice cloning. The author suggests that the ElevenLabs is currently the best voice cloning solution available, but it is not open source and can be expensive. The article also includes comments from other Reddit users, who suggest other open source options and provide additional insights into each option's strengths and weaknesses. https://www.reddit.com/r/MachineLearning/comments/133hanr/d_what_are_the_differences_between_the_major_open/\n- The article provides instructions on how to use OpenAI's ChatGPT chatbot on an Android device using the Tasker app. The process involves importing a ChatGPT profile into Tasker, obtaining an API key from OpenAI, and setting up home screen shortcuts. The article also notes that ChatGPT can be run through Google Assistant with voice commands. The author suggests that while ChatGPT may not necessarily be better than Google Assistant, it can perform tasks that Google Assistant may not be capable of. https://www.howtogeek.com/882019/how-to-use-chatgpt-like-google-assistant-on-android/\n- The Voice Assistant is an AI-powered chatbot that uses several APIs to understand natural language commands and provide helpful responses. It features a wide range of capabilities, including answering general knowledge questions, providing recommendations, performing productivity tasks, and entertaining users. The Voice Assistant was built using ChatGPT, Whisper API, Gradio, and Microsoft's SpVoice TTS API, and it can be accessed through a web-based interface. The installation process involves cloning the repository and installing the required Python packages. Contributions to the project are welcome. https://github.com/DonGuillotine/chatGPT_whisper_AI_voice_assistant\n- The Retrieval-based Voice Conversion WebUI is a voice conversion framework that uses a top-1 retrieval algorithm to eliminate voice leakage. It is capable of quickly training even on relatively poor GPUs and can achieve good results even with just 10 minutes of low noise voice data. It has a user-friendly web interface and the ability to use a model fusion system to change voice timbre. The setup recommends using Poetry and downloading the necessary pre-trained models from their Hugging Face space. It also includes additional files such as ffmpeg and ffprobe that may need to be downloaded. The WebUI can be initiated using the command \"python infer-web.py\" and Windows users can run the \"go-web.bat\" file. The project also acknowledges the contributions of related tools and libraries such as Gradio, HIFIGAN, and ContentVec. https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI\n- VoicePen is a tool that uses AI to convert audio or video files into blog posts and transcriptions in minutes. The service includes a transcription and SRT file generated by a top speech-to-text model, an English blog post that pulls out key topics from the audio, and the ability to convert audio in 96 different languages. Use cases include repurposing podcasts, webinars, and tutorial videos. Monthly plans are available, with options for one-time conversions. Testimonials praise the accuracy and speed of VoicePen's service. https://voicepen.ai\n- Krisp is a software application designed to improve the productivity of online meetings by using AI-powered voice clarity and a meeting assistant to cancel background noise, echo, and accent localization. It works on both Mac and Windows platforms and processes only the user's voice on their device, unlike other solutions that transmit voice over the internet. Krisp offers a free forever plan with no credit card required and is trusted by global brands. The insights gathered from calls can be viewed by the user to improve their communication skills over time. Krisp has received recognition from various prestigious awards such as America's Most Promising AI Companies and has been awarded for its quality of support and ease of use. Krisp also offers SDK for developers, pricing and plans, and use cases such as contact centers and enterprise. The company prioritizes customers' privacy, security and offers accessible support, including video tutorials and a help center. By accepting all cookies, users consent to the storing of cookies on their device to enhance site navigation, analyze site usage and assist in the company's marketing efforts. https://krisp.ai/\n- Cleanvoice AI is an artificial intelligence platform that assists users in editing their podcasts or audio recordings. The platform offers various features such as filler sound removal, mouth sound removal, stutter removal, and Deadair remover to make the audio recording more professional. Cleanvoice AI is multilingual and can detect filler sounds in multiple languages, including accents from various countries. The platform also allows for manual editing with assistance and offers tools like podcast mixing and background noise remover. Users can try Cleanvoice AI for free for 30 minutes without providing credit card details. However, users must accept the platform's cookie policy to use the service. https://cleanvoice.ai/\n- The article discusses the potential of Central Intelligent Agents (CIAs) and the role of large language models (LLMs) and other next-generation AI technologies in enabling them. It highlights the need for businesses to have a cross-functional team, ethical guidelines, and clear objectives in deploying their own CIA. The article also suggests steps to build a solid foundation for deploying a CIA, assess organizational readiness, assemble a cross-functional team, define objectives, develop the CIA components and evaluate its performance while continuing to learn and adapt. The author discusses the potential of AI tools and voice assistants in transforming the way businesses interact with their customers and suggests that the advent of advanced AI technologies has revolutionized the shift of businesses towards a more personalized and ethically responsible approach to engaging with their customers. Finally, the article ends by highlighting the importance of experimenting through crisis and providing expert guidance tailored to specific business needs. https://www.linkedin.com/pulse/central-intelligent-agent-enabling-next-generation-james-poulter?\n- [TensorSpeech/TensorFlowTTS: :stuck_out_tongue_closed_eyes: TensorFlowTTS: Real-Time State-of-the-art Speech Synthesis for Tensorflow 2 (supported including English, French, Korean, Chinese, German and Easy to adapt for other languages)](https://github.com/TensorSpeech/TensorFlowTTS) [[Translation]] [[Accessibility]] [[Speech and voice]] [[Speech and voice]]\n- [Variety](https://variety.com/2022/digital/news/james-earl-jones-darth-vader-retiring-star-wars-ai-1235382827/%7D%7BRespeecher%7D) [[Speech and voice]] [[Social contract and jobs]]\n- [transcriptionstream/transcriptionstream: turnkey self-hosted offline transcription and diarization service with llm summary (github.com)](https://github.com/transcriptionstream/transcriptionstream) [[Speech and voice]] transcription locally [[SHOULD🟡]]\n- [Tincans - Gazelle v0.2](https://tincans.ai/slm3) [[Speech and voice]] fast speech engine [[SHOULD🟡]]\n- [[Speech and voice]] [Open Voice (myshell.ai)](https://research.myshell.ai/open-voice) cloning MIT license\n- [EndlessDreams: Voice directed real-time videos at 1280x1024 : r/StableDiffusion (reddit.com)](https://www.reddit.com/r/StableDiffusion/comments/1c8oea6/endlessdreams_voice_directed_realtime_videos_at/) [[Speech and voice]] [[Speech and voice]] [[Product Design]] [[real time]]\n- https://demo.hume.ai/? [[Speech and voice]] [[Large language models]] empathetic voice to voice\n- [[Speech and voice]] [metavoiceio/metavoice-src: AI for human-level speech intelligence (github.com)](https://github.com/metavoiceio/metavoice-src) check for [[PlayerTwo]]\n- [NeMo/tutorials/tts/NeMo_TTS_Primer.ipynb at main · NVIDIA/NeMo (github.com)](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tts/NeMo_TTS_Primer.ipynb) [[NVIDIA Omniverse]] [[Speech and voice]] primer and demo.",
        "link_types": [
            "Translation",
            "Accessibility",
            "Speech and voice",
            "Speech and voice",
            "Speech and voice",
            "Social contract and jobs",
            "Speech and voice",
            "SHOULD🟡",
            "Speech and voice",
            "SHOULD🟡",
            "Speech and voice",
            "Speech and voice",
            "Speech and voice",
            "Product Design",
            "real time",
            "Speech and voice",
            "Large language models",
            "Speech and voice",
            "PlayerTwo",
            "NVIDIA Omniverse",
            "Speech and voice"
        ],
        "file_size": 13445
    },
    {
        "id": "Bitcoin ETF.md",
        "name": "Bitcoin ETF",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- There is a non-zero risk that Bitcoin could be co-opted and therefore controlled by the US financial system\n- {{video https://youtu.be/tu3V-3zV3H4}}\n- The USA is currently positioning it's tax system such that Lightning service providers, and Bitcoin and crypto personal wallets will be forced in law to comply with money transmitter licenses. This reporting requirement is a practical impossibility and unlikely to be codified into law. Nonetheless the chilling effect is shuttering businesses.\n\t- https://twitter.com/PhoenixWallet/status/1783878658014249027\n\t- {{twitter https://twitter.com/PhoenixWallet/status/1783878658014249027}}\n- The emerging direction of travel here is that USA consumers will be heavily incentivised to use the licensed and approved ETF vehicles, which can be sufficiently monitored by their tax services. It is likely that self custody of Bitcoin will by allowed, but it's very possible that the on and off ramps in to the dollar system will be very tightly controlled.\n\t- ![GMMQGt6XAAMBn48.jpeg](../assets/GMMQGt6XAAMBn48_1714304539573_0.jpeg)\n- In this hypothetical scenario, there is the opportunity for Wall Street to successfully orchestrates an attack on Bitcoin through the proliferation of Bitcoin exchange-traded funds (ETFs) that are settled in cash rather than actual Bitcoin. We might consider the potential impacts and the narrative that could unfold. This situation would essentially create \"paper Bitcoin,\" similar to what has occurred in other commodity markets, where the traded instruments represent the asset but don't necessarily entail ownership of the physical commodity.\n- ### The Setup\n\t- Imagine a world where Bitcoin ETFs have gained significant traction, primarily among U.S. investors who prefer the regulated, traditional financial market entry points to the actual cryptocurrency. These ETFs are appealing because they offer exposure to Bitcoin's price movements without requiring investors to deal with the complexities and security concerns of holding the cryptocurrency. However, as these are cash-settled, the ETFs do not impact the actual supply and demand of Bitcoin directly but rather create a parallel market for Bitcoin exposure.\n- ### The Disjunction\n\t- With approximately 2 million Bitcoin reportedly liquid on exchanges at this moment, the market is relatively thin compared to the vast global financial markets. If a large portion of Bitcoin investment shifts to these ETFs, forced through tax compliance laws in the USA, there could be a significant discrepancy between the \"paper\" Bitcoin and actual Bitcoin supply-demand dynamics. The real crunch comes when, for any reason, a substantial number of ETF holders decide to convert their holdings into actual Bitcoin. The ETFs, being cash-settled, might not be backed by an equivalent amount of real Bitcoin. This disjunction between the paper and physical Bitcoin could lead to a crisis of trust and liquidity.\n\t- https://x.com/CryptoVizArt/status/1800394787284996362\n\t- {{tweet tweet https://x.com/CryptoVizArt/status/1800394787284996362}}\n- ### Global vs. U.S. Market Dynamics\n\t- While the U.S. might spearhead this form of Bitcoin investment through ETFs, the global Bitcoin market remains diverse and less regulated in many jurisdictions. International holders and traders of actual Bitcoin might react differently to the ETF market movements, leading to potential arbitrage situations or exacerbating the liquidity crisis if they lose confidence in the price stability and seek to liquidate their holdings for fiat or other assets.\n- ### The Fallout of Being \"Caught\"\n\t- If it becomes apparent that the ETFs are significantly unbacked by actual Bitcoin, or if there's a regulatory or market shift that forces a reconciliation between paper and physical Bitcoin, the fallout could be dramatic. The immediate effect would likely be a significant price correction as the market attempts to realign the perceived value of Bitcoin with its actual available supply. This correction could be further amplified by panic selling, leading to a crash in both the paper and physical Bitcoin markets.\n- ### Regulatory Repercussions and Market Reaction\n\t- The revelation of a large-scale discrepancy between paper and physical Bitcoin would likely lead to intense regulatory scrutiny and possibly new regulations or bans on similar financial products. This regulatory response could stifle innovation and investment in the cryptocurrency space, at least temporarily, and lead to a loss of trust in financial institutions involved in the ETF market. The cryptocurrency community, known for its resilience and innovation, might respond by pushing further towards decentralized finance (DeFi) solutions and away from traditional financial systems. This shift could accelerate the adoption of technologies that provide more transparency and direct control over digital assets, such as improved self-custody solutions and transparent, decentralized exchanges that do not rely on traditional financial intermediaries.\n- ### Conclusion\n\t- In this hypothetical narrative, the creation and widespread adoption of cash-settled Bitcoin ETFs lead to a significant disjunction between the paper and physical Bitcoin markets, eventually resulting in a crisis of confidence and liquidity when the discrepancy becomes apparent. The repercussions would ripple through the cryptocurrency and traditional financial markets, leading to regulatory crackdowns, market crashes, and potentially a paradigm shift towards more decentralized and transparent financial systems. While this scenario is speculative, it underscores the importance of understanding and critically evaluating the implications of integrating cryptocurrency into traditional financial products and the systemic risks that could emerge from such integration.\n- ![image.png](../assets/image_1707899842471_0.png)\n- <iframe width=\"100%\" height=\"420\" frameborder=\"0\" src=\"https://www.theblock.co/data/crypto-markets/bitcoin-etf/spot-bitcoin-etf-assets/embed\" title=\"Spot Bitcoin ETF AUM\"></iframe>",
        "link_types": [],
        "file_size": 6110
    },
    {
        "id": "Blender.md",
        "name": "Blender",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- https://twitter.com/3DAIStudio/status/1779944710435713512 [[Text to 3D and 4D]]\n- {{twitter https://twitter.com/3DAIStudio/status/1779944710435713512}}",
        "link_types": [
            "Text to 3D and 4D"
        ],
        "file_size": 168
    },
    {
        "id": "AnimateDiff.md",
        "name": "AnimateDiff",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- [Beginner Friendly AI Animation Tutorial #1 (youtube.com)](https://www.youtube.com/watch?v=WPlUSnLTmfI)\n- <iframe src=\"https://civitai.com/models/372584/ipivs-morph-img2vid-animatediff-lcm-hyper-sd\" style=\"width: 80%; height: 600px\"></iframe>",
        "link_types": [],
        "file_size": 298
    },
    {
        "id": "Bitcoin.md",
        "name": "Bitcoin",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n#Public page automatically published\n\n- # Why is this section here?\n\t- Bitcoin allows value and ideas to be transmitted over the internet, gaining the moniker \"magic internet money\".\n\t- This feature set is scalable and opensource.\n\t- It is a trillion dollar digital asset class with 200M users.\n\t- **It is ideal for AI agent economic action.**\n\t- {{video https://www.youtube.com/watch?v=y48uAeHwZGg}}\n\t\t- [Wicked on X: \"#Bitcoin has officially processed over 1 billion transactions. https://t.co/kS704YYoW5\" / X (twitter.com)](https://twitter.com/w_s_bitcoin/status/1787240456197222632)\n\t\t- [David Marcus says #Bitcoin is “going to be the native currency of AI”](https://twitter.com/BitcoinMagazine/status/1785824384961151131) - note he is now an industry insider, take this with appropriate pinch of salt.\n\t\t\t- {{twitter https://twitter.com/BitcoinMagazine/status/1785824384961151131}}\n- An old video I made in 2021\n\t- {{video https://youtu.be/Tq-kvADT4xE}}\n- ![image.png](../assets/image_1710363853647_0.png){:width 300}\n-\n- # What is Bitcoin, what does it do?\n\t- Bitcoin isn’t simply \"magic internet money\" any more. It’s a swarm of open source tools which can (in theory) accomplish a great many things.\n- ![image](./assets/ed9e1ee6cabd689fbe9c3ca7df3659939ec7a18f.jpg)\n-\n- These newer, ancillary elements to Bitcoin, are emergent right now. Some of them won’t be around until next year, and it’s questionable whether they will even work out. With that said we aren’t convinced by the value proposition of of Ethereum, and there’s enough Bitcoin tooling for us to cherry pick useful components.\n- # About Bitcoin\n\t- The first blockchain was the Bitcoin network, [[Nakamoto 2008]] some two decades after Haber et al. first described the idea. [[Haber 1990]] Prior to Bitcoin, these structures were called ‘timechains.’ [[Nakamoto 2018]] It can be considered a triple entry bookkeeping system, [[Ijiri 1986; Faccia 2019]] the first of its kind, integrating a ‘provable’ timestamp with a transaction ledger, solving the “double spend problem.” [[Chohan 2021; Perez 2019; Grunspan 2018]] Some see this as the first major innovation in ledger technology since double entry was codified in Venice in fourteen seventy-five. [[Sangster 2015]]\n\t- It was created pseudonomously by an [individual](https://open.spotify.com/episode/6bUyu2izFznSqdb6bbGLr0) calling themselves ‘Satoshi Nakamoto’ in 2009, as a direct response to the perceived mishandling of the 2008 global financial crisis, [[nakamoto2018]] with the stated aim of challenging the status quo, with an [uncensorable](https://world.hey.com/dhh/i-was-wrong-we-need-crypto-587ccb03) technology, to create a money which could not be [debased by inflation policy](http://p2pfoundation.ning.com/forum/topics/bitcoin-open-source), and outside of the [politically captured](https://www.coindesk.com/layer2/2022/05/04/matt-taibbi-paypals-deplatforming-and-the-case-for-crypto/) fintech incumbents. It’s interesting to note that the narrative around the use case for Bitcoin has [shifted over its lifetime](https://uncommoncore.co/visions-of-bitcoin-how-major-bitcoin-narratives-changed-over-time/).\n\t- The [“genesis block”](https://en.bitcoin.it/wiki/Genesis_block) which was hard coded at the beginning of the ‘chain’ contains text from The Times newspaper detailing the second bank bailout.\n\t- There will only ever be ([just short of](https://blog.amberdata.io/why-the-bitcoin-supply-will-never-reach-21-million))21 million bitcoins issued, of which around 19 million have already been minted, and around 4 million lost forever. This ‘hard money’ absolute scarcity is a strong component of the Bitcoin meme landscape. These are basically arbitrary figures though; a combination of the issuance schedule, and an [‘educated guess’](https://plan99.net/~mike/satoshi-emails/thread1.html) byNakamoto:[[nakamoto2018]]\n\t\t- *”My choice for the number of coins and distribution schedule was an educated guess. It was a difficult choice, because once the network is going it’s locked in and we’re stuck with it. I wanted to pick something that would make prices similar to existing currencies, but without knowing the future, that’s very hard. I ended up picking something in the middle. If Bitcoin remains a small niche, it’ll be worth less perunit than existing currencies. If you imagine it being used for some fraction of world commerce, then there’s only going to be 21 million coins for the whole world, so it would be worth much more per unit.”*\n\t- Digital scarcity is incredibly important and is explained well bysoftware engineer Hillibrand in a podcast (this text is paraphased:it“Digital scarcity is an interesting concept that was well explained byGerman economist Guido Hülsmann in his book “The Ethics of MoneyProduction,”[[hulsmann2008ethics]] published in 2007. Hülsmann stated that an economic good that is defined entirely in terms of bits andbytes is unlikely ever to be produced spontaneously on a free market,and at the time, he was right. However, the emergence of Bitcoin would soon prove that digital scarcity could indeed be achieved. Hülsman nnoted that an economic good must be scarce and rivalrous, meaning thereis a potential for conflict over who can utilize the resource. For example, air is abundant but still considered scarce as its availability can be limited in specific situations, leading to conflicts over its use. The concept of digital scarcity is built on the idea that information, which is fundamentally not scarce, can be made scarce through specific mechanisms. Bitcoin, for instance, addresses the double-spending problem, where a digital token could be spent more thanonce, by establishing a decentralized network that prevents the samecoin from being used in multiple transactions. Nakamoto devised a system that allows users to establish scarcity and rivalrousness in cyberspace without relying on a single trusted third party. Instead of relying on a central authority, like a government, to determine the validity of transactions, Bitcoin relies on a network of computers known as “full nodes” that verify and enforce a set of rules. This decentralized system enables the creation of digital goods that are both scarce and rivalrous, which was previously thought to be impossible.”\n\t- In theory there is no [barrier toaccess](https://www.forbes.com/sites/peterizzo/2021/09/29/against-cryptocurrency-the-ethical-argument-for-bitcoin-maximalism/?),and [equality ofopportunity](https://www.coindesk.com/layer2/2022/02/16/why-bitcoin-is-a-tool-for-social-justice/)to accumulate and save over long periods. This is not true of chains and tokens since, which lock up some of their value for seed investors to cash out later. None of the blockchains since are decentralised in thesame way.[[selvam2021blockchain]] Bitcoin was probably a [singularevent](https://danhedl.medium.com/bitcoins-distribution-was-fair-e2ef7bbbc892).\n\t- Each Bitcoin can be divided into 100 million satoshis (sats), so anyone buying into Bitcoin can buy a thousandth of a pound, assuming they canfind someone willing to transact that with them.\n\t- Satoshi Nakamoto (the name of the publishing entity) [disappeared from the forums](https://bitcoinmagazine.com/technical/what-happened-when-bitcoin-creator-satoshi-nakamoto-disappeared)forever in 2010. Bitcoin has the marks of cypherpunks and anarcho capitalism. The IMF has recently conceded that the Bitcoin [poses a risk](https://blogs.imf.org/2022/01/11/crypto-prices-move-more-in-sync-with-stocks-posing-new-risks/)to the traditional financial systems, so it could be argued that it is succeeding in this original aim.\n\t- Although there were some earlier experiments (hashcash, b-money etc),Bitcoin is the first viably decentralised ‘cryptocurrency’; the network is used to [store economicvalue](https://www.aier.org/article/why-does-bitcoin-have-value/)because it is judged to be secure and trusted. It is a singular event in that it became established at scale, such that it could be seen to be afully distributed system, without a controlling entity. This is the differentiated trust model previously mentioned. This relative security is the specific unique selling point of the network. It is many timesmore secure than all the networks which came after based on a like for like comparison of [transaction‘confirmations’](https://howmanyconfs.com/). This network effect ofBitcoin is a compounding feature, attracting value through the security of the system. It is deliberately more conservative and feature poor,preferring instead to [add to it’s feature set](https://bips.xyz/)slowly, preserving the integrity of the value invested in it over the last decade. At time of writing it is a [top quartile](https://fiatmarketcap.com/) largest global currency and has settled over $13 trillion Dollars in 2021, though Makarov et al. contest this, citing network overheads, and speculation.[[makarov2021blockchain]]Institution grade ‘exchange tradable funds’ which allow investment inBitcoin are available throughout the world, and the native asset can be bought by the public easily through apps in all but a handful of countries as seen in Figure<a href=\"#fig:settled2021\" data-reference-type=\"ref\" data-reference=\"fig:settled2021\">3.5</a>.\n\t- ![image](./assets/96342a08b8cb63131164317415a96f5d4852b12d.jpg)\n\t- {{twitter https://twitter.com/glxyresearch/status/1469039427028664320?}}\n\t- [twitter link to the render loading below](https://twitter.com/_Checkmatey_/status/1699581893078085705)\n\t  {{twitter https://twitter.com/_Checkmatey_/status/1699581893078085705}}\n\t- Only around 7 transactions per second can be settled on Bitcoin. The native protocol does not scale well, and this is an inherent trade-off as described by Croman et al. in their positioning paper on public blockchains.[[croman2016scaling]] Over time, competition for the limited transaction bandwidth drives up the price to use the network. This effectively prices out small transactions, even locking up some value below what is a termed the ’[dust limit](https://github.com/bitcoin/bitcoin/blob/v0.10.0rc3/src/primitives/transaction.h#L137)’ of unspent transactions too small to ever moveagain.[[delgado2018analysis]]\n\t- Bitcoin has developed quickly, with a [faster adoption](https://phemex.com/blogs/crypto-bitcoin-s-curve-adoption-curve) than even the internet itself.\n\t\t- https://crypto.com/company-news/global-cryptocurrency-owners-grow-to-580-million-through-2023\n\t\t- ![GMjjXj5bQAAzvPQ.jpeg](../assets/GMjjXj5bQAAzvPQ_1715376509027_0.jpeg){:width 500}\n\t- It is already a mature ecosystem, with[enterprise grade software](https://www.fortris.com/) stacks, and is seeing adoption as a [corporate treasury asset](https://bitcointreasuries.net/).\n\t- Adoption by civil authorities is increasing, and legislators the world over are being forced to [adopt aposition](https://www.politico.com/news/2022/01/16/bitcoin-crashes-the-midterms-527126).California has an [explicitly Web 3 and blockchain executiveorder](https://www.gov.ca.gov/2022/05/04/governor-newsom-signs-blockchain-executive-order-to-spur-responsible-web3-innovation-grow-jobs-and-protect-consumers/)to investigate and support opportunities. Many city treasuries have[addedit](https://www.bloomberg.com/news/articles/2022-01-14/rio-de-janeiro-wants-to-become-brazil-s-cryptocurrency-capital)to their balance sheet. Honduras [has launched](https://www.reuters.com/world/americas/honduras-launches-bitcoin-valley-tourist-town-santa-lucia-2022-07-29/) “Bitcoin Valley” as a tourist initiative, and the Swiss city of Luganois launching a [huge initiative](https://twitter.com/Stadicus3000/status/1499656424422526977)alongside Tether. It is already legal tender in the country of El Salvador [[oxford2021salvador]] and the [Central AfricanRepublic](https://finance.yahoo.com/news/central-african-republic-passes-bill-180910797.html?), and will be soon in [Madeira and Roatánisland](https://www.forbes.com/sites/ninabambysheva/2022/04/07/two-new-territories-are-adopting-bitcoin/?sh=7f014ed2499a).This means it it must be accepted as a means of payment, with uncertain global political legal consequences.[[katterbauer2022impact]] In places such as Panama it simply has legal status and it can be accepted without double taxation.\n\t- Global asset manager “Fidelity” wrote the following in their [2021trendsreport](https://www.fidelitydigitalassets.com/articles/2021-trends-impact).it“We also think there is very high stakes game theory at play here,whereby if Bitcoin adoption increases, the countries that secure some bitcoin today will be better off competitively than their peers.Therefore, even if other countries do not believe in the investment thesis or adoption of bitcoin, they will be forced to acquire some as aform of insurance. In other words, a small cost can be paid today as a hedge compared to a potentially much larger cost years in the future. We therefore wouldn’t be surprised to see other sovereign nation states acquire bitcoin in 2022 and perhaps even see a central bank make an acquisition.”\n\t- #### The Bitcoin Network Software\n\t\t- There isn’t a single GitHub which can be considered the final arbiter ofthe development direction, because it is a distributed community effortw ith some [500developers](https://decrypt.co/66740/who-are-the-fastest-growing-developer-communities-in-crypto)out of a wider ‘crypto’ pool of around 9000 contributors (the vastmajority are spread across disparate Ethereum and some Solana projects).[Development and innovation continues](https://bitcoinops.org/en/newsletters/2021/12/22/) but thereis an emphasis on careful iteration to avoid damage to the network. Visualisation of code commitments to the various open source softwarerepositories can be seen at [Bitpaint youtubechannel](https://www.youtube.com/channel/UC4DT4qudqogkmbqVAQy8eFg/videos)and in Figure<a href=\"#fig:gource\" data-reference-type=\"ref\" data-reference=\"fig:gource\">[fig:gource]</a>.\n\t\t  ![image](./assets/ae27e917fbfbdd847e6f9d89e5518433a4503ee0.jpg)\n\t\t- [Bitcoin core](https://github.com/bitcoin/) is the main historicaleffort (with around a dozen major contributors guiding the direction),but there are alternatives ([LibBitcoin inC++](https://github.com/libbitcoin/libbitcoin-node/wiki), [BTCD inGo](https://github.com/btcsuite/btcd), and [BitcoinJ inJava](https://bitcoinj.github.io/getting-started)), and as innovation on layer one slows, attention is shifting to codebases which interact with the base layer asset. Much more on these later.\n\t- ##### Mining process overview\n\t\t- Bitcoin mining is the process of adding public transactions into the ledger, in return for two economic rewards, paid in Bitcoin. These are the mining fee, and the block reward. The transactions which are added into the next ‘block’ of the chain are selected preferentially based onthe fee they offer, which is up to the user trying to get their transaction into the chain. This can be within the next 10 minutes (next block), or a gamble out toward ’never’ depending how competitive the network is at any time. Miners try to find a sufficiently low result from a cryptographic hash function[[rogaway2004cryptographic]](a random process), and upon finding it, they can take their pre-prepared ‘block’of transactions sourced from their local queue (mempool), and add it into the chain, for confirmation by other miners. In return they take all the fees within that mined block, and whatever the block reward isat the time. When the network started the block reward was 50 Bitcoin,but has [halved](https://ma.ttias.be/dissecting-code-bitcoin-halving/)repeatedly every 210,000 blocks (four years) and now stands at 6.25 BTC.The rate of mining is kept roughly at one block every 10 minutes, by a difficulty adjustment every 2016 blocks (2 weeks). This in a complex interdependent mechanism and is explained very well in [this article](https://bitcoinmagazine.com/technical/how-mining-protects-the-bitcoin-network).These components are explained in slightly more detail later.\n\t- ##### Energy & policy response\n\t\t- Bitcoin uses a staggering amount of energy to secure the blockchain(Figure<a href=\"#fig:top500\" data-reference-type=\"ref\" data-reference=\"fig:top500\">[fig:top500]</a>),and this [has climaterepercussions](https://www.edmundconway.com/bitcoin-money-and-the-planet/).A simple back of the envelope use of the [IEA total energysupply](https://www.iea.org/reports/key-world-energy-statistics-2021/supply),and the [Cambridge Bitcoin energy use](https://ccaf.io/cbeci/index)estimate puts the network at [around0.1%](https://www.wolframalpha.com/input?i=153+terawatt+hours+as+percentage+of+%28600+exa+joules+as+terrawatt+hours%29+)of global energy use.\n\t\t  ![image](./assets/02b34adaad63fc8abdf4a851df584c5a74825102.jpg)\n\t\t  ![image](./assets/5fd0c12ed090d4eb415c03ccc2cecb522eff6ef8.jpg)\n\t\t- It is an [industrial scale](https://www.ruetir.com/2022/03/18/riot-whinstone-the-bitcoin-farm-with-100000-computers-that-uses-excess-energy-from-an-oil-platform-to-mine-cryptocurrencies-ruetir/)global business with ‘mining companies’ investing [hundreds of millionsofpounds](https://ir.marathondh.com/news-events/press-releases/detail/1272/marathon-digital-holdings-bitcoin-mining-fleet-to-reach)at a time in specialist[ASIC](https://en.wikipedia.org/wiki/Application-specific_integrated_circuit)mining hardware and facilities. The latest purpose designed Intel chip[touts](https://www.intel.com/content/www/us/en/newsroom/opinion/thoughts-blockchain-custom-compute-group.html#gs.pd9ofu)both Web3 and metaverse applications. This is “proof of work”, and isessential to the technology, and is still thought by some to be the[best available option](https://www.truthcoin.info/blog/pow-cheapest/).The [Cambridge Bitcoin Energy ConsumptionIndex](https://ccaf.io/cbeci/index) monitors this energy usage. Their[2022report](https://www.jbs.cam.ac.uk/insight/2022/bitcoin-mining-new-data-reveal-a-surprising-resurgence/)sees American mining leading globally. Even they have had a [terrible time recently](https://compassmining.io/education/the-worst-of-bitcoin-mining-in-2022/)with many companies either failing or looking likely to.\n\t\t- At the end of 2024 it is thought to be the case that the lead profitable miners are the large scale companies who are also providing load balancing services to energy companies. This is unusual in the historyof mining, and the situation will likely change over time. This is notto say that all mining is, or should be, so concentrated. Anyone running the hashing algorithm can [get lucky](https://twitter.com/ckpooldev/status/1485585814419812356) and claim the block reward. PoW ties the value of the ‘money’ component ofBitcoin directly to energy production. This is not a new idea. HenryFord proposed an intimate tie between energy and money to create a separation of powers from government, as can be seen in Figure<a href=\"#fig:energyNYT\" data-reference-type=\"ref\" data-reference=\"fig:energyNYT\">3.6</a>.\n\t- ![image](./assets/0952364c98b50bd20011064ed34b70ccbdeb65f0.png)\n\t- <a href=\"https://www.nytimes.com/1921/12/06/archives/mr-fords-energy-dollar.html\">Intimate tie between energy and money, Henry Ford</a>\n\t- The potential ecological footprint of the network has always been aconcern; Hal Finney himself was [thinking about thisissue](https://twitter.com/halfin/status/1153096538) with a matureBitcoin network as early as 2009, and [adebate](https://satoshi.nakamotoinstitute.org/posts/bitcointalk/threads/167/#35)on the Bitcoin mailing lists called the mining process“thermodynamically perverse”. The most cited negative analysis on thematter by Mora et al sees Bitcoin mining alone warming the planet above2 degrees.[[mora2018bitcoin]]\n\t- [Proponents of the technology](https://electricmoney.org/) say that the balance shifted dramatically in 2021 with China outright banning the technology; this has forced the bulk of the energy use [toward theUSA](https://docs.google.com/spreadsheets/d/1E7489rM7Q62oXwk1f4NUlMvok9noAbpYfTynY2VTyww/edit#gid=0),and away from ‘dirty coal’.\n\t- ![image](./assets/c7df58a87afaece67e17783237cf4bb6c68ef898.png)\n\t- Hash rate <a href=\"https://ccaf.io/cbeci/ining_map\">suddenly migrates</a> from China [Reuse rights requested]\n\t- Some adherents [have proposedmitigations](https://docs.google.com/document/d/1N2N-5jY00cmteoY_puWI9oosM1foa4EQqsO1FFfIFR4/edit).[[cross2021greening]]As a worked example of [Cross and Bailey’sproposal](https://docs.google.com/spreadsheets/d/15e_a-D3x4fv3tglEzFmQ6TLQx0fZe6-iKO9Fc9SyISQ/edit#gid=0)a retail investor owning 1 BTC would have to buy around 700 shares of‘CleanSpark’ mining company (CLSK) to make their [holding completelyneutral](https://docs.google.com/spreadsheets/d/1r32T8p_PHTP8S781u7PhPSwehLx2VcJTaJJKesMswD0/edit#gid=0).Some more strident voices suggest that [‘ending financialisation’ through use ofBitcoin](https://medium.com/@magusperivallon/a-financial-hail-mary-for-the-climate-an-argument-for-bitcoin-adoption-9c58e707d0)may be net positive for the environment at a macro level.[[bitcoinisvenice]] Indeed it may [provide a route](https://www.newsweek.com/bitcoin-mining-americas-most-misunderstood-industry-opinion-1669892)to support [electrifyingeverything](https://mobile.twitter.com/DSBatten/status/1514072998881665027)through deployment of [flexible demandload](https://lancium.com/solutions/). This enables a kind of[‘financial battery’](https://medium.com/@theendoftheworldpartyparty/deep-bitcarbonization-c8f483716ff7)that can soak up excess capacity from overbuilt renewables (something which needs to be done). Money saving uses like [drying wood](https://www.theguardian.com/technology/2022/feb/09/can-bitcoin-be-sustainable-inside-the-norwegian-mine-that-also-dries-wood),and even heating greenhouses ([ironicallytulips](https://www.euronews.com/next/2022/12/14/a-bitcoin-miner-and-tulip-grower-team-up-to-reduce-costs))show the use case of the technology as a universal subsidy in heating applications.\n\t- Some projects are using the financial incentive of Bitcoin to enable trials of new infrastructure. For instance; Bhutan in the Himalayas hasbeen quietly (or secretly!) mining Bitocin for years and plans a [$500Mfund](https://www.straitstimes.com/business/bhutan-plans-a-500-million-fund-for-crypto-mining-in-the-himalayas)to expand specifically Bitcoin mining. Makai Ocean engineering havepartnered with Oceanbit Hawaii to trail [‘ocean thermal energy conversion’](https://en.wikipedia.org/wiki/Ocean_thermal_energy_conversion)as a possible power source for the Islands. Local subsidy initiatives may begin to [drive this kind ofadoption](https://fortune.com/2022/08/14/bitcoin-has-plunged-but-texas-miners-are-flush-with-profits-thanks-to-an-unusual-arrangement-the-state-is-paying-them-not-to-mine/)as seems to be [happening inTexas](https://braiins.com/blog/bitcoin-mining-the-grid-generators)[[griffith2021electrify; @ercotimpact2021; @Menati2022]]and [NewHampshire](https://www.governor.nh.gov/sites/g/files/ehbemt336/files/inline-documents/sonh/cryptocurrencie-report.pdf).Brad Jones, [interim CEO of the Texas grid said](https://www.youtube.com/watch?v=gKnRfDeFgr0):\n\t\t- “As we get more renewable generation, in particular wind \\[which\\] is operating at night ... we have to find a home for it, otherwise we haveto turn the wind down. It’s such a great resource we shouldn’t turn itdown. Bitcoin mining or what some call crypto has found a way to come into our markets and take some of that wind in off-peak periods. Thenwhen we get to peak period times they are very quick to remove themselves from the market as prices increases The fact that we can turndown whenever we need the power for other customers is fantastic. We can use that crypto currency to soak up that excess generation when there’s a lot of that, and find a home for more solar and more wind to come toour grid. Then they reduce consumption when we need that power for other customers. So it’s a great balancing act. Most other data centers \\[such as\\] Microsoft or Amazon have other customers to serve every other day,so they can’t just turn off. But these crypto customers can. If the costof energy gets too high they can remove themselves from the market. They are also helpful if we lose a generator. They can quickly respond tothat frequency disruption and allow us to balance our grid.”  Flexible load balancing is entering the [mainstream newscycle](https://www.forbes.com/sites/jemmagreen/2023/01/27/why-no-one-saw-the-success-of-demand-response-coming/?)as and is gaining traction in legislative bodies. This [“global energymarketrevolution”](https://www.citadel21.com/bitcoin-is-the-first-global-market-for-electricity-and-will-unleash-renewables)is explained by Tabatabai of Modo Energy. Incredibly Bitcoin mining inTexas is now making the grid both more reliable and cheaper for consumers. In the UK we have similar problems because wind power is not evenly distributed, and moving it around is complex and expensive, andthe whole system needs smoothing out with [gasplants](https://archy.deberker.com/the-uk-is-wasting-a-lot-of-wind-power/).\n\t- There is growing interest and adoption of so called [“stranded energymining”](https://www.bloomberg.com/news/articles/2022-06-01/oman-backs-u-s-firm-mining-crypto-to-cut-natural-gas-flaring)which cannot be effectively transmitted to consumers, and is therebysold at a huge discount while also [developing power capacity](https://www.renewableenergyworld.com/wind-power/900mw-wind-farm-to-power-bitcoin-mining-operation/),without the [usualconstraints](https://batcoinz.com/the-renewable-energy-cannot-happen-without-bitcoin-mining%ef%bf%bc/).[[bastian2021hedging]]One such example is [“Gridless” inKenya](https://gridlesscompute.com/news/), which seeks to harnessabundant green energy resources in rural areas with the hope ofkick-starting economic growth. This feature of the network first came topopular attention in 2020 when Stevens, CEO of Stoneridge capital included the following text in a letter to shareholders within their[annual report](https://www.stoneridgefunds.com/documents/AnnualReport.pdf?v=4):“\n\t\t- \"Bitcoin mining is the only profitable use of energy in human historythat does not need to be located near human settlement to operate. Thelong-term implications of this are world changing and hiding in plainsight.”\n\t- In addition to new build it is possible to [re-purposehistoric](https://www.curbed.com/2021/07/crypto-currency-mining-old-power-plants.html)infrastructure, and/or [reducing thecarbon](https://www.bloomberg.com/news/articles/2022-03-24/exxon-considers-taking-gas-to-bitcoin-pilot-to-four-countries)(or [moreinterestingly](https://batcoinz.com/quantifying-the-potential-impact-of-bitcoin-mining-on-global-methane-emissions-4/)the methane) of existing and [abandoned infrastructure](https://www.axios.com/2023/01/27/crypto-mining-advocate-green-abandoned-gas-wells).Both the [World EconomicForum](https://www.weforum.org/videos/this-start-up-catches-waste-methane-to-power-data-centres),and UK’s Department for Energy [have expressedinterest](https://www.contractsfinder.service.gov.uk/Notice/a99aa482-c7d1-4ec4-82fe-5c4b16827a6d)in this use case. Adam Wright of [VespeneEnergy](https://vespene.energy/) says: it“You could either mine Bitcoinon one small landfill for a year, or you could plant 5 million trees andlet them grow for 10 years\n\t\t- both of those are going to have the same environmental impact.”\n\t- ![image](./assets/0af874af13fd5b03de32abc60f26c6d83a02a86d.png)\n\t- <a href=\"https://twitter.com/DSBatten/status/1566735902617276416\">Climate tech investor Daniel Batten asserts that methane capture could highly impactful</a>\n\t- Cheikosman, a policy analyst for the World Economic Forum (somewhatsurprisingly)[wrote](https://www.weforum.org/agenda/2022/03/crypto-energy-consumption/?)it“Crypto is becoming an essential part of developing a carbon-neutralenergy grid and has made it economically viable to invest in, developand build renewable energy power generation.” This is explored in detail by Ibanez et al.[[ibanez2023sok]]\n\t- The most cited example of building capacity before grid connection is ElSalvador’s ‘volcano mining’ proposal, which is supporting their national power infrastructure plans. Uzbekistan seems to be promoting a [similarmodel](https://www.reuters.com/business/finance/uzbekistan-legalises-solar-powered-crypto-mining-2022-05-04/)with zero tax provided the Bitcoin mining companies build out their own solar infrastructure. A more poignant example is the [Mechanicville hydro plant in theUSA](https://www.timesunion.com/news/article/Mechanicville-hydro-plant-gets-new-life-16299115.php).The refurbishment of this 123 year old power plant is being funded byBitcoin mining. This is the [“buyer of lastresort”](https://www.lynalden.com/bitcoin-energy/) model first [advanced by Square Inc](https://squareup.com/us/en/press/bcei-white-paper).\n\t- Conversely it might be that vertical integration of Bitcoin mining[within legacy fossil fuel stations](https://bitcoinmagazine.com/business/oil-companies-partner-with-bitcoin-miners)gives them a new lease of life. New York State has dealt with this kindof threat by imposing a moratorium on new, fossil fuel powered mining activity. On a global stage something as portable and industrial asBitcoin mining will have unintended impacts on fragile energy systems,as has happened in [SouthOssetia](https://ceobs.org/environmental-governance-in-frozen-conflicts/)and[Kazakhstan](https://restofworld.org/2022/crypto-miners-fleeing-kazakhstan/)(note [Russia has stepped intothis](https://thenewscrypto.com/kazakhstans-crypto-miners-to-acquire-electricity-from-russia/)mess). Undeniably the [consensusposition](https://time.com/6193004/crypto-climate-impact-facts/) is thatit’s overall very negative, (with some caveats) and this will it probably persist. Perhaps though if it’s happening anyway, then finding utility of the asset might mitigate the net harm.\n\t- More pragmatically, Baur and Oll found that it“Bitcoin investments canbe less carbon intensive than standard equity investments and thus reduce the total carbon footprint of a portfolio.”[[baur2021bitcoin]].Perhaps of note for the near future is that KPMG whose investment was mentioned in the introduction also matched their position in the space with equivalent carbon offsets. This may provide an investment andgrowth model for others.\n\t- The first US-based [nuclear-powered Bitcoin miningfacility](https://www.businesswire.com/news/home/20230305005096/en/TeraWulf-Announces-Energization-and-Rapid-Deployment-of-Mining-Operations-at-the-Nautilus-Facility-in-Pennsylvania)has just opened in Pennsylvania. The facility has been completed by Cumulus Data, a subsidiary of independent power producer Talon Energy. Talon Energy owns the adjacent 2.5 GW Nuclear Power Plant and has been dabbling in Bitcoin mining for some time, opening a zero carbon Bitcoin mining facility in collaboration with Terawolf in August 2021. The new facility will operate with a maximum capacity of 48 MW, drawing on excess power from the nuclear plant. By locating the mining facility on the combined 1200 acre campus, there is no intermediation by legacy electric transmission and distribution utilities, as the mining is directly connected to the power station. Cumulus Data is in the process of building two additional 48 MW facilities and has identified 18additional Talon Energy sites with potential to host data centres directly connected to electricity generation infrastructure. In general, there is a shift in attitudes towards nuclear in the US. The enormous benefit to this model stems from the cots associated with scaling down  atomic power output to match grid requirements. By co-locating in this way the reactor can work at highest efficiency all the time, and can earn money from the generation of Bitcoin when the grid is unable to accept the energy. It is increasingly possible to find excited talk about funding smaller more pragmatic nuclear power plants using the cost benefits of the Bitcoin mining model, though this remains untested.\n\t- The power commitment to the network is variously projected [to increase](https://www.nature.com/articles/s41558-018-0321-8), or [leveloff overtime](https://assets.website-files.com/614e11526f6630959fc98679/616df63a27a7ec339f5e6a80_NYDIG-BitcoinNetZero_SML.pdf).The emission schedule of the code suggests that the energy usage will decrease exponentially over time, and indeed many analysts feel that it has peaked due to a combination of factors. It’s one of the maddening unknowns of the technology how this will all pan out. The [industry now argues](https://www.forbes.com/sites/martinrivers/2022/04/03/is-bitcoin-really-that-bad-for-the-environment/?sh=6a3203427143) that economic pressures mean that most of the ‘hashrate’ is [generatedby renewableenergy](https://bitcoinminingcouncil.com/q4-bitcoin-mining-council-survey-confirms-sustainable-power-mix-and-technological-efficiency/)[[blandin20203rd]].As a recent example of this trend Telsa (Elon Musk), Block (TwittersJack Dorsey), and Blockstream (Adam Back) are teaming up to [mine with solar energy](https://www.cnbc.com/2022/04/08/tesla-block-blockstream-to-mine-bitcoin-off-solar-power-in-texas.html)in Texas.\n\t- Paez and Cross [prepared apaper](https://uploads-ssl.webflow.com/627aa615676bdd1d47ec97d4/62f41b9ce54e014f9869efa7_OSTP.docx.pdf)for the White House Office of Science and Technology Policy, submitted through the Bitcoin Policy Institute, which is a growing think tank for academics and industry leaders. Their summary points echo the assertions made here, but they provide rich additional referencing for those who wish to dig deeper into this:\n\t\t- Bitcoin’s value—its economic value and promotion of American values and American national interests—must frame any discussion of its environmental impact.\n\t\t- Bitcoin’s value is inherently tied to its consensus mechanism: proof of work.\n\t\t- While bitcoin mining is energy-intensive, its energy use is often overestimated and improperly characterized as a function of transaction volume.\n\t\t- Due to bitcoin’s exponentially decreasing schedule of issuance, mining’s actual emissions are likely to peak at under 1% of global emissions, even if prices rise more than tenfold within the decade.\n\t\t- Mining’s profile as a consumer of energy is unique: extremely cost-sensitive, and invariant across times and locations.\n\t\t- Bitcoin mining, as a buyer of first and last resort, incentivizes the buildout of renewable power production. As a controllable load resource (CLR) bitcoin mining also strengthens the grid, allowing it to reliably function at a high level of renewable penetration.\n\t\t- Mining’s energy use is increasingly non-rival, trending towards a diet of renewables and stranded, wasted energy resources such as flared methane.\n\t- [The debate](https://www.youtube.com/watch?v=6LP8G-oZnEs) whether this consumption is ‘worth’ it is[complex](https://www.utilitydive.com/news/bitcoin-mining-as-a-grid-resource-its-complicated/617896/)and [rapidlyevolving](https://www.aei.org/technology-and-innovation/no-hearing-on-bitcoins-energy-use-is-complete-without-nic-carter/).\n\t- Useful examples of this are:\n\t\t- the [online pushback](https://www.zerohedge.com/crypto/questionable-ethics-anti-bitcoin-esg-junk-science) to an academic article by PhD candidate de Vries et al.[[de2022revisiting]]\n\t\t- the assertion that the widely cited Mora er al. paper in Nature[[mora2018bitcoin]] was based on an [undergraduate class discussion](https://twitter.com/NateHawaii/status/1460706785216450560), and has had an outsized effect on global policy.\n\t\t- a [paper from the Bitcoin Policy Institute](https://rebrand.ly/v8qq1sx),\n\t\t- and the industry [open letter to the EPA](https://bitcoinminingcouncil.com/wp-content/uploads/2022/05/Bitcoin_Letter_to_the_Environmental_Protection_Agency.pdf).\n\t\t- this well considered [Twitter thread](https://twitter.com/jyn_urso/status/1508899761319038983) by climate scientist Margot Paez.\n\t- It is somewhat confusing that positive views are coming only from diverse and non-specialist voices in the community, and never the academic community, but the shortcomings they point out in the supposedly considered articles such as Mora et al[[mora2018bitcoin]] areeasily verified. Academia seems [poorly positioned](https://bitcoinmagazine.com/culture/bitcoin-could-never-be-invented-in-a-university)to pivot to this subject, as an ethical bar has to be established beforeresearch can commence, and the field is too new to make this an affordable task. This stuff is existentially important to the whole technology. Is a trillion dollar asset which [potentiallyreplaces](https://www.theheldreport.com/p/bitcoin-vs-gold) the money utility of gold, but doesn’t need to be stored under guard in vaults(Figure<a href=\"#fig:goldmanVgold\" data-reference-type=\"ref\" data-reference=\"fig:goldmanVgold\">3.9</a>),worth the equivalent power consumption of clothes dryers in NorthAmerica? Probably not with the current level of adoption, but this is an experiment in replacing global money. If that were to happen then Bitcoin would be around 50 times more efficient than the current system according to Khazzaka.[[khazzaka2022bitcoin]] To be clear it’s not the position of this book that replacing Fiat money is a good idea, but the experiment is being run regardless. This is explored in [[money]].\n\t- {{embed ((661d5f6a-ce5e-479e-8722-2128890607bd))}}\n\t- <span class=\"image\">Goldman suggest growth opportunity and potential demonetisation of gold?</span>\n\t- Legislators globally, are [starting to codify](https://www.lopp.net/bitcoin-information/legal.html) their positions on proof of work as a technology (including Bitcoin). US States are variously [supporting](https://capitol.texas.gov/tlodocs/88R/billtext/html/HC00089I.htm)or constricting the technology, according to [state legislatures](https://www.ncsl.org/research/financial-services-and-commerce/cryptocurrency-2021-legislation.aspx).Notably New York has [banned new carbonintensive](https://www.nysenate.gov/legislation/bills/2021/A7389) mining facilities for 2 years, while rust and farm belt states with energy build-out problems are [providingincentives](https://financialpost.com/fp-finance/cryptocurrency/texas-governor-abbott-turns-to-bitcoin-miners-to-bolster-the-grid-and-his-re-election)and passing legislation to protect [mining datacenters](https://www.arkleg.state.ar.us/Bills/Detail?id=hb1799). At the federal level the white house has strongly signalled their concerns about the sector [in a  report](https://www.whitehouse.gov/wp-content/uploads/2023/03/ERP-2023.pdf).Many of the points in the report are fair, and true, and reflect things said in this knowledgebase (which pre-dates the report). It’s worth picking out the conclusion of that section verbatim:\n\t\t- “Innovation in financial services brings both risks and opportunities for the broader economy. It can challenge business models and existing industries, but it cannot challenge basic economic principles, such as what makes an asset effective as money and the incentives that give rise to run risk. Although the underlying technologies are a clever solution for the problem of how to execute transactions without a trusted authority, crypto assets currently do not offer widespread economic benefits. They are largely speculative investment vehicles and are not an effective alternative to fiat currency. Also, they are too risky at present to function as payment instruments or to expand financial inclusion. Even so, it is possible that their underlying technology may still find productive uses in the future as companies and governments continue to experiment with DLT. In the meantime, some crypto assets appear to be here to stay, and they continue to cause risks for financial markets, investors, and consumers. Much of the activity in the crypto asset space is covered by existing regulations and regulators are expanding their capabilities to bring a large number of new entities under compliance(SEC 2022). Other parts of the crypto asset space require coordination by various agencies and deliberations about how to address the risks they pose (U.S. Department of the Treasury 2022a). Certain innovations, such as FedNow and a potential U.S. CBDC, could help bring the U.S. financial infrastructure into the digital era in a clear and simple way, without the risks or irrational exuberance brought by crypto assets. Hence, continued investments in the Nation’s financial infrastructure have the potential to offer significant benefits to consumers and businesses, but regulators must apply the lessons that civilization has learned, and thus rely on economic principles, in regulating crypto assets.”\n\t- Reading between the lines suggest that strong regulation is coming. Indeed the [SEC is nowsuing](https://www.sec.gov/Archiv es/edgar/data/1679788/000167978823000051/coin-20230322.htm)the major tech company in the space, Coinbase, while closing a bank servicing the sector, and signalling that stable coins may be un registered securities in law. The report itself has no ‘teeth’ but is likely a sign of things to come. There is purportedly $2.4B [entering the regulation ecosystems](https://docs.house.gov/meetings/AP/AP23/20230329/115576/HHRG-118-AP23-TTF-GenslerG-20230329.pdf) to enhance regulatory oversight. In actual fact, because of the nature of the federation of states it is likely that a variety of different approaches in law will be taken across the geography and the sector seems to have responded with a shrug. As an aside the report contains an excellent taxonomy of digital assets from Hoffman (Figure<a href=\"#fig:PresidentTaxonomy\" data-reference-type=\"ref\" data-reference=\"fig:PresidentTaxonomy\">3.10</a>).\n\t- <span class=\"image\">Taxonomy of digital assets Hoffman 2022</span> <spanid=\"fig:PresidentTaxonomy\"label=\"fig:PresidentTaxonomy\">\\[fig:PresidentTaxonomy\\]</span>\n\t- Conversely the recent “[Climate and energyimplications](https://www.whitehouse.gov/ostp/news-updates/2022/09/08/fact-sheet-climate-and-energy-implications-of-crypto-assets-in-the-united-states/)”report is parts positive and parts negative about proof of work, andleaves the door open to a legislative clampdown. This is most notable ina [White Houseproposal](https://www.whitehouse.gov/cea/written-materials/2023/05/02/cost-of-cryptomining-dame-tax/)to tax Bitcoin mining at 30%, a plan which will destroy much of the USbased mining industry over the coming years. Carter provides a [detailedresponse](https://medium.com/@nic__carter/comments-on-the-white-house-report-on-the-climate-implications-of-crypto-mining-8d65d30ec942)to the tardy scientific analysis in the report. Perhaps most interestingly it notes the potential of methane mitigation as mentioned earlier. It is conceivable that methane mitigation alone could provide aroute forward for the technology. The report says: it“The crypto-asset industry can potentially use stranded methane gas, which is the principal component of natural gas, to generate electricity for mining.Methane gas is produced during natural gas drilling and transmission,and by oil wells, landfills, sewage treatment, and agricultural processes. Methane is a potent GHG that can result in 27 to 30 times the global warming potential of CO2 over a 100-year time frame, and is about80 times as powerful as CO2 over a 20-year time frame. Reducing methane emissions can slow near-term climate warming, which is why theBiden-Harris Administration released the U.S. methane emissions reduction action plan in 2021. Venting and flaring methane at oil and natural gas wells wastes 4% of global methane production. In 2021,venting and flaring methane emitted the equivalent of 400 million metric tons of CO2, representing about 0.7% of global GHG emissions. This methane is vented or flared, because of the high cost of constructing permanent pipelines or electricity transmission that could transport the methane or its potential electricity generation from remote oil and gas operations to end-users, or because of the high cost of installing equipment on older landfills. Crypto-asset companies are now exploring ways to use electricity generation from vented and flared methane at oil and gas wells and at landfills. While the EPA and the Department of theInterior have proposed new rules to reduce methane for oil and naturalgas operations, crypto-asset mining operations that capture ventedmethane to produce electricity can yield positive results for the climate, by converting the potent methane to CO2 during combustion.Mining operations that replace existing methane flares would not likely affect CO2 emissions, since this methane would otherwise be flared and converted to CO2. Mining operations, though, could potentially be more reliable and more efficient at converting methane to CO2. While such operations can reduce wasted methane, another option is low-cost recovery of methane using existing vapor capture technologies at oil and gas wells, which can reduce global methane emissions up to 50% by 2030.”\n\t- The EU has just voted to add the whole of ‘crypto’, including PoW, tothe EU taxonomy for sustainable activities. This EU wide classification system provides investors with guidance as to the sustainability of agiven technology, and can have a meaningful impact on the flows of investment. With that said the report and addition of PoW is not slated until 2025, and it is by no means clear what the analysis will be by that point. Meanwhile they’re tightening controls of transactions, on which there will be more detail later. For it’s part the EuropeanCentral Bank has come out [in favour of strong constraints]() on cryptomining. They use the [widelydiscredited](https://medium.com/crescofin/the-reports-of-bitcoin-environmental-damage-are-garbage-5a93d32c2d7)“digiconimist” estimates to assert that mining operations are[disproportionately damaging to theenvironment](https://www.ecb.europa.eu/pub/financial-stability/macroprudential-bulletin/html/ecb.mpbu202207_3~d9614ea8e6.en.html).\n\t- We have seen that China has cracked down hard on the technology, banning mining and pressuring holders of the assets. They have unwound this somewhat, and based on past experience it seems that they will continueto nuance their position as they seek adoption of their own digital currency. As much as 20% of all mining activity is now suspected to take place within China.\n\t- Russia is moving to ban the whole technology, most especially Bitcoin, in response to capital flight concerns.\n\t\t- ![GMVHsb7WMAAT3tg.jpeg](../assets/GMVHsb7WMAAT3tg_1714416578876_0.jpeg){:width 400}\n\t- In India there has been confusion for years as more “local” law vieswith confusing central government signalling. It has variously been banned and unbanned, and is now subject to punitive tax. The central bank of India is [strongly infavour](http://164.100.24.220/loksabhaquestions/annex/179/AS10.pdf) of a complete ban. Ajay Seth, secretary of the Finance Ministry’s Department of Economic Affairs recently said it“We have gone through a deep dive consulting with not just the domestic and institutional stakeholders but also organizations like IMF and World Bank.... Simultaneously we are also beginning our work for some sort of a global regulation (todetermine) what role India can play... Whatever we do, even if we go tothe extreme form, the countries that have chosen to prohibit, they can’t succeed unless there is a global consensus”\n\t- It feels like a global political response is just around the corner, but reputable voices in the community suggest that it always feels this way.There is more detail on this in Money chapter later in the book.\n- ## The Bitcoin Network Software\n\t- There isn't a single GitHub which can be considered the final arbiter of the development direction, because it is a distributed community effort with some [500 developers](https://decrypt.co/66740/who-are-the-fastest-growing-developer-communities-in-crypto) out of a wider 'crypto' pool of around 9000 contributors (the vast majority are spread across disparate Ethereum and some Solana projects). [Development and innovation continues](https://bitcoinops.org/en/newsletters/2021/12/22/) but there is an emphasis on careful iteration to avoid damage to the network. Visualisation of code commitments to the various open source software repositories can be seen at [Bitpaint youtube channel](https://www.youtube.com/channel/UC4DT4qudqogkmbqVAQy8eFg/videos) and in Figure [3.14](https://arxiv.org/html/2207.09460v11/#Ch3.F14 \"Figure 3.14 ‣ 3.4.1 The Bitcoin Network Software ‣ 3.4 Bitcoin ‣ Chapter 3 DLT, Blockchain, and Bitcoin ‣ Part I State of the art\").\n\t- ![Figure 3.14: [Bitpaint](https://github.com/bitpaint/bitcoin-gources): Contributions to the Bitcoin ecosystem. Reused with permission.](../assets/gource.jpg)\n\t- [Bitcoin core](https://github.com/bitcoin/) is the main historical effort (with around a dozen major contributors guiding the direction), but there are alternatives ([LibBitcoin in C++](https://github.com/libbitcoin/libbitcoin-node/wiki), [BTCD in Go](https://github.com/btcsuite/btcd), and [BitcoinJ in Java](https://bitcoinj.github.io/getting-started)), and as innovation on layer one slows, attention is shifting to codebases which interact with the base layer asset. Much more on these later.\n\t-\n- ### More technology details\n\t- [[Bitcoin Technical Overview]] is an in depth primer\n\t- Bitcoin is further extended by [[Lightning and Similar L2]] and [[BTC Layer 3]] expands on the emergent tech which underpins my use of the asset\n-\n\t- {{embed ((65b8aeb5-9c3f-4e4c-9d55-2e2b3166744c))}}\n- ## [[Politics, Law, Privacy]]\n\t- ![Figure 3.21: Goldman suggest growth opportunity and potential demonetisation of gold?](../assets/goldmanVgold.jpg)\n\t- Legislators globally, are [starting to codify](https://www.lopp.net/bitcoin-information/legal.html) their positions on proof of work as a technology (including Bitcoin). US States are variously [supporting](https://capitol.texas.gov/tlodocs/88R/billtext/html/HC00089I.htm) or constricting the technology, according to [state legislatures](https://www.ncsl.org/research/financial-services-and-commerce/cryptocurrency-2021-legislation.aspx). Notably New York has [banned new carbon intensive](https://www.nysenate.gov/legislation/bills/2021/A7389) mining facilities for 2 years, while rust and farm belt states with energy build-out problems are [providing incentives](https://financialpost.com/fp-finance/cryptocurrency/texas-governor-abbott-turns-to-bitcoin-miners-to-bolster-the-grid-and-his-re-election) and passing legislation to protect [mining datacenters](https://www.arkleg.state.ar.us/Bills/Detail?id=hb1799). At the federal level the white house has strongly signalled their concerns about the sector [in a report](https://www.whitehouse.gov/wp-content/uploads/2023/03/ERP-2023.pdf). Many of the points in the report are fair, and true, and reflect things said in this book (which pre-dates the report). It's worth picking out the conclusion of that section verbatim: [\"Innovation in financial services brings both risks and opportunities for the broader economy. It can challenge business models and existing industries, but it cannot challenge basic economic principles, such as what makes an asset effective as money and the incentives that give rise to run risk. Although the underlying technologies are a clever solution for the problem of how to execute transactions without a trusted authority, crypto assets currently do not offer widespread economic benefits. They are largely speculative investment vehicles and are not an effective alternative to fiat currency. Also, they are too risky at present to function as payment instruments or to expand financial inclusion. Even so, it is possible that their underlying technology may still find productive uses in the future as companies and governments continue to experiment with DLT. In the meantime, some crypto assets appear to be here to stay, and they continue to cause risks for financial markets, investors, and consumers. Much of the activity in the crypto asset space is covered by existing regulations and regulators are expanding their capabilities to bring a large number of new entities under compliance (SEC 2022). Other parts of the crypto asset space require coordination by various agencies and deliberations about how to address the risks they pose (U.S. Department of the Treasury 2022a). Certain innovations, such as FedNow and a potential U.S. CBDC, could help bring the U.S. financial infrastructure into the digital era in a clear and simple way, without the risks or irrational exuberance brought by crypto assets. Hence, continued investments in the Nation's financial infrastructure have the potential to offer significant benefits to consumers and businesses, but regulators must apply the lessons that civilization has learned, and thus rely on economic principles, in regulating crypto assets.\"]\n\t- Reading between the lines suggest that strong regulation is coming. Indeed the [SEC is now suing](https://www.sec.gov/Archives/edgar/data/1679788/000167978823000051/coin-20230322.htm) the major tech company in the space, Coinbase, while closing a bank servicing the sector, and signalling that stable coins may be unregistered securities in law. The report itself has no 'teeth' but is likely a sign of things to come. There is purportedly \\$2.4B [entering the regulation ecosystems](https://docs.house.gov/meetings/AP/AP23/20230329/115576/HHRG-118-AP23-TTF-GenslerG-20230329.pdf) to enhance regulatory oversight. In actual fact, because of the nature of the federation of states it is likely that a variety of different approaches in law will be taken across the geography and the sector seems to have responded with a shrug. As an aside the report contains an excellent taxonomy of digital assets from Hoffman (Figure [3.22](https://arxiv.org/html/2207.09460v11/#Ch3.F22 \"Figure 3.22 ‣ Energy & policy response ‣ 3.4.2 Mining and Energy concerns ‣ 3.4 Bitcoin ‣ Chapter 3 DLT, Blockchain, and Bitcoin ‣ Part I State of the art\")).\n\t- ![Figure 3.22: Taxonomy of digital assets Hoffman 2022](../assets/PresidentTaxonomy.jpg)\n\t- Conversely the recent \"[Climate and energy implications](https://www.whitehouse.gov/ostp/news-updates/2022/09/08/fact-sheet-climate-and-energy-implications-of-crypto-assets-in-the-united-states/)\" report is parts positive and parts negative about proof of work, and leaves the door open to a legislative clampdown. This is most notable in a [White House proposal](https://www.whitehouse.gov/cea/written-materials/2023/05/02/cost-of-cryptomining-dame-tax/) to tax Bitcoin mining at 30%, a plan which will destroy much of the US based mining industry over the coming years. Carter provides a [detailed response](https://medium.com/@nic__carter/comments-on-the-white-house-report-on-the-climate-implications-of-crypto-mining-8d65d30ec942) to the tardy scientific analysis in the report. Perhaps most interestingly it notes the potential of methane mitigation as mentioned earlier. It is conceivable that methane mitigation alone could provide a route forward for the technology. The report says: [\"The crypto-asset industry can potentially use stranded methane gas, which is the principal component of natural gas, to generate electricity for mining. Methane gas is produced during natural gas drilling and transmission, and by oil wells, landfills, sewage treatment, and agricultural processes. Methane is a potent GHG that can result in 27 to 30 times the global warming potential of CO2 over a 100-year time frame, and is about 80 times as powerful as CO2 over a 20-year timeframe. Reducing methane emissions can slow near-term climate warming, which is why the Biden-Harris Administration released the U.S. methane emissions reduction action plan in 2021. Venting and flaring methane at oil and natural gas wells wastes 4% of global methane production. In 2021, venting and flaring methane emitted the equivalent of 400 million metric tons of CO2, representing about 0.7% of global GHG emissions. This methane is vented or flared, because of the high cost of constructing permanent pipelines or electricity transmission that could transport the methane or its potential electricity generation from remote oil and gas operations to end-users, or because of the high cost of installing equipment on older landfills. Crypto-asset companies are now exploring ways to use electricity generation from vented and flared methane at oil and gas wells and at landfills. While the EPA and the Department of the Interior have proposed new rules to reduce methane for oil and natural gas operations, crypto-asset mining operations that capture vented methane to produce electricity can yield positive results for the climate, by converting the potent methane to CO2 during combustion. Mining operations that replace existing methane flares would not likely affect CO2 emissions, since this methane would otherwise be flared and converted to CO2. Mining operations, though, could potentially be more reliable and more efficient at converting methane to CO2. While such operations can reduce wasted methane, another option is low-cost recovery of methane using existing vapor capture technologies at oil and gas wells, which can reduce global methane emissions up to 50% by 2030.\"]\n\t- The EU has just voted to add the whole of 'crypto', including PoW, to the EU taxonomy for sustainable activities. This EU wide classification system provides investors with guidance as to the sustainability of a given technology, and can have a meaningful impact on the flows of investment. With that said the report and addition of PoW is not slated until 2025, and it is by no means clear what the analysis will be by that point. Meanwhile they're tightening controls of transactions, on which there will be more detail later. For it's part the European Central Bank has come out in favour of strong constraints on crypto mining. They use the [widely discredited](https://medium.com/crescofin/the-reports-of-bitcoin-environmental-damage-are-garbage-5a93d32c2d7) \"digiconimist\" estimates to assert that mining operations are [disproportionately damaging to the environment](https://www.ecb.europa.eu/pub/financial-stability/macroprudential-bulletin/html/ecb.mpbu202207_3~d9614ea8e6.en.html).\n\t- We have seen that China has cracked down hard on the technology, banning mining and pressuring holders of the assets. They have unwound this somewhat, and based on past experience it seems that they will continue to nuance their position as they seek adoption of their own digital currency. As much as 20% of all mining activity is now suspected to take place within China.\n\t- In India there has been confusion for years as more \"local\" law vies with confusing central government signalling. It has variously been banned and unbanned, and is now subject to punitive tax. The central bank of India is [strongly in favour](http://164.100.24.220/loksabhaquestions/annex/179/AS10.pdf) of a complete ban. Ajay Seth, secretary of the Finance Ministry's Department of Economic Affairs recently said [\"We have gone through a deep dive consulting with not just the domestic and institutional stakeholders but also organizations like IMF and World Bank.... Simultaneously we are also beginning our work for some sort of a global regulation (to determine) what role India can play... Whatever we do, even if we go to the extreme form, the countries that have chosen to prohibit, they can't succeed unless there is a global consensus\"]\n\t- It feels like a global political response is just around the corner, but reputable voices in the community suggest that it always feels this way. There is more detail on this in Money chapter later in the book.\n- ##  Risks and mitigations\n\t- Looking across the whole sector, this paragraph from the Bank of International Settlement (BIS) [sums everything up](https://www.bis.org/publ/arpdf/ar2022e3.htm):\n\t- [\"...it is now becoming clear that crypto and DeFi have deeper structural limitations that prevent them from achieving the levels of efficiency, stability or integrity required for an adequate monetary system. In particular, the crypto universe lacks a nominal anchor, which it tries to import, imperfectly, through stablecoins. It is also prone to fragmentation, and its applications cannot scale without compromising security, as shown by their congestion and exorbitant fees. Activity in this parallel system is, instead, sustained by the influx of speculative coin holders. Finally, there are serious concerns about the role of unregulated intermediaries in the system. As they are deep-seated, these structural shortcomings are unlikely to be amenable to technical fixes alone. This is because they reflect the inherent limitations of a decentralised system built on permissionless blockchains.\"]\n\t- [[Lightning and Similar L2]] is still considered to be experimental and not completely battle tested. There have been various attacks and a major double spend attack may be possible \\[[78]\\], but there have been no major problems in the years it's been running with careful design choices and cybersecurity best practice it it likely a production ready component of our planning.\n-\n- # Scraps to be integrated\n\t-\n\t\t- ### Sociopaths everywhere\n\t\t- In the wake of the rampant crime spree by Sam Bankman-Freid and his top teams at Alameda research and the Bahamas registered exchange ‘FTX’ the whole industry has suffered, and will continue to suffer, seismic shocks. There is a chance the sector will never recover, and that we have already seen the top of the hype bubble. Fortunately this doesn’t diminish our use cases for these technologies, as we were never planning to speculate with the asset, but rather use the network. As a side note it is generally accepted that convention money is far more [popular for crime.](https://home.treasury.gov/system/files/136/DeFi-Risk-Full-Review.pdf)\n\t\t- [COPA vs Craig Wright: The Identity Trial (lopp.net)](https://blog.lopp.net/copa-vs-craig-wright-identity-trial/) -\n\t- ### Digital assets\n\t- For digital assets more generally it is useful to look at the recent “whole government executive order” signed by President Biden early in 2022. It was mainly framed in terms of “responsible innovation, and leadership” in the new space. The resulting, “Comprehensive Framework for Responsible Development of Digital Assets” is a product of multi agency collaboration and can be seen as 9 reports and a summary document, and has been long anticipated. The summary itself is neither particularly comprehensive nor a framework, and mainly serves to identifies high level risks, aspirations, and challenges, and strongly hints toward eventual development of a “digital dollar” (CBDC, expanded later).\n\t-\n\t\t- The risks section of the original executive order shows how legislators are framing this, so it’s useful to break down here.\n\t-\n\t\t- Consumer and business protections. This is likely to pertain to custodians and is much needed. Misselling is rife. Security presents a challenge.\n\t- Systemic risk, and market integrity are a concern. The legislators clearly worry about contagion risks from the sector.\n\t- Illicit finance (criminality and sanction busting etc) are a concern, but not particularly front and centre[79]. Criminality in 2021 was a mere 0.15% of transactions according to Chainalysis, but this number varies year to year. There are claims that Iran have begun official overseas buying with cryptocurrencies, but again, the numbers are small. One of the better sections of the work is the US treasury department’s recently published ‘National Risk Assessments for Money Laundering, Terrorist Financing, and Proliferation Financing’. This is a comprehensive report and speaks to careful research across the space. It is broken into three parts. Perhaps surprisingly, while they do see activity in these areas, they do not rate the risk as very significant. Cash remains the main problem for illicit funding. There is some talk that the nature of public blockchain analysis allows greater oversight of these tools and that this is to the advantage of government and civil enforcement agencies.\n\t- Highlighting the need for international coordination suggests they are mindful of jurisdictional arbitrage. The partial regulatory capture of these technologies, where activity flows to globally more lenient legislative regimes, continues to be a concern. Many of the centralised exchanges for instance are located in tax havens such as Malta. As the world catches up with these products it is likely that this will be smoothed out.\n\t- Climate goals, diversity, equality and inclusion are mentioned. It seems that the “environment” aspect of ESG is more important then “social” and “governance” at this time.\n\t- Privacy and human rights are mentioned.\n\t- Energy policy is highlighted, including grid management and reliability, energy efficiency incentives and standards, and sources of energy supply.\n\t- The latest summary report resulting from the above guidance actually adds little tangible meat to the bones. This possibly reflects the complexity of these issues. The recommendations seem to be broadly as follows, and are really a copy/paste of the executive order.\n\t-\n\t\t- Carry on doing research into central bank digital currencies, but there’s no particular rush.\n\t- Support development of better instant payment methods both at home and globally.\n\t- Ensure consumer and systemic protections.\n\t- More monitoring, civil and criminal prosecutions.\n\t- Issue more rules and clarity in response to risks (this is actually likely net positive as rules are currently unclear).\n\t- Improve global reporting on users (KYC/AML).\n\t- The government rhetoric to date in the USA can be seen to be converging on an understanding of the technology, at different rates in different parts of government. One thing that seems to shine through is their own perception of their global leadership on legislation on these matters. They seems to assume that what they decide will guide the world, and this may be true through their KYC/AML pressures.\n\t-\n\t\t- A recent proposed bi-partisan bill in the USA will likely help inform global law, though it is unlikely to pass itself. It encourages the use of Bitcoin as a medium of exchange by applying a tax exemption on transactions of less than $200. The issue of whether an asset is a commodity (a raw material thing) or a security (a promise) is left to a couple of major government agencies to unpick, with corresponding reporting requirements. Crucially for this book these nascent bills all regard both Bitcoin and Ethereum as sufficiently decentralised to qualify as commodities, meaning they would enjoy more lenient oversight. Far more likely to pass is the proposed DCCPA bill which has senior lawmaker support and would see commodities in the space regulated in such a way that trading of it could be halted in the USA. In this line of policy, exchanges will be required to do far more reporting, and would be penalised for trading against their customers. DOAs and DeFi are the big potential losers. In a maddening twist the Office of Government Ethics in the USA has banned anyone who owns digital assets from working on the legislation. This is an exceptional move and likely to result in poorly crafted laws in the first instance.\n\t-\n\t\t- The most recent and troubling example is the US ban on any Ethereum assets which have been through a “mixer service” that obfuscates history. This is a huge constraint on the code and smart contract itself, not just sanctions against individuals. It has ‘free speech’ and constitutional implications [80]. More such actions and arrests of developers are feared. It has led to Circle (who issue the USDC stablecoin) blacklisting every address sanctioned by the US government. Centrally issued digital assets are obviously neither uncensorable nor permissionless. This intersects (again) with the whole question of what decentralisation means and how effective it can be in it’s stated goal of circumventing global policies.\n\t-\n\t\t- 3.9.3Bitcoin specifically\n\t- In addition it’s useful for this document to focus more on the technical challenges to the Bitcoin network.\n\t-\n\t\t- The block reward is reduced every 4 years (epochs). This means a portion of the mining reward is trending to zero, and nobody knows what effect this will have on the incentives for securing the network through proof of work [81]. It is increasingly being discussed as the major eventual problem for the network.\n\t- Stablecoins are a vital transitional technology (described later) but do not meaningfully exist yet on the Bitcoin network. This may change.\n\t- Bitcoin lacks privacy by design. All transactions are publicly viewable. This is a major drag to the concept of BTC as a money. Upgrade of the network is possible, and has indeed been achieved for a Bitcoin fork called Litecoin [82].\n\t- The Lightning network (described later) has terrible UX design at this time.\n\t- The basic ‘usability’ of the network is still poor in the main. Any problems which users experience demand a steep learning curve and risk loss of funds. There is obviously no technical support number people can call.\n\t- Only around one billion unspent transactions can be generated a year on the network. This means that it might become impossible for everyone on the planet to have their own Bitcoin address (with it’s associated underpinning UTXO).\n\t- Chip manufacture is concentrated in only a few companies and countries, as identified by Matthew Pines.\n\t- Potential constraints on monetary policy flexibility.\n\t- Future protocol changes.\n\t- Unanticipated effects on the domestic and international energy system.\n\t- Vulnerability to adversary attacks are widely studied[83, 84, 85, 86], and still pretty much completely speculative because of the complex nature of the attack surface.\n\t- Mining tends toward economy of scale concentration. Many are already on their own specialised network to connect to one another.\n\t- Future hard forks. There will doubtless be pressure to fork the code to add inflation, or ESG mitigations, or to fix the UNIX clock issue in 2106. Each fork is a risk.\n\t- Other unknown, unanticipated risks given Bitcoin’s limited 13-year history.\n\t- There is a “non-zero” chance that Bitcoin is a complex government intelligence agency construct, much like Crpto AG was toward the end of the last century [87].\n\t-\n\t\t- https://bitcoinmagazine.com/culture/how-bitcoin-can-save-political-dissidents-in-myanmar\n\t-\n\t\t- Lightning\n\t-\n\t\t- [Setup lnbits and lightningtipbot](https://www.massmux.com/howto-complete-lightningtipbot-lnbits-setup-vps/)\n\t-\n\t\t- [GitHub\n\t\t- ln-vortex/ln-vortex: Lightning and Taproot enabled collaborative transactions (other)](https://github.com/ln-vortex/ln-vortex)\n\t-\n\t\t- [RGB is a smart contract platform that is scalable, private, and interoperable with Bitcoin and Lightning Network. It is possible to issue assets, create NFTs, and run DAOs on RGB.](https://rgb.tech/)\n\t-\n\t\t- [RGB 20 longhand manual](https://github.com/oneforalone/rgb20-usdt/blob/8ee4243d415ccd3ab76d750614148cd1cb44c1b9/Readme.md)\n\t-\n\t\t- [RGB22](https://standards.lnp-bp.org/rgb/lnpbp-0022)\n\t-\n\t\t- [This is a node management software for large Lightning Network nodes. It provides a way to automate workflows, manage code changes, and track work progress.](https://github.com/lncapital/torq)\n\t-\n\t\t- -\n\t-\n\t\t- L402 lightning reverse proxy with LND for AI\n\t-\n\t\t- [discord](https://app.slack.com/client/T6AK88MGV/C6AFCN3KL/rimeto_profile/U05H0AMLCR5)\n\t-\n\t\t- [docs](https://docs.lightning.engineering/the-lightning-network/l402)\n\t-\n\t\t- [RGB report](https://www.utxo.management/content/files/2023/10/UTXO_Management_RGB_Report.pdf)\n\t-\n\t\t- Adoption\n\t-\n\t\t- [90 Million People Use Cryptocurrency in Nigeria\n\t\t- Report | Investors King](https://investorsking.com/2023/03/08/90-million-people-use-cryptocurrency-in-nigeria-reports/)\n\t-\n\t\t- [2023 Independent Reserve Cryptocurrency Index shows Singaporeans are still actively investing in crypto despite hit in overall confidence: /PRNewswire/ -- In the latest study[1] by Independent Reserve, Singapore's first regulated cryptocurrency exchange for all investors, Singaporeans[2] are still...](https://www.prnewswire.com/apac/news-releases/2023-independent-reserve-cryptocurrency-index-shows-singaporeans-are-still-actively-investing-in-crypto-despite-hit-in-overall-confidence-301783400.html)\n\t-\n\t\t- Despite a recent dip in overall confidence, the 2023 Independent Reserve Cryptocurrency Index shows that Singaporeans are still actively investing in cryptocurrency. The study found that Singaporeans are most interested in investing in Bitcoin, Ethereum, and Litecoin.\n\t-\n\t\t- [Bitnob African exchange](https://bitnob.com/blog/how-to-buy-and-sell-bitcoin-in-nigeria)\n\t-\n\t\t- [Noones peer2peer for Africa](https://bitcoinmagazine.com/business/bitcoin-entrepreneurs-introduce-noones-app-aimed-at-empowering-financial-freedom)\n\t-\n\t\t- [Africa leads the world in peer to peer bitcoin](https://twitter.com/documentingbtc/status/1646656229958361091)\n\t-\n\t\t- [Econometrics of adoption in USA](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4453714)\n\t-\n\t\t- Mining and energy\n\t-\n\t\t- [Bitcoin uses more energy than sweden](https://www.reddit.com/r/CryptoCurrency/comments/12xu714/bitcoin_has_just_surpassed_sweden_for_overall/)\n\t-\n\t\t- [THE 'RIGHT TO MINE' #BITCOIN📷 IS NOW LAW IN THE STATE OF ARKANSAS!](https://twitter.com/satoshiactfund/status/1648445448833875969)\n\t-\n\t\t- [Bitcoin is a more sustainable energy than EVs, and significantly less fossil fuel.](https://www.linkedin.com/posts/danielsbatten_like-evs-bitcoin-is-a-fully-electrified-activity-7049321186605858816-t4MB?utm_source=share&utm_medium=member_android)\n\t-\n\t\t- [Batton's energy tracker](http://batcoinz.com/BEEST/)\n\t-\n\t\t- [sazmining hosted hydro](https://www.sazmining.com/)\n\t-\n\t\t- decentralised storage\n\t-\n\t\t- [bitstream](https://robinlinus.com/bitstream.pdf)\n\t-\n\t\t- [git](https://github.com/robinlinus/bitstream)\n\t-\n\t\t- |\n\t- Swap Service is an orderbook that allows for submarine swaps over Nostr, enabling Bitcoin users to earn a yield on their Bitcoin. Submarine swaps allow for the swapping of funds on Lightning for funds on the base layer and vice versa, without the need for opening or closing channels or giving custody of funds to other people. Swap Service also enables channel rebalancing and is the foundation for wallets and services like Muun, Lightning Loop, and Boltz Exchange. Anyone who runs an LND Lightning node can become a yield chaser by running Swap Service on their computer and hooking it up to their node. Yield chasers can set parameters and earn a fee for swaps. Swap Service is available on both the mainnet and testnet. https://www.nobsbitcoin.com/swap-service-submarine-swaps-over-nostr/\n\t-\n\t\t- [Durabit torrent bitcoin storage](https://www.nobsbitcoin.com/durabit-whitepaper/\n\t-\n\t\t- Taproot Assets\n\t-\n\t\t- On May 16, Lightning Labs announced Taproot Assets v0.2, the newest version of its scalable protocol to issue assets on Bitcoin and Lightning. Taproot Assets v0.2 has a core set of features that enable developers to issue assets and bitcoinize assets in a chain-efficient manner. This specific version offers a variety of useful features, such us vPSBT support for send and receive, Universe APIs for asset discovery and multi-asset transactions to save chain space. The team called all bitcoin and Lightning developers to test the code, give feedback and start building on Taproot Assets.  The announcement has generated feedback from users on Twitter, including comments calling for Bolt12, RGB, and Podcast Token. https://twitter.com/lightning/status/1658497809895809025\n\t-\n\t\t- The Swap Service is an order book designed for performing submarine swaps over the Nostr protocol. It provides users with a way to earn yield on their bitcoin holdings. Submarine swaps allow lightning users to swap funds on the lightning network for funds on the base layer, or vice versa, without opening and closing channels and without the need to give custody of their money to other people. They are also beneficial for channel rebalancing and create the foundation for important wallets and services such as Muun, Lightning Loop and Boltz Exchange. Any person running an LND lightning node can run the Swap Service on their computer to become a yield chaser, setting parameters, such as how much sats they are willing to swap and the fee for swaps, with the Swap Service providing a simple tool to execute these actions. The Swap Service website includes a demo video and instruction for use on the mainnet or testnet. https://www.nobsbitcoin.com/swap-service-submarine-swaps-over-nostr/\n\t-\n\t\t- Diamond Hands has released an alpha version of Shiro Wallet, which is compatible with RGB protocol and can be added easily to other services by calling endpoints for the wallet. It is an open-source, self-hosted RGB wallet for the Bitcoin blockchain. Shiro Wallet can issue, send and receive fungible RGB tokens, which allows users to experiment with the protocol and gain first-hand experience. The wallet is a web-server wallet and can be integrated easily with other services. It is the first RGB wallet available on Umbrel, a popular Bitcoin node management platform. However, the current form of Shiro Wallet is still very rough and alpha and only available on testnet for now. https://www.nobsbitcoin.com/shiro-wallet-umbrel-release/\n\t-\n\t\t- The nbd-wtf/soma repository on GitHub is a demo Spacechain that allows users to issue and transfer non-fungible assets on a fully-fledged blockchain that does not require any shitcoins to be created or spam to be dumped into the Bitcoin chain. The blockchain is designed using SIGHASH_ANYPREVOUT and runs on signet. The repository includes a Docker container with everything pre-packaged for running the Spacechain demo, along with a tutorial. There are also hosted tools available for users who just want to see something happen. The repository is primarily written in Scala and JavaScript, with smaller portions written in Dockerfile, HTML, Go, Shell, and Makefile. https://github.com/nbd-wtf/soma\n\t-\n\t\t- BRC-20 is an experiment to test if ordinal theory can facilitate fungibility on Bitcoin. It allows for the deployment, minting, and transfer of token amounts through a JSON file inscription, enabling the tracking of rudimentary token balances on Bitcoin. BRC-20 defines ticker length as four characters, with little to no restrictions on character type. The deployment contract sets a maximum \"lim* amount for the token, which anyone can mint after. The activity around BRC-20s remained modest until early March, but exploded in late April, leading to Bitcoin network transactions surpassing regular Bitcoin transactions for two days straight. However, this creates a significant risk to the ecosystem as third-party services keep track of balances and token indexes instead of the Bitcoin blockchain or ord client, potentially exposing third party security to systemic risk. The ecosystem is accelerating with DeFi-type *liquidity pool\" standards popping up as it mirrors the early stages of the previous crypto cycle before DeFi Summer. This is an ongoing and rapidly developing story, which requires continued tracking of the Ordinals ecosystem. https://blog.ordinalhub.com/brc-20-mania/\n\t-\n\t\t- |A new open-source Bitcoin blockchain analyzer is being developed to provide regular Bitcoin users with tools to research their transactions and avoid high fees charged by analytics companies. A recent post found that over 80% of inscriptions created in early-mid May 2023 belonged to a single entity, controlled by a single private key, belonging to a possible user of Unisat. The centralisation of control means a single entity can significantly impact the entire Blockchain regime, with the tests highlighting worrying vulnerabilities in the Bitcoin network. Further research is required to address the issue. https://block21m.substack.com/p/most-bitcoin-inscriptions-belong-d6d\n\t-\n\t\t- The text is a preview of the Spotify streaming service that encourages users to sign up and create a playlist. It also features a podcast episode from the Bitcoin Core developer Matt Corallo, discussing the impact of mining rewards and decentralization risks. The text highlights the importance of user privacy, stating that cookies are used to store and access personal data for purposes such as personalized content and advertising, and users can adjust their preferences using the Cookie Settings button. The text suggests that Spotify works in coordination with an industry framework to indicate user preferences globally for all participating websites. https://open.spotify.com/episode/460zip5X9UVSFxJ91JY0J3?si=n6rh-ctDR1Ga6Erql84ZQg\n\t-\n\t\t- The text talks about how Twitter users are the first to know about things, with a tweet from Farooq Ahmed suggesting that Bitcoin could render the Belgian association known as SWIFT obsolete. The tweet has received views, retweets, and likes, and there are also other tweets from Ahmed, such as one about Bitcoin to the IMF, and another praising the progress made by Nayib Bukele in El Salvador. The text also mentions that Twitter and its partners use cookies to provide better and safer services. https://mobile.twitter.com/FarooqAhmedX/status/1620925310379368448\n\t- Ark is a privacy-focused off-chain protocol that offers anonymity similar to the classic Chaumian eCash system. However, unlike eCash, transactions made through Ark are backed by actual bitcoins, making it more secure. Compared to Lightning, Ark is a liquidity network that consumes significantly less on-chain footprint and allows recipients to receive payments without acquiring inbound liquidity or revealing their identity. Ark also mimics the on-chain wallet UX but does not require transactions to be on-chain and does not introduce inbound liquidity constraints. Compared to validity rollups, Ark has higher throughput as it does not require on-chain data per transaction. While in theory, Ark service providers can double-spend their pool transactions while they sit on mempool, users can redeem their previously redeemed coins through a hypothetical data manipulation opcode in case of double-spending. Overall, Ark offers a more secure and private way to make transactions that is faster and more efficient than other methods available. https://www.arkpill.me/faq\n\t-\n\t\t- Node config tools\n\t-\n\t\t- [VPS config](https://github.com/flyerbear/pleb-vpn/blob/main/Raspibolt%20Install%20Guide.md)\n\t-\n\t\t- [plebVPN](https://github.com/allyourbankarebelongtous/pleb-vpn#how-it-works)\n\t-\n\t\t- [Cleveland bank paper on lighting improving Bitcoin](https://www.clevelandfed.org/en/publications/working-paper/2022/wp-2219-the-lightning-network-turning-bitcoin-into-money)\n\t-\n\t\t- [DLC wiki](https://www.dlc.wiki/)\n\t-\n\t\t- [layer 2 and rollups](https://0rkun.com/posts/my-view-on-layer-2-and-rollups)\n\t-\n\t\t- Digital currency, without a central bank or single administrator, that can be sent from user to user on the peer-to-peer bitcoin network without the need for intermediaries. Transactions are verified by network nodes through cryptography and recorded in a public distributed ledger called a blockchain.\n\t-\n\t\t- Bitcoin\n\t- The Freedom of Value\n\t\t- How Value-for-Value Fixes the Monetization of Information | dergigi.com,Thoughts about Bitcoin and other things.\n\t- <https://dergigi.com/2021/12/30/the-freedom-of-value/>\n\t- http://bitcoin secure multisig setup (bsms        2 file_get_contents(): php_network_getaddresses: getaddrinfo failed: Name or service not known 2 file_get_contents(http://bitcoin secure multisig setup (bsms): failed to open stream: php_network_getaddresses: getaddrinfo failed: Name or service not known\n\t- *  https://bitcoinmagazine.com/legal/u-s-treasury-introduces-cbdc-digital-dollar-working-group\n\t- Crypto Wave Gaining Momentum In Germany: Network Of 1,200 Banks To Offer Bitcoin: Deutsche WertpapierService Bank (Dwpbank), a provider of securities processing to approximately 1,200 banks in Germany, plans to launch a new platform called wpNex. This platform will offer Bitcoin access to all affiliated retail customers in the latter half of 2023. The innovative service will integrate cryptocurrency accounts with customers' existing bank accounts, bypassing the need for additional Know Your Customer procedures, local media...\n\t- <https://www.msn.com/en-us/money/news/crypto-wave-gaining-momentum-in-germany-network-of-1-200-banks-to-offer-bitcoin/ar-AA198Lxc>\n\t- https://www.cointime.com/news/hal-finneys-theory-of-bitcoin-backed-banks-74474\n\t- bitcoin-mining-analogy-beginners-guide\n\t- <https://braiins.com/blog/bitcoin-mining-analogy-beginners-guide>\n\t- Introducing Floresta, a Utreexo-powered Electrum Server implementation: Bitcoin is a groundbreaking technology that enables users worldwide to transfer value in a trustless and borderless manner. Bitcoin’s core…\n\t- <https://medium.com/vinteum-org/introducing-floresta-an-utreexo-powered-electrum-server-implementation-60feba8e179d>\n\t- This is an implementation of an Electrum Server using Utreexo. Utreexo is a Bitcoin scaling solution that enables trustless and borderless value transfers. This implementation of an Electrum Server should help improve Bitcoin's decentralization.\n\t- New critical white house report\n\t- <https://www.whitehouse.gov/wp-content/uploads/2023/03/ERP-2023.pdf>\n\t- Fedimint Hackathon Winners Announced: 2.58 BTC in Prizes: \"The quality of the modules that were submitted was truly impressive, with projects from federated storage to community finance tools that really highlighted the potential impact of Fedimint as a platform that could solve real-world problems.\"\n\t- <https://www.nobsbitcoin.com/fedimint-hackathon-winners-announced/>\n\t- The Fedimint hackathon has come to a close, with 2.58 BTC in prizes being awarded to the winners. The quality of the submissions was impressive, with a range of modules being submitted that highlighted the potential of Fedimint as a platform for solving real-world problems.\n\t- first ref in the book\n\t- <https://github.com/flossverse/product/commit/e3ab5e7c7566184a84356608d7cd19049236ce8d?diff=unified#diff-3dd31e6ffeab329413da9cd244e8d27e892b95ca1b89390ad168124bbb88357cR241>\n\t- https://geometry.xyz/notebook/A-light-introduction-to-ZeroSync\n\t- Deception, exploited workers, and cash handouts: How Worldcoin recruited its first half a million test users: The startup promises a fairly-distributed, cryptocurrency-based universal basic income. So far all it's done is build a biometric database from the bodies of the poor.\n\t- <https://www.technologyreview.com/2022/04/06/1048981/worldcoin-cryptocurrency-biometrics-web3/>\n\t- Cashu rust implementation\n\t- <https://github.com/ngutech21/cashu-rs>\n\t- Zerosync bitcoin rollup proofs\n\t- <https://zerosync.org/>\n\t- 10101 custodial DLC trading\n\t- <https://medium.com/10101-finance/itchysats-becomes-10101-216dd64941d2>\n\t- Quantum miners\n\t- <https://arxiv.org/pdf/2306.03321.pdf>\n\t-\n\t\t- [address_index](https://github.com/bitcoin/bips/blob/master/bip-0044.mediawiki) and deterministic paths (BIP44)\n\t- -\n\t-\n\t-\n\t\t- #### 3.9.1 Sociopaths [everywhere]\n\t- In the wake of the [rampant crime spree](https://www.bloomberg.com/opinion/articles/2022-11-14/ftx-s-balance-sheet-was-bad) by Sam Bankman-Freid and his top teams at Alameda research and the Bahamas registered exchange 'FTX' the whole industry has suffered, and will continue to suffer, seismic shocks. There is a chance the sector will never recover, and that we have already seen the top of the hype bubble. Fortunately this doesn't diminish our use cases for these technologies, as we were never planning to speculate with the asset, but rather use the network.\n\t-\n\t\t- #### 3.9.2 Digital assets\n\t- For digital assets more generally it is useful to look at the recent [\"whole government executive order\"](https://www.whitehouse.gov/briefing-room/presidential-actions/2022/03/09/executive-order-on-ensuring-responsible-development-of-digital-assets/) signed by President Biden early in 2022. It was mainly framed in terms of \"responsible innovation, and leadership\" in the new space. The resulting, \"Comprehensive Framework for Responsible Development of Digital Assets\" is a product of multi agency collaboration and can be seen as 9 reports and a summary document, and has been long anticipated. The summary itself is neither particularly comprehensive nor a framework, and mainly serves to identifies high level risks, aspirations, and challenges, and strongly hints toward eventual development of a \"digital dollar\" (CBDC, expanded later).\n\t- The risks section of the original executive order shows how legislators are framing this, so it's useful to break down here.\n\t- Consumer and business protections. This is likely to pertain to     custodians and is much needed. Misselling is rife. Security presents     a challenge.     Systemic risk, and market integrity are a concern. The legislators     clearly worry about contagion risks from the sector.     Illicit finance (criminality and sanction busting etc) are a     concern, but not particularly front and     centre\\[[79]\\].     Criminality in 2021 was a mere 0.15% of transactions according to     Chainalysis, but this number varies year to year. There are claims     that Iran have begun official overseas buying with cryptocurrencies,     but again, the [numbers are     small](https://finbold.com/iran-makes-the-first-ever-import-of-goods-using-cryptocurrency-worth-millions/).     One of the better sections of the work is the US treasury     department's recently published 'National Risk Assessments for Money     Laundering, Terrorist Financing, and Proliferation Financing'. This     is a comprehensive report and speaks to careful research across the     space. It is broken into [three     parts](https://home.treasury.gov/news/press-releases/jy0619).     Perhaps surprisingly, while they do see activity in these areas,     they do not rate the risk as very significant. Cash remains the main     problem for illicit funding. There is some talk that the nature of     public blockchain analysis allows greater oversight of these tools     and that this is to the advantage of government and civil     enforcement agencies.     Highlighting the need for international coordination suggests they     are mindful of jurisdictional arbitrage. The partial regulatory     capture of these technologies, where activity flows to globally more     lenient legislative regimes, continues to be a concern. Many of the     centralised exchanges for instance are located in tax havens such as     Malta. As the world catches up with these products it is likely that     this will be smoothed out.     Climate goals, diversity, equality and inclusion are mentioned. It     seems that the \"environment\" aspect of ESG is more important then     \"social\" and \"governance\" at this time.     Privacy and human rights are mentioned.     Energy policy is highlighted, including grid management and     reliability, energy efficiency incentives and standards, and sources     of energy supply.\n\t- The [latest summary report](https://www.whitehouse.gov/briefing-room/statements-releases/2022/09/16/fact-sheet-white-house-releases-first-ever-comprehensive-framework-for-responsible-development-of-digital-assets/) resulting from the above guidance actually adds little tangible meat to the bones. This possibly reflects the complexity of these issues. The recommendations seem to be broadly as follows, and are really a copy/paste of the executive order.\n\t- Carry on doing research into central bank digital currencies, but     there's no particular rush.     Support development of better instant payment methods both at home     and globally.     Ensure consumer and systemic protections.     More monitoring, civil and criminal prosecutions.     Issue more rules and clarity in response to risks (this is actually     likely net positive as rules are currently unclear).     Improve global reporting on users (KYC/AML).\n\t- The government rhetoric to date in the USA can be seen to be converging on an understanding of the technology, at different rates in different parts of government. One thing that seems to shine through is their own perception of their global leadership on legislation on these matters. They seems to assume that what they decide will guide the world, and this may be true through their KYC/AML pressures.\n\t- A recent proposed [bi-partisan bill in the USA](https://bitcoinmagazine.com/business/heres-whats-in-senator-lummis-bitcoin-bill) will likely help inform global law, though it is unlikely to pass itself. It encourages the use of Bitcoin as a medium of exchange by applying a tax exemption on transactions of less than \\$200. The issue of whether an asset is a commodity (a raw material thing) or a security (a promise) is left to a couple of major government agencies to unpick, with corresponding reporting requirements. Crucially for this book these nascent bills all regard both Bitcoin and Ethereum as sufficiently decentralised to [qualify as commodities](https://www.coincenter.org/a-new-senate-bill-focuses-on-cryptocurrency-exchanges-heres-what-developers-and-users-should-keep-an-eye-on/), meaning they would enjoy more lenient oversight. Far more likely to pass is the [proposed DCCPA bill](https://www.agriculture.senate.gov/imo/media/doc/crypto_one-pager1.pdf) which has senior lawmaker support and would see commodities in the space regulated in such a way that trading of it could be halted in the USA. In this line of policy, exchanges will be required to do far more reporting, and would be penalised for trading against their customers. DOAs and DeFi are the big potential losers. In a maddening twist the Office of Government Ethics in the USA has banned anyone who owns digital assets from working on the legislation. This is an exceptional move and likely to result in poorly crafted laws in the first instance.\n\t- The most recent and troubling example is the US ban on any Ethereum assets which have been through a \"mixer service\" [that obfuscates history](https://www.coincenter.org/u-s-treasury-sanction-of-privacy-tools-places-sweeping-restrictions-on-all-americans/). This is a huge constraint on the code and smart contract itself, not just sanctions against individuals. It has ['free speech'](https://hoffmang9.github.io/free-speech/the-history-code-is-free-speech.html) and constitutional implications \\[[80]\\]. More such actions and [arrests of developers](https://www.dw.com/en/dutch-investigators-say-developer-of-tornado-cash-arrested/a-62793823) are feared. It has led to Circle (who issue the USDC stablecoin) blacklisting every [address sanctioned by the US government](https://home.treasury.gov/policy-issues/financial-sanctions/recent-actions/20220808). Centrally issued digital assets are obviously neither uncensorable nor permissionless. This intersects (again) with the whole question of what decentralisation means and how effective it can be in it's stated goal of circumventing global policies.\n\t-\n\t\t- #### 3.9.3 Bitcoin specifically\n\t- In addition it's useful for this document to focus more on the technical challenges to the Bitcoin network.\n\t- The block reward is reduced every 4 years (epochs). This means a     portion of the mining reward is trending to zero, and nobody knows     what effect this will have on the incentives for [securing the     network](https://www.truthcoin.info/blog/security-budget-ii-mm/)     through proof of work     \\[[81]\\]. It is     increasingly [being     discussed](https://cryptostackers.substack.com/p/bitcoin-is-not-a-store-of-value?sd=pf&s=r)     as the major eventual problem for the network.     Stablecoins are a vital transitional technology (described later)     but do not meaningfully exist yet on the Bitcoin network. This may     change.     Bitcoin lacks privacy by design. All transactions are publicly     viewable. This is a major drag to the concept of BTC as a money.     Upgrade of the network is possible, and has indeed been achieved for     a Bitcoin fork called Litecoin     \\[[82]\\].     The Lightning network (described later) has terrible UX design at     this time.     The basic 'usability' of the network is still poor in the main. Any     problems which users experience demand a steep learning curve and     risk loss of funds. There is obviously no technical support number     people can call.     Only around one billion unspent transactions can be generated a year     on the network. This means that it might become impossible for     everyone on the planet to have their own Bitcoin address (with it's     associated underpinning UTXO).     Chip manufacture is concentrated in only a few companies and     countries, as identified by [Matthew     Pines](https://www.btcpolicy.org/authors/matthew-pines).     Potential constraints on monetary policy flexibility.     Unanticipated effects on the domestic and international energy     system.     Vulnerability to adversary attacks are [widely     studied](https://braiins.com/blog/bitcoin-mining-attacks-explained)\\[[83],     [84],     [85],     [86]\\], and still     pretty much completely speculative because of the complex nature of     the attack surface.     Mining tends toward economy of scale concentration. Many are already     on their [own specialised network](https://bitcoinfibre.org/) to     connect to one another.     Future hard forks. There will doubtless be pressure to fork the code     to add inflation, or ESG mitigations, or to fix the UNIX clock issue     in 2106. Each fork is a risk.     Other unknown, unanticipated risks given Bitcoin's limited 13-year     history.     There is a \"non-zero\" chance that Bitcoin is a complex government     intelligence agency construct, [much like Crpto AG     was](https://en.wikipedia.org/wiki/Crypto_AG) toward the end of the     last century     \\[[87]\\].\n-",
        "link_types": [
            "Nakamoto 2008",
            "Haber 1990",
            "Nakamoto 2018",
            "Ijiri 1986; Faccia 2019",
            "Chohan 2021; Perez 2019; Grunspan 2018",
            "Sangster 2015",
            "nakamoto2018",
            "nakamoto2018",
            "hulsmann2008ethics",
            "selvam2021blockchain",
            "makarov2021blockchain",
            "croman2016scaling",
            "delgado2018analysis",
            "oxford2021salvador",
            "katterbauer2022impact",
            "rogaway2004cryptographic",
            "mora2018bitcoin",
            "cross2021greening",
            "bitcoinisvenice",
            "griffith2021electrify; @ercotimpact2021; @Menati2022",
            "bastian2021hedging",
            "ibanez2023sok",
            "baur2021bitcoin",
            "blandin20203rd",
            "de2022revisiting",
            "mora2018bitcoin",
            "mora2018bitcoin",
            "khazzaka2022bitcoin",
            "money",
            "Bitcoin Technical Overview",
            "Lightning and Similar L2",
            "BTC Layer 3",
            "Politics, Law, Privacy",
            "Lightning and Similar L2"
        ],
        "file_size": 98639
    },
    {
        "id": "AI Adoption.md",
        "name": "AI Adoption",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ## The Gap\n  id:: 659fe0be-a52a-42ef-8f50-73695a802945\n\t- McKinsey identified in 2022 that companies with a 5 year AI roadmap would likely pull ahead. [They called this \"The Gap\"](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review#gap)\n\t- Hindsight shows us that this was correct. Those companies feel somewhat unassailable, but the nature of the research publishing environment, and pace of progress, means there are plenty of opportunities.\n\t- ### Ways to close The Gap\n\t\t- [Daily Papers Hugging Face](https://huggingface.co/papers)  << you can do worse than this to ambiently learn\n- ## Custom Gen AI models in business\n  id:: 659a9231-4d21-415e-8b07-25b215e6b712\n\t- ![image.png](../assets/image_1704997279791_0.png){:width 500}\n\t- ### **DO play with tools**\n\t\t- Use the tools that come free with where you already keep your data.\n\t\t- Start to sort out your data. Learn it's structure, and whether it's useful to optimise it.\n\t\t- High quality data gives high quality outcomes.\n\t\t- Use the paid and private version of [RunDiffusion](https://app.rundiffusion.com/) to start to play with the open tooling. [[Fooocus]] is new and very accessible and on that platform with **everything** else of value.\n\t\t- See if there's something on the market that is trustable when your data and product are ready, don't spread data about too much.\n\t\t- Do check if this is worth it. Get an expert opinion. Bloomberg spent around $20M on a model based on their financial data only to find that GPT4 [still beats it](https://arxiv.org/pdf/2305.05862.pdf).\n\t\t- Think about integrating the open tooling into your product development, consider the software licenses. Take **some** legal advice.\n\t- ### Avoid the [Secret Cyborg](https://www.oneusefulthing.org/p/reshaping-the-tree-rebuilding-organizations).\n\t\t- [twitter link to the render loading below](https://twitter.com/emollick/status/1775176524653642164){{twitter https://twitter.com/emollick/status/1775176524653642164}}\n\t\t- Acknowledge that employees are already using AI at work, often without approval. Over half of people using AI at work are doing so without telling their bosses. [Microsoft put this number at a staggering 75%](https://www.microsoft.com/en-us/worklab/work-trend-index/ai-at-work-is-here-now-comes-the-hard-part/) [[Microsoft Work Trends Impact 2024]]\n\t\t\t- | Statistic | Value |\n\t\t\t  |-----------|-------|\n\t\t\t  | Percentage of global knowledge workers using generative AI | 75% |\n\t\t\t  | Percentage of AI users who say it helps them save time | 90% |\n\t\t\t  | Percentage of AI users who say it helps them focus on their most important work | 85% |\n\t\t\t  | Percentage of AI users who say it helps them be more creative | 84% |\n\t\t\t  | Percentage of AI users who say it helps them enjoy their work more | 83% |\n\t\t\t  | Percentage of AI users who are bringing their own AI tools to work (BYOAI) | 78% |\n\t\t\t  | Percentage of AI users at small and medium-sized companies who are bringing their own AI to work | 80% |\n\t\t\t  | Percentage of AI users reluctant to admit using AI for their most important tasks | 52% |\n\t\t\t  | Percentage of leaders who would rather hire a less experienced candidate with AI skills than a more experienced candidate without them | 71% |\n\t\t\t  | Percentage of leaders who say early-in-career talent will be given greater responsibilities with AI | 77% |\n\t\t- Create a culture of exploration and openness around AI use. Encourage employees to share how they are using AI to assist their work.\n\t\t- Completely rethink and redesign work processes around AI capabilities, rather than just using AI to automate existing processes. Cut down the org chart and regrow it for AI.\n\t\t- Let teams develop their own methods for incorporating AI as an \"intelligence\" that adds to processes. Manage AI more like additional team members than external IT solutions.\n\t\t- Align incentives and provide clear guidelines so employees feel empowered to ethically experiment with AI.\n\t\t- Build for the rapidly evolving future of AI, not just today's models. Organizational change takes time, so consider future AI capabilities.\n\t\t- Act quickly\n\t\t- organizations that wait too long to experiment and adapt processes for AI efficiency gains will fall behind. Provide guidelines for short-term experimentation vs slow top-down solutions.\n\t\t- Realize there are only two ways to react to exponential AI change\n\t\t- too early or too late. The capabilities are increasing rapidly, so it's better to start adapting sooner than later.\n\t- ### Custom models\n\t\t- AI/ML is the high interest rate credit card of product development\n\t\t- The likely emerging trend for [[Large language models]] is small models optimised for your data, with API collaboration and support from a big foundational model.\n\t\t- Think [[Mistral]], replacing one of the experts with YOUR expert\n\t\t- This is kinda true for image and video too, in that you can blend workflows between powerful online systems and more nuanced personal models. (imagebashing).\n\t\t- ### How to train models?\n\t\t\t- Smaller data and workflows:\n\t\t\t\t- Do it yourself with suitable cloud hardware. This applies to all Gen AI.\n\t\t\t\t- [[LoRA]] are very accessible. Basically nudge the existing models for your requirements.\n\t\t\t\t- Low legal peril.\n\t\t\t- Medium scale problems:\n\t\t\t\t- Own the skills you need for your data / product problem.\n\t\t\t\t- There's a lot of guidance from the major players like Microsoft\n\t\t\t\t  [Develop Generative AI solutions with Azure OpenAI Service\n\t\t\t- Training | Microsoft Learn](https://learn.microsoft.com/en-us/training/paths/develop-ai-solutions-azure-openai/)\n\t\t\t\t- Get in a private consultant like me and onboard the skills for your product / data problem\n\t\t\t\t- This is the same model a the hub and spokes needed for larger models\n\t\t\t- Large / complex product and data challenges:\n\t\t\t\t- The industry is set up around the necessary datacentres. These are centres of excellence, commercial labs, Universities, etc.\n\t\t\t\t- Engage commercial data team who get you up to speed and train your model on their hardware.\n\t\t\t\t\t- Salford Uni will doubtless have a strategy with Azure.\n\t\t\t\t\t- [Deep Learning & Artificial Intelligence SCAN Business | SCAN UK](https://www.scan.co.uk/business/deep-learning)\n\t\t\t\t\t- [Europe’s largest private AI lab | Silo AI](https://www.silo.ai/)\n\t\t\t\t\t- [Advanced Solutions Lab Google Cloud](https://cloud.google.com/asl/)\n\t\t\t\t\t- Hartree?\n\t\t- ### Roll out in the cloud.\n\t\t- Play with [Runpod](https://www.runpod.io/). There's some great [YouTube tutorials](https://www.youtube.com/watch?v=WjiX3lCnwUI)\n\t\t- I use a [Lambda Labs H100](https://lambdalabs.com/).\n\t\t- Unless you really know what you're doing, or you have a LOT of data, I wouldn't buy GPUs and attempt the inferencing side yourself\n\t\t- ## In Politics.\n\t\t\t- [An AI Bot Is (Sort of) Running for Mayor in Wyoming | WIRED](https://www.wired.com/story/ai-bot-running-for-mayor-wyoming/)\n\t\t\t- [There’s an AI Candidate Running for Parliament in the UK | WIRED](https://www.wired.com/story/ai-candidate-running-for-parliament-uk/)\n\t\t\t- [[Politics, Law, Privacy]]\n- This is a [[presentation]] slide and the next slide is [[State of the art in AI]]",
        "link_types": [
            "Fooocus",
            "Microsoft Work Trends Impact 2024",
            "Large language models",
            "Mistral",
            "LoRA",
            "Politics, Law, Privacy",
            "presentation",
            "State of the art in AI"
        ],
        "file_size": 7211
    },
    {
        "id": "National Industrial Centre for Virtual Environments.md",
        "name": "National Industrial Centre for Virtual Environments",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n\t- This was from our first paper, published by [Ruth Aylett](https://www.linkedin.com/in/ACoAAAACrVwB204Ab7f4c5tb6XmlXPpd9ov_mrA), which we did as the project at the end of the masters programme. Every single triangle in that was hand drawn seperately, one at a time, by me. Modelling wasn't really a proper thing back then. It was CAD, or Medit on an SGI O2. You can see the resemblance to N64 games of the era which were all the same hardware/software pipelines. [https://www.aaai.org/Papers/Symposia/Fall/1999/FS-99-01/FS99-01-014.pdf](https://www.aaai.org/Papers/Symposia/Fall/1999/FS-99-01/FS99-01-014.pdf)\n\t- ![prospectus.bmp](../assets/prospectus_1704195118229_0.bmp)\n\t- [Dr Simon Campion](https://www.linkedin.com/in/ACoAAAfPu4gBKe76g1PvTLMvi7uMUwf9ZAMC60s) using our experimental Barco based immersion workbench. Again a mockup, but about right. We took this to Farnborough airshow in support of [Euravia Engineering & Supply Co. Limited](https://www.linkedin.com/company/euravia/)\n\t- ![workbench.jpg](../assets/workbench_1704195169470_0.jpg)\n\t- The NICVE 4 sided system, which was powered by a three rack SGI Onyx2 IR2 \"supercomputer\". It was made of wood because the tracking systems was electromagnetic (flock of birds). When trains went past everything wobbled a bit. I used to sit in the dark reconverging the CRT guns every week with music blaring. It was a good task.\n\t- ![1666439576666.png](../assets/1666439576666_1708174000080_0.png)\n\t- One of the SGI cabs being delivered. Must be 1997 then? They were brand new. That was expensive. Really really expensive. We ran the whole building off them.\n\t- ![Untitled-23.jpg](../assets/Untitled-23_1704195226252_0.jpg)\n\t- This was our reality room, with 3 edge blended Barco projectors. They were RGB CRT guns. Pre digital. Wow. This is a mockup because there wasn't enough light for cameras of the time to capture the glory. That's a laser scan of a 747 by Mensi, who sold us a laser scanner for a couple of hundred thousand pounds that took a couple of samples a second.\n\t- ![1666439697003.png](../assets/1666439697003_1708174028512_0.png)\n\t- This was the Trimension Relocatable Reality Centre, at GMEX in Manchester in this case, and a very young me. The compute on the left is an SGI Onyx2 Deskside.\n\t- ![DSCF2204.JPG](../assets/DSCF2204_1704195427620_0.JPG)\n\t- ### Adrenaline Rush\n\t- I was a member of the science team on the first ever jump of DaVinci's parachute design, for an IMAX film called [Adrenaline rush, The science of risk (2002) Video\n\t- Pinkbike](https://www.pinkbike.com/video/464827/)\n\t- ![Screenshot 2024-01-29 175325.png](../assets/Screenshot_2024-01-29_175325_1706551309172_0.png)",
        "link_types": [],
        "file_size": 2721
    },
    {
        "id": "infrastructure.md",
        "name": "infrastructure",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t- automatically published\n- [Microsoft to launch AI hub in London (msn.com)](https://www.msn.com/en-gb/money/technology/microsoft-to-launch-ai-hub-in-london/)\n\t- “I know – through my close work with thought leaders in the UK Government, business community and academia – that the country is committed to advancing AI responsibly and with a safety-first commitment to drive investment, innovation and economic growth,\" Suleyman wrote in a company blog post published on Monday. [[Trust and Safety]]\n- [Microsoft to invest £2.5bn in UK to boost AI plans | The Independent](https://www.independent.co.uk/business/microsoft-to-invest-ps2-5bn-in-uk-to-boost-ai-plans-b2456219.html)\n- [Boost for UK AI as Microsoft unveils £2.5 billion investment\n\t- GOV.UK (www.gov.uk)](https://www.gov.uk/government/news/boost-for-uk-ai-as-microsoft-unveils-25-billion-investment)\n- HP thin client [Teradici Documentation and Downloads | Documents and Downloads for Teradici products](https://docs.teradici.com/knowledge)\n- [Fireworks - Generative AI For Product Innovation!](https://fireworks.ai/) - fine tuning and high speed inferencing\n-\n-",
        "link_types": [
            "Trust and Safety"
        ],
        "file_size": 1161
    },
    {
        "id": "Semantic Web.md",
        "name": "Semantic Web",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published but is broken, move on\n- The “semantic web” definition of Web3.0 has been somewhat overhauled by other innovations in decentralised internet technologies, now evolving toward the slightly different Web3 moniker. Tim Berners Lee (of WWW fame) first mentioned the semantic web in 1999 Mark Berners-Lee Tim; Fischetti. Weaving the web.\n  title:: Semantic Web\n\t- “I have a dream for the Web [in which computers] become capable of analyzing all the data on the Web – the content, links, and transactions between people and computers. A \"Semantic Web\", which makes this possible, has yet to emerge, but when it does, the day-to-day mechanisms of trade, bureaucracy and our daily lives will be handled by machines talking to machines. The \"intelligent agents\" people have touted for ages will finally materialize.”\n- Attention developed around three core themes, ubiquitous availability and searchability of data, intelligent search assistants, and highly available end points such as phones, and ‘internet of things’ devices. This is certainly manifesting in home devices, but few people think of this as a Web3 revolution. Since ratification of the standards by the World Wide Web (W3C) consortium it seems that their imperative toward decentralisation has become lost. Instead, it can be seen that Facebook, Amazon, Google, and Apple have a harmful oligopoly on users data (Sean S Costigan. World Without Mind:) ()Threat of Big Tech (Franklin Foer). 2018.)\n- This is at odds with Berners-Lee’s vision, and he has recently spoken out about this discrepancy, and attempted to refocus the media onto Web3.0.\n\t- It is worth taking a look at his software implementation called Solid, which is far more mindful of the sovereignty of user data. \n\t  “Solid is an exciting new project led by Prof. Tim Berners-Lee, inventor of the World Wide Web, taking place at MIT. The project aims to radically change the way Web applications work today, resulting in true data ownership as well as improved privacy. Solid (derived from \"social linked data\") is a proposed set of conventions and tools for building decentralized social applications based on Linked Data principles. Solid is modular and extensible and it relies as much as possible on existing W3C standards and protocols.”\n- Excitement around this kind of differentiated trust model, hinted at in ubiquitous availability of data (and implemented explicitly in Solid), has led to exploration of different paths by cryptographers, and this will be described later. For instance, one of the main developers of Solid, Carvelho, is now a leading developer and propotent of Nostr, another very interesting option which will be described later. This technology space is prolific, but still comparatively young and small.\n-\n- # Scrappy AI written section\n\t- ### 1.  **Decentralized Identifiers (DIDs)**\n\t- **Overview**: DIDs are a new type of identifier that enables verifiable, self-sovereign digital identities. DIDs are fully under the control of the DID subject, independent from any centralized registry, identity provider, or certificate authority.\n\t- **Use Cases**: DIDs are used in personal identity verification, secure communication, and in enabling individuals to directly own and control their digital identities.\n\t- ### 2.  **Solid (Social Linked Data)**\n\t- **Overview**: While WebID is a part of Solid, the broader Solid project itself deserves mention. Solid aims to reshape the web, allowing users to store their data in personal online data stores (PODs) and share them with applications and services they trust.\n\t- **Use Cases**: Solid enables users to maintain control over their data while using web applications for social networking, data storage, and personalized services without vendor lock-in.\n\t- ### 3.  **Verifiable Credentials (VCs)**\n\t- **Overview**: VCs are a standard for conveying claims about an identity in a way that is cryptographically secure, privacy-respecting, and machine-verifiable.\n\t- **Use Cases**: They are used in scenarios ranging from proving educational qualifications and professional certifications to identity verification online without revealing unnecessary personal information.\n\t- ### 4.  **Blockchain and Distributed Ledger Technology (DLT)**\n\t- **Overview**: Although not directly analogous to WebID, blockchain and DLTs provide the infrastructure for many decentralized identity systems. They offer a secure and immutable way to record transactions and manage identities without central control.\n\t- **Use Cases**: Blockchain technology is behind cryptocurrencies like Bitcoin but is also used for securing digital identities, supply chain management, and in creating decentralized applications (dApps).\n\t- ### 5.  **ActivityPub**\n\t- **Overview**: ActivityPub is a decentralized social networking protocol based on the ActivityStreams 2.0 data format. It provides a client-server API for creating, updating, and deleting content, as well as a federated server-to-server API for delivering notifications and content.\n\t- **Use Cases**: ActivityPub powers decentralized social networks like Mastodon, enabling them to interoperate and share data without a central authority.\n\t- ### 6.  **InterPlanetary File System (IPFS)**\n\t- **Overview**: IPFS is a protocol and peer-to-peer network for storing and sharing data in a distributed file system. IPFS uses content-addressing to uniquely identify each file in a global namespace connecting all computing devices.\n\t- **Use Cases**: IPFS is used for decentralized website hosting, secure file sharing, and as a foundational technology for various decentralized applications (dApps).\n\t- ### 7.  **OAuth and OpenID Connect (OIDC)**\n\t- **Overview**: While not decentralized, OAuth and OIDC are standards for authorization and identity verification across the web. They are widely used in web applications to allow users to log in with existing credentials from services like Google, Facebook, and Twitter.\n\t- **Use Cases**: OAuth and OIDC are used for secure authorization and identity verification across countless web services, providing a smoother user experience while managing access permissions.\n- # Intersection of Semantic and Ontological Knowledge with AI\n\t- overview of how semantic web technologies, ontologies, and knowledge graphs are being integrated with modern Large Language Models (LLMs), focusing on fine-tuning, Retrieval Augmented Generation (RAG), and large-context multi-shot learning.\n- **Knowledge Injection and Enhancement**\n\t- **Knowledge Graphs for LLM Pre-Training:** LLMs can be pre-trained on knowledge graphs or structured datasets incorporating ontologies, improving factual knowledge and reasoning abilities.\n\t\t- **Example:** K-BERT [1] pre-trained on a knowledge graph.\n\t- **Retrieval-Augmented Generation (RAG):** LLMs use knowledge graphs to retrieve relevant information and incorporate it into their responses.\n\t\t- **Examples:** RAG models [2], Realm [3]\n\t- **Ontologies for Fine-Tuning:** Ontologies can structure fine-tuning data and guide LLMs towards learning specific domain concepts and relations.\n- **Semantic Grounding and Reasoning**\n\t- **Formalizing Knowledge:** Ontologies provide a structured foundation for LLMs to represent and reason about concepts and relationships.\n\t\t- **Example:** Ontology-guided question answering and reasoning with LLMs [4]\n\t- **Improving Consistency:** Semantic technologies can help constrain LLM output to be more consistent with domain knowledge and logical rules defined in ontologies.\n\t- **Explainability:** The use of knowledge graphs and ontologies can contribute to more explainable LLM decisions by tracing the reasoning steps.\n- **Task Adaptation & Generalization**\n\t- **Semantic Transfer Learning:** Leveraging knowledge encoded in ontologies across different tasks and domains can improve LLM adaptability.\n\t- **Zero-Shot/Few-Shot Learning:** Knowledge graphs can support LLMs in learning new tasks with limited training examples by providing rich background knowledge.\n\t  \n\t  **Challenges and Open Research Areas**\n- **Scalability:** Integrating large-scale knowledge graphs with LLMs poses computational challenges, requiring efficient query and retrieval methods.\n- **Knowledge Representation Gaps:** Ensuring ontologies and knowledge graphs are comprehensive and accurately reflect real-world knowledge is an ongoing effort.\n- **Implicit vs. Explicit Knowledge Alignment:** Balancing LLMs' ability to learn implicit knowledge patterns from text with the explicit knowledge in ontologies and knowledge graphs.\n- **Evaluation:** Developing robust benchmarks and evaluation metrics to assess the effectiveness of semantic integration in LLMs.\n- **References**\n- **K-BERT: Enabling Language Representation with Knowledge Graph** (Liu et al., 2019) [[[https://arxiv.org/abs/1909.07606](https://arxiv.org/abs/1909.07606)]]([[https://arxiv.org/abs/1909.07606](https://arxiv.org/abs/1909.07606)])\n- **Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks** (Lewis et al., 2020). [[[https://arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)]]([[https://arxiv.org/abs/2005.11401](https://arxiv.org/abs/2005.11401)])\n- **REALM: Retrieval-Augmented Language Model Pre-Training** (Guu et al. 2020) [[[https://arxiv.org/abs/2002.08909](https://arxiv.org/abs/2002.08909)]]([[https://arxiv.org/abs/2002.08909](https://arxiv.org/abs/2002.08909)])\n- **Ontology-Guided Semantic Consistency Regularization for Zero-shot Learning** (Zhang et al. 2023) [[[https://arxiv.org/abs/2301.00416](https://arxiv.org/abs/2301.00416)]]([[https://arxiv.org/abs/2301.00416](https://arxiv.org/abs/2301.00416)])\n  \n  **Let me know if you want to dive deeper into a specific area or explore  additional references!**\n  \n  share\n  \n  more_vert\n  \n  ![profile picture](https://lh3.googleusercontent.com/a/ACg8ocLzn2xPZNE9iWDHK_VhFDTYlcKAl4vZRZUYGX9W0m3ZMO0a=s64-c)\n- Integrating Semantic Web, Knowledge Graphs, and Large Language Models\n- ## Foundations and Core Concepts\n- **Introduction to the Semantic Web**\n\t- History and motivation [1, 2]\n\t- Key Components: RDF, RDFS, OWL, SPARQL [3]\n\t- Knowledge Representation with Ontologies [4, 5]\n- **Knowledge Graphs**\n\t- Construction and Representation [6]\n\t- Applications in Industry (Google, Amazon, etc.) [7]\n\t- Knowledge Graph Embeddings [8]\n- **Large Language Models (LLMs)**\n\t- Architectures (Transformers, Attention) [9]\n\t- Pre-training, Fine-tuning, Prompting [10]\n\t  \n\t  **Seminar 2: Knowledge Injection and Enhancement in LLMs**\n- **Pre-training LLMs with Knowledge Structures**\n\t- K-BERT and variations [11, 12]\n\t- Challenges of knowledge consistency and updates [13]\n- **Retrieval-Augmented Generation (RAG) Models**\n\t- Overview of the RAG Framework [14]\n\t- Variations and Enhancements (REALM, etc.) [15, 16]\n\t- Knowledge Retrieval (Dense vs. Sparse) [17]\n- **Semantic Fine-tuning of LLMs**\n\t- Ontologies as guides [18]\n\t- Applications in domain-specific tasks [19]\n- ## Semantic Grounding, Reasoning, and Explainability**\n- **Ontology-Guided Question Answering and Reasoning**\n\t- Formalizing knowledge representations [20]\n\t- Techniques for inference and reasoning over LLMs and KGs [21]\n- **Logic and Constraints for LLMs**\n\t- Integrating rule-based systems and ontologies [22]\n\t- Challenges and potential of hybrid approaches [23]\n- **Explainable AI and the Role of Knowledge Graphs**\n\t- Tracing LLM decisions through ontologies [24]\n\t- Case studies in explainability [25]\n- ## Task Adaptation, Generalization, and Evaluation**\n- **Semantic Transfer Learning for LLMs**\n\t- Leveraging knowledge across domains [26]\n\t- Techniques for cross-domain adaptation [27]\n- **Zero-shot and Few-shot Learning with Knowledge Support**\n\t- Knowledge graphs as a source of background information [28]\n\t- Hybrid approaches combining implicit and explicit knowledge [29]\n- **Evaluation of Semantically-Enhanced LLMs**\n\t- Benchmarks beyond standard NLP tasks [30]\n\t- Measuring factual correctness and reasoning ability [31]\n- ## Open Challenges and Future Directions**\n- **Scalability and Computational Efficiency**\n\t- Large-scale knowledge graph integration [32]\n\t- Efficient query and retrieval methods [33]\n- **Aligning Implicit and Explicit Knowledge**\n\t- Bridging LLMs' learned patterns and ontological structures [34]\n\t- Techniques for continuous knowledge grounding [35]\n- **Applications in Specialized Domains**\n\t- Medicine, scientific research, legal domain [36, 37, 38]\n- **Ethical Considerations**\n\t- Fairness and bias in knowledge graphs [39]\n\t- Responsible and transparent use of semantic AI [40]\n- Berners-Lee, T., Hendler, J., & Lassila, O. (2001). The semantic web. Scientific american, 284(5), 34-43.\n- Shadbolt, N., Berners-Lee, T., & Hall, W. (2006). The semantic web revisited. IEEE intelligent systems, 21(3), 96-101.\n- W3C Standards: [https://www.w3.org/standards/semanticweb/](https://www.w3.org/standards/semanticweb/)\n- Gruber, T. R. (1993). A translation approach to portable ontology specifications. Knowledge acquisition, 5(2), 199-220.\n- Noy, N. F., & McGuinness, D. L. (2001). Ontology development 101: A guide to creating your first ontology. Stanford knowledge systems laboratory technical report KSL-01-05.\n- Ehrlinger, L., & Wöß, W. (2016). Towards a definition of knowledge graphs. SEMANTiCS (Posters, Demos, SuCCESS).\n- Hogan, A., Blomqvist, E., Cochez, M., d'Amato, C., Melo, G., Gutierrez, C., ... & Polleres, A. (2021). Knowledge graphs. arXiv preprint arXiv:2103.02421.\n- Wang, Q., Mao, Z., Wang, B., & Guo, L. (2017). Knowledge graph embedding: A survey of approaches and applications. IEEE Transactions on Knowledge and Data Engineering, 29(12), 2724-2743.\n- Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.\n- Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Amodei, D., ... & Amodei, D. (2020). Language models are few-shot learners. Advances in neural information processing systems, 33, 1877-1901.\n- Liu, W., Zhou, P., Zhao, Z., Wang, Z., Ju, Q., Deng, H., & Wang, P. (2020). K-bert: Enabling language representation with knowledge graph. In Proceedings of the AAAI Conference on Artificial Intelligence (Vol. 34, No. 03, pp. 2901-2908).\n- Peters, M. E., Neumann, M., Iyyer, M., Gardner, M., Clark, C., Lee, K., & Zettlemoyer, L. (2019). Deep contextualized word representations. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (pp. 2227-2237).\n- Yao, L., Mao, C., & Luo, Y. (2019). KG-BERT: BERT for knowledge graph completion. arXiv preprint arXiv:1909.03193.\n- Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., ... & Kiela, D. (2020). Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in Neural Information Processing Systems, 33, 9459-9474.\n- Guu, K., Lee, K., Tung, Z., Pasupat, P., & Chang, M. W. (2020). Realm: Retrieval-augmented language model pre-training. arXiv preprint arXiv:2002.08909.\n- ... (More examples of RAG variations)\n- Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., ... & Yih, W. T. (2020). Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906.",
        "link_types": [],
        "file_size": 15551
    },
    {
        "id": "AI Risks.md",
        "name": "AI Risks",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- Original chat\n\t- While I was doing my masters in ML in 2020 the term for [[safety and alignment]] was simply bias. Bias is a huge and potentially unsolvable problem at scale. You can actually revert to using bias and very quickly get to a terrifying outcome if you simply cast AI as a near ubiquitous data helper, that carries racism and sexism very deep inside. This already is an existential risk to people suffering wrongful prosecution. What Hinton clearly means by existential risk is risk to the rich.\n\t- AI already is capable of out producing humans on data, and that is also already a catastrophe for human data online, because of signal to noise. No mitigation possible.\n\t- The FOOM risk is unknown, likely unknowable and POSSIBLY not zero.\n\t- The branching tree of outcomes has something like 90 net negative end points for humans and only one positive, and that turns out to be \"the culture\"\n\t  We are doing virtually nothing to address, mitigate, plan for, or even discuss these things, outside of a few crackpot self help actuators. Also see Transhumanism, Singularitarians, Crypto-Anarchists, Biohackers/Grinders, Effective Altruists, Technotopians, AI Optimists/Pessimists, Quantified Self Movement, Affective Accelerationism. Many of whom are incredibly wealthy and influential nut jobs.\n\t- [The Rise of Techno-authoritarianism\n\t- The Atlantic](https://www.theatlantic.com/magazine/archive/2024/03/facebook-meta-silicon-valley-politics/677168/)\n\t- In return AI promises to be able to do our \"drudge work\": also see, sitting down type jobs.\n\t- Add in [[Cyber security and Cryptography]], [[Bio Terror]] , mass 3D printing of weapons, [[Cyber Security and Military]] fully autonomous killing machines, [[Death of the Internet]] and gated AI controlled communities, and you have pretty much nothing but dystopia all the way down.\n\t- Do I think about a dozen luny men should be in charge of the pack of stick on adjustments that align AI? Something they all agree they have no plan to actuate? GOD NO.\n\t- Am I determined not to be asleep at the wheel? Depends if I can even find a wheel tbh.\n\t-\n- Statistical engines which are very difficult not to anthropomorphise.\n\t- These incredibly profitable stacks are the product of surveillance capitalism.\n\t- Check meredith whittaker from signal for grounded risks. Regulation from below, and part of the [[Social contract and jobs]].\n\t- They didn't make these for the public good, they made them for profit, and these products entrench the surveillance capitalism abuse.\n\t- It is not being democratically or equitably distributed.\n\t- Natasha tiku at the post.\n\t- Main risk is actually the concentration of power in a few huge corporations\n\t- AI cultural imperialism. This is countered by national models like Falcon, Alibaba, Mistral. Interestingly the Economist brands this [the era of AI nationalism](https://www.economist.com/business/2024/01/01/welcome-to-the-era-of-ai-nationalism)\n\t-\n- Updated by gpt\n\t- **Bias in AI:** Represents a critical and stubborn issue. At scale, unchecked AI can perpetuate racism and sexism, leading to deeply entrenched societal problems. Vigilance and continuous improvement in AI ethics are required to prevent these outcomes.\n\t- **Data Overwhelm:** AI's ability to process information far exceeds human capacity, creating a deluge of data that threatens the quality and integrity of human knowledge. This \"signal-to-noise\" problem is not just an inconvenience; it's a critical challenge for information validity in the digital age.\n\t- **FOOM Risk:** The fear of rapid, uncontrollable advancements in AI (FOOM) presents a scenario of existential uncertainty. While its probability is debated, the potential consequences are so severe that they demand serious attention and preemptive planning.\n\t- **Dystopian Outcomes:** Considering the branching tree of potential futures, the overwhelming majority appear to lead to negative outcomes for humanity. This isn't a mere pessimistic view but a call to steer technology towards a singular, positive cultural and societal impact.\n\t- **Inaction and Fragmentation:** The current landscape of AI governance is a tapestry of competing ideologies and interests, from Transhumanists to Crypto-Anarchists. The lack of coherent and concerted action is alarming, given the stakes involved.\n\t- **The Automation Promise:** While AI promises to relieve us from drudgery, there's a thin line between utopian efficiency and a dystopian replacement of human roles. Ensuring AI serves to augment rather than replace is a delicate balance.\n\t- **Emerging Threats:** The confluence of AI with cybersecurity, bioterrorism, autonomous [[Cyber Security and Military]], and other technologies is a real and present danger, leading potentially to a dystopian future if not governed wisely.\n\t- **Governance Vacuum:** The idea that a small group of individuals could steer the course of AI, without a comprehensive plan or consensus, is deeply unsettling. The need for inclusive, wise, and proactive governance has never been more critical.\n-",
        "link_types": [
            "safety and alignment",
            "Cyber security and Cryptography",
            "Bio Terror",
            "Cyber Security and Military",
            "Death of the Internet",
            "Social contract and jobs",
            "Cyber Security and Military"
        ],
        "file_size": 5071
    },
    {
        "id": "multimodal.md",
        "name": "multimodal",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page automatically published\n- # OpenAI ChatGPT-4o (omni)\n  id:: 66446c0e-93be-431d-93d4-1e5fa36848c5\n\t- Free to use, for everyone! Not private by default.\n\t- True multi modality across video, images, and audio.\n\t- The first of the true publicly accessible models trained without compromise for multi-modality.\n\t- Multi-lingual across 50 languages, supporting image input and output, real time video input, text to 3D.\n\t- Empathetic voice to voice with very low latency.\n\t- [Min Choi on X: \"I used GPT-4o to create STL file for 3D model in ~ 20 seconds on my phone. Pretty remarkable what you can generate with AI and simple prompt now. https://t.co/2fbObrpPol\" / X (twitter.com)](https://twitter.com/minchoi/status/1790396782200987662)\n\t- {{twitter https://twitter.com/minchoi/status/1790396782200987662}}\n- # Google DeepMind Gemini\n\t- Gemini is a multimodal LLM capable of inputting and outputting text, understanding images, and generating images.\n\t- While specific architecture details are scarce, it represents a leap in LLMs interacting with multiple data types.\n- ### Multi-Modal Large Language Models (LLMs)\n\t- **Introduction:**\n\t\t- [[Large language models]] are adept at generating coherent text sequences, predicting word probabilities and co-occurrences.\n\t\t- Multimodal models extend LLMs capabilities to not just output text, but images and understand multimodal inputs.\n\t- **Core Concepts:**\n\t\t- **LLMs for Text:**\n\t\t\t- LLMs process prompts and generate replies one token at a time, acting as a multiclass classifier.\n\t\t- **Image Generation:**\n\t\t\t- Traditional pixel-by-pixel image generation is intractable; hence, a different approach is needed.\n\t\t\t- The solution is treating image generation as a language generation problem, akin to ancient hieroglyphics.\n\t- **Techniques in Multi-Modal LLMs:**\n\t\t- **Autoencoders:**\n\t\t\t- Compress images into a lower-dimensional latent space and then regenerate them, learning crucial properties.\n\t\t- **[[Variational Autoencoders]] (VAE) & VQ-VAE:**\n\t\t\t- VAEs add a generative aspect by allowing for new image generation from random latent embeddings.\n\t\t\t- VQ-VAE further discretizes this process, creating a vocabulary of image \"words\" or tokens.\n\t- **Implementation:**\n\t\t- **Vector Quantization:**\n\t\t\t- Creates a discrete set of embedding vectors forming the vocabulary for our image-based language.\n\t\t- **Encoding and Decoding:**\n\t\t\t- Images are encoded to these discrete codes and decoded back to form new or reconstructed images.\n\t- **Training and Inference:**\n\t\t- A mixed sequence of embeddings (words and image tokens) is created for training.\n\t\t- The model learns to generate image tokens, forming a coherent sequence with the text, allowing for the generation of images corresponding to text descriptions.\n\t- **Challenges and Developments:**\n\t\t- The importance of quality data over quantity, especially for large, complex models.\n\t\t- Ongoing efforts focus on refining data quality, applying safety measures, and improving model transparency.\n-\n- ```mermaid\n  flowchart LR\n  A[Text Input] -->|Processed by LLM| B[Text Tokens]\n  B -->|Alongside Image Tokens| D[Mixed Embeddings]\n  C[Image Input] -->|Encoded via VQ-VAE| E[Image Tokens]\n  E --> D\n  D -->|Next Token Prediction| F[Generated Sequence]\n  F -->|Decoded| G[Output Image & Text]\n  ```\n-\n- Some random links\n\t- Apple Ferret is a [[Multimodal]] [[Large language models]] from [[Apple]] that can understand and ground anything at any granularity [apple/ml-ferret (github.com)](https://github.com/apple/ml-ferret)\n\t- [THUDM/CogVLM: a state-of-the-art-level open visual language model | 多模态预训练模型 (github.com)](https://github.com/THUDM/CogVLM)\n\t- [moondream\n\t\t- a tiny vision language model](https://moondream.ai/)\n\t- Key Papers\n\t\t- [Variational Autoencoder (VAE)](https://arxiv.org/abs/1312.6114)\n\t\t- [Vector Quantized Variational Autoencoder (VQ-VAE)](https://arxiv.org/abs/1711.00937)\n\t\t- [Vector Quantized Generative Adversarial Network (VQ-GAN)](https://compvis.github.io/taming-transformers/)\n\t\t- [Gemini](https://assets.bwbx.io/documents/users/iqjWHBFdfxIU/rJRW6x8V4P0g/v0)\n\t\t- [Parti](https://sites.research.google/parti/)\n\t\t- [DallE](https://arxiv.org/pdf/2102.12092.pdf)\n\t\t- [2304.06939.pdf (arxiv.org)](https://arxiv.org/pdf/2304.06939.pdf) C4 model\n\t\t- [huggingface/OBELICS: Code used for the creation of OBELICS, an open, massive and curated collection of interleaved image-text web documents, containing 141M documents, 115B text tokens and 353M images. (github.com)](https://github.com/huggingface/OBELICS?tab=readme-ov-file)\n\t\t-\n\t\t-",
        "link_types": [
            "Large language models",
            "Variational Autoencoders",
            "Multimodal",
            "Large language models",
            "Apple"
        ],
        "file_size": 4601
    },
    {
        "id": "Evaluation and leaderboards.md",
        "name": "Evaluation and leaderboards",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- ![1719268663052.jpeg](../assets/1719268663052_1719301674255_0.jpeg)\n- [https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n- [https://huggingface.co/spaces/CultriX/Alt_LLM_LeaderBoard](https://huggingface.co/spaces/CultriX/Alt_LLM_LeaderBoard)\n- [https://huggingface.co/spaces/opencompass/open_vlm_leaderboard](https://huggingface.co/spaces/opencompass/open_vlm_leaderboard)\n- [https://tatsu-lab.github.io/alpaca_eval/](https://tatsu-lab.github.io/alpaca_eval/)\n- [https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard](https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard)\n- [https://huggingface.co/spaces/NPHardEval/NPHardEval-leaderboard](https://huggingface.co/spaces/NPHardEval/NPHardEval-leaderboard)\n- [https://paperswithcode.com/sota/code-generation-on-humaneval](https://paperswithcode.com/sota/code-generation-on-humaneval)\n- [https://evalplus.github.io/leaderboard.html](https://evalplus.github.io/leaderboard.html)\n- [https://eqbench.com/](https://eqbench.com/)\n- [https://ayumi.m8geil.de/](https://ayumi.m8geil.de/)",
        "link_types": [],
        "file_size": 1148
    },
    {
        "id": "Model Optimisation and Performance.md",
        "name": "Model Optimisation and Performance",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- ## Quantization in Machine Learning Models\n\t- ![image.png](../assets/image_1707150720702_0.png)\n\t-\n\t- ### Introduction\n\t\t- Quantization refers to the process of reducing the precision of the numbers that represent the weights and activations of a machine learning model without significantly reducing its accuracy.\n\t\t- It is a critical technique for deploying models on resource-constrained devices like mobile phones, embedded systems, and IoT devices.\n\t\t- [Quantization (huggingface.co)](https://huggingface.co/docs/transformers/main/quantization)\n\t- ### Benefits of Quantization\n\t\t- **Memory Efficiency**: Reduces the model size, enabling it to fit in the limited memory of small devices.\n\t\t- **Computational Efficiency**: Lower precision operations are faster and consume less power.\n\t\t- **Bandwidth Reduction**: Smaller models require less data to be transferred when downloaded or updated.\n\t- ### Strategies for Quantization\n\t\t- #### Sparsification\n\t - **Description**: Involves reducing the number of non-zero elements in the model's weights, effectively compressing the model.\n\t - **Techniques**:\n\t\t\t\t- Weight Pruning: Removing weights that have little impact on the output.\n\t\t\t\t- Structured Pruning: Removing entire channels or filters that are not contributing significantly to the model's performance.\n\t - **References**:\n\t\t\t\t- [The Lottery Ticket Hypothesis](https://arxiv.org/abs/1803.03635)\n\t\t- #### Removal of Least Significant Bits (LSB)\n\t - **Description**: This strategy involves truncating the least significant bits from the weights' binary representation.\n\t - **Approach**:\n\t\t\t\t- Fixed-Point Quantization: Converts floating-point numbers to fixed-point format, removing the least significant bits.\n\t\t\t\t- Dynamic Quantization: Adjusts the quantization parameters dynamically based on the distribution of the parameters.\n\t - **Benefits**:\n\t\t\t\t- Reduces the precision of weights with minimal impact on accuracy.\n\t\t\t\t- Simplifies the hardware implementation of mathematical operations.\n\t - **References**:\n\t\t\t\t- [Post-Training Quantization](https://www.tensorflow.org/lite/performance/post_training_quantization)\n\t\t- #### Uniform and Non-Uniform Quantization\n\t - **Uniform Quantization**:\n\t\t\t\t- Applies the same quantization step size across all values.\n\t\t\t\t- Easier to implement but might not be optimal for all distributions of model parameters.\n\t - **Non-Uniform Quantization**:\n\t\t\t\t- Adapts the quantization step size according to the distribution of the parameters.\n\t\t\t\t- Can achieve better accuracy for the same level of compression.\n\t - **References**:\n\t\t\t\t- [Mixed Precision Training](https://arxiv.org/abs/1710.03740)\n\t- ### Tools and Frameworks for Quantization\n\t\t- **TensorFlow Lite**: Provides tools for post-training quantization and quantization-aware training.\n\t - [TensorFlow Lite Guide](https://www.tensorflow.org/lite)\n\t\t- **PyTorch Quantization**: Supports dynamic quantization, static quantization, and quantization-aware training.\n\t - [PyTorch Quantization](https://pytorch.org/docs/stable/quantization.html)\n\t\t- **ONNX Runtime**: Offers support for quantized models, enabling optimized inference on different hardware.\n\t - [ONNX Runtime Quantization](https://onnxruntime.ai/docs/performance/quantization.html)\n\t- ### Challenges and Considerations\n\t\t- **Accuracy Trade-offs**: Finding the right balance between model size reduction and accuracy preservation.\n\t\t- **Hardware Compatibility**: Ensuring quantized models are compatible with the target hardware's instruction set.\n\t\t- **Quantization Granularity**: Deciding between per-layer, per-channel, or per-tensor quantization for optimal performance.\n\t- **Quantized Neural Networks (QNNs)**\n\t- **Goal:** Reduce model size without sacrificing accuracy.\n\t- **Concept:** Lower precision representation of weights and activations (e.g., from 32-bit floats to 8-bit integers).\n\t- ### Key Techniques\n\t- #### [Overview of GGUF quantization methods : LocalLLaMA (reddit.com)](https://www.reddit.com/r/LocalLLaMA/comments/1ba55rj/overview_of_gguf_quantization_methods/)\n\t- **Quantization:**\n\t\t- Rounding of weights and activations to lower precision representation.\n\t\t- **Example:**\n\t\t  \n\t\t  ```\n\t\t  Quantized Weight = Round(Original Weight / Scale)\n\t\t  ```\n\t- **Binary Quantization:**\n\t\t- Extremely aggressive quantization to binary values (1 or -1).\n\t\t- **Example:**\n\t\t  \n\t\t  ```\n\t\t  Binary Weight = Sign(Original Weight)\n\t\t  ```\n\t- **Ternary Quantization:**\n\t\t- Weights quantized to -1, 0, or 1.\n\t\t- Offers better information retention than binary quantization.\n\t- **Quantization-Aware Training (QAT):**\n\t\t- Integrate quantization effects into the training process for smoother transitions and less accuracy loss.\n\t\t  \n\t\t  **Quantization Schemes**\n\t- **Fixed-Point:** Quantization into fixed bit-width representations.\n\t- **Logarithmic:** Leverages logarithmic scale for wider dynamic range.\n\t- **Quantized Inference**\n\t- Running inference using the quantized model.\n\t- Often requires integer math operations, leading to computational efficiency gains.\n\t- **Dequantization:** Process of converting quantized output back to a familiar floating-point representation.\n\t-\n\t- ### Benefits of QNNs\n\t\t- **Smaller model sizes:** Ideal for memory-constrained devices.\n\t\t- **Faster inference:** Lower precision often leads to faster computations.\n\t\t- **Reduced power consumption:** Benefits embedded systems and mobile devices.\n\t\t- Mobile and edge devices\n\t\t- Real-time applications\n\t\t- Resource-constrained environments\n- ## Hyperparameter Tuning ([LinkedIn Thread](https://www.linkedin.com/posts/maryammiradi_machinelearning-ai-datascience-activity-7179427786799861760-WFtN/))\n\t- 𝐇𝐲𝐩𝐞𝐫𝐩𝐚𝐫𝐚𝐦𝐞𝐭𝐞𝐫 𝐎𝐩𝐭𝐢𝐦𝐢𝐳𝐚𝐭𝐢𝐨𝐧: 𝟏𝟎 𝐓𝐨𝐩 𝐏𝐲𝐭𝐡𝐨𝐧 𝐋𝐢𝐛𝐫𝐚𝐫𝐢𝐞𝐬 𝐟𝐨𝐫 𝐒𝐞𝐜𝐫𝐞𝐭 𝐈𝐧𝐠𝐫𝐞𝐝𝐢𝐞𝐧𝐭 𝐢𝐧 𝐌𝐚𝐜𝐡𝐢𝐧𝐞 𝐋𝐞𝐚𝐫𝐧𝐢𝐧𝐠 𝐒𝐮𝐜𝐜𝐞𝐬𝐬\n\t- Hyperparameter optimization plays a crucial role in determining the performance of a machine learning model. They are one the 3 components of training.\n\t- 𝟛 ℂ𝕠𝕞𝕡𝕠𝕟𝕖𝕟𝕥𝕤 𝕠𝕗 𝕄𝕠𝕕𝕖𝕝:\n\t- 1️⃣ Training data: Training data is what the algorithm leverages (think: instructions to build a model) to identify patterns\n\t- 2️⃣ Parameters: Algorithm 'learns' by adjusting parameters, such as weights, based on training data to make accurate predictions, which are saved as part of the final model.\n\t- 3️⃣ Hyperparameters: Hyperparameters are variables that regulate the process of training and are constant during the training process.\n\t- 𝔻𝕚𝕗𝕗𝕖𝕣𝕖𝕟𝕥 𝕋𝕪𝕡𝕖𝕤 𝕠𝕗 𝕊𝕖𝕒𝕣𝕔𝕙:\n\t- 🔎Grid Search : Training models with every possible combination of the provided hyperparameter values a time-consuming process.\n\t- 🔎Random Search: Training models with randomly samples hyperparameter values from the defined distributions, a more effective search.\n\t- 🔎 Having Grid Search: Training models with all values, and then repeatedly \"halving\" the search space by only considering the parameter values that performed the best in the previous round.\n\t- 🔎 Bayesian Search: Starting with an initial guess of values, using performance of the model to the values. It's like how a detective might start with a list of suspects, then use new information to narrow down the list.\n\t- I found these 𝟏𝟎 𝐩𝐲𝐭𝐡𝐨𝐧 𝐥𝐢𝐛𝐫𝐚𝐫𝐢𝐞𝐬 𝐟𝐨𝐫 𝐇𝐲𝐩𝐞𝐫𝐩𝐚𝐫𝐚𝐦𝐞𝐭𝐞𝐫 𝐎𝐩𝐭𝐢𝐦𝐢𝐳𝐚𝐭𝐢𝐨𝐧:\n\t- 📚 Optuna\n\t- You can tune estimators of almost any ML, DL package/framework, including Sklearn, PyTorch, TensorFlow, Keras, XGBoost, LightGBM, CatBoost, etc with a real-time Web Dashboard called optuna-dashboard.\n\t- 📚Hyperopt\n\t- Optimizing using Bayesian optimization, including conditional dimensions.\n\t- 📚 Scikit-learn\n\t- different searches such as GridSearchCV or HalvingGridSearchCV.\n\t- 📚 Auto-Sklearn\n\t- AutoML and a drop-in replacement for a scikit-learn estimator.\n\t- 📚 Hyperactive\n\t- Very easy to learn but extremly versatile providing intelligent optimization.\n\t- 📚 Optunity\n\t- Provides distinct approaches such plethora of score functions.\n\t- 📚 HyperparameterHunter\n\t- Automatic save/learn from Experiments for persistent optimization\n\t- 📚 MLJAR\n\t- AutoML creating Markdown reports from ML pipeline\n\t- 📚 KerasTuner\n\t- with Bayesian Optimization, Hyperband, and Random Search algorithms built-in\n\t- 📚 Talos\n\t- Hyperparameter Optimization for TensorFlow, Keras and PyTorch\n\t- Extra:\n\t- 📚 Sweeps\n\t- 📚 Scikit-optimize\n\t- 📚 PyCaret\n\t- ![No alternative text description for this image](https://media.licdn.com/dms/image/D4E22AQHw_nWSZpbsyQ/feedshare-shrink_800/0/1711708970372?e=1714608000&v=beta&t=ZQCj26yY9vyZLbOegFQ97DYGWAmZno_65zrwVm31X5g)\n\t-\n- [The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction\n\t - Microsoft Research](https://www.microsoft.com/en-us/research/publication/the-truth-is-in-there-improving-reasoning-in-language-models-with-layer-selective-rank-reduction/)\n\t- [pratyushasharma/laser: The Truth Is In There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction (github.com)](https://github.com/pratyushasharma/laser)\n- [huggingface/optimum-nvidia (github.com)](https://github.com/huggingface/optimum-nvidia)\n- [[width=0.06]./figs/logo EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty (arxiv.org)](https://arxiv.org/pdf/2401.15077.pdf)\n- [run-ai/llmperf (github.com)](https://github.com/run-ai/llmperf) Tensor vs serving frameworks\n- [[Bitnet and the rise of the 1bit model]]\n\t- [The Dawn of 1-Bit Large Language Models (substack.com)](https://emsime.substack.com/p/the-dawn-of-1-bit-large-language)\n\t- [[2402.17764] The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits (arxiv.org)](https://arxiv.org/abs/2402.17764)\n\t- [Advancing AI for humanity | Foundation of AI (thegenerality.com)](https://thegenerality.com/agi/)\n\t-",
        "link_types": [
            "Bitnet and the rise of the 1bit model"
        ],
        "file_size": 10270
    },
    {
        "id": "Metaverse and Spatial Risks.md",
        "name": "Metaverse and Spatial Risks",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n-\n- Metaverse is fraught with risks, partly because it’s new, and partlybecause of the pace of adoption. Regulation is well behind thetechnology, to the alarm of some academicobservers.[[rosenberg2022regulation]]\n-\n\t - Abuse; because of the real-time and spatio-temporal abuse happens less like in the current web 2 social media, and more like in the real world, but with less opportunity for repercussions. It might be that natural language processing and machine learning can help with this, but it’s a tough problem. One idea might be to record the speech to text of interactions between participants, and flag to them if a “bullying, harassment, predation threshold” is met. This could be encrypted with the public keys of the participants and a notice sent to them that if they wished to follow up with authorities then they have the necessary attestations and proofs. This is minimally invasive and privacy preserving, and acts as a strong disincentive to repeat offence. It can also feed into a global “web of trust” reputation system in a ‘zero knowledge’ way. Users who flag abuse to the reputation system can leverage the machine learning opinion without revealing what happened (though they would have the data). This would also act as a disincentive without the social stigma issues of reporting.\n- Reporting could be achieved without machine learning identification of potential problems, but there would have to be a social cost to reporting (like gossiping incessantly about others) which would erode the social score of the reporting entity. This would mitigate bot based reputation harm.\n-\n\t - Miscommunication; which as we have seen in the early section of the metaverse chapter is both complex and hard to mitigate\n-\n\t - Lost information\n-\n\t - Distraction\n-\n\t - Jitter, judder, jagginess, and interruption of flow; because the network overhead is higher than other communication media it’s much more exposed to latency effects\n-\n\t - Physical harms, especially to developing brains and ocular systems\n- The UK is [positioning itself](https://bills.parliament.uk/bills/3137)to heavily regulate safeguarding in the space, with significant fines for non-compliance. This will of course simply lead to users operating on platforms which are not subject to UK law.  [some links on consumerprotection](https://dataethics.eu/the-three-ms-of-the-metaverse/)",
        "link_types": [
            "rosenberg2022regulation"
        ],
        "file_size": 2443
    },
    {
        "id": "IPAdapter.md",
        "name": "IPAdapter",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- #Public page\n\t - automatically published\n- From [ip-adapter.github.io /](https://ip-adapter.github.io/)\n- # IP-Adapter: Text Compatible Image Prompt Adapter for Text-to-Image Diffusion Models\n\t- Hu Ye Jun Zhang Sibo Liu Xiao Han Wei Yang Tencent AI Lab4-5 minutes\n\t  \n\t  ---\n\t  \n\t  ![](https://ip-adapter.github.io/assets/fig0.jpg){:height 430, :width 1159}\n- ### *Various image synthesis with our proposed IP-Adapter applied on the pretrained text-to-image diffusion model and additional structure controller.*\n  \n  [[Paper]](https://arxiv.org/abs/2308.06721)      [[Code]](https://github.com/tencent-ailab/IP-Adapter)      [[BibTeX]](https://ip-adapter.github.io/files/bibtex.txt)\n- ## Abstract\n  \n  Recent years have witnessed the strong power of large text-to-image diffusion models for the impressive generative capability to create high-fidelity images. But, it is very tricky to generate desired images using only text prompt as it often involves complex prompt engineering. An alternative to text prompt is image prompt, as the saying goes: \"an image is worth a thousand words\". Although existing methods of direct fine-tuning from pretrained models are effective, they require large computing resources and are not compatible with other base models, text prompt, and structural controls. In this paper, we present IP-Adapter, an effective and lightweight adapter to achieve image prompt capability for the pretrained text-to-image diffusion models. The key design of our IP-Adapter is decoupled cross-attention mechanism that separates cross-attention layers for text features and image features. Despite the simplicity of our method, an IP-Adapter with only 22M parameters can achieve comparable or even better performance to a fine-tuned image prompt model. As we freeze the pretrained duffusion model, the proposed IP-Adapter can be generalized not only to other custom models fine-tuned from the same base model, but also to controllable generation using existing controllable tools. With the benefit of the decoupled cross-attention strategy, the image prompt can also work well with the text prompt to accomplish multimodal image generation.\n- ## Approach\n  \n  The image prompt adapter is designed to enable a pretrained text-to-image diffusion model to generate images with image prompt. The proposed IP-Adapter consists of two parts: a image encoder to extract image features from image prompt, and adapted modules with decoupled cross-attention to embed image features into the pretrained text-to-image diffusion model.\n  \n  ![](https://ip-adapter.github.io/assets/fig1.png)\n- ## Comparison with Existing Methods\n  \n  The comparison of our proposed IP-Adapter with other methods conditioned on different kinds and styles of images.\n  \n  ![](https://ip-adapter.github.io/assets/result1.jpg)\n- ## More Results\n  \n  **Generalizable to Custom Models**\n  \n  Once the IP-Adapter is trained, it can be directly reusable on custom models fine-tuned from the same base model.\n  \n  ![](https://ip-adapter.github.io/assets/result2.jpg)\n  \n  **Structure Control**\n  \n  The IP-Adapter is fully compatible with existing controllable tools, e.g., ControlNet and T2I-Adapter.\n  \n  ![](https://ip-adapter.github.io/assets/result3.jpg)\n  \n  Our method not only outperforms other methods in terms of image quality, but also produces images that better align with the reference image.\n  \n  ![](https://ip-adapter.github.io/assets/result4.jpg)\n  \n  **Image-to-Image and Inpainting**\n  \n  Image-guided image-to-image and inpainting can be also achieved by simply replacing text prompt with image prompt.\n  \n  ![](https://ip-adapter.github.io/assets/result5.jpg)\n  \n  **Multimodal Prompt**\n  \n  Due to the decoupled cross-attention strategy, image prompt can work together with text prompt to realize multimodal image generation.\n  \n  ![](https://ip-adapter.github.io/assets/result6.jpg)\n  \n  Compared with other existing methods, our method can generate superior results in both image quality and alignment with multimodal prompts.\n  \n  ![](https://ip-adapter.github.io/assets/result7.jpg)\n-",
        "link_types": [
            "Paper",
            "Code",
            "BibTeX"
        ],
        "file_size": 4117
    },
    {
        "id": "Upscaling.md",
        "name": "Upscaling",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\nid:: 65cbd03a-f9a8-4ed4-83d5-fcd7b6855282\n\t - CSSR [[ComfyUI]] SOTA  [workflow for upscale](https://discord.com/channels/1076117621407223829/1196177599244812468/1196177599244812468)\n\t- [ccsr_creative_upscale.json](../assets/ccsr_creative_upscale_1706648180350_0.json)\n\t- Might have to install from github [kijai/ComfyUI-CCSR: ComfyUI wrapper node for CCSR (github.com)](https://github.com/kijai/ComfyUI-CCSR)\n- [kijai/ComfyUI-SUPIR: SUPIR upscaling wrapper for ComfyUI (github.com)](https://github.com/kijai/ComfyUI-SUPIR)\n\t- [SUPIR: Best Stable Diffusion Super Resolution Upscaler + full workflow. (youtube.com)](https://www.youtube.com/watch?v=Q9y-7Nwj2ic)\n\t  id:: 65e4a38d-8489-471b-a4b5-77cc867f3299\n\t- [(2) SUPIR v2 nodes from Kijai are available on manager, and they look brilliant! : comfyui (reddit.com)](https://www.reddit.com/r/comfyui/comments/1bh07ke/supir_v2_nodes_from_kijai_are_available_on/)\n\t- https://medium.com/@yushantripleseven/supir-image-restoration-cd4f409ccd34#3b78\n\t-\n\t-\n- [OpenModelDB](https://openmodeldb.info/)\n\t- [Civitai's Guide to Image Upscaling!\n\t - Civitai Education](https://education.civitai.com/civitais-guide-to-image-upscaling/#upscaling-with-comfyui)\n\t-",
        "link_types": [
            "ComfyUI"
        ],
        "file_size": 1208
    },
    {
        "id": "Diffusion Models.md",
        "name": "Diffusion Models",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n",
        "link_types": [],
        "file_size": 14
    },
    {
        "id": "Cashu.md",
        "name": "Cashu",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n\t- #Public page automatically published\n- ## Introduction to Cashew\n\t- Cashew is a protocol designed for facilitating Bitcoin banking operations. It leverages the concept of blinded servers to enhance privacy, allowing for the secure issuance and management of electronic cash (ecash) notes.\n\t- [Cashu workshop YouTube](https://www.youtube.com/watch?v=xfYmwc-gnK8)\n\t- ![video_2024-04-18_16-47-14.mp4](../assets/video_2024-04-18_16-47-14_1713458378752_0.mp4)\n- [twitter link to the render loading below](https://twitter.com/callebtc/status/1777598819355496587)\n  {{twitter https://twitter.com/callebtc/status/1777598819355496587}}\n\t-\n\t- ## References and Resources\n\t- Direct users to important resources for deeper exploration and troubleshooting:\n\t- [Cashew Documentation:](https://cashu.space/)\n\t- [Cashew GitHub Repository](https://github.com/cashubtc)\n\t- [Get started with eNuts](https://www.enuts.cash/get-started)\n\t- [Cashu Token Decoder (nostrapps.github.io)](https://nostrapps.github.io/cashu/)\n\t-\n- # Workshop stuff\n\t- ## Prerequisites\n\t\t- Before beginning, ensure you have:\n\t\t\t- A modern web browser for testing your wallet.\n\t\t\t- A text editor or IDE (e.g., Visual Studio Code, Sublime Text) for writing and editing code.\n\t\t\t- Access to the internet to fetch resources and documentation from the Cashew GitHub repository.\n\t- ## Setup Environment\n\t\t- ### Create Project Directory\n\t\t\t- Make a new folder on your computer named `cashew_wallet`.\n\t\t- ### Initialize Project File\n\t\t\t- Inside this folder, create a file named `index.html`.\n\t\t\t- Open `index.html` in your preferred code editor.\n\t\t\t- Set up a basic HTML skeleton with the `<html>`, `<head>`, and `<body>` tags.\n\t- ## Implementing Cashew Functionality\n\t\t- ### Wallet Interface Setup\n\t\t\t- Add basic HTML to create buttons for sending and receiving ecash.\n\t\t\t- Example:\n\t\t\t  ```html\n\t\t\t  <button id=\"sendBtn\">Send eCash</button>\n\t\t\t  <button id=\"receiveBtn\">Receive eCash</button>\n\t\t\t  ```\n\t\t- ### Fetching Keysets from Cashew Mint\n\t\t\t- Use JavaScript to asynchronously fetch the list of available keysets from the Cashew mint's API.\n\t\t\t- This step is crucial for understanding which denominations of ecash your wallet can handle.\n\t\t\t- Example API call: `fetch('https://cashew-mint.example/api/keysets').then(response => response.json())`\n\t\t- ### Generating a Secret for Blind Signatures\n\t\t\t- Implement JavaScript code to generate a new secret key. This key will be essential for creating blind signatures, a cornerstone of Cashew's privacy features.\n\t\t\t- Utilize cryptographic libraries available in JavaScript for secure key generation.\n\t\t- ### Creating and Paying a Lightning Invoice\n\t\t\t- Generate a lightning invoice for depositing Bitcoin into your Cashew wallet. This involves interacting with the Cashew mint to issue the invoice.\n\t\t\t- Implement a function to check the payment status of the invoice, waiting for confirmation before proceeding.\n\t\t- ### Requesting a Blinded Signature from the Mint\n\t\t\t- Once the invoice payment is confirmed, request a blinded signature for a specified ecash amount from the mint. This signature is necessary for the mint to acknowledge your ecash holdings without compromising privacy.\n\t\t- ### Unblinding the Signature\n\t\t\t- Use the previously generated secret key to unblind the mint's signature. This process converts the blinded signature into a form usable for transactions while maintaining the integrity of the privacy guarantees.\n\t\t- ### Sending and Receiving Ecash\n\t\t\t- #### Sending Ecash\n\t\t\t\t- Create functionality to allow users to send ecash by generating a transaction (nut) with the unblinded signature and a specified amount.\n\t\t\t\t- Include input fields for the recipient's address and the amount to be sent.\n\t\t\t- #### Receiving Ecash\n\t\t\t\t- Implement the ability to receive ecash by processing transactions from others. Validate these transactions with the Cashew mint to ensure they have not been double-spent.\n\t- ## Advanced Features (Optional)\n\t\t- Expand upon the basic wallet functionality by exploring advanced features such as:\n\t\t\t- Supporting transactions of multiple ecash denominations.\n\t\t\t- Implementing a withdrawal feature to convert ecash back into Bitcoin.\n\t\t\t- Adding multisig capabilities for enhanced security.\n-",
        "link_types": [],
        "file_size": 4261
    },
    {
        "id": "Machine Learning.md",
        "name": "Machine Learning",
        "position": [
            0,
            0,
            0
        ],
        "weight": 1.0,
        "velocity": [
            0,
            0,
            0
        ],
        "pinned": false,
        "block_content": "public:: true\n\n- # Useful papers\n\t- ### F o u n d a t i o n a l   C o n c e p t s\n\t  \n\t  **1. The Annotated Transformer (2017):** This paper explains the Transformer architecture, a groundbreaking model that revolutionized natural language processing (NLP). It introduced the attention mechanism, allowing the model to focus on relevant parts of the input sequence, leading to significant improvements in machine translation and other NLP tasks.\n\t  \n\t  **2. The First Law of Complexodynamics (2008):** This paper introduces a framework for understanding complex systems, arguing that complexity increases initially but eventually reaches a peak and then decreases. This framework is relevant for understanding the evolution of AI models and the challenges of managing their complexity.\n\t  \n\t  **3. The Unreasonable Effectiveness of RNNs (2015):** This paper explores the surprising success of Recurrent Neural Networks (RNNs) in various tasks, highlighting their ability to model sequential data and their role in natural language understanding and generation.\n\t  \n\t  **4. Understanding LSTM Networks (2015):** This paper delves into Long Short-Term Memory (LSTM) networks, a specific type of RNN that excels at capturing long-range dependencies in sequences. It explains the internal mechanisms of LSTMs and their key advantages.\n\t  \n\t  **5. Recurrent Neural Network Regularization (2014):** This paper focuses on techniques for preventing overfitting in RNNs, addressing a critical issue in deep learning. It explores various regularization methods, including dropout and weight decay, which enhance the generalizability of RNN models.\n\t  \n\t  **6. Keeping Neural Networks Simple by Minimizing the Description Length of the Weights (2014):** This paper proposes a novel approach to model simplification by minimizing the description length of the weights. It explores the connection between model complexity and generalization performance, offering valuable insights for building more efficient and robust neural networks.\n\t  \n\t  **7. Pointer Networks (2015):** This paper introduces Pointer Networks, a neural architecture specifically designed for tasks involving selecting elements from a given input set. These networks are particularly useful in tasks like machine reading comprehension and code generation.\n\t  \n\t  **8. ImageNet Classification with Deep CNNs (2012):** This seminal paper describes AlexNet, one of the first successful deep convolutional neural networks (CNNs) for image classification. It demonstrated the power of deep learning for computer vision, marking a major turning point in the field.\n\t  \n\t  **9. Order Matters: Sequence to Sequence for Sets (2016):** This paper explores the application of sequence-to-sequence (seq2seq) models for handling sets of data, where the order of elements doesn't matter. It proposes strategies for incorporating set information into seq2seq models, enhancing their capabilities for various tasks.\n\t  \n\t  **10. GPipe: Efficient Training of Giant Neural Networks (2018):** This paper introduces GPipe, a distributed training framework for scaling up neural network training on multiple GPUs. It allows researchers to train larger models more efficiently, pushing the boundaries of deep learning capabilities.\n\t  \n\t  **11. Deep Residual Learning for Image Recognition (2015):** This paper presents the ResNet architecture, which uses residual connections to facilitate the training of very deep networks. It demonstrated the effectiveness of residual learning for overcoming the vanishing gradient problem, leading to significant improvements in image recognition performance.\n\t  \n\t  **12. Multi-Scale Context Aggregation by Dilated Convolutions (2015):** This paper introduces dilated convolutions, a technique for expanding the receptive field of CNNs without increasing the number of parameters. It enables the network to capture information from a larger area, improving its ability to understand complex visual patterns.\n\t  \n\t  **13. Neural Quantum Chemistry (2017):** This paper explores the application of neural networks in quantum chemistry, a field traditionally dominated by computationally expensive methods. It shows how neural networks can be used to predict molecular properties, potentially revolutionizing the field.\n\t  \n\t  **14. Attention Is All You Need (2017):** This paper further develops the Transformer architecture, emphasizing the importance of the attention mechanism. It proposes a model that solely relies on attention, achieving state-of-the-art results in machine translation, demonstrating the power and flexibility of attention.\n\t  \n\t  **15. Neural Machine Translation by Jointly Learning to Align and Translate (2014):** This paper describes the original seq2seq model for machine translation, introducing the concept of jointly learning alignment and translation. It set the stage for the development of more sophisticated models like the Transformer.\n\t  \n\t  **16. Identity Mappings in Deep Residual Networks (2016):** This paper explores the effectiveness of identity mappings in ResNet, demonstrating their role in improving the performance of deep networks. It highlights the importance of understanding the role of different architectural components.\n\t  \n\t  **17. A Simple NN Module for Relational Reasoning (2017):** This paper introduces a simple neural network module for relational reasoning, enabling the model to reason about relationships between entities. It opens up new possibilities for tackling complex reasoning tasks in NLP and other domains.\n\t  \n\t  **18. Variational Lossy Autoencoder (2013):** This paper proposes a variational approach to building autoencoders, allowing for a more efficient and robust representation of data. It explores the connection between variational inference and deep learning, offering new insights into the theoretical foundations of these models.\n\t  \n\t  **19. Relational RNNs (2015):** This paper explores the application of RNNs to relational data, where relationships between entities play a crucial role. It presents a novel architecture for relational RNNs, enabling them to effectively handle data with complex relationships.\n\t  \n\t  **20. Quantifying the Rise and Fall of Complexity in Closed Systems (2008):** This paper expands on the \"First Law of Complexodynamics,\" providing a mathematical framework for understanding the emergence and decline of complexity in closed systems. It offers valuable insights into the dynamics of complex systems, including AI systems.\n\t  \n\t  **21. Neural Turing Machines (2014):** This paper introduces the concept of Neural Turing Machines (NTMs), which combine neural networks with external memory modules, allowing them to store and access information like a traditional Turing machine. NTMs represent a step towards more powerful AI models with increased memory capacity and reasoning abilities.\n\t  \n\t  **22. Deep Speech 2: End-to-End Speech Recognition in English and Mandarin (2015):** This paper presents Deep Speech 2, a deep learning-based speech recognition system that achieves state-of-the-art performance. It demonstrates the power of deep learning for tackling complex tasks like speech recognition, opening up new possibilities for human-computer interaction.\n\t  \n\t  **23. Scaling Laws for Neural Language Models (2020):** This paper investigates the relationship between model size, training data size, and performance in large language models (LLMs). It reveals power law scaling laws, suggesting that increasing model size and data can lead to dramatic performance improvements.\n\t  \n\t  **24. A Tutorial Introduction to the Minimum Description Length Principle (2002):** This paper provides a thorough introduction to the Minimum Description Length (MDL) principle, a fundamental principle in information theory and model selection. It explains how MDL can be used to select the best model from a set of candidates, balancing model complexity and predictive accuracy.\n\t  \n\t  **25. Machine Super Intelligence Dissertation (2014):** This dissertation explores the potential for and dangers of developing superintelligent AI, highlighting the importance of aligning AI goals with human values. It presents a framework for understanding and managing the risks associated with advanced AI.\n\t  \n\t  **26. PAGE 434 onwards: Komogrov Complexity (2009):** This document introduces Kolmogorov complexity, a measure of the complexity of an object. It discusses the limitations of computable complexity and the potential for using it to understand the complexity of AI systems.\n\t  \n\t  **27. CS231n Convolutional Neural Networks for Visual Recognition (2016):** This Stanford course provides a comprehensive introduction to convolutional neural networks (CNNs), covering their architecture, training, and applications in computer vision. It's a great resource for anyone wanting to learn more about this foundational topic in deep learning.\n\t  \n\t  **28. On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? (2021):** This paper raises critical concerns about the potential dangers of large language models (LLMs), emphasizing the need for ethical considerations and responsible development. It highlights the risks of bias, misinformation, and misuse of these powerful models.\n\t- ### Key LLM Papers\n\t  \n\t  **GPT-1 (2018):** This paper introduces the first version of Generative Pre-trained Transformer (GPT), a generative model trained on a massive dataset of text. It demonstrates the ability of LLMs to generate coherent and grammatically correct text, paving the way for future advancements.\n\t  \n\t  **GPT-2 (2019):** This paper presents a significantly larger GPT model with improved capabilities. It showcases the ability of LLMs to perform various language tasks, including text summarization, question answering, and even code generation.\n\t  \n\t  **GPT-3 (2020):** This paper introduces GPT-3, a truly massive LLM with billions of parameters. It demonstrates impressive capabilities in diverse tasks, showcasing the emergence of general-purpose language abilities.\n\t  \n\t  **GPT-4 (2023):** This paper introduces the latest iteration of GPT, featuring multi-modal capabilities and advanced reasoning abilities. It further pushes the boundaries of what LLMs can achieve, demonstrating impressive performance in a wide range of tasks.\n\t  \n\t  **Llama-2 (2023):** This paper introduces Llama-2, a large language model designed with a focus on efficiency and accessibility. It offers a more resource-friendly alternative to other LLMs, making it more accessible for research and development.\n\t  \n\t  **Tools (2023):** This paper introduces the \"Tools\" paradigm for LLMs, allowing them to interact with external tools and resources. It enables LLMs to perform more complex tasks by leveraging the power of external tools, expanding their capabilities significantly.\n\t  \n\t  **Gemini-Pro-1.5 (2023):** This paper introduces Gemini-Pro-1.5, a large language model developed by Google. It showcases impressive capabilities in various tasks, including code generation, creative writing, and reasoning. It's a strong contender in the race for developing advanced LLMs.\n\t- ### Ng's Agentic Patterns Series\n\t  \n\t  This series of papers explores the concept of agentic patterns in AI, focusing on the development of agents capable of independent learning and goal-directed behavior. It delves into the principles and design of such agents, offering valuable insights into the future of AI and its potential impact on society.\n\t-\n-\n-\n- Building recommenders, [recommenders-team/recommenders: Best Practices on Recommendation Systems (github.com)](https://github.com/recommenders-team/recommenders)\n- [ML Blocks | Home](https://www.mlblocks.com/) is machine learning vision lego\n-",
        "link_types": [],
        "file_size": 13286
    }
]